{"citeStart": 141, "citeEnd": 159, "citeStartToken": 141, "citeEndToken": 159, "sectionName": "UNKNOWN SECTION NAME", "string": "In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation (Brown et al., 1993; Brown et al., 1991; Church, 1993; Simard et al., 1992) , large amount of human effort and time has been invested in collecting parallel corpora of translated texts. Our goal is to alleviate this effort and enlarge the scope of corpus resources by looking into monolingual, comparable texts. This type of texts are known as nonparallel corpora. Such nonparallel, monolingual texts should be much more prevalent than parallel texts. However, previous attempts at using nonparallel corpora for terminology translation were constrained by the inadequate availability of same-domain, comparable texts in electronic form. The type of nonparallel texts obtained from the LDC or university libraries were often restricted, and were usually out-of-date as soon as they became available. For new word translation, the timeliness of corpus resources is a prerequisite, so is the continuous and automatic availability of nonparallel, comparable texts in electronic form. Data collection effort should not inhibit the actual translation effort. Fortunately, nowadays the World Wide Web provides us with a daily increase of fresh, up-to-date multilingual material, together with the archived versions, all easily downloadable by software tools running in the background. It is possible to specify the URL of the online site of a newspaper, and the start and end dates, and automatically download all the daily newspaper materials between those dates.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It remains to be seen how we can also make use of the multilingual texts as NLP resources.", "mid_sen": "In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation (Brown et al., 1993; Brown et al., 1991; Church, 1993; Simard et al., 1992) , large amount of human effort and time has been invested in collecting parallel corpora of translated texts. ", "after_sen": "Our goal is to alleviate this effort and enlarge the scope of corpus resources by looking into monolingual, comparable texts. "}
{"citeStart": 0, "citeEnd": 11, "citeStartToken": 0, "citeEndToken": 11, "sectionName": "UNKNOWN SECTION NAME", "string": "Since our experiments, other related work in NLP has been performed. Some of this work addresses related but different classification tasks. Three studies classify reviews as positive or negative (Turney 2002; Pang, Lee, and Vaithyanathan 2002; Dave, Lawrence, Pennock 2003) . The input is assumed to be a review, so this task does not include finding subjective documents in the first place. The first study listed above (Turney 2002) uses a variation of the semantic similarity procedure presented in Wiebe (2000) (Section 3.4). The third (Dave, Lawrence, and Pennock 2003) uses ngram features identified with a variation of the procedure presented in (Section 3.3) . Tong (2001) addresses finding sentiment timelines, that is, tracking sentiments over time in multiple documents. For clues of subjectivity, he uses manually developed lexical rules, rather than automatically learning them from corpora. Similarly, Gordon et al. (2003) use manually developed grammars to detect some types of subjective language. Agrawal et al. (2003) partition newsgroup authors into camps based on quotation links. They do not attempt to recognize subjective language.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The third (Dave, Lawrence, and Pennock 2003) uses ngram features identified with a variation of the procedure presented in (Section 3.3) . ", "mid_sen": "Tong (2001) addresses finding sentiment timelines, that is, tracking sentiments over time in multiple documents. ", "after_sen": "For clues of subjectivity, he uses manually developed lexical rules, rather than automatically learning them from corpora. "}
{"citeStart": 148, "citeEnd": 165, "citeStartToken": 148, "citeEndToken": 165, "sectionName": "UNKNOWN SECTION NAME", "string": "We used the direct output of the 42-topic model of the 105th-108th Senates from (Quinn et al., 2006) to further divide the speech documents into topic clusters. In their paper, they use a model where the probabilities of a document belonging to a certain topic varies smoothly over time and the words within a given document have exactly the same probability of being drawn from a particular topic. These two properties make the model different than standard mixture models (McLachlan and Peel, 2000) and the latent Dirichlet allocation model of (Blei et al., 2003) . The model of (Quinn et al., 2006) is most closely related to the model of (Blei and Lafferty, 2006) , who present a generalization of the model used by (Quinn et al., 2006) . Table 1 lists the 42 topics and their related committees.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In their paper, they use a model where the probabilities of a document belonging to a certain topic varies smoothly over time and the words within a given document have exactly the same probability of being drawn from a particular topic. ", "mid_sen": "These two properties make the model different than standard mixture models (McLachlan and Peel, 2000) and the latent Dirichlet allocation model of (Blei et al., 2003) . ", "after_sen": "The model of (Quinn et al., 2006) is most closely related to the model of (Blei and Lafferty, 2006) , who present a generalization of the model used by (Quinn et al., 2006) . "}
{"citeStart": 124, "citeEnd": 137, "citeStartToken": 124, "citeEndToken": 137, "sectionName": "UNKNOWN SECTION NAME", "string": "The training set for these experiments was sections 01-21 of the Penn Treebank (Marcus et al., 1993) . The test set was section 23. The parser induction algorithm used in all of the experiments in this paper was a distribution of Collins's model 2 parser (Collins, 1997) . All comparisons made below refer to results we obtained using Collins's parser. The results for bagging are shown in Figure 2 and Table 1 . The row of figures are (from left-to-right) training set F-measure ~, test set F-measure, percent perfectly parsed sentences in training set, and percent perfectly parsed sentences in test set. An ensemble of bags was produced one bag at a time. In the table, the Initial row shows the performance achieved when the ensemble contained only one bag, Final(X) shows the performance when the ensemble contained X bags, BestF gives the performance of the ensemble size that gave the best F-measure score. TrainBestF and TestBestF give the test set performance for the ensemble size that performed the best on the training and test sets, respectively.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The test set was section 23. ", "mid_sen": "The parser induction algorithm used in all of the experiments in this paper was a distribution of Collins's model 2 parser (Collins, 1997) . ", "after_sen": "All comparisons made below refer to results we obtained using Collins's parser. "}
{"citeStart": 153, "citeEnd": 176, "citeStartToken": 153, "citeEndToken": 176, "sectionName": "UNKNOWN SECTION NAME", "string": "It has been argued that, in an incremental approach, gradable properties should be given a low preference ranking because they are difficult to process (Krahmer and Theune 2002) . We have seen in Section 4.3 that generation and interpretation of vague descriptions does have a slightly higher computational complexity than that of nonvague descriptions. Yet, by giving gradable properties a low ranking, we might cause the algorithm to underuse them, for example, in situations where gradable properties are highly relevant to the purpose of the discourse (e.g., a fist fight between people of very different sizes). Luckily, there are no semantic or algorithmic reasons for giving gradables a low ranking. Let us see how things would work if they were ranked more highly.", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "It has been argued that, in an incremental approach, gradable properties should be given a low preference ranking because they are difficult to process (Krahmer and Theune 2002) . ", "after_sen": "We have seen in Section 4.3 that generation and interpretation of vague descriptions does have a slightly higher computational complexity than that of nonvague descriptions. "}
{"citeStart": 144, "citeEnd": 164, "citeStartToken": 144, "citeEndToken": 164, "sectionName": "UNKNOWN SECTION NAME", "string": "By implementing our own version of the publicly available Collins parser (Collins, 1996) , we also learned a dependency model that enables the mapping of parse trees into sets of binary relations between the head-word of each constituent and its sibling-words. For example, the parse tree of TREC-9 question Q210: \"How many dogs pull a sled in the Iditarod ?\" is: For each possible constituent in a parse tree, rules first described in (Magerman, 1995) and (Jelinek et al., 1994 ) identify the head-child and propagate the head-word to its parent. For the parse of question Q210 the propagation is:", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For example, the parse tree of TREC-9 question Q210: ", "mid_sen": "\"How many dogs pull a sled in the Iditarod ?\" is: For each possible constituent in a parse tree, rules first described in (Magerman, 1995) and (Jelinek et al., 1994 ) identify the head-child and propagate the head-word to its parent. ", "after_sen": "For the parse of question Q210 the propagation is:"}
{"citeStart": 76, "citeEnd": 91, "citeStartToken": 76, "citeEndToken": 91, "sectionName": "UNKNOWN SECTION NAME", "string": "The full formulation of the integrated grammar transformation and construction of the finite automaton is rather long and is therefore not given here. A very similar formulation, for another grammar transformation, is given in Nederhof (1998) .", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The full formulation of the integrated grammar transformation and construction of the finite automaton is rather long and is therefore not given here. ", "mid_sen": "A very similar formulation, for another grammar transformation, is given in Nederhof (1998) .", "after_sen": ""}
{"citeStart": 126, "citeEnd": 142, "citeStartToken": 126, "citeEndToken": 142, "sectionName": "UNKNOWN SECTION NAME", "string": "For the Markov model, we need the inverse conditional probabilities P(/,-i+l,... lnlt) which are obtained by Bayesian inversion. A theoretical motivated argumentation uses the standard deviation of the maximum likelihood probabilities for the weights 0i (Samuelsson, 1993) • This leaves room for interpretation. 1) One has to identify a good value for m, the longest suffix used• The approach taken for TnT is the following: m depends on the word in question. We use the longest suffix that we can find in the training set (i.e., for which the frequency is greater than or equal to 1), but at most 10 characters. This is an empirically determined choice• 2) We use a context-independent approach for 0i, as we did for the contextual weights )%i. It turned out to be a good choice to set all 0i to the standard deviation of the unconditioned maximum likelihood probabilities of the tags in the training corpus, i.e., we set 3) We use different estimates for uppercase and lowercase words, i.e., we maintain two different suffix tries depending on the capitalization of the word. This information improves the tagging results• 4) Another freedom concerns the choice of the words in the lexicon that should be used for suffix handling. Should we use all words, or are some of them better suited than others? Accepting that unknown words are most probably infrequent, one can argue that using suffixes of infrequent words in the lexicon is a better approximation for unknown words than using suffixes of frequent words. Therefore, we restrict the procedure of suffix handling to words with a frequency smaller than or equal to some threshold value. Empirically, 10 turned out to be a good choice for this threshold.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For the Markov model, we need the inverse conditional probabilities P(/,-i+l,... lnlt) which are obtained by Bayesian inversion. ", "mid_sen": "A theoretical motivated argumentation uses the standard deviation of the maximum likelihood probabilities for the weights 0i (Samuelsson, 1993) • This leaves room for interpretation. ", "after_sen": "1) One has to identify a good value for m, the longest suffix used• The approach taken for TnT is the following: m depends on the word in question. "}
{"citeStart": 104, "citeEnd": 124, "citeStartToken": 104, "citeEndToken": 124, "sectionName": "UNKNOWN SECTION NAME", "string": "Categorial framework is particularly suited for this mapping due to its lexicalism. Grammatical functions of the nouns in the lexicon are assigned 2aka. type raising, lifting, or type change by case markers, which are also in the lexicon. Thus, grammatical function marking follows naturally from the general CCG schema comprising rules of application (A) and composition (B). The functor-argument distinction in CG helps to model prominence relations without extra levels of representation. CCG schema (Steedman (1988; ) is summarized in (4). Combinator notation is preferred here because they are the formal primitives operating on the PAS (cf. (Curry and Feys, 1958) for Combinatory Logic). Application is the only primitive of the combinatory system; it is indicated by juxtaposition in the examples and denoted by • in the normal order evaluator ( §4). B has the reduction rule B f ga>_f (ga).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "CCG schema (Steedman (1988; ) is summarized in (4). ", "mid_sen": "Combinator notation is preferred here because they are the formal primitives operating on the PAS (cf. (Curry and Feys, 1958) for Combinatory Logic). ", "after_sen": "Application is the only primitive of the combinatory system; it is indicated by juxtaposition in the examples and denoted by • in the normal order evaluator ( §4). "}
{"citeStart": 187, "citeEnd": 205, "citeStartToken": 187, "citeEndToken": 205, "sectionName": "UNKNOWN SECTION NAME", "string": "Many of the subjective clues are from manually developed resources, including entries from (Levin, 1993; Ballmer and Brennenstuhl, 1981) , Framenet lemmas with frame element experiencer (Baker et al., 1998) , adjectives manually annotated for polarity (Hatzivassiloglou and McKeown, 1997) , and subjectivity clues listed in (Wiebe, 1990) . Others were derived from corpora, including subjective nouns learned from unannotated data using bootstrapping (Riloff et al., 2003) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Any data used to develop this vocabulary does not overlap with the test sets or the unannotated data used in this paper.", "mid_sen": "Many of the subjective clues are from manually developed resources, including entries from (Levin, 1993; Ballmer and Brennenstuhl, 1981) , Framenet lemmas with frame element experiencer (Baker et al., 1998) , adjectives manually annotated for polarity (Hatzivassiloglou and McKeown, 1997) , and subjectivity clues listed in (Wiebe, 1990) . ", "after_sen": "Others were derived from corpora, including subjective nouns learned from unannotated data using bootstrapping (Riloff et al., 2003) ."}
{"citeStart": 88, "citeEnd": 112, "citeStartToken": 88, "citeEndToken": 112, "sectionName": "UNKNOWN SECTION NAME", "string": "Features that occur rarely in the training set are problematic because the statistics extracted for these features are not reliable. They may still contribute positively to the ME model because we use Gaussian smoothing (Chen and Rosenfeld, 1999) help avoid overfitting.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Features that occur rarely in the training set are problematic because the statistics extracted for these features are not reliable. ", "mid_sen": "They may still contribute positively to the ME model because we use Gaussian smoothing (Chen and Rosenfeld, 1999) help avoid overfitting.", "after_sen": "Instead of including every possible feature, we used a cutoff to remove features that occur less than four times. "}
{"citeStart": 65, "citeEnd": 89, "citeStartToken": 65, "citeEndToken": 89, "sectionName": "UNKNOWN SECTION NAME", "string": "For agglutinative languages such as Korean, Finnish and Turkish (Kwon and Karttunen, 1994; Koskenniemi, 1983; Oflazer, 1993) , dimension (b) is very large, so creating an exhaustive word list is out of the question unless the lexicon is trivial. Compilation to a network may still make sense, however, and because these languages tend to exhibit few non-eoncatenative morphophonological phenomena other than vowel harmony, the continuation class mechanism may suffice to describe the allowed affix sequences at the surface level.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Alternatively, there may be no need to provide as powerful a mechanism as two-level morphology at all; a simpler device such as affix stripping (A1shawi, 1992, pll9ff) or merely listing all inflected forms explicitly may be preferable.", "mid_sen": "For agglutinative languages such as Korean, Finnish and Turkish (Kwon and Karttunen, 1994; Koskenniemi, 1983; Oflazer, 1993) , dimension (b) is very large, so creating an exhaustive word list is out of the question unless the lexicon is trivial. ", "after_sen": "Compilation to a network may still make sense, however, and because these languages tend to exhibit few non-eoncatenative morphophonological phenomena other than vowel harmony, the continuation class mechanism may suffice to describe the allowed affix sequences at the surface level."}
{"citeStart": 77, "citeEnd": 96, "citeStartToken": 77, "citeEndToken": 96, "sectionName": "UNKNOWN SECTION NAME", "string": "We have thus far implemented two objective functions which operate on individual sentences without regard for choices made on other sentences. When the final evaluation metric incorporates global statistics, however, an objective function which takes them into account is desirable. For example, when using BLEU, it makes a big difference whether individual sentences are both longer and shorter than the reference or systematically shorter than the reference, but these two cases can not be distinguished by single-sentence objective functions. Our plan is to implement a windowed or moving-average version of BLEU as in (Chiang et al., 2008) .", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For example, when using BLEU, it makes a big difference whether individual sentences are both longer and shorter than the reference or systematically shorter than the reference, but these two cases can not be distinguished by single-sentence objective functions. ", "mid_sen": "Our plan is to implement a windowed or moving-average version of BLEU as in (Chiang et al., 2008) .", "after_sen": "We also plan to further speed up the tuning process by parallelizing the decoding of the sentences in the tuning set. "}
{"citeStart": 60, "citeEnd": 77, "citeStartToken": 60, "citeEndToken": 77, "sectionName": "UNKNOWN SECTION NAME", "string": "It is not yet clear what the generative capacity of such lexicalized discontinuous DGs is, but at least some index languages (such as anbnc n) can be characterized. have shown that recognition and parsing of such grammars is A/'7~-complete. A parser operating on the model structures is described in (Hahn et al., 1997) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "have shown that recognition and parsing of such grammars is A/'7~-complete. ", "mid_sen": "A parser operating on the model structures is described in (Hahn et al., 1997) .", "after_sen": ""}
{"citeStart": 33, "citeEnd": 52, "citeStartToken": 33, "citeEndToken": 52, "sectionName": "UNKNOWN SECTION NAME", "string": "We use maximum entropy modeling (Berger et al., 1996) to directly model the conditional probability", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "(in our case, potential A speakers), the one candidate ¢ that maximizes a given conditional probability distribution.", "mid_sen": "We use maximum entropy modeling (Berger et al., 1996) to directly model the conditional probability", "after_sen": "¢ ! # \"$ & % , where each ' ¥ in $ ) ( 0 1 ' 2 ¤ 3 ¦ § © © © ¦ # ' 4 %"}
{"citeStart": 178, "citeEnd": 201, "citeStartToken": 178, "citeEndToken": 201, "sectionName": "UNKNOWN SECTION NAME", "string": "The governing category feature is only applicable for NPs. In the original formulation for English in Gildea and Jurafsky (2002) , it answers the question: Is the NP governed by IP or VP? An NP governed by an IP is likely to be a subject, while an NP governed by a VP is more likely to be an object. For Chinese, we added a third option in which the governing category of an NP is neither IP nor VP, but an NP. This is caused by the \"DE\" construction, in which a clause is used as a modifier of an NP. For instance, in the example indicated in Figure 1 , for the last NP, \" \"(\"international Olympic conference\") the parent node is NP, from where it goes down to the target verb \" \"(\"taking place\"). Since the governing category information is encoded in the path feature, it may be redundant; indeed this redundancy might explain why the governing category feature was used in Gildea & Jurafsky(2002) but not in Gildea and Palmer(2002) . Since the \"DE\" construction caused us to modify the feature for Chinese, we conducted several experiments to test whether the governing category feature is useful or whether it is redundant with the path and position features. Using the paradigm to be described in section 3.4, we found a small improvement using governing category, and so we include it in our model.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For instance, in the example indicated in Figure 1 , for the last NP, \" \"(\"international Olympic conference\") the parent node is NP, from where it goes down to the target verb \" \"(\"taking place\"). ", "mid_sen": "Since the governing category information is encoded in the path feature, it may be redundant; indeed this redundancy might explain why the governing category feature was used in Gildea & Jurafsky(2002) but not in Gildea and Palmer(2002) . ", "after_sen": "Since the \"DE\" construction caused us to modify the feature for Chinese, we conducted several experiments to test whether the governing category feature is useful or whether it is redundant with the path and position features. "}
{"citeStart": 78, "citeEnd": 102, "citeStartToken": 78, "citeEndToken": 102, "sectionName": "UNKNOWN SECTION NAME", "string": "1. A tagger, a first-order HMM part-of-speech (PoS) and punctuation tag disambiguator, is used to assign and rank tags for each word and punctuation token in sequences of sentences (Elworthy, 1994 ). 2. A lemmatizer is used to replace word-tag pairs with lemma-tag pairs, where a lemma is the morphological base or dictionary headword form appropriate for the word, given the PoS assignment made by the tagger. We use an enhanced version of the GATE project stemmer (Cunningham et al., 1995) . 3. A probabilistic LR parser, trained on a treebank, returns ranked analyses (Briscoe &: Carroll, 1993; Carroll, 1993 Carroll, , 1994 , using a grammar written in a feature-based unification grammar formalism which assigns 'shallow' phrase structure analyses to tag networks (or 'lattices') returned by the tagger (Briscoe & Carroll, 1994 , 1995 Carroll & Briscoe, 1996) . 4. A patternset extractor which extracts subcategorization patterns, including the syntactic categories and head lemmas of constituents, from sentence subanalyses which begin/end at the boundaries of (specified) predicates.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We use an enhanced version of the GATE project stemmer (Cunningham et al., 1995) . ", "mid_sen": "3. A probabilistic LR parser, trained on a treebank, returns ranked analyses (Briscoe &: Carroll, 1993; Carroll, 1993 Carroll, , 1994 , using a grammar written in a feature-based unification grammar formalism which assigns 'shallow' phrase structure analyses to tag networks (or 'lattices') returned by the tagger (Briscoe & Carroll, 1994 , 1995 Carroll & Briscoe, 1996) . ", "after_sen": "4. A patternset extractor which extracts subcategorization patterns, including the syntactic categories and head lemmas of constituents, from sentence subanalyses which begin/end at the boundaries of (specified) predicates."}
{"citeStart": 133, "citeEnd": 144, "citeStartToken": 133, "citeEndToken": 144, "sectionName": "UNKNOWN SECTION NAME", "string": "1Spivey-Knowlton et al. reported 3 experiments. One showed effects before the end of a word when there was no other appropriate word with the same initial phonology. Another showed on-line effects from adjectives and determiners during noun phrase processing. constituency, so that an initial fragment of a sentence, such as John likes, can be treated as a constituent, and hence be assigned a type and a semantics. This approach is exemplified by Combinatory Categorial Grammar, CCG (Steedman 1991) , which takes a basic CG with just application, and adds various new ways of combining elements together 2. Incremental interpretation can then be achieved using a standard bottom-up shift reduce parser, working from left to right along the sentence. The alternative approach, exemplified by the work of Stabler on top-down parsing (Stabler 1991) , and Pulman on left-corner parsing (Pulman 1986 ) is to associate a semantics directly with the partial structures formed during a topdown or left-corner parse. For example, a syntax tree missing a noun phrase, such as the following", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Incremental interpretation can then be achieved using a standard bottom-up shift reduce parser, working from left to right along the sentence. ", "mid_sen": "The alternative approach, exemplified by the work of Stabler on top-down parsing (Stabler 1991) , and Pulman on left-corner parsing (Pulman 1986 ) is to associate a semantics directly with the partial structures formed during a topdown or left-corner parse. ", "after_sen": "For example, a syntax tree missing a noun phrase, such as the following"}
{"citeStart": 102, "citeEnd": 118, "citeStartToken": 102, "citeEndToken": 118, "sectionName": "UNKNOWN SECTION NAME", "string": "1 Recently, a similar task has been addressed by the Affective Text Task at SemEval-1 where even shorter units -headlines -were classified into positive, negative and neutral categories using a variety of techniques (Strapparava and Mihalcea, 2007) . The experiments comparing in-domain trained system performance on texts vs. sentences were conducted on 2,002 movie review texts and on 10,662 movie review snippets. The results with 10-fold cross-validation are reported in Consistent with findings in the literature (Cui et al., 2006; Dave et al., 2003; , on the large corpus of movie review texts, the indomain-trained system based solely on unigrams had lower accuracy than the similar system trained on bigrams. But the trigrams fared slightly worse than bigrams. On sentences, however, we have observed an inverse pattern: unigrams performed better than bigrams and trigrams. These results highlight a special property of sentence-level annotation: greater sensitivity to sparseness of the model: On texts, classifier error on one particular sentiment marker is often compensated by a number of correctly identified other sentiment clues. Since sentences usually contain a much smaller number of sentiment clues than texts, sentence-level annotation more readily yields errors when a single sentiment clue is incorrectly identified or missed by the system. Due to lower frequency of higher-order n-grams (as opposed to unigrams), higher-order ngram language models are more sparse, which increases the probability of missing a particular sentiment marker in a sentence (Table 3 3 ). Very large 2 All results are statistically significant at α = 0.01 with two exceptions: the difference between trigrams and bigrams for the system trained and tested on texts is statistically significant at alpha=0.1 and for the system trained on sentences and tested on texts is not statistically significant at α = 0.01.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The experiments comparing in-domain trained system performance on texts vs. sentences were conducted on 2,002 movie review texts and on 10,662 movie review snippets. ", "mid_sen": "The results with 10-fold cross-validation are reported in Consistent with findings in the literature (Cui et al., 2006; Dave et al., 2003; , on the large corpus of movie review texts, the indomain-trained system based solely on unigrams had lower accuracy than the similar system trained on bigrams. ", "after_sen": "But the trigrams fared slightly worse than bigrams. "}
{"citeStart": 178, "citeEnd": 194, "citeStartToken": 178, "citeEndToken": 194, "sectionName": "UNKNOWN SECTION NAME", "string": "As can be reconstructed from the numbering of the facts in figure 3 the resulting processing behavior is identical to the behavior that would result from Earley generation as in Gerdemann (1991) except that the different filtering steps are performed in a bottom-up fashion. In order to obtain a generator similar to the bottom-up generator as described in Shieber (1988) the compilation process can be modified such that only lexical entries are extended with magic literals. Just like in case of Shieber's bottom-up generator, bottom-up evaluation of magic-compiled grammars produced with this Magic variant is only guaranteed to be complete in case the original grammar obeys the semantic monotonicity constraint.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Dotted lines are used to represent when 'normal' facts are combined with magic facts to derive new magic facts.", "mid_sen": "As can be reconstructed from the numbering of the facts in figure 3 the resulting processing behavior is identical to the behavior that would result from Earley generation as in Gerdemann (1991) except that the different filtering steps are performed in a bottom-up fashion. ", "after_sen": "In order to obtain a generator similar to the bottom-up generator as described in Shieber (1988) the compilation process can be modified such that only lexical entries are extended with magic literals. "}
{"citeStart": 80, "citeEnd": 94, "citeStartToken": 80, "citeEndToken": 94, "sectionName": "UNKNOWN SECTION NAME", "string": "For incomplete-data estimation, a sequence of likelihood values is guaranteed to converge to a critical point of the likelihood function L. This is shown for the IM algorithm in Riezler (1999) . The process of nding likelihood maxima is chaotic in that the nal likelihood value is extremely sensitive to the starting values of , i.e. limit points can be local maxima (or saddlepoints), which are not necessarily also global maxima. A way to search for order in this chaos is to search for starting values which are hopefully attracted by the global maximum of L. This problem can best be explained in terms of the minimum divergence paradigm (Kullback, 1959) , which is equivalent to the maximum likelihood paradigm by the following theorem. Let", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A way to search for order in this chaos is to search for starting values which are hopefully attracted by the global maximum of L. ", "mid_sen": "This problem can best be explained in terms of the minimum divergence paradigm (Kullback, 1959) , which is equivalent to the maximum likelihood paradigm by the following theorem. ", "after_sen": "Let"}
{"citeStart": 65, "citeEnd": 85, "citeStartToken": 65, "citeEndToken": 85, "sectionName": "UNKNOWN SECTION NAME", "string": "Similarly, we can assess other strategies of sentence ordering that have been proposed in the literature. Hard-core centering approaches only deal with the last sentence (Brennan et al., 1987) . In Negra, these approaches can consequently have at most a success rate of 44.2%. Performance is particularly low with possessive pronouns which often only have antecedents in the current sentence. Strube (1998)'s centering approach (whose sentence ordering is designated as SR2 in Table 2 ) also deals with and even prefers intrasentential anaphora, which raises the upper limit to a more acceptable 80.2%. Strube and Hahn (1999) extend the context to more than the last sentence, but switch preference order between the last and the current sentence so that an antecedent is determined in the last sentence, whenever possible. In Negra, this ordering imposes an upper limit of 51.2%.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Similarly, we can assess other strategies of sentence ordering that have been proposed in the literature. ", "mid_sen": "Hard-core centering approaches only deal with the last sentence (Brennan et al., 1987) . ", "after_sen": "In Negra, these approaches can consequently have at most a success rate of 44.2%. "}
{"citeStart": 102, "citeEnd": 121, "citeStartToken": 102, "citeEndToken": 121, "sectionName": "UNKNOWN SECTION NAME", "string": "In our second series of experiments, we incrementally developed a new grammar from scratch. The new grammar is basically a scaleddown and adapted version of the Core Language Engine grammar for English Pulman 1992; Rayner 1993 ; concrete development w ork and testing were organized around a speech interface to a set of functionalities o ered by a simple simulation of the Space Shuttle Rayner, Hockey and James 2000. Rules and lexical entries were added in small groups, typically 2 3 rules or 5 10 lexical entries in one increment. After each round of expansion, we tested to make sure that the grammar could still be compiled into a usable recognizer, and at several points this suggested changes in our implementation strategy. The rest of this section describes the new grammar in more detail.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In our second series of experiments, we incrementally developed a new grammar from scratch. ", "mid_sen": "The new grammar is basically a scaleddown and adapted version of the Core Language Engine grammar for English Pulman 1992; Rayner 1993 ; concrete development w ork and testing were organized around a speech interface to a set of functionalities o ered by a simple simulation of the Space Shuttle Rayner, Hockey and James 2000. ", "after_sen": "Rules and lexical entries were added in small groups, typically 2 3 rules or 5 10 lexical entries in one increment. "}
{"citeStart": 50, "citeEnd": 73, "citeStartToken": 50, "citeEndToken": 73, "sectionName": "UNKNOWN SECTION NAME", "string": "Two speech samples from each of three subjects were used in the simulations in one sample a mother was speaking to her daughter and in the other, the same mother was speaking to the researcher. The samples were taken from the CHILDES database (MacWhinney ~ Snow, 1990) from studies reported in Bernstein (1982) . Each sample was checked for consistent word spellings (e.g., 'ts wits changed to its), then was transcribed into an ASCll-I)ased I)honemic rel)res(mtation :l. 'Fhe transcription sysl, em was based on IPA an(I used one character for each consonant or vowel; diphthongs, r-colored vowels and syllabic consonants were each represented as one character. For example, \"boy\" was written as bT, \"bird\" as bRd and \"label\" as lebL. For purposes of phonotactic constraints, syllabic consonants were treate(! as vowels. Sample lengths were selected to make the nmnber of available segmentation points nearly equal (about 1,350) when no ph0notactic constraints were applied; child-directed samples had 498-536 tokens and 153-166 types, adult-directed sa.ml)les had 443-484 tokens and 196--205 types. I\"inMly, Iwl'ore tim saml)les were fi~(I to the sinmlations, divisions bel,wcell words (but not l)(%w(~en s(HIt(qIcos) wcr(~ reiuovc'.(L The sl)ace of l)Ossil)le hyl)oi, hcses is vlmt 4, so sonl(~ nmthod of finding a minimum-length hypothesis without considering all hypotheses is necessary. We used the following method: first, evaluate the input sample with no segmentation points added; then evaluate all hypotheses obtained by adding one or two segmentation points; take the shortest hypothesis found in the previous step and evaluate all hypotheses obtained by adding one or two more segmentation points; continue this way until the sample has been segmented into the smallest possible units and report the shortest hypothesis ever found. Two variants of this simulation wcre used: (1) DIST-FREE was free of any phonotactic restrictions on the hypotheses it could form (DIST refers to the measurement of distri-butionaJ information), whereas (2) DIST-PtloNO ,Ise~l I.Iw i)hon~,t;wtic r (,sl.ricl,i(ms (lescril.,I ;,.I,,w,'. 3The I,ranisi:riptioli nil%hod CUlSiix'(!d the identh:al trallscripl~ioii of all occurrences of a word.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Two speech samples from each of three subjects were used in the simulations in one sample a mother was speaking to her daughter and in the other, the same mother was speaking to the researcher. ", "mid_sen": "The samples were taken from the CHILDES database (MacWhinney ~ Snow, 1990) from studies reported in Bernstein (1982) . ", "after_sen": "Each sample was checked for consistent word spellings (e.g., 'ts wits changed to its), then was transcribed into an ASCll-I)ased I)honemic rel)res(mtation :l. 'Fhe transcription sysl, em was based on IPA an(I used one character for each consonant or vowel; diphthongs, r-colored vowels and syllabic consonants were each represented as one character. "}
{"citeStart": 102, "citeEnd": 125, "citeStartToken": 102, "citeEndToken": 125, "sectionName": "UNKNOWN SECTION NAME", "string": "Although not the first to employ a generative approach to directly model content, the seminal work of Barzilay and Lee (2004) is a noteworthy point of reference and comparison. However, our study differs in several important respects. Barzilay and Lee employed an unsupervised approach to building topic sequence models for the newswire text genre using clustering techniques. In contrast, because the discourse structure of medical abstracts is welldefined and training data is relatively easy to obtain, we were able to apply a supervised approach. Whereas Barzilay and Lee evaluated their work in the context of document summarization, the fourpart structure of medical abstracts allows us to conduct meaningful intrinsic evaluations and focus on the sentence classification task. Nevertheless, their work bolsters our claims regarding the usefulness of generative models in extrinsic tasks, which we do not describe here.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Although not the first to employ a generative approach to directly model content, the seminal work of Barzilay and Lee (2004) is a noteworthy point of reference and comparison. ", "after_sen": "However, our study differs in several important respects. "}
{"citeStart": 189, "citeEnd": 210, "citeStartToken": 189, "citeEndToken": 210, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper, we apply Alternating Structure Optimization (ASO) (Ando and Zhang, 2005a) to the semantic role labeling task on NomBank. ASO is a recently proposed linear multi-task learning algorithm based on empirical risk minimization. The method requires the use of multiple auxiliary problems, and its effectiveness may vary depending on the specific auxiliary problems used. ASO has been shown to be effective on the following natural language processing tasks: text categorization, named entity recognition, part-of-speech tagging, and word sense disambiguation (Ando and Zhang, 2005a; Ando and Zhang, 2005b; Ando, 2006) . This paper makes two significant contributions. First, we present a novel application of ASO to the SRL task on NomBank. We explore the effect of different auxiliary problems, and show that learning predictive structures with ASO results in significantly improved SRL accuracy. Second, we achieve accuracy higher than that reported in (Jiang and Ng, 2006) and advance the state of the art in SRL research.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The method requires the use of multiple auxiliary problems, and its effectiveness may vary depending on the specific auxiliary problems used. ", "mid_sen": "ASO has been shown to be effective on the following natural language processing tasks: text categorization, named entity recognition, part-of-speech tagging, and word sense disambiguation (Ando and Zhang, 2005a; Ando and Zhang, 2005b; Ando, 2006) . ", "after_sen": "This paper makes two significant contributions. "}
{"citeStart": 83, "citeEnd": 109, "citeStartToken": 83, "citeEndToken": 109, "sectionName": "UNKNOWN SECTION NAME", "string": "From the Japanese Wikipedia entries of April 10, 2007, we extracted 550,832 gazetteer entries (482,599 entries have hypernyms other than UNK). Various statistics for this extraction are shown in Table 1 . The number of distinct hypernyms in the gazetteer was 12,786. Although this Wikipedia gazetteer is much smaller than the English version used by Kazama and Torisawa (2007) that has over 2,000,000 entries, it is the largest gazetteer that can be freely used for Japanese NER. Our experimental results show that this Wikipedia gazetteer can be used to improve the accuracy of Japanese NER.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The number of distinct hypernyms in the gazetteer was 12,786. ", "mid_sen": "Although this Wikipedia gazetteer is much smaller than the English version used by Kazama and Torisawa (2007) that has over 2,000,000 entries, it is the largest gazetteer that can be freely used for Japanese NER. ", "after_sen": "Our experimental results show that this Wikipedia gazetteer can be used to improve the accuracy of Japanese NER."}
{"citeStart": 70, "citeEnd": 96, "citeStartToken": 70, "citeEndToken": 96, "sectionName": "UNKNOWN SECTION NAME", "string": "The most detailed evaluation of link tokens to date was performed by (Macklovitch & Hannan, 1996) , who trained Brown et al.'s Model 2 on 74 million words of the Canadian Hansards. These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set. We generated links in the same 51 sentences using our two-class word-to-word model, and manually evaluated the content-word links from both models. The IBM models are directional; i.e. they posit the English words that gave rise to each French word, but ignore the distribution of the English words. Therefore, we ignored English words that were linked to nothing.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The most detailed evaluation of link tokens to date was performed by (Macklovitch & Hannan, 1996) , who trained Brown et al.'s Model 2 on 74 million words of the Canadian Hansards. ", "after_sen": "These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set. "}
{"citeStart": 13, "citeEnd": 39, "citeStartToken": 13, "citeEndToken": 39, "sectionName": "UNKNOWN SECTION NAME", "string": "There have been some attempts to capture the behavior of semantic categories in a distributional setting, despite the unavailability of sense-annotated corpora. For example, Hearst and Schtltze (1993) take steps toward a distributional treatment of WordNet-based classes, using Schtltze's (1993) approach to constructing vector representations from a large co-occurrence matrix. Yarowsky's (1992) algorithm for sense disambiguation can be thought of as a way of determining how Roget's thesaurus categories behave with respect to contextual features. And my own treatment of selectional constraints (Resnik, 1993) provides a way to describe the plausibility of co-occuffence in terms of WordNet's semantic categories, using co-occurrence relationships mediated by syntactic structure. In each case, one begins with known semantic categories (WordNet synsets, Roget's numbered classes) and non-sense-annotated text, and proceeds to a distributional characterization of semantic category behavior using co-occurrence relationships.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There have been some attempts to capture the behavior of semantic categories in a distributional setting, despite the unavailability of sense-annotated corpora. ", "mid_sen": "For example, Hearst and Schtltze (1993) take steps toward a distributional treatment of WordNet-based classes, using Schtltze's (1993) approach to constructing vector representations from a large co-occurrence matrix. ", "after_sen": "Yarowsky's (1992) algorithm for sense disambiguation can be thought of as a way of determining how Roget's thesaurus categories behave with respect to contextual features. "}
{"citeStart": 169, "citeEnd": 188, "citeStartToken": 169, "citeEndToken": 188, "sectionName": "UNKNOWN SECTION NAME", "string": "word sense disambiguation, information retrieval, natural language generation and so on. Also, the use of collocations in different applications has been discussed by various authors ((McRoy, 1992) , (Pnstejovsky et al., 1992) , (Smadja and McKeown, 1990) etc.). However, collocations are not only considered usefnl, but also a problem both in certain applications (e.g. generation, (Nirenburg et al., 1988) , machine translation, (Heid and Raab, 1989) ) and fiom a more theoretical point of view (e.g. (Abeill6 and Schabes, 1989) , (Krenn and Erbach, to appear) ).", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Also, the use of collocations in different applications has been discussed by various authors ((McRoy, 1992) , (Pnstejovsky et al., 1992) , (Smadja and McKeown, 1990) etc.). ", "mid_sen": "However, collocations are not only considered usefnl, but also a problem both in certain applications (e.g. generation, (Nirenburg et al., 1988) , machine translation, (Heid and Raab, 1989) ) and fiom a more theoretical point of view (e.g. (Abeill6 and Schabes, 1989) , (Krenn and Erbach, to appear) ).", "after_sen": "We have been concerned with investigating the lexical . ['unctions (IJTs) of Mel'0,uk (Mel'6uk and Zolkovsky, 1984) as a candidate interllngual device for tbe translation of adjectival and verbal collocates. "}
{"citeStart": 56, "citeEnd": 71, "citeStartToken": 56, "citeEndToken": 71, "sectionName": "UNKNOWN SECTION NAME", "string": "The algorithm we implemented is inspired by the work of Yarowsky (1995) on word sense disambiguation. He classified the senses of a word on the basis of other words that the given word co-occurs with. Collins and Singer (1999) classified proper names as PERSON, ORGANIZATION, or LOCATION using contextual rules (that rely on other words appearing in the context of the proper names) and spelling rules (that rely on words in the proper names). Starting with a few spelling rules (using some proper-name features) in the decision list, their algorithm learns new contextual rules; using these rules, it then learns more spelling rules, and so on, in a process of mutual bootstrapping. Riloff and Jones (1999) learned domain-specific lexicons and extraction patterns (such as shot in x for the terrorism domain). They used a mutual bootstrapping technique to alternately select the best extraction pattern for a category and add its extractions to the semantic lexicon; the newly added entries in the lexicon help in the selection of the next best extraction pattern.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "These are split further for each leaf class, as explained in Section 2.3.", "mid_sen": "The algorithm we implemented is inspired by the work of Yarowsky (1995) on word sense disambiguation. ", "after_sen": "He classified the senses of a word on the basis of other words that the given word co-occurs with. "}
{"citeStart": 126, "citeEnd": 140, "citeStartToken": 126, "citeEndToken": 140, "sectionName": "UNKNOWN SECTION NAME", "string": "Local collocation knowledge yields the highest accuracy, followed by POS and morphological form. Surrounding words give lower accuracy, perhaps because in our work, only the current sentence forms the surrounding context, which averages about 20 words. Previous work on using the unordered set of surrounding words have used a much larger window, such as the 100-word window of (Yarowsky, 1992) , and the 2-sentence context of (Leacock et al., 1993) . Verb-object syntactic relation is the weakest knowledge source.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Surrounding words give lower accuracy, perhaps because in our work, only the current sentence forms the surrounding context, which averages about 20 words. ", "mid_sen": "Previous work on using the unordered set of surrounding words have used a much larger window, such as the 100-word window of (Yarowsky, 1992) , and the 2-sentence context of (Leacock et al., 1993) . ", "after_sen": "Verb-object syntactic relation is the weakest knowledge source."}
{"citeStart": 199, "citeEnd": 216, "citeStartToken": 199, "citeEndToken": 216, "sectionName": "UNKNOWN SECTION NAME", "string": "This paper proposes an approach to improve domain-specific word alignment through alignment model adaptation. Our approach first trains two alignment models with a large-scale out-of-domain corpus and a small-scale domain-specific corpus. Second, we build a new adaptation model by linearly interpolating these two models. Third, we apply the new model to the domain-specific corpus and improve the word alignment results. In addition, with the training data, an interpolated translation dictionary is built to select the word alignment links from different alignment results. Experimental results indicate that our approach achieves a precision of 84.90% and a recall of 75.99% for word alignment in a specific domain. Our method achieves a relative error rate reduction of 17.43% as compared with the method directly combining the out-of-domain corpus and the in-domain corpus as training data. It also achieves a relative error rate reduction of 6.56% as compared with the previous work in ( Wu and Wang, 2004) . In addition, when we train the model with a smaller-scale in-domain corpus as described in (Wu and Wang, 2004) , our method achieves an error rate reduction of 10.15% as compared with the method in (Wu and Wang, 2004) .", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It also achieves a relative error rate reduction of 6.56% as compared with the previous work in ( Wu and Wang, 2004) . ", "mid_sen": "In addition, when we train the model with a smaller-scale in-domain corpus as described in (Wu and Wang, 2004) , our method achieves an error rate reduction of 10.15% as compared with the method in (Wu and Wang, 2004) .", "after_sen": "We also use in-domain corpora and out-of-domain corpora of different sizes to perform adaptation experiments. "}
{"citeStart": 154, "citeEnd": 172, "citeStartToken": 154, "citeEndToken": 172, "sectionName": "UNKNOWN SECTION NAME", "string": "There have been a number of efforts to exploit weak or external signals of quality to train better prediction models. This includes work on generalized expectation (Mann and McCallum, 2010) , posterior regularization (Ganchev et al., 2010) and constraint driven learning (Chang et al., 2007; . The work of Chang et al. (2007) on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5. In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics. For our setting this would mean using weak application specific signals to improve dependency parsing. Though we explore such ideas in our experiments, in particular for semi-supervised domain adaptation, we are primarily interested in the case where the weak signal is precisely what we wish to optimize, but also desire the benefit from using both data with annotated parse structures and data specific to the task at hand to guide parser training.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There have been a number of efforts to exploit weak or external signals of quality to train better prediction models. ", "mid_sen": "This includes work on generalized expectation (Mann and McCallum, 2010) , posterior regularization (Ganchev et al., 2010) and constraint driven learning (Chang et al., 2007; . ", "after_sen": "The work of Chang et al. (2007) on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5. "}
{"citeStart": 98, "citeEnd": 124, "citeStartToken": 98, "citeEndToken": 124, "sectionName": "UNKNOWN SECTION NAME", "string": "A wide range of contextual information, such as surrounding words (GREF ), dependency or case structure (GTREF ), and dependency path (GREF ), has been utilized for similarity calculation, and achieved considerable success. Table 3 compares the precision, recall, F1, and accuracy for the three methods described in Section 4 and their variations. All the metrics were computed at the word level. The results show that all our methods outperform the baseline method AR-2011 that was proposed by Abu-Jbara and Radev (2011) . In the word classification method, we notice no significant difference between the performance of the SVM vs Logistic Regression classifier. We also notice that the CRF-based sequence labeling method performs significantly better than the word classification method. This result corroborates our intuition that the labels of neighboring words are dependent. The results also show that segment labeling generally performs better than word labeling. More specifically, the results indicate that segmentation based on chunking and the label aggregation based on plurality when used together (i.e., SC-S2-R1) achieve higher precision, accuracy, and F-measure than the punctuation-based segmentation and the other label aggregation rules. Table 2 shows the output of the three methods on two example sentences. The underlined words are labeled by the system as scope words.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "All the metrics were computed at the word level. ", "mid_sen": "The results show that all our methods outperform the baseline method AR-2011 that was proposed by Abu-Jbara and Radev (2011) . ", "after_sen": "In the word classification method, we notice no significant difference between the performance of the SVM vs Logistic Regression classifier. "}
{"citeStart": 123, "citeEnd": 127, "citeStartToken": 123, "citeEndToken": 127, "sectionName": "UNKNOWN SECTION NAME", "string": "A more controversial question concerns rhetorical relations and the extent to which these are detected and used by listeners[GS86]. Hobbs has applied COHERENCE RELATIONS to face-to-face conversation in which mixed-initiative is displayed by participants [HA85, Hob79] . One category of rhetorical relation he describes is that of ELABORATION, in which a speaker repeats the propositional content of a previous utterance. Hobbs has some difficulties determining the function of this repetition, but we maintain that the function follows from the more general principles of the control rules: speakers signal that they wish to shift control by supplying no new propositional content. Abdications, repetitions and summaries all add no new information and function to signal to the listener that the speaker has nothing further to say right now. The listener certainly must recognize this fact.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A more controversial question concerns rhetorical relations and the extent to which these are detected and used by listeners[GS86]. ", "mid_sen": "Hobbs has applied COHERENCE RELATIONS to face-to-face conversation in which mixed-initiative is displayed by participants [HA85, Hob79] . ", "after_sen": "One category of rhetorical relation he describes is that of ELABORATION, in which a speaker repeats the propositional content of a previous utterance. "}
{"citeStart": 34, "citeEnd": 47, "citeStartToken": 34, "citeEndToken": 47, "sectionName": "UNKNOWN SECTION NAME", "string": "max The auxiliary constraint g * (•) can take on many forms and the one we used in this work is an L 2 penalty function (Dudík, 2007) . We trained the model with L-BFGS (Nocedal, 1980) in supervised, semi-supervised and unsupervised fashions on labeled and/or unlabeled data, using the Mallet software (McCallum, 2002) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "max The auxiliary constraint g * (•) can take on many forms and the one we used in this work is an L 2 penalty function (Dudík, 2007) . ", "mid_sen": "We trained the model with L-BFGS (Nocedal, 1980) in supervised, semi-supervised and unsupervised fashions on labeled and/or unlabeled data, using the Mallet software (McCallum, 2002) .", "after_sen": ""}
{"citeStart": 119, "citeEnd": 146, "citeStartToken": 119, "citeEndToken": 146, "sectionName": "UNKNOWN SECTION NAME", "string": "We computed sentence-level correlations following the benchmark assessment procedure used by WMT and NIST MetricsMaTr (Callison-Burch et al., 2008 , 2010 Macháček and Bojar, 2013) , which use Kendall's τ correlation coefficient, to evaluate the correlation of evaluation metrics against human judgment on ranking the translation adequacy of the three systems' output. A higher value for Kendall's τ indicates more similarity to the human adequacy rankings by the evaluation metrics. The range of possible values of Kendall's τ correlation coefficient is [-1, 1] , where 1 means the systems are ranked in the same order as the human judgment by the evaluation metric; and -1 means the systems are ranked in the reverse order as human judgment by the evaluation metric. For both reference and machine translations, the ASSERT (Pradhan et al., 2004) semantic role labeler was used to automatically predict semantic parses.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The corpus includes the Chinese input sentences, each accompanied by an English reference translation and three participating state-of-the-art MT systems' output.", "mid_sen": "We computed sentence-level correlations following the benchmark assessment procedure used by WMT and NIST MetricsMaTr (Callison-Burch et al., 2008 , 2010 Macháček and Bojar, 2013) , which use Kendall's τ correlation coefficient, to evaluate the correlation of evaluation metrics against human judgment on ranking the translation adequacy of the three systems' output. ", "after_sen": "A higher value for Kendall's τ indicates more similarity to the human adequacy rankings by the evaluation metrics. "}
{"citeStart": 79, "citeEnd": 100, "citeStartToken": 79, "citeEndToken": 100, "sectionName": "UNKNOWN SECTION NAME", "string": "Lexical-Functional Grammar (SLFG) is a stochastic extension of Lexical-Functional Grammar (LFG), a UBG formalism developed by Kaplan and Bresnan (1982) . Given a base LFG, an SLFG is constructed by defining features which identify salient constructions in a linguistic structure (in LFG this is a c-structure/f-structure pair and its associated mapping; see Kaplan (1995) ). Apart from the auxiliary distributions, we based our features on those used in Johnson et al. (1999) , which should be consulted for further details. Most of these feature values range over the natural numbers, counting the number of times that a particular construction appears in a linguistic structure. For example, adjunct and argument features count the number of adjunct and argument attachments, permitting SLFG to capture a general argument attachment preference, while more specialized features count the number of attachments to each grammatical function (e.g., SUB J, OBJ, COMP, etc.). The flexibility of features in stochastic UBGs permits us to include features for relatively complex constructions, such as date expressions (it seems that date interpretations, if possible, are usually preferred), right-branching constituent structures (usually preferred) and non-parallel coordinate structures (usually dispreferred). Johnson et al. remark that they would have liked to have included features for lexical selectional preferences. While such features are perfectly acceptable in a SLFG, they felt that their corpora were so small that the large number of lexical dependency parameters could not be accurately estimated. The present paper proposes a method to address this by using an auxiliary distribution estimated from a corpus large enough to (hopefully) provide reliable estimates for these parameters.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Given a base LFG, an SLFG is constructed by defining features which identify salient constructions in a linguistic structure (in LFG this is a c-structure/f-structure pair and its associated mapping; see Kaplan (1995) ). ", "mid_sen": "Apart from the auxiliary distributions, we based our features on those used in Johnson et al. (1999) , which should be consulted for further details. ", "after_sen": "Most of these feature values range over the natural numbers, counting the number of times that a particular construction appears in a linguistic structure. "}
{"citeStart": 60, "citeEnd": 78, "citeStartToken": 60, "citeEndToken": 78, "sectionName": "UNKNOWN SECTION NAME", "string": "We use the dataset from Athar (2011) as our starting point, which consists of 8,736 citations in the ACL Anthology (Bird et al., 2008) that cite a target set of 310 ACL Anthology papers. The citation summary data from the ACL Anthology Network 1 (Radev et al., 2009) is used. This dataset is rather large, and since manual annotation of context for each citation is a time consuming task, a subset of 20 target papers (i.e., all citations to these) has been selected for annotation. These 20 papers correspond to approximately 20% of incoming citations in the original dataset. They contain a total of 1,555 citations from 854 citing papers.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We use the dataset from Athar (2011) as our starting point, which consists of 8,736 citations in the ACL Anthology (Bird et al., 2008) that cite a target set of 310 ACL Anthology papers. ", "mid_sen": "The citation summary data from the ACL Anthology Network 1 (Radev et al., 2009) is used. ", "after_sen": "This dataset is rather large, and since manual annotation of context for each citation is a time consuming task, a subset of 20 target papers (i.e., all citations to these) has been selected for annotation. "}
{"citeStart": 47, "citeEnd": 67, "citeStartToken": 47, "citeEndToken": 67, "sectionName": "UNKNOWN SECTION NAME", "string": "To address this limitation, our previous work (Zhang and Chai, 2009) has initiated an investigation on the problem of conversation entailment. The problem was formulated as follows: given a conversation discourse D and a hypothesis H concerning its participant, the goal was to identify whether D entails H. For instance, as in Example 1, the first hypothesis can be entailed from the conversation segment while the second hypothesis cannot. While our previous work has provided some interesting preliminary observations, it mostly focused on data collection and initial experiments and analysis using a small set of development data. It is not clear whether the previous results are generally applicable, how different components in the entailment framework interact with each other, and how different representations may influence the entailment outcome.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "(2) B is eighty-three.", "mid_sen": "To address this limitation, our previous work (Zhang and Chai, 2009) has initiated an investigation on the problem of conversation entailment. ", "after_sen": "The problem was formulated as follows: given a conversation discourse D and a hypothesis H concerning its participant, the goal was to identify whether D entails H. For instance, as in Example 1, the first hypothesis can be entailed from the conversation segment while the second hypothesis cannot. "}
{"citeStart": 105, "citeEnd": 126, "citeStartToken": 105, "citeEndToken": 126, "sectionName": "UNKNOWN SECTION NAME", "string": "A class of technique that can handle all kinds of functions of random variables without the above problems is the computationally-intensive randomization tests (Noreen, 1989, Ch. 2) (Cohen, 1995, Sec. 5.3 ). These tests have previously used on such functions during the \"message understanding\" (MUC) evaluations (Chinchor et al., 1993) . The randomization test we use is like a randomization version of the paired sample (matched-pair) t test (Cohen, 1995, Sec. 5.3.2) . This is a type of stratified shuffling (Noreen, 1989, Sec. 2.7) . When comparing two techniques, we gather-up all the responses (whether actually of interest or not) produced by one of the two techniques when examining the test data, but not both techniques. Under the null hypothesis, the two techniques are not really different, so any response produced by one of the techniques could have just as likely come from the other. So we shuffle these responses, reassign each response to one of the two techniques (equally likely to either technique) and see how likely such a shuffle produces a difference (new technique minus old technique) in the metric(s) of interest (in our case, precision and F-score) that is at least as large as the difference observed when using the two techniques on the test data. n responses to shuffle and assign 4 leads to 2 n different ways to shuffle and assign those responses. So when n is small, one can try each of the different shuffles once and produce an exact randomization. When n gets large, the number of different shuffles gets too large to be exhaustively evaluated. Then one performs an approximate randomization where each shuffle is performed with random assignments.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A class of technique that can handle all kinds of functions of random variables without the above problems is the computationally-intensive randomization tests (Noreen, 1989, Ch. 2) (Cohen, 1995, Sec. 5.3 ). ", "mid_sen": "These tests have previously used on such functions during the \"message understanding\" (MUC) evaluations (Chinchor et al., 1993) . ", "after_sen": "The randomization test we use is like a randomization version of the paired sample (matched-pair) t test (Cohen, 1995, Sec. 5.3.2) . "}
{"citeStart": 169, "citeEnd": 197, "citeStartToken": 169, "citeEndToken": 197, "sectionName": "UNKNOWN SECTION NAME", "string": "Most psycholinguistic experimentation has been concerned with which scope preferences are made, rather than the point at which the preferences are establishcd (see e.g. Kurtzman and MacDonald, 1993) . Given tile illtuitive evidence, our hypothesis is that scope preferences can sometimes be established early, befbre the end ofa sentence. This leaves open the possibility that in other cases, where the scoping inIbrmation is not particularly of interest to the hearer, preferences are determined late, if at all.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "10) Mary pttt the inIbrmation that statistics show that every 11 seconds a man is mugged here in New York city and that she was to interview him in her diary", "mid_sen": "Most psycholinguistic experimentation has been concerned with which scope preferences are made, rather than the point at which the preferences are establishcd (see e.g. Kurtzman and MacDonald, 1993) . ", "after_sen": "Given tile illtuitive evidence, our hypothesis is that scope preferences can sometimes be established early, befbre the end ofa sentence. "}
{"citeStart": 166, "citeEnd": 181, "citeStartToken": 166, "citeEndToken": 181, "sectionName": "UNKNOWN SECTION NAME", "string": "There has been much work in other fields, including linguistics, literary theory, psychology, philosophy, and content analysis, involving subjective language. As mentioned in Section 2, the conceptualization underlying our manual annotations is based on work in literary theory and linguistics, most directly Dolezel (1973), Uspensky (1973) , Kuroda (1973 Kuroda ( , 1976 , Chatman (1978) , Cohn (1978) , Fodor (1979) , and Banfield (1982) . We also mentioned existing knowledge resources such as affective lexicons (General-Inquirer 2000; Heise 2000) and annotations in more general-purpose lexicons (e.g., the attitude adverb features in Comlex [Macleod, Grishman, and Meyers 1998] ). Such knowledge may be used in future work to complement the work presented in this article, for example, to seed the distributional-similarity process described in Section 3.4.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There has been much work in other fields, including linguistics, literary theory, psychology, philosophy, and content analysis, involving subjective language. ", "mid_sen": "As mentioned in Section 2, the conceptualization underlying our manual annotations is based on work in literary theory and linguistics, most directly Dolezel (1973), Uspensky (1973) , Kuroda (1973 Kuroda ( , 1976 , Chatman (1978) , Cohn (1978) , Fodor (1979) , and Banfield (1982) . ", "after_sen": "We also mentioned existing knowledge resources such as affective lexicons (General-Inquirer 2000; Heise 2000) and annotations in more general-purpose lexicons (e.g., the attitude adverb features in Comlex [Macleod, Grishman, and Meyers 1998] ). "}
{"citeStart": 153, "citeEnd": 176, "citeStartToken": 153, "citeEndToken": 176, "sectionName": "UNKNOWN SECTION NAME", "string": "The parameters of subspace model in Equation 2, S and C were estimated to minimize the negative log-likelihood of the correct class. Training employed conventional Stochastic Gradient Descent (Rumelhart et al., 1985) with mini-batch size 1 and random uniform initialization similar to (Glorot and Bengio, 2010) . After some initial experiments, it was determined that a learning rate of 0.01 and selecting the model with the best accuracy on the 20% set after 8 iterations led to the best results.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The parameters of subspace model in Equation 2, S and C were estimated to minimize the negative log-likelihood of the correct class. ", "mid_sen": "Training employed conventional Stochastic Gradient Descent (Rumelhart et al., 1985) with mini-batch size 1 and random uniform initialization similar to (Glorot and Bengio, 2010) . ", "after_sen": "After some initial experiments, it was determined that a learning rate of 0.01 and selecting the model with the best accuracy on the 20% set after 8 iterations led to the best results."}
{"citeStart": 120, "citeEnd": 140, "citeStartToken": 120, "citeEndToken": 140, "sectionName": "UNKNOWN SECTION NAME", "string": "Note that the experiments in (Carpuat and Wu, 2005) did not use a state-of-the-art MT system, while the experiments in (Vickrey et al., 2005) were not done using a full-fledged MT system and the evaluation was not on how well each source sentence was translated as a whole. The relatively small improvement reported by Cabezas and Resnik (2005) without a statistical significance test appears to be inconclusive. Considering the conflicting results reported by prior work, it is not clear whether a WSD system can help to improve the performance of a state-of-the-art statistical MT system.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "They obtained a relatively small improvement, and no statistical significance test was reported to determine if the improvement was statistically significant.", "mid_sen": "Note that the experiments in (Carpuat and Wu, 2005) did not use a state-of-the-art MT system, while the experiments in (Vickrey et al., 2005) were not done using a full-fledged MT system and the evaluation was not on how well each source sentence was translated as a whole. ", "after_sen": "The relatively small improvement reported by Cabezas and Resnik (2005) without a statistical significance test appears to be inconclusive. "}
{"citeStart": 62, "citeEnd": 82, "citeStartToken": 62, "citeEndToken": 82, "sectionName": "UNKNOWN SECTION NAME", "string": "By extending the analysis of temporal subordinate clauses in (Kamp and Reyle, 1993) , to sentences which include quantification over eventualities, we can propose an alternative DRT solution to Partee's quantification problem. As in (Partee, 1984) , such sentences trigger box-splitting. But now, the location time of the eventuality in the subordinate clause serves as the antecedent for the location time of the eventuality in the main clause. In this approach, each of the relevant temporal markers resides in its appropriate box, yielding the correct quantificational structure. This quantification structure does not need to be stipulated as part of the Q-adverb's meaning, but arises directly from the temporal system. We illustrate this analysis by constructing a DRS in Figure lb for sentence 1.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "By extending the analysis of temporal subordinate clauses in (Kamp and Reyle, 1993) , to sentences which include quantification over eventualities, we can propose an alternative DRT solution to Partee's quantification problem. ", "after_sen": "As in (Partee, 1984) , such sentences trigger box-splitting. "}
{"citeStart": 79, "citeEnd": 102, "citeStartToken": 79, "citeEndToken": 102, "sectionName": "UNKNOWN SECTION NAME", "string": "We represent each citation as a feature set in a Support Vector Machine (SVM) (Cortes and Vapnik, 1995) framework. The corpus is processed using WEKA (Hall et al., 2008) and the Weka LibSVM library (EL-Manzalawy and Honavar, 2005; Chang and Lin, 2001 ). For each i th sentence S i , we use the following binary features.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Furthermore, to ensure there is enough data for training each class, we use 10-fold cross-validation (Lewis, 1991) in all our experiments.", "mid_sen": "We represent each citation as a feature set in a Support Vector Machine (SVM) (Cortes and Vapnik, 1995) framework. ", "after_sen": "The corpus is processed using WEKA (Hall et al., 2008) and the Weka LibSVM library (EL-Manzalawy and Honavar, 2005; Chang and Lin, 2001 ). "}
{"citeStart": 31, "citeEnd": 43, "citeStartToken": 31, "citeEndToken": 43, "sectionName": "UNKNOWN SECTION NAME", "string": "Since semantic classes are often domain-specific, their automatic acquisition is not trivial. Such classes can be derived either by distributional means or from existing taxonomies, knowledge bases, dictionaries, thesauruses, and so on. A prime example of the latter is WordNet which has been used to 1The author is currently at Texas Instruments and all inquiries should be addressed to rajeev@csc.ti.com. provide such semantic classes (Resnik, 1993; Basili et al., 1994) to assist in text understanding. Our efforts to obtain such semantic clusters with limited human intervention have been described elsewhere (Agarwal, 1995) . This paper concentrates on the aspect of evahiating the obtained clusters against classes provided by human experts.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A prime example of the latter is WordNet which has been used to 1The author is currently at Texas Instruments and all inquiries should be addressed to rajeev@csc.ti.com. ", "mid_sen": "provide such semantic classes (Resnik, 1993; Basili et al., 1994) to assist in text understanding. ", "after_sen": "Our efforts to obtain such semantic clusters with limited human intervention have been described elsewhere (Agarwal, 1995) . "}
{"citeStart": 240, "citeEnd": 259, "citeStartToken": 240, "citeEndToken": 259, "sectionName": "UNKNOWN SECTION NAME", "string": "Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities. They proved to be useful in a number of NLP applications such as natural language generation (Iordanskaja et al., 1991) , multidocument summarization (McKeown et al., 2002) , automatic evaluation of MT (Denkowski and Lavie, 2010) , and TE (Dinu and Wang, 2009) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities. ", "mid_sen": "They proved to be useful in a number of NLP applications such as natural language generation (Iordanskaja et al., 1991) , multidocument summarization (McKeown et al., 2002) , automatic evaluation of MT (Denkowski and Lavie, 2010) , and TE (Dinu and Wang, 2009) .", "after_sen": "One of the proposed methods to extract paraphrases relies on a pivot-based approach using phrase alignments in a bilingual parallel corpus (Bannard and Callison-Burch, 2005) . "}
{"citeStart": 126, "citeEnd": 143, "citeStartToken": 126, "citeEndToken": 143, "sectionName": "UNKNOWN SECTION NAME", "string": "mlSystem ruleFeats We provide mlSystem ruleFeats with the same knowledge resources as the rule-based system. All rules from the rule-based system are incorporated into mlSystem ruleFeats as the features. mlSystem ruleFeats + atomFeats We augment mlSystem ruleFeats with more features from our previous work (Markert et al., 2012; Hou et al., 2013a; Hou et al., 2013b) on bridging anaphora recognition and antecedent selection. Some of these features overlap with the atomic features used in the rule-based system. Table 4 shows all the features we use for recognizing bridging anaphora. \" * \" indicates the resources are used in the rule-based system. We apply them to the first element a of a pairwise instance (a, c). Markert et al. (2012) and Hou et al. (2013a) . \"b\" indicates binary, \"n\" nominal, \"l\" lexical features, \" * \" resources used in the rule-based system.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "All rules from the rule-based system are incorporated into mlSystem ruleFeats as the features. ", "mid_sen": "mlSystem ruleFeats + atomFeats We augment mlSystem ruleFeats with more features from our previous work (Markert et al., 2012; Hou et al., 2013a; Hou et al., 2013b) on bridging anaphora recognition and antecedent selection. ", "after_sen": "Some of these features overlap with the atomic features used in the rule-based system. "}
{"citeStart": 72, "citeEnd": 94, "citeStartToken": 72, "citeEndToken": 94, "sectionName": "UNKNOWN SECTION NAME", "string": "For more references and information about these algorithms we refer to (Daelemans et al., 1998; Daelemans et al., 1999b) . For other", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "IGTree : In.this variant, a decision tree is created with features as tests, and ordered according to the information gain of the features, as a heuristic approximation of the computationally more expensive IB1 variants.", "mid_sen": "For more references and information about these algorithms we refer to (Daelemans et al., 1998; Daelemans et al., 1999b) . ", "after_sen": "For other"}
{"citeStart": 119, "citeEnd": 134, "citeStartToken": 119, "citeEndToken": 134, "sectionName": "UNKNOWN SECTION NAME", "string": "The second column of Table 2 gives the results of the POS-based model, the third column gives the results of incorporating the detection and correction of speech repairs and detection of intonational phrase boundary tones, and the fourth column gives the results of adding in silence information. As can be seen, modeling the user's utterances improves POS tagging, identification of discourse markers, and word perplexity; with the POS error rate decreasing by 3.1% and perplexity by 5.3%. Furthermore, adding in silence information to help detect the boundary tones and speech repairs results in a further improvement, with the overall POS tagging error rate decreasing by 8.6% and reducing perplexity by 7.8%. In contrast, a word-based trigram backoff model (Katz, 1987) built with the CMU statistical language modeling toolkit (Rosenfeld, 1995) achieved a perplexity of 26.13. Thus our full language model results in 14.1% reduction in perplexity. Table 3 gives the results of detecting intonational boundaries. The second column gives the results of adding the boundary tone detection to the POS model, the third column adds silence information, Table 4 : Detecting and Correcting Speech Repairs and the fourth column adds speech repair detection and correction. We see that adding in silence information gives a noticeable improvement in detecting boundary tones. Furthermore, adding in the speech repair detection and correction further improves the results of identifying boundary tones. Hence to detect intonational phrase boundaries in spontaneous speech, one should also model speech repairs. Table-4 gives the results of detecting and correcting speech repairs. The detection results report the number of repairs that were detected, regardless of whether the type of repair (e.g. modification repair versus abridged repair) was properly determined. The second column gives the results of adding speech repair detection to the POS model. The third column adds in silence information. Unlike the case for boundary tones, adding silence does not have much of an effect. 4 The fourth column adds in speech repair correction, and shows that taking into account the correction, gives better detection rates (Heeman, Loken-Kim, and Allen, 1996) . The fifth column adds in boundary tone detection, which improves both the detection and correction of speech repairs.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Furthermore, adding in silence information to help detect the boundary tones and speech repairs results in a further improvement, with the overall POS tagging error rate decreasing by 8.6% and reducing perplexity by 7.8%. ", "mid_sen": "In contrast, a word-based trigram backoff model (Katz, 1987) built with the CMU statistical language modeling toolkit (Rosenfeld, 1995) achieved a perplexity of 26.13. ", "after_sen": "Thus our full language model results in 14.1% reduction in perplexity. "}
{"citeStart": 1, "citeEnd": 14, "citeStartToken": 1, "citeEndToken": 14, "sectionName": "UNKNOWN SECTION NAME", "string": "Recently, many people have looked at cascaded and/or shallow parsing and GR assignment. Abney (1991) is one of the first who proposed to split up parsing into several cascades. He suggests to first find the chunks and then the dependecies between these chunks. Grefenstette (1996) describes a cascade of finite-state transducers, which first finds noun and verb groups, then their heads, and finally syntactic functions. Brants and Skut (1998) describe a partially automated annotation tool which constructs a complete parse of a sentence by recursively adding levels to the tree. (Collins, 1997; Ratnaparkhi, 1997) use cascaded processing for full parsing with good results. Argamon et al. (1998) applied Memory-Based Sequence Learning (MBSL) to NP chunking and subject/object identification. However, their subject and object finders are independent of their chunker (i.e. not cascaded).", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Brants and Skut (1998) describe a partially automated annotation tool which constructs a complete parse of a sentence by recursively adding levels to the tree. ", "mid_sen": "(Collins, 1997; Ratnaparkhi, 1997) use cascaded processing for full parsing with good results. ", "after_sen": "Argamon et al. (1998) applied Memory-Based Sequence Learning (MBSL) to NP chunking and subject/object identification. "}
{"citeStart": 47, "citeEnd": 62, "citeStartToken": 47, "citeEndToken": 62, "sectionName": "UNKNOWN SECTION NAME", "string": "Defining dialects is one of the first tasks that linguists need to pursue when approaching a language. Knowing the dialect areas helps one allocate resources in language research and has implications for language learners, publishers, broadcasters, educators, and language planners. Unfortunately, dialect definition can be a timeconsuming and ill-defined process. The traditional approach has been to plot isoglosses, delineating regions where the same word is used for the same concept, or perhaps the same pronunciation for the same phoneme. But isoglosses are frustrating. The first problem, as Gaston Paris noted (apud Durand, 1889:49) , is that isoglosses rarely coincide. At best, isoglosses for different features approach each other, forming vague bundles; at *I thank Martin Kay, Paul Kiparsky, Tom Wasow, and a reviewer for helpful comments.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "But isoglosses are frustrating. ", "mid_sen": "The first problem, as Gaston Paris noted (apud Durand, 1889:49) , is that isoglosses rarely coincide. ", "after_sen": "At best, isoglosses for different features approach each other, forming vague bundles; at *I thank Martin Kay, Paul Kiparsky, Tom Wasow, and a reviewer for helpful comments."}
{"citeStart": 1, "citeEnd": 19, "citeStartToken": 1, "citeEndToken": 19, "sectionName": "UNKNOWN SECTION NAME", "string": "The MPQA corpus contains news articles manually annotated using an annotation scheme for subjectivity (opinions and other private states that cannot be directly observed or verified. (Quirk et al., 1985) , such as beliefs, emotions, sentiment, speculation, etc.). This corpus was collected and annotated as part of the summer 2002 NRRC Workshop on Multi-Perspective Question Answering (MPQA) sponsored by ARDA. It contains 535 documents and 10,657 sentences. The annotation scheme contains two main components: a type of explicit private state and speech event, and a type of expressive subjective element. Several detailed attributes and strengths are annotated as well. More details are provided in .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The MPQA corpus contains news articles manually annotated using an annotation scheme for subjectivity (opinions and other private states that cannot be directly observed or verified. ", "mid_sen": "(Quirk et al., 1985) , such as beliefs, emotions, sentiment, speculation, etc.). ", "after_sen": "This corpus was collected and annotated as part of the summer 2002 NRRC Workshop on Multi-Perspective Question Answering (MPQA) sponsored by ARDA. "}
{"citeStart": 66, "citeEnd": 87, "citeStartToken": 66, "citeEndToken": 87, "sectionName": "UNKNOWN SECTION NAME", "string": "Collaborative negoti~ion occurs when conflicts arise among agents developing a shared plan 1 during collaborative planning. A collaborative agent is driven by the goal of developing a plan that best satisfies the interests of all the agents as a group, instead of one that maximizes his own interest. This results in several distinctive features of collaborative negotiation: 1) A collaborative agent does not insist on winning an argument, and may change his beliefs ff another agent presents convincing justification for an opposing belief. This differentiates collaborative negotiation from argumentation (Birnbaum et al., 1980; Reichman, 1981; Cohen, 1987; Quilici, 1992) . 2) Agents involved in collaborative negotiation are open and honest with one another; they will not deliberately present false information to other agents, present information in such a way as to mislead the other agents, or strategically hold back information from other agents for later use. This distinguishes collaborative negotiation from non-collaborative negotiation such as labor negotiation (Sycara, 1989) . 3) Collaborative agents are interested in 1The notion of shared plan has been used in (Grosz and Sidner, 1990; Allen, 1991) . others' beliefs in order to decide whether to revise their own beliefs so as to come to agreement (Chu-Carroll and Carberry, 1995) . Although agents involvedin argumentation and non-collaborative negotiation take other agents' beliefs into consideration, they do so mainly to find weak points in their opponents' beliefs and attack them to win the argument.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "1) A collaborative agent does not insist on winning an argument, and may change his beliefs ff another agent presents convincing justification for an opposing belief. ", "mid_sen": "This differentiates collaborative negotiation from argumentation (Birnbaum et al., 1980; Reichman, 1981; Cohen, 1987; Quilici, 1992) . ", "after_sen": "2) Agents involved in collaborative negotiation are open and honest with one another; they will not deliberately present false information to other agents, present information in such a way as to mislead the other agents, or strategically hold back information from other agents for later use. "}
{"citeStart": 174, "citeEnd": 191, "citeStartToken": 174, "citeEndToken": 191, "sectionName": "UNKNOWN SECTION NAME", "string": "Finally, we evaluated SLBD in comparison with other bilingual semi-supervised methods, including (Xu et al., 2008) (Xu) ; (Ma and Way, 2009) (Ma) ; (Xi et al., 2012) (Xi) ; (Zeng et al., 2014 . The results presented in Table 4 indicate that SLBD demonstrates much stronger performance, primarily because these other methods were developed with a focus on SMT, which causes them to preferentially decrease the perplexity of the subsequent SMT steps rather than producing a highly accurate segmentation. In contrast to these methods, the SLBD method exhibits greater generalizability.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The results demonstrate that either leveraging the same unlabeled data or providing a much larger unlabeled dataset for the monolingual semisupervised methods, the SLBD method can significantly outperform the evaluated monolingual semi-supervised methods, which indicates that the segmenting information obtained using SLBD is much more efficient at optimizing segmentation.", "mid_sen": "Finally, we evaluated SLBD in comparison with other bilingual semi-supervised methods, including (Xu et al., 2008) (Xu) ; (Ma and Way, 2009) (Ma) ; (Xi et al., 2012) (Xi) ; (Zeng et al., 2014 . ", "after_sen": "The results presented in Table 4 indicate that SLBD demonstrates much stronger performance, primarily because these other methods were developed with a focus on SMT, which causes them to preferentially decrease the perplexity of the subsequent SMT steps rather than producing a highly accurate segmentation. "}
{"citeStart": 298, "citeEnd": 320, "citeStartToken": 298, "citeEndToken": 320, "sectionName": "UNKNOWN SECTION NAME", "string": "Standard symbolic machine learning techniques have been successfully applied to a number of tasks in natural language processing (NLP). Examples include the use of decision trees for syntactic analysis (Magerman, 1995) , coreference (Aone and Bennett, 1995; McCarthy and Lehnert, 1995) , and cue phrase identification (Litman, 1994) ; the use of inductive logic programming for learning semantic grammars and building prolog parsers (Zelle and Mooney, 1994; Zelle and Mooney, 1993) ; the use of conceptual clustering algorithms for relative pronoun resolution (Cardie, 1992a; Cardie 1992b) , and the use of case-based learning techniques for lexical tagging tasks (Cardie, 1993a; Daelemans et al., submitted) . In theory, both statistical and machine learning techniques can significantly reduce the knowledge-engineering effort for building large-scale NLP systems: they offer an automatic means for acquiring robust heuristics for a host of lexical and structural disambiguation tasks. It is well-known in the machine learning community, however, that the success of a learning algorithm depends critically on the representation used to describe the training and test instances (Almuallim and Dietterich, 1991, Langley and Sage, in press ). Unfortunately, the task of designing an appropriate instance representation --also known as feature set selection --can be extraordinarily difficult, time-consuming, and knowledge-intensive (Quinlan, 1983) . This poses a problem for current statistical and machine learning approaches to natural language understanding where a new instance representation is typically required for each linguistic task tackled.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Standard symbolic machine learning techniques have been successfully applied to a number of tasks in natural language processing (NLP). ", "mid_sen": "Examples include the use of decision trees for syntactic analysis (Magerman, 1995) , coreference (Aone and Bennett, 1995; McCarthy and Lehnert, 1995) , and cue phrase identification (Litman, 1994) ; the use of inductive logic programming for learning semantic grammars and building prolog parsers (Zelle and Mooney, 1994; Zelle and Mooney, 1993) ; the use of conceptual clustering algorithms for relative pronoun resolution (Cardie, 1992a; Cardie 1992b) , and the use of case-based learning techniques for lexical tagging tasks (Cardie, 1993a; Daelemans et al., submitted) . ", "after_sen": "In theory, both statistical and machine learning techniques can significantly reduce the knowledge-engineering effort for building large-scale NLP systems: they offer an automatic means for acquiring robust heuristics for a host of lexical and structural disambiguation tasks. "}
{"citeStart": 200, "citeEnd": 223, "citeStartToken": 200, "citeEndToken": 223, "sectionName": "UNKNOWN SECTION NAME", "string": "Natural language involves statements that do not contain complete, exact, and unbiased information. Many of these are subjective, which share the common property described in narrative theory (Banfield, 1982) as \"(subjective statements) must all be referred to the speaking subject for interpretation\". Wiebe (1990) further adapted this definition of subjectivity to be \"the linguistic expression of private states (Quirk et al., 1985) \". So far, linguistic cues have played an important role in research of subjectivity recognition (e.g. (Wilson et al., 2006) ), sentiment analysis (e.g. Pang and Lee, 2004) ), and emotion studies (e.g. (Pennebaker et al., 2001) ). While most linguistic cues are grouped under the general rubric of subjectivity, they are usually originated from different dimensions, including:", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Wiebe (1990) further adapted this definition of subjectivity to be \"the linguistic expression of private states (Quirk et al., 1985) \". ", "mid_sen": "So far, linguistic cues have played an important role in research of subjectivity recognition (e.g. (Wilson et al., 2006) ), sentiment analysis (e.g. Pang and Lee, 2004) ), and emotion studies (e.g. (Pennebaker et al., 2001) ). ", "after_sen": "While most linguistic cues are grouped under the general rubric of subjectivity, they are usually originated from different dimensions, including:"}
{"citeStart": 71, "citeEnd": 96, "citeStartToken": 71, "citeEndToken": 96, "sectionName": "UNKNOWN SECTION NAME", "string": "Running time for English is faster, because the average number of candidate phonemes for each letter is lower. We measured running time (including training and the actual g2p conversion in 10-fold cross validation) for a Perl implementation of our algorithm on the English NetTalk corpus (20,008 words) on an Intel Pentium 4, 3.0 GHz machine. Running time was less than 1h for each of the following three test conditions: c1) g2p conversion only, c2) syllabification first, then g2p conversion, c3) simultaneous g2p conversion and syllabification, given perfect syllable boundary input, c4) simultaneous g2p conversion and syllabification when correct syllabification is not available beforehand. This is much faster than the times for Pronunciation by Analogy (PbA) (Marchand and Damper, 2005) on the same corpus. Marchand and Damper reported a processing time of several hours for c4), two days for c2) and several days for c3).", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Running time was less than 1h for each of the following three test conditions: c1) g2p conversion only, c2) syllabification first, then g2p conversion, c3) simultaneous g2p conversion and syllabification, given perfect syllable boundary input, c4) simultaneous g2p conversion and syllabification when correct syllabification is not available beforehand. ", "mid_sen": "This is much faster than the times for Pronunciation by Analogy (PbA) (Marchand and Damper, 2005) on the same corpus. ", "after_sen": "Marchand and Damper reported a processing time of several hours for c4), two days for c2) and several days for c3)."}
{"citeStart": 91, "citeEnd": 112, "citeStartToken": 91, "citeEndToken": 112, "sectionName": "UNKNOWN SECTION NAME", "string": "Because of considerations like these, our aim in the implementation work was to treat tense, aspect, cue words and rhetorical relations as mutually constraining, with more specific information such as explicit cue words having higher priority than less specific information such as tense. The main advantage of this approach is that it reduces temporal structure ambiguity without having to rely on detailed world knowledge postulates. Table 1 lists the possible temporal relations between the eventualities described by two consecutive sentences without temporal expressions or cue words, where the first sentence (S1) may have any tense and aspect and the second sentence (S~) expresses a simple past event. We constrain $2 in this way because of lack of space; additional constraints are given in (Hitzeman et al., 1994) . For example, if a simple past eventive sentence follows a simple past eventive sentence the second event can be understood to occur just after the first, to precede the first or to refer to the same event as the first (an elaboration relation), but the two events cannot overlap; these constraints are weaker, however, than explicit clues such as cue words to rhetorical relations and temporal expressions. When $1 expresses a state, it is possible for the temporal relation to hold between the event described by $2 and the event or activity most closely preceding $1, i.e., the temporal focus of $1, here referred to as TF1.1 However, we haven't solved the problem completely at this point: although tense can provide a further constraint on the temporal structure of such discourses, it can also add a further ambiguity. Consider (9):(9) Sam rang the bell. He had lost the key. Clearly, the event described by the past perfect sentence must precede the event described by the first, simple past sentence. However, if a third sentence is added, an ambiguity results. Consider the following possible continuations of (9): The temporal relation between these continuations and the portion of earlier text they attach to is constrained along the lines sketched before. The problem here is determining which thread in (9) they continue; (10a) continues the thread in which Sam rings the bell, but (10b) continues the thread in which Sam loses the key.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Table 1 lists the possible temporal relations between the eventualities described by two consecutive sentences without temporal expressions or cue words, where the first sentence (S1) may have any tense and aspect and the second sentence (S~) expresses a simple past event. ", "mid_sen": "We constrain $2 in this way because of lack of space; additional constraints are given in (Hitzeman et al., 1994) . ", "after_sen": "For example, if a simple past eventive sentence follows a simple past eventive sentence the second event can be understood to occur just after the first, to precede the first or to refer to the same event as the first (an elaboration relation), but the two events cannot overlap; these constraints are weaker, however, than explicit clues such as cue words to rhetorical relations and temporal expressions. "}
{"citeStart": 280, "citeEnd": 299, "citeStartToken": 280, "citeEndToken": 299, "sectionName": "UNKNOWN SECTION NAME", "string": "There have been successful attempts at using machine learning in search of a solution for linguistic tasks, e.g. discriminating between discourse and sentential senses of cues ( [Litman 1996]) or resolution of coreferences in texts ([McCarthy & Lehnert 1995] ). Like our work, these problems are cast as classification problems, and then machine learning (mainly C4.5) techniques are used to induce classifiers for each class. What makes these applications different from ours is that they have worked on surface linguistic or mixed surface linguistic and intonational representation, and that the classes are relatively balanced, while in our case the class of compound sentences is much less numerous than the class of non-composite sentences. Such unbalanced classes create problems for the majority of inductive learning systems. A distinctive feature of our work is the fact that we used machine learning techniques to improve an existing rule-based natural language processor from the inside. This contrasts with approaches where there are essentially no explicit rules, such as neural networks (e.g. [Buo 1996]) , or approaches where the machine learning algorithms attempt to infer--via deduction (e.g. [Samuelsson 1994 ]), induction (e.g. [Theeramunkong et al. 1997] ; [Zelle & Mooney 1994] ) under user cooperation (e.g. [Simmons & Yu 1992] ; [Hermjakob & Mooney 1997] ), transformation-based error-driven learning (e.g. [Brill 1993]) , or even decision trees (e.g. [Magerman 1995] )--a grammar from raw or preprocessed data. In our work, we do not wish to acquire a grammar: we have one and want to devise a mechanism to make some of its parts adaptable to the corpus at hand or, to improve some aspect of its performance. Other researchers, such as [Lawrence et al. 1996] , have compared neural networks and machine learning methods at the task of sentence classification. In this task, the system must classify a string as either grammatical or not. We do not content ourselves with results based on a grammatical/ungrammatical dichotomy. We are looking for heuristics, using relevant features, that will do better than the current ones and improve the overall performance of a natural language processor: this is a very difficult problem (see, e.g., [Huyck & Lytinen 1993] ). One could also look at this problem as one of optimisation of a rule-based system.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A distinctive feature of our work is the fact that we used machine learning techniques to improve an existing rule-based natural language processor from the inside. ", "mid_sen": "This contrasts with approaches where there are essentially no explicit rules, such as neural networks (e.g. [Buo 1996]) , or approaches where the machine learning algorithms attempt to infer--via deduction (e.g. [Samuelsson 1994 ]), induction (e.g. [Theeramunkong et al. 1997] ; [Zelle & Mooney 1994] ) under user cooperation (e.g. [Simmons & Yu 1992] ; [Hermjakob & Mooney 1997] ), transformation-based error-driven learning (e.g. [Brill 1993]) , or even decision trees (e.g. [Magerman 1995] )--a grammar from raw or preprocessed data. ", "after_sen": "In our work, we do not wish to acquire a grammar: we have one and want to devise a mechanism to make some of its parts adaptable to the corpus at hand or, to improve some aspect of its performance. "}
{"citeStart": 93, "citeEnd": 104, "citeStartToken": 93, "citeEndToken": 104, "sectionName": "UNKNOWN SECTION NAME", "string": "We explore the effect of this context on citation sentiment detection. For a baseline, we use features of the state-of-the-art system proposed in our earlier work (Athar, 2011) . While there we used n-gram and dependency feature on sentences containing explicit citations only, our annotation is not restricted to such citations and we may have more than one While this test may not be adequate as the data is highly skewed, we are reporting the results since there is no obvious alternative for discrete skewed data. In future, we plan to use the continuous probability estimates produced by the classifier for testing significance. sentiment per each explicit citation. For example, in Figure 2 , our 2011 system will be restricted to analysing sentence 33 only. However, it is clear from our annotation that there is more sentiment present in the succeeding sentences which belongs to this explicit citation. While sentence 34 in Figure 2 is positive towards the cited paper, the next sentence criticises it. Thus for this explicit citation, there are three sentences with sentiment and all of them are related to the same explicit citation. Treating these sentences separately will result in an artificial increase in the amount of data because they participate in the same discourse. It would also make it impossible to compare the sentiment annotated in the previous work with our annotation.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We explore the effect of this context on citation sentiment detection. ", "mid_sen": "For a baseline, we use features of the state-of-the-art system proposed in our earlier work (Athar, 2011) . ", "after_sen": "While there we used n-gram and dependency feature on sentences containing explicit citations only, our annotation is not restricted to such citations and we may have more than one While this test may not be adequate as the data is highly skewed, we are reporting the results since there is no obvious alternative for discrete skewed data. "}
{"citeStart": 107, "citeEnd": 123, "citeStartToken": 107, "citeEndToken": 123, "sectionName": "UNKNOWN SECTION NAME", "string": "A test set of syntactically ambiguous noun compounds was extracted from our 8 million word Grolier's encyclopedia corpus in the following way. 2 Because the corpus is not tagged or parsed, a somewhat conservative strategy of looking for unambiguous sequences of nouns was used. To distinguish nouns from other words, the University of Pennsylvania morphological analyser (described in Karp et al, 1992) was used to generate the set of words that can only be used as nouns (I shall henceforth call this set AZ). All consecutive sequences of these words were extracted, and the three word sequences used to form the test set. For reasons made clear below, only sequences consisting entirely of words from Roget's thesaurus were retained, giving a total of 308 test triples. 3 These triples were manually analysed using as context the entire article in which they appeared. In 2We would like to thank Grolier's for permission to use this material for research purposes.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "2 Because the corpus is not tagged or parsed, a somewhat conservative strategy of looking for unambiguous sequences of nouns was used. ", "mid_sen": "To distinguish nouns from other words, the University of Pennsylvania morphological analyser (described in Karp et al, 1992) was used to generate the set of words that can only be used as nouns (I shall henceforth call this set AZ). ", "after_sen": "All consecutive sequences of these words were extracted, and the three word sequences used to form the test set. "}
{"citeStart": 167, "citeEnd": 185, "citeStartToken": 167, "citeEndToken": 185, "sectionName": "UNKNOWN SECTION NAME", "string": "• We generalize cube pruning and adapt it to two systems very different from Hiero: a phrasebased system similar to Pharaoh (Koehn, 2004) and a tree-to-string system (Huang et al., 2006) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We push the idea behind this method further and make the following contributions in this paper:", "mid_sen": "• We generalize cube pruning and adapt it to two systems very different from Hiero: a phrasebased system similar to Pharaoh (Koehn, 2004) and a tree-to-string system (Huang et al., 2006) .", "after_sen": "• We also devise a faster variant of cube pruning, called cube growing, which uses a lazy version of k-best parsing (Huang and Chiang, 2005) that tries to reduce k to the minimum needed at each node to obtain the desired number of hypotheses at the root."}
{"citeStart": 186, "citeEnd": 211, "citeStartToken": 186, "citeEndToken": 211, "sectionName": "UNKNOWN SECTION NAME", "string": "The idea of using a bridge (i.e., full-form) to obtain translation entries for unseen words (i.e., abbreviation) is similar to the idea of using paraphrases in MT (see Callison-Burch et al. (2006) and references therein) as both are trying to introduce generalization into MT. At last, the goal that we aim to exploit monolingual corpora to help MT is in-spirit similar to the goal of using non-parallel corpora to help MT as aimed in a large amount of work (see Munteanu and Marcu (2006) and references therein).", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The idea of using a bridge (i.e., full-form) to obtain translation entries for unseen words (i.e., abbreviation) is similar to the idea of using paraphrases in MT (see Callison-Burch et al. (2006) and references therein) as both are trying to introduce generalization into MT. ", "mid_sen": "At last, the goal that we aim to exploit monolingual corpora to help MT is in-spirit similar to the goal of using non-parallel corpora to help MT as aimed in a large amount of work (see Munteanu and Marcu (2006) and references therein).", "after_sen": ""}
{"citeStart": 117, "citeEnd": 131, "citeStartToken": 117, "citeEndToken": 131, "sectionName": "UNKNOWN SECTION NAME", "string": "The SPATTER parser is a history-based parser that uses decision tree models to guide the operations of a few tree building procedures. It differs from the maximum entropy parser in how it builds trees and more critically, in how its decision trees use information. The SPATTER decision trees use predicates on word classes created with a statistical clustering technique, whereas the maximum entropy parser uses predicates that contain merely the words themselves, and thus lacks the need for a (typically expensive) word clustering procedure. Furthermore, the top K BFS search heuristic appears to be much simpler than the stack decoder algorithm outlined in (Magerman, 1995) .", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The SPATTER decision trees use predicates on word classes created with a statistical clustering technique, whereas the maximum entropy parser uses predicates that contain merely the words themselves, and thus lacks the need for a (typically expensive) word clustering procedure. ", "mid_sen": "Furthermore, the top K BFS search heuristic appears to be much simpler than the stack decoder algorithm outlined in (Magerman, 1995) .", "after_sen": ""}
{"citeStart": 138, "citeEnd": 161, "citeStartToken": 138, "citeEndToken": 161, "sectionName": "UNKNOWN SECTION NAME", "string": "We have given an account of resource sharing in the syntax/semantics interface of LFG. The multiple use of semantic contributions results from viewing dependencies in f-structures as resources; in this way the one-to-one correspondence between f-structure relations and meanings is maintained. The resulting account does not suffer from overgeneration inherent in other approaches, and applies equally to cases of resource sharing that do not involve coordination. Furthermore, it lends itself readily to an extension for the intensional verb case that has advantages over the widely-assumed account of Partee and Rooth (1983) .Here we have separated the issue of arriving at the appropriate f-structure in the syntax from the issue of deriving the correct semantics from the f-structure. We have argued that this is the correct distinction to make, and have given a treatment of the second issue. A treatment of the first issue will be articulated in a future forum.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The resulting account does not suffer from overgeneration inherent in other approaches, and applies equally to cases of resource sharing that do not involve coordination. ", "mid_sen": "Furthermore, it lends itself readily to an extension for the intensional verb case that has advantages over the widely-assumed account of Partee and Rooth (1983) .", "after_sen": "Here we have separated the issue of arriving at the appropriate f-structure in the syntax from the issue of deriving the correct semantics from the f-structure. "}
{"citeStart": 156, "citeEnd": 171, "citeStartToken": 156, "citeEndToken": 171, "sectionName": "UNKNOWN SECTION NAME", "string": "x 3 :VPB → x 1 x 3 with x 2 Figure 1 : Example translation rule r 1 . The Chinese conjunction yǔ \"and\" is translated into English prep. \"with\". also inefficient to extract rules separately from each of these very similar trees (or from the cross-product of k 2 similar tree-pairs in tree-to-tree models). We instead propose a novel approach that extracts rules from packed forests (Section 3), which compactly encodes many more alternatives than kbest lists. Experiments (Section 5) show that forestbased extraction improves BLEU score by over 1 point on a state-of-the-art tree-to-string system (Liu et al., 2006; Mi et al., 2008) , which is also 0.5 points better than (and twice as fast as) extracting on 30-best parses. When combined with our previous orthogonal work on forest-based decoding (Mi et al., 2008) , the forest-forest approach achieves a 2.5 BLEU points improvement over the baseline, and even outperforms the hierarchical system of Hiero, one of the best-performing systems to date.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We instead propose a novel approach that extracts rules from packed forests (Section 3), which compactly encodes many more alternatives than kbest lists. ", "mid_sen": "Experiments (Section 5) show that forestbased extraction improves BLEU score by over 1 point on a state-of-the-art tree-to-string system (Liu et al., 2006; Mi et al., 2008) , which is also 0.5 points better than (and twice as fast as) extracting on 30-best parses. ", "after_sen": "When combined with our previous orthogonal work on forest-based decoding (Mi et al., 2008) , the forest-forest approach achieves a 2.5 BLEU points improvement over the baseline, and even outperforms the hierarchical system of Hiero, one of the best-performing systems to date."}
{"citeStart": 77, "citeEnd": 104, "citeStartToken": 77, "citeEndToken": 104, "sectionName": "UNKNOWN SECTION NAME", "string": "The HPSG grammar developed with MicroCUF models a fragment of German. Since our focus is on the lexicon, the range of syntactic variation treated is currently limited to simplex sentences with canonical word order. We have incorporated some recent developments of HPSG, esp. the revisions of Pollard & Sag (1994, ch. 9) , Manning & Sag (1995) 's proposal for an independent level of argument structure and Bouma (1997) 's use of argument structure to eliminate procedural lexical rules in favour of relational constraints. Our elaborate ontology of semantic types -useful for non-trivial acquisition of selectional restrictions and nominal sorts -was derived from a systematic corpus study of a biological domain (Knodel 1980, 154-188) . The grammar also covers all valence classes encountered in the corpus. As for the lexicon format, we currently list full forms only. Clearly, a morphology component would supply more contextual information from known affixes but would still require the processing of unknown stems.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Since our focus is on the lexicon, the range of syntactic variation treated is currently limited to simplex sentences with canonical word order. ", "mid_sen": "We have incorporated some recent developments of HPSG, esp. the revisions of Pollard & Sag (1994, ch. 9) , Manning & Sag (1995) 's proposal for an independent level of argument structure and Bouma (1997) 's use of argument structure to eliminate procedural lexical rules in favour of relational constraints. ", "after_sen": "Our elaborate ontology of semantic types -useful for non-trivial acquisition of selectional restrictions and nominal sorts -was derived from a systematic corpus study of a biological domain (Knodel 1980, 154-188) . "}
{"citeStart": 198, "citeEnd": 208, "citeStartToken": 198, "citeEndToken": 208, "sectionName": "UNKNOWN SECTION NAME", "string": "In addition, a χ 2 dependency analysis showed that the NM presence interacts significantly with both AsrMis (p<0.02) and SemMis (p<0.001), with fewer than expected AsrMis and SemMis in the 3 Due to random assignment to conditions, before the first problem the F and S populations are similar (e.g. no difference in pretest); thus any differences in metrics can be attributed to the NM presence/absence. However, in the second problem, the two populations are not similar anymore as they have received different forms of instruction; thus any difference has to be attributed to the NM presence/absence in this problem as well as to the NM absence/presence in the previous problem. 4 Due to logging issues, 2 S users are excluded from this analysis (13 F and 13 S users remaining). We run the subjective metric analysis from Section 5.1 on this subset and the results are similar. NM condition. The fact that in the second problem the differences are much smaller (e.g. 2% for AsrMis) and that the NM-AsrMis and NM-SemMis interactions are not significant anymore, suggests that our observations can not be attributed to a difference in population with respect to system's ability to recognize their speech. We hypothesize that these differences are due to the NM text influencing users' lexical choice. Discourse structure has been successfully used in non-interactive settings (e.g. understanding specific lexical and prosodic phenomena (Hirschberg and Nakatani, 1996) , natural language generation (Hovy, 1993) , essay scoring (Higgins et al., 2004) as well as in interactive settings (e.g. predictive/generative models of postural shifts (Cassell et al., 2001) , generation/interpretation of anaphoric expressions (Allen et al., 2001) , performance modeling (Rotaru and Litman, 2006) ).", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We hypothesize that these differences are due to the NM text influencing users' lexical choice. ", "mid_sen": "Discourse structure has been successfully used in non-interactive settings (e.g. understanding specific lexical and prosodic phenomena (Hirschberg and Nakatani, 1996) , natural language generation (Hovy, 1993) , essay scoring (Higgins et al., 2004) as well as in interactive settings (e.g. predictive/generative models of postural shifts (Cassell et al., 2001) , generation/interpretation of anaphoric expressions (Allen et al., 2001) , performance modeling (Rotaru and Litman, 2006) ).", "after_sen": "In this paper, we study the utility of the discourse structure on the user side of a dialogue system. "}
{"citeStart": 73, "citeEnd": 101, "citeStartToken": 73, "citeEndToken": 101, "sectionName": "UNKNOWN SECTION NAME", "string": "Our work is in line with these studies, all of which focus on the relation between linguistic expressions, prosody, dialogue content and gestures. In this paper, we investigate how feedback expressions can be classified into different dialogue act categories based on prosodic and gesture features. Our data are made up by a collection of eight video-recorded map-task dialogues in Danish, which were annotated with phonetic and prosodic information. We find that prosodic features improve the classification of dialogue acts and that head gestures, where they occur, contribute to the semantic interpretation of feedback expressions. The results, which partly confirm those obtained on a smaller dataset in Paggio and Navarretta (2010) , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions. The classification results improve, however, if similar categories such as head nods and jerks are collapsed into a more general category.", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We find that prosodic features improve the classification of dialogue acts and that head gestures, where they occur, contribute to the semantic interpretation of feedback expressions. ", "mid_sen": "The results, which partly confirm those obtained on a smaller dataset in Paggio and Navarretta (2010) , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions. ", "after_sen": "The classification results improve, however, if similar categories such as head nods and jerks are collapsed into a more general category."}
{"citeStart": 162, "citeEnd": 173, "citeStartToken": 162, "citeEndToken": 173, "sectionName": "UNKNOWN SECTION NAME", "string": "LEXAS assumes that each word in an input sen-tence has been pre-tagged with its correct POS, so that the possible senses to consider for a content word w are only those associated with the particular POS of w in the sentence. For instance, given the sentence \"A reduction of principal and interest is one way the problem may be solved.\", since the word \"interest\" appears as a noun in this sentence, LEXAS will only consider the noun senses of \"interest\" but not its verb senses. That is, LEXAS is only concerned with disambiguating senses of a word in a given POS. Making such an assumption is reasonable since POS taggers that can achieve accuracy of 96% are readily available to assign POS to unrestricted English sentences (Brill, 1992; Cutting et al., 1992) . In addition, sense definitions are only available for root words in a dictionary. These are words that are not morphologically inflected, such as \"interest\" (as opposed to the plural form \"interests\"), \"fall\" (as opposed to the other inflected forms like \"fell\", \"fallen\", \"falling\", \"falls\"), etc. The sense of a morphologically inflected content word is the sense of its uninflected form. LEXAS follows this convention by first converting each word in an input sentence into its morphological root using the morphological analyzer of WORD NET, before assigning the appropriate word sense to the root form.", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "That is, LEXAS is only concerned with disambiguating senses of a word in a given POS. ", "mid_sen": "Making such an assumption is reasonable since POS taggers that can achieve accuracy of 96% are readily available to assign POS to unrestricted English sentences (Brill, 1992; Cutting et al., 1992) . ", "after_sen": "In addition, sense definitions are only available for root words in a dictionary. "}
{"citeStart": 36, "citeEnd": 57, "citeStartToken": 36, "citeEndToken": 57, "sectionName": "UNKNOWN SECTION NAME", "string": "Compared to the research on English, the research on Chinese SRL is still in its infancy stage. Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English, such as Sun and Jurafsky (2004) , and Xue (2008) . Sun and Jurafsky (2004) did the preliminary work on Chinese SRL without any large semantically annotated corpus of Chinese. They just labeled the predicate-argument structures of ten specified verbs to a small collection of Chinese sentences, and used Support Vector Machines to identify and classify the arguments. This paper made the first attempt on Chinese SRL and produced promising results. After the PropBank (Xue and Palmer 2003) was built, and Xue (2008) have produced more complete and systematic research on Chinese SRL. Moschitti et al. (2005) has made some preliminary attempt on the idea of hierarchical semantic role labeling. However, without considerations on how to utilize the characteristics of linguistically similar semantic roles, the purpose of the hierarchical system is to simplify the classification process to make it less time consuming. So the hierarchical system in their paper performs a little worse than the traditional SRL systems, although it is more efficient. Xue and Palmer (2004) did very encouraging work on the feature calibration of semantic role labeling. They found out that different features suited for different sub tasks of SRL, i.e. semantic role identification and classification. For semantic analysis, developing features that capture the right kind of information is crucial. Experiments on Chinese SRL (Xue and Palmer 2005, Xue 2008) reassured these findings.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For semantic analysis, developing features that capture the right kind of information is crucial. ", "mid_sen": "Experiments on Chinese SRL (Xue and Palmer 2005, Xue 2008) reassured these findings.", "after_sen": "In this paper, we mainly focus on the semantic role classification (SRC) process. "}
{"citeStart": 104, "citeEnd": 122, "citeStartToken": 104, "citeEndToken": 122, "sectionName": "UNKNOWN SECTION NAME", "string": "It is well known that a simple tabulation of frequencies of certain words participating in certain configurations, for example of frequencies of pairs of a transitive main verb and the head noun of its direct object, cannot be reliably used for comparing the likelihoods of different alternative configurations. The problemis that for large enough corpora the number of possible joint events is much larger than the number of event occurrences in the corpus, so many events are seen rarely or never, making their frequency counts unreliable estimates of their probabilities. Hindle (1990) proposed dealing with the sparseness problem by estimating the likelihood of unseen events from that of \"similar\" events that have been seen. For instance, one may estimate the likelihood of a particular direct object for a verb from the likelihoods of that direct object for similar verbs. This requires a reasonable definition of verb similarity and a similarity estimation method. In Hindle's proposal, words are similar if we have strong statistical evidence that they tend to participate in the same events. His notion of similarity seems to agree with our intuitions in many cases, but it is not clear how it can be used directly to construct word classes and corresponding models of association. Our research addresses some of the same questions and uses similar raw data, but we investigate how to factor word association tendencies into associations of words to certain hidden senses classes and associations between the classes themselves. While it may be worth basing such a model on preexisting sense classes (Resnik, 1992) , in the work described here we look at how to derive the classes directly from distributional data. More specifically, we model senses as probabilistic concepts or clusters c with corresponding cluster membership probabilities p(clw ) for each word w. Most other class-based modeling techniques for natural language rely instead on \"hard\" Boolean classes (Brown et al., 1990) . Class construction is then combinatorially very demanding and depends on frequency counts for joint events involving particular words, a potentially unreliable source of information as noted above. Our approach avoids both problems.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "More specifically, we model senses as probabilistic concepts or clusters c with corresponding cluster membership probabilities p(clw ) for each word w. ", "mid_sen": "Most other class-based modeling techniques for natural language rely instead on \"hard\" Boolean classes (Brown et al., 1990) . ", "after_sen": "Class construction is then combinatorially very demanding and depends on frequency counts for joint events involving particular words, a potentially unreliable source of information as noted above. "}
{"citeStart": 120, "citeEnd": 146, "citeStartToken": 120, "citeEndToken": 146, "sectionName": "UNKNOWN SECTION NAME", "string": "Disappointingly, we did not succeed in establishing a clear improvement for more than one of the six corpora. Although we have not been successful in Figure 6 : Learning curve for Super GREC Figure 7 : Learning curve for EPI proving our initial hypothesis we argue that our results calls for further study due to several concerns raised by the results remaining unanswered. It may be that our notion of distance to lexical resource entries is too naive. A possible future direction would be to compare the query string to retrieved results using a method similar to that of Tsuruoka and Tsujii (2003) . This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It may be that our notion of distance to lexical resource entries is too naive. ", "mid_sen": "A possible future direction would be to compare the query string to retrieved results using a method similar to that of Tsuruoka and Tsujii (2003) . ", "after_sen": "This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry."}
{"citeStart": 88, "citeEnd": 110, "citeStartToken": 88, "citeEndToken": 110, "sectionName": "UNKNOWN SECTION NAME", "string": "The key components of OPINE described in this paper are the PMI feature assessment which leads to high-precision feature extraction and the use of relaxation-labeling in order to find the semantic orientation of potential opinion words. The review-mining work most relevant to our research is that of (Hu and Liu, 2004) and (Kobayashi et al., 2004) . Both identify product features from reviews, but OPINE significantly improves on both. (Hu and Liu, 2004) doesn't assess candidate features, so its precision is lower than OPINE's. (Kobayashi et al., 2004) employs an iterative semi-automatic approach which requires human input at every iteration. Neither model explicitly addresses composite (feature of feature) or implicit features. Other systems (Morinaga et al., 2002; Kushal et al., 2003) also look at Web product reviews but they do not extract opinions about particular product features. OPINE's use of meronymy lexico-syntactic patterns is similar to that of many others, from (Berland and Charniak, 1999) to (Almuhareb and Poesio, 2004) . Recognizing the subjective character and polarity of words, phrases or sentences has been addressed by many authors, including (Turney, 2003; Riloff et al., 2003; Wiebe, 2000; Hatzivassiloglou and McKeown, 1997) . Most recently, (Takamura et al., 2005) reports on the use of spin models to infer the semantic orientation of words. The paper's global optimization approach and use of multiple sources of constraints on a word's semantic orientation is similar to ours, but the mechanism differs and they currently omit the use of syntactic information. Subjective phrases are used by (Turney, 2002; Pang and Vaithyanathan, 2002; Kushal et al., 2003; Kim and Hovy, 2004) and others in order to classify reviews or sentences as positive or negative. So far, OPINE's focus has been on extracting and analyzing opinion phrases corresponding to specific features in specific sentences, rather than on determining sentence or review polarity.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The key components of OPINE described in this paper are the PMI feature assessment which leads to high-precision feature extraction and the use of relaxation-labeling in order to find the semantic orientation of potential opinion words. ", "mid_sen": "The review-mining work most relevant to our research is that of (Hu and Liu, 2004) and (Kobayashi et al., 2004) . ", "after_sen": "Both identify product features from reviews, but OPINE significantly improves on both. "}
{"citeStart": 79, "citeEnd": 100, "citeStartToken": 79, "citeEndToken": 100, "sectionName": "UNKNOWN SECTION NAME", "string": "Previous algorithms for compiling rewrite rules into transducers have followed Kaplan and Kay (1994) by introducing special marker symbols (markers) into strings in order to mark off candidate regions for replacement. The assumption is that these markers are outside the resulting transducer's alphabets. But previous algorithms have not ensured that the assumption holds. This problem was recognized by Karttunen (1996) , whose algorithm starts with a filter transducer which filters out any string containing a marker. This is problematic for two reasons. First, when applied to a string that does happen to contain a marker, the algorithm will simply fail. Second, it leads to logical problems in the interpretation of complementation. Since the complement of a regular expression R is defined as E -R, one needs to know whether the marker symbols are in E or not. This has not been clearly addressed in previous literature.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Previous algorithms for compiling rewrite rules into transducers have followed Kaplan and Kay (1994) by introducing special marker symbols (markers) into strings in order to mark off candidate regions for replacement. ", "after_sen": "The assumption is that these markers are outside the resulting transducer's alphabets. "}
{"citeStart": 86, "citeEnd": 97, "citeStartToken": 86, "citeEndToken": 97, "sectionName": "UNKNOWN SECTION NAME", "string": "SVD addresses the problems of generalization and sparseness because broad and stable generalizations are represented on dimensions with large values which will be retained in the dimensionality reduction. In contrast, dimensions corresponding to small singular values represent idiosyncrasies, like the phonological constraint on the usage of \"an\" vs. \"a\", and will be dropped. We also gain efficiency since we can manipulate smaller vectors, reduced to 50 dimensions. We used SVDPACK to compute the singular value decompositions described in this paper (Berry, 1992) . Table 1 shows the nearest neighbors of two words (ordered according to closeness to the head word) after the dimensionality reduction. Neighbors with highest similarity according to both left and right context are listed. One can see clear differences between the nearest neighbors in the two spaces. The right-context neighbors of \"onto\" contain verbs because both prepositions and verbs govern noun phrases to their right. The left-context neighborhood of \"onto\" reflects the fact that prepositional phrases are used in the same position as adverbs like \"away\" and \"together\", thus making their left context similar. For \"seemed\", left-context neighbors are words that have similar types of noun phrases in subject position (mainly auxiliaries). The rightcontext neighbors all take \"to\"-infinitives as complements. An adjective like \"likely\" is very sim-ilar to \"seemed\" in this respect although its left context is quite different from that of \"seemed\". Similarly, the generalization that prepositions and transitive verbs are very similar if not identical in the way they govern noun phrases would be lost if \"left\" and \"right\" properties of words were lumped together in one representation. These examples demonstrate the importance of representing generalizations about left and right context separately.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We also gain efficiency since we can manipulate smaller vectors, reduced to 50 dimensions. ", "mid_sen": "We used SVDPACK to compute the singular value decompositions described in this paper (Berry, 1992) . ", "after_sen": "Table 1 shows the nearest neighbors of two words (ordered according to closeness to the head word) after the dimensionality reduction. "}
{"citeStart": 29, "citeEnd": 44, "citeStartToken": 29, "citeEndToken": 44, "sectionName": "UNKNOWN SECTION NAME", "string": "The solution we have adopted is to derive a semantic classification of the particular sense of the verb under consideration on the basis of the complete set of codes assigned to that sense. In any subcategorisation frame which involves a predicate complement there will be a non-transparent relationship between the superficial syntactic form and the underlying logical relations in the sentence. In these situations the parser can use the semantic type of the verb to compute this relationship. Expanding on a suggestion of Michiels (1982) , we classify verbs as Subject Equi, Object Equi, Subject Raising or Object Raising for each sense which has a predicate complement code associated with it. These terms, which derive from Transformational Grammar, are used as convenient labels for what we regard as a semantic distinction; the actual output of the program is a specification of the mapping from superficial syntactic form to an underlying logical representation. For example, labelling believe(3) (Type 20Raising) indicates that this is a two place predicate and that, if believe(3) occurs with a syntactic direct object, as in 1John believes the Earth to be round it will function as the logical subject of the predicate complement. Michiels proposed rules for doing this for infinitive complement codes; however there seems to be no principled reason not to extend this approach to computing the underlying relations in other types of VP as well as in cases of NP, AP and PP predication (see Williams (1980) , for further discussion).", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In these situations the parser can use the semantic type of the verb to compute this relationship. ", "mid_sen": "Expanding on a suggestion of Michiels (1982) , we classify verbs as Subject Equi, Object Equi, Subject Raising or Object Raising for each sense which has a predicate complement code associated with it. ", "after_sen": "These terms, which derive from Transformational Grammar, are used as convenient labels for what we regard as a semantic distinction; the actual output of the program is a specification of the mapping from superficial syntactic form to an underlying logical representation. "}
{"citeStart": 162, "citeEnd": 181, "citeStartToken": 162, "citeEndToken": 181, "sectionName": "UNKNOWN SECTION NAME", "string": "SAs we noted earlier, an Mternative would be to employ an agglomerative Mgorithm. model to be estimated is very large, and therefore such a model is difficult to estimate with a reasonable data size that is available in practice. (This problem is usually referred to as the 'data sparseness problem'.) We could smooth the estimated probabilities using an existing smoothing technique (e.g., (Dagan el, al., 1992; Gale and Church, 1990) ), then calculate some similarity measure using the smoothed probabilities, and then cluster words according to it. There is no guarantee, however, that the employed smoothing method is in any way consistent with the clustering method used subsequently. Our method based on MDL resolves this issue in a unified fashion. By employing models that embody the assumption that words belonging to a same class occur in the same context with equal likelihood, our method achieves the smoothing effect as a side effect of the clustering process, where the domains of smoothing coincide with the classes obtained by clustering. Thus, the coarseness or fineness of clustering also determines the degree of smoothing. All of these effects fall out naturally as a corollary of the imperatiw? of 'best possible estimation', the original motivation behind the MDL principle.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "model to be estimated is very large, and therefore such a model is difficult to estimate with a reasonable data size that is available in practice. ", "mid_sen": "(This problem is usually referred to as the 'data sparseness problem'.) We could smooth the estimated probabilities using an existing smoothing technique (e.g., (Dagan el, al., 1992; Gale and Church, 1990) ), then calculate some similarity measure using the smoothed probabilities, and then cluster words according to it. ", "after_sen": "There is no guarantee, however, that the employed smoothing method is in any way consistent with the clustering method used subsequently. "}
{"citeStart": 69, "citeEnd": 89, "citeStartToken": 69, "citeEndToken": 89, "sectionName": "UNKNOWN SECTION NAME", "string": "The first major use of HMMs for part of speech tagging was in CLAWS (Garside et al., 1987) in the 1970s. With the availability of large corpora and fast computers, there has been a recent resurgence of interest, and a number of variations on and alter-natives to the FB, Viterbi and BW algorithms have been tried; see the work of, for example, Church (Church, 1988) , Brill (Brill and Marcus, 1992; Brill, 1992) , DeRose (DeRose, 1988) and gupiec (Kupiec, 1992) . One of the most effective taggers based on a pure HMM is that developed at Xerox (Cutting et al., 1992) . An important aspect of this tagger is that it will give good accuracy with a minimal amount of manually tagged training data. 96% accuracy correct assignment of tags to word token, compared with a human annotator, is quoted, over a 500000 word corpus.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The algorithm is again described by Cutting et al. and by Sharman, and a mathematical justification for it can be tbund in Huang et al. (1990) .", "mid_sen": "The first major use of HMMs for part of speech tagging was in CLAWS (Garside et al., 1987) in the 1970s. ", "after_sen": "With the availability of large corpora and fast computers, there has been a recent resurgence of interest, and a number of variations on and alter-natives to the FB, Viterbi and BW algorithms have been tried; see the work of, for example, Church (Church, 1988) , Brill (Brill and Marcus, 1992; Brill, 1992) , DeRose (DeRose, 1988) and gupiec (Kupiec, 1992) . "}
{"citeStart": 155, "citeEnd": 169, "citeStartToken": 155, "citeEndToken": 169, "sectionName": "UNKNOWN SECTION NAME", "string": "Priist utilizing a mixed representation (called syntactic/semantic structures) and Asher utilizing Discourse Representation Theory constructs, each defines mechanisms for determining relations such as parallelism and contrast, and gives constraints on resolving VP-ellipsis and related forms within their more general frameworks. However, each essentially follows Sag in requiring that elided VP representations be alphabetic variants of their referents. This constraint rules out cases where VP-ellipsis obtains syntactically mismatched antecedents, such as example (19) and other non-parallel cases given in Kehler (1993b) . It also appears that neither approach can account for the infelicity of mixed gapping/VP-ellipsis cases such as sentence (25).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, each essentially follows Sag in requiring that elided VP representations be alphabetic variants of their referents. ", "mid_sen": "This constraint rules out cases where VP-ellipsis obtains syntactically mismatched antecedents, such as example (19) and other non-parallel cases given in Kehler (1993b) . ", "after_sen": "It also appears that neither approach can account for the infelicity of mixed gapping/VP-ellipsis cases such as sentence (25)."}
{"citeStart": 117, "citeEnd": 127, "citeStartToken": 117, "citeEndToken": 127, "sectionName": "UNKNOWN SECTION NAME", "string": "Despite its simplicity, the performance of our approach was on the level with the previously highest reported results on the same test collections. The error rate on sentence boundaries in the Brown corpus was not significantly worse than the lowest quoted before (Riley 1989 : 0.28% vs. 0.20% error rate). On the WSJ corpus our system performed slightly better than the combination of the Alembic and SATZ systems described in Palmer and Hearst (1997) (0.44% vs. 0.5% error rate). Although these error rates seem to be very small, they are quite significant. Unlike general POS tagging, in which it is unfair to expect an error rate of less than 2% because even human annotators have a disagreement rate of about 3%, sentence boundaries are much less ambiguous (with a disagreement of about 1 in 5,000). This shows that an error rate of 1 in 200 (0.5%) is still far from reaching the disagreement level. On the other hand, one error in 200 periods means that there is one error in every two documents in the Brown corpus and one error in every four documents in the WSJ corpus.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Despite its simplicity, the performance of our approach was on the level with the previously highest reported results on the same test collections. ", "mid_sen": "The error rate on sentence boundaries in the Brown corpus was not significantly worse than the lowest quoted before (Riley 1989 : 0.28% vs. 0.20% error rate). ", "after_sen": "On the WSJ corpus our system performed slightly better than the combination of the Alembic and SATZ systems described in Palmer and Hearst (1997) (0.44% vs. 0.5% error rate). "}
{"citeStart": 312, "citeEnd": 329, "citeStartToken": 312, "citeEndToken": 329, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper, we show that a similar reduction to Datalog is possible for more powerful grammar formalisms with \"context-free\" derivations, such as (multi-component) tree-adjoining grammars (Joshi and Schabes, 1997; Weir, 1988) , IO macro grammars (Fisher, 1968) , and (parallel) multiple contextfree grammars (Seki et al., 1991) . For instance, the TAG in Figure 3 is represented by the Datalog program in Figure 4 . Moreover, the method of reduc- Figure 3 : A TAG with one initial tree (left) and one auxiliary tree (right) tion extends to the problem of tactical generation (surface realization) for these grammar formalisms coupled with Montague semantics (under a certain restriction). Our method essentially relies on the encoding of different formalisms in terms of abstract categorial grammars (de Groote, 2001) .", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "N(i, j) :− unicorn(i, j).", "mid_sen": "In this paper, we show that a similar reduction to Datalog is possible for more powerful grammar formalisms with \"context-free\" derivations, such as (multi-component) tree-adjoining grammars (Joshi and Schabes, 1997; Weir, 1988) , IO macro grammars (Fisher, 1968) , and (parallel) multiple contextfree grammars (Seki et al., 1991) . ", "after_sen": "For instance, the TAG in Figure 3 is represented by the Datalog program in Figure 4 . "}
{"citeStart": 295, "citeEnd": 313, "citeStartToken": 295, "citeEndToken": 313, "sectionName": "UNKNOWN SECTION NAME", "string": "The last five years have seen a surge of interest in the problem of textual inference, that is, automatically determining whether a natural-language hypothesis can be inferred from a given premise. A broad spectrum of approaches have been explored, ranging from shallow-but-robust to deep-but-brittle. Up to now, the most successful approaches have used fairly impoverished semantic representations, relying on measures of lexical or semantic overlap (Jijkoun and de Rijke, 2005) , pattern-based relation extraction (Romano et al., 2006) , or approximate matching of predicate-argument structure (Hickl et al., 2006) . Such methods, while robust and broadly effective, are imprecise, and are easily confounded by ubiquituous inferences involving monotonicity, particularly in negative polarity contexts, as in: P: No case of indigenously acquired rabies infection has been confirmed in the past 2 years. H: No rabies cases have been confirmed. Because it drops important qualifiers in a negative context, the hypothesis does not follow; yet both the lexical content and the predicate-argument structure of the hypothesis closely match the premise.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A broad spectrum of approaches have been explored, ranging from shallow-but-robust to deep-but-brittle. ", "mid_sen": "Up to now, the most successful approaches have used fairly impoverished semantic representations, relying on measures of lexical or semantic overlap (Jijkoun and de Rijke, 2005) , pattern-based relation extraction (Romano et al., 2006) , or approximate matching of predicate-argument structure (Hickl et al., 2006) . ", "after_sen": "Such methods, while robust and broadly effective, are imprecise, and are easily confounded by ubiquituous inferences involving monotonicity, particularly in negative polarity contexts, as in: P: "}
{"citeStart": 76, "citeEnd": 89, "citeStartToken": 76, "citeEndToken": 89, "sectionName": "UNKNOWN SECTION NAME", "string": "ZWe ignore the difference of accents, stresses and parts of speech. That is, the homophone set is the set of words having the same expression in hiragana characters. statistical methods proposed for the word sense disambiguation problem (Fujii, 1998) . Take the case of context-sensitive spelling error detection 3, which is equivalent to the homophone problem. For that problem, some statistical methods have been applied and succeeded (Golding, 1995; Golding and Schabes, 1996) . Hence, statistical methods axe certainly valid for the homophone problem. In particular, the decision list is valid for the homophone problem (Shinnou, 1998) . The decision list arranges evidences to identify the word sense in the order of strength of identifying the sense. The word sense is judged by the evidence, with the highest identifying strength, in the context.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Take the case of context-sensitive spelling error detection 3, which is equivalent to the homophone problem. ", "mid_sen": "For that problem, some statistical methods have been applied and succeeded (Golding, 1995; Golding and Schabes, 1996) . ", "after_sen": "Hence, statistical methods axe certainly valid for the homophone problem. "}
{"citeStart": 258, "citeEnd": 267, "citeStartToken": 258, "citeEndToken": 267, "sectionName": "UNKNOWN SECTION NAME", "string": "Based on the identified interest aspects, we further adopt multi-manifold ranking algorithm to fuse the sentence relationships against different aspects in a unified ranking process, which has performed successfully in the multi-subtopic summarization task (Wan, 2009) . In this study, we collaboratively summarize the target document by multiple topic-related documents within the document context, since topic-related documents can provide more clues from global context to aid extracting salient summary sentences from the specified document.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Based on the identified interest aspects, we further adopt multi-manifold ranking algorithm to fuse the sentence relationships against different aspects in a unified ranking process, which has performed successfully in the multi-subtopic summarization task (Wan, 2009) . ", "after_sen": "In this study, we collaboratively summarize the target document by multiple topic-related documents within the document context, since topic-related documents can provide more clues from global context to aid extracting salient summary sentences from the specified document."}
{"citeStart": 43, "citeEnd": 61, "citeStartToken": 43, "citeEndToken": 61, "sectionName": "UNKNOWN SECTION NAME", "string": "We first adopted the full feature set from Zhou et al. (2005) , a state-of-the-art feature based relation extraction system. For space reasons, we only show the lexical features as in Table 3 and refer the reader to the paper for the rest of the features.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We first adopted the full feature set from Zhou et al. (2005) , a state-of-the-art feature based relation extraction system. ", "after_sen": "For space reasons, we only show the lexical features as in Table 3 and refer the reader to the paper for the rest of the features."}
{"citeStart": 148, "citeEnd": 168, "citeStartToken": 148, "citeEndToken": 168, "sectionName": "UNKNOWN SECTION NAME", "string": "Our assessment is supported by comparing our results to those of Core and Allen (1997) who used the unadapted DRI manual --see Table 2 . Overall, our Forward Function results are better than theirs (the non significant K for I-on-S in Table 2 reveals problems with coding for that tag), while the Backward Function results are compatible. Finally, our assessment may only hold for task-oriented collaborative dialogues. One research group tried to use the DRI core scheme on free-flow conversations, and had to radically modify it in order to achieve reliable coding (Stolcke et al., 1998) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Finally, our assessment may only hold for task-oriented collaborative dialogues. ", "mid_sen": "One research group tried to use the DRI core scheme on free-flow conversations, and had to radically modify it in order to achieve reliable coding (Stolcke et al., 1998) .", "after_sen": ""}
{"citeStart": 82, "citeEnd": 98, "citeStartToken": 82, "citeEndToken": 98, "sectionName": "UNKNOWN SECTION NAME", "string": "The interest data was created by (Bruce and Wiebe, 1994) by tagging all occurrences of interest in the ACL/DCI Wall Street Journal corpus with senses from the Longman Dictionary of Contemporary English. This data set was subsequently used for word sense disambiguation experiments by (Ng and Lee, 1996) , , and (Pedersen and . The previous studies and this paper use the entire 2,368 sense-tagged sentence corpus in their experiments. The senses and their ire- quency distribution are shown in Table 2 . Unlike line, the sense distribution is skewed; the majority sense occurs in 53% of the sentences, while the smallest minority sense occurs in less than 1%.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The interest data was created by (Bruce and Wiebe, 1994) by tagging all occurrences of interest in the ACL/DCI Wall Street Journal corpus with senses from the Longman Dictionary of Contemporary English. ", "mid_sen": "This data set was subsequently used for word sense disambiguation experiments by (Ng and Lee, 1996) , , and (Pedersen and . ", "after_sen": "The previous studies and this paper use the entire 2,368 sense-tagged sentence corpus in their experiments. "}
{"citeStart": 37, "citeEnd": 54, "citeStartToken": 37, "citeEndToken": 54, "sectionName": "UNKNOWN SECTION NAME", "string": "People have been writing programs for automatic Word Sense Disambiguation (WSD) for forty years now, yet the validity of the task has remained in doubt. At a first pass, the task is simply defined: a word like bank can mean 'river bank' or 'money bank' and the task-is to determine which of these applies in a context in which the word bank appears. The problems arise because most sense distinctions are not as clear as the distinction between 'river bank' and 'money b.~nk', so it is not always straightforward for a person to say what the correct answer is. Thus we do not always know what it would mean to say that a computer program got the right answer. The issue is discussed in detail by (Gale et al., 1992) who identify the problem as one of identifying the 'upper bound' for the performance of a WSD program. If people can only agree on the correct answer x% of the time, a claim that a program achieves more than x% accuracy is hard to interpret, and x% is the upper bound for what the program can (meaningfully) achieve.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Thus we do not always know what it would mean to say that a computer program got the right answer. ", "mid_sen": "The issue is discussed in detail by (Gale et al., 1992) who identify the problem as one of identifying the 'upper bound' for the performance of a WSD program. ", "after_sen": "If people can only agree on the correct answer x% of the time, a claim that a program achieves more than x% accuracy is hard to interpret, and x% is the upper bound for what the program can (meaningfully) achieve."}
{"citeStart": 195, "citeEnd": 211, "citeStartToken": 195, "citeEndToken": 211, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper we focus on the behaviour of older vs. younger adults. Most of the work to date on dialogue systems focuses on young users. However, as average life expectancy increases, it becomes increasingly important to design dialogue systems in such a way that they can accommodate older people's behaviour. Older people are a user group with distinct needs and abilities (Czaja and Lee, 2007) that present challenges for user modelling. To our knowledge no one so far has built statistical user simulation models for older people. The only statistical spoken dialogue system for older people we are aware of is Nursebot, an early application of statistical methods (POMDPs) within the context of a medication reminder system (Roy et al., 2000) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "To our knowledge no one so far has built statistical user simulation models for older people. ", "mid_sen": "The only statistical spoken dialogue system for older people we are aware of is Nursebot, an early application of statistical methods (POMDPs) within the context of a medication reminder system (Roy et al., 2000) .", "after_sen": "In this study, we build SUs for both younger and older adults using n-grams. "}
{"citeStart": 10, "citeEnd": 30, "citeStartToken": 10, "citeEndToken": 30, "sectionName": "UNKNOWN SECTION NAME", "string": "We have applied our model to two publicly available word aligned corpora. The first is the English-French Hansards corpus, which consists of 1.1 million aligned sentences and 484 wordaligned sentences. This data set was used for the 2003 NAACL shared task (Mihalcea and Pedersen, 2003) , where the word-aligned sentences were split into a 37 sentence trial set and a 447 sentence testing set. Unlike the unsupervised entrants in the 2003 task, we require word-aligned training data, and therefore must cannibalise the test set for this purpose. We follow Taskar et al. (2005) by using the first 100 test sentences for training and the remaining 347 for testing. This means that our results should not be directly compared to those entrants, other than in an approximate manner. We used the original 37 sentence trial set for feature engineering and for fitting a Gaussian prior. The word aligned data are annotated with both sure (S) and possible (P ) alignments (S ⊆ P ; Och and Ney (2003) ), where the possible alignments indicate ambiguous or idiomatic alignments. We measure the performance of our model using alignment error rate (AER), which is defined as:", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Unlike the unsupervised entrants in the 2003 task, we require word-aligned training data, and therefore must cannibalise the test set for this purpose. ", "mid_sen": "We follow Taskar et al. (2005) by using the first 100 test sentences for training and the remaining 347 for testing. ", "after_sen": "This means that our results should not be directly compared to those entrants, other than in an approximate manner. "}
{"citeStart": 96, "citeEnd": 106, "citeStartToken": 96, "citeEndToken": 106, "sectionName": "UNKNOWN SECTION NAME", "string": "It has not yet generally been investigated how the type of data influences the learning result (Yang, 1999) , or under which circumstances which kind of preprocessing and which learning algorithm is most appropriate. Several aspects must be considered: Length of the documents, morphological and syntactic well-formedness, the degree to which a document can be uniquely classified, and, of course, the language of the documents.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The database contained 74 categories with at least 10 documents, but the selected ones covered 94% of all e-malls, i.e. 4490 documents.", "mid_sen": "It has not yet generally been investigated how the type of data influences the learning result (Yang, 1999) , or under which circumstances which kind of preprocessing and which learning algorithm is most appropriate. ", "after_sen": "Several aspects must be considered: Length of the documents, morphological and syntactic well-formedness, the degree to which a document can be uniquely classified, and, of course, the language of the documents."}
{"citeStart": 112, "citeEnd": 128, "citeStartToken": 112, "citeEndToken": 128, "sectionName": "UNKNOWN SECTION NAME", "string": "The major components of the algorithm are not new, but straightforward modifications of components presented in Karttunen (1996) and Mohri and Sproat (1996) . We improve upon existing approaches because we solve a problem concerning the use of special marker symbols ( §2.1.2). A further contribution is that all steps are implemented in a freely available system, the FSA Utilities of van Noord (1997) ( §2.1.1).", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In the following section, we initially concentrate on the simple Case in (1) and show how (1) may be compiled assuming left-to-right processing along with the overall longest match strategy described by Karttunen (1996) .", "mid_sen": "The major components of the algorithm are not new, but straightforward modifications of components presented in Karttunen (1996) and Mohri and Sproat (1996) . ", "after_sen": "We improve upon existing approaches because we solve a problem concerning the use of special marker symbols ( §2.1.2). "}
{"citeStart": 161, "citeEnd": 180, "citeStartToken": 161, "citeEndToken": 180, "sectionName": "UNKNOWN SECTION NAME", "string": "The only publicly-available resource with these two characteristics at the time of this work was the subset of the Brown Corpus that is included in both SemCor (Landes et al., 1998) and the Penn Treebank (PTB). 2 This provided the basis of our dataset. After sentence-and word-aligning the SemCor and PTB data (discarding sentences where there was a difference in tokenisation), we were left with a total of 8,669 sentences containing 151,928 words. Note that this dataset is smaller than the one described by Bikel (2000) in a similar exercise, the reason being our simple and conservative approach taken when merging the resources.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The gold-standard parse tree annotations are required in order to carry out evaluation of parser and PP attachment performance.", "mid_sen": "The only publicly-available resource with these two characteristics at the time of this work was the subset of the Brown Corpus that is included in both SemCor (Landes et al., 1998) and the Penn Treebank (PTB). ", "after_sen": "2 This provided the basis of our dataset. "}
{"citeStart": 250, "citeEnd": 262, "citeStartToken": 250, "citeEndToken": 262, "sectionName": "UNKNOWN SECTION NAME", "string": "Statistical machine translation (SMT) is complicated by the fact that words can move during translation. If one assumes arbitrary movement is possible, that alone is sufficient to show the problem to be NPcomplete (Knight, 1999) . Syntactic cohesion 1 is the notion that all movement occurring during translation can be explained by permuting children in a parse tree (Fox, 2002) . Equivalently, one can say that phrases in the source, defined by subtrees in its parse, remain contiguous after translation. Early methods for syntactic SMT held to this assumption in its entirety (Wu, 1997; Yamada and Knight, 2001 ). These approaches were eventually superseded by tree transducers and tree substitution grammars, which allow translation events to span subtree units, providing several advantages, including the ability to selectively produce uncohesive translations (Eisner, 2003; Graehl and Knight, 2004; Quirk et al., 2005) . What may have been forgotten during this transition is that there is a reason it was once believed that a cohesive translation model would work: for some language pairs, cohesion explains nearly all translation movement. Fox (2002) showed that cohesion is held in the vast majority of cases for English-French, while Cherry and Lin (2006) have shown it to be a strong feature for word alignment. We attempt to use this strong, but imperfect, characterization of movement to assist a non-syntactic translation method: phrase-based SMT.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Early methods for syntactic SMT held to this assumption in its entirety (Wu, 1997; Yamada and Knight, 2001 ). ", "mid_sen": "These approaches were eventually superseded by tree transducers and tree substitution grammars, which allow translation events to span subtree units, providing several advantages, including the ability to selectively produce uncohesive translations (Eisner, 2003; Graehl and Knight, 2004; Quirk et al., 2005) . ", "after_sen": "What may have been forgotten during this transition is that there is a reason it was once believed that a cohesive translation model would work: for some language pairs, cohesion explains nearly all translation movement. "}
{"citeStart": 63, "citeEnd": 83, "citeStartToken": 63, "citeEndToken": 83, "sectionName": "UNKNOWN SECTION NAME", "string": "The second approach is a recent refinement of the traditional word-based approach. This is similar to what was introduced as \"flat hybrid model\" (Bisani and Ney, 2005) , and it tries to model OOV-words as sequences of words and fragments. \"Hybrid\" refers to the LM histories being composed of hybrids of words and fragments, while \"flat\" refers to the model being composed of one n-gram model instead of several models for the different item types. The models tested in this work differ in that since Estonian has a very regular phonemic orthography, grapheme sequences can be directly used instead of more complex pronunciation modeling. Subsequently the fragments used are just one grapheme in length.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The second approach is a recent refinement of the traditional word-based approach. ", "mid_sen": "This is similar to what was introduced as \"flat hybrid model\" (Bisani and Ney, 2005) , and it tries to model OOV-words as sequences of words and fragments. ", "after_sen": "\"Hybrid\" refers to the LM histories being composed of hybrids of words and fragments, while \"flat\" refers to the model being composed of one n-gram model instead of several models for the different item types. "}
{"citeStart": 227, "citeEnd": 245, "citeStartToken": 227, "citeEndToken": 245, "sectionName": "UNKNOWN SECTION NAME", "string": "Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009) , discourse structure (Burstein et al., 2003; Webber et al., 2011) , qualitative dimensions (Shatkay et al., 2008) , scientific claims (Blake, 2009) , scientific concepts and information status (Markert et al., 2012) . Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012) . Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012) . Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012) . ", "mid_sen": "Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012) . ", "after_sen": "Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. "}
{"citeStart": 81, "citeEnd": 96, "citeStartToken": 81, "citeEndToken": 96, "sectionName": "UNKNOWN SECTION NAME", "string": "Lexical selection is the task of choosing target language words that accurately reflect the meaning of the corresponding source language words. It plays an important role in machine translation ( (Dorr, 1989) or interlingua (Nirenberg, 1987) . This engineering approach requires great effort in designing the representation and the mapping rules.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Lexical selection is the task of choosing target language words that accurately reflect the meaning of the corresponding source language words. ", "mid_sen": "It plays an important role in machine translation ( (Dorr, 1989) or interlingua (Nirenberg, 1987) . ", "after_sen": "This engineering approach requires great effort in designing the representation and the mapping rules."}
{"citeStart": 175, "citeEnd": 200, "citeStartToken": 175, "citeEndToken": 200, "sectionName": "UNKNOWN SECTION NAME", "string": "Q1: Is the personality projected by models trained on ratings from a few expert judges recognised by a larger sample of naive judges? (Section 3.2) Q2: Can a combination of multiple traits within a single utterance be detected by naive judges? (Section 3.2) Q3: How does PERSONAGE-PE compare to PERSON-AGE, a psychologically-informed rule-based generator for projecting extreme personality? (Section 3.3) Q4: Does the parameter estimation SNLG method produce natural utterances? (Section 3.4) Table 6 shows that extraversion is the dimension modeled most accurately by the parameter estimation models, producing a .45 correlation with the subjects' ratings (p < .01). Emotional stability, agreeableness, and openness to experience ratings also correlate strongly with the target scores, with correlations of .39, .36 and .17 respectively (p < .01). Additionally, Table 6 shows that the magnitude of the correlation increases when considering the perception of a hypothetical average subject, i.e. smoothing individual variation by averaging the ratings over all 24 judges, producing a correlation r avg up to .80 for extraversion. These correlations are unexpectedly high; in corpus analyses, significant correlations as low as .05 to .10 are typically observed between personality and linguistic markers (Pennebaker and King, 1999; Mehl et al., 2006) .", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Additionally, Table 6 shows that the magnitude of the correlation increases when considering the perception of a hypothetical average subject, i.e. smoothing individual variation by averaging the ratings over all 24 judges, producing a correlation r avg up to .80 for extraversion. ", "mid_sen": "These correlations are unexpectedly high; in corpus analyses, significant correlations as low as .05 to .10 are typically observed between personality and linguistic markers (Pennebaker and King, 1999; Mehl et al., 2006) .", "after_sen": ""}
{"citeStart": 122, "citeEnd": 140, "citeStartToken": 122, "citeEndToken": 140, "sectionName": "UNKNOWN SECTION NAME", "string": "The automatic extraction of terminologies has been the focus of many studies in the past (Maynard and Ananiadou, 2000) , (Zhang and Wu, 2012) , but not many works have focussed on automatic extraction of method mentions. We believe that the extraction of method expressions from research papers can help to build lexical resources that can be used in various NLP tasks on research papers.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In some cases, the context in which the method terminologies are used in the text can contain valuable information about the method mention, such as synonyms, definition, and other relations with entities in the text.", "mid_sen": "The automatic extraction of terminologies has been the focus of many studies in the past (Maynard and Ananiadou, 2000) , (Zhang and Wu, 2012) , but not many works have focussed on automatic extraction of method mentions. ", "after_sen": "We believe that the extraction of method expressions from research papers can help to build lexical resources that can be used in various NLP tasks on research papers."}
{"citeStart": 133, "citeEnd": 144, "citeStartToken": 133, "citeEndToken": 144, "sectionName": "UNKNOWN SECTION NAME", "string": "(3) VERB OBJ: A VERB OBJ feature is created in a similar fashion as SUBJ VERB if NP i participates in a verb-object relation. Again, this represents our attempt to coarsely model subcategorization. (4) NE: We use BBN's IdentiFinder (Bikel et al., 1999) , a MUC-style NE recognizer to determine the NE type of NP i . If NP i is determined to be a PERSON or ORGANIZATION, we create an NE feature whose value is simply its MUC NE type. However, if NP i is determined to be a LOCATION, we create a feature with value GPE (because most of the MUC LOCA-TION NEs are ACE GPE NEs). Otherwise, no NE feature will be created (because we are not interested in the other MUC NE types). (5) WN CLASS: For each keyword w shown in the right column of Table 1 , we determine whether the head noun of NP i is a hyponym of w in WordNet, using only the first WordNet sense of NP i . 1 If so, we create a WN CLASS feature with w as its value. These keywords are potentially useful features because some of them are subclasses of the ACE SCs shown in the left column of Table 1 , while others appear to be correlated with these ACE SCs. 2 (6) INDUCED CLASS: Since the first-sense heuristic used in the previous feature may not be accurate in capturing the SC of an NP, we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics (e.g., Hearst (1992) ). Given a large, unannotated corpus 3 , we use Identi-Finder to label each NE with its NE type and MINI-PAR to extract all the appositive relations. An example extraction would be <Eastern Airlines, the carrier>, where the first entry is a proper noun labeled with either one of the seven MUC-style NE types 4 or OTHERS 5 and the second entry is a common noun. We then infer the SC of a common noun as follows: (1) we compute the probability that the common noun co-occurs with each of the eight NE types 6 based on the extracted appositive relations, and (2) if the most likely NE type has a co-occurrence probability above a certain threshold (we set it to 0.7), we create a INDUCED CLASS fea-ture for NP i whose value is the most likely NE type. (7) NEIGHBOR: Research in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs (see Lin (1998a) ). Motivated by this observation, we create for each of NP i 's ten most semantically similar NPs a NEIGH-BOR feature whose value is the surface string of the NP. To determine the ten nearest neighbors, we use the semantic similarity values provided by Lin's dependency-based thesaurus, which is constructed using a distributional approach combined with an information-theoretic definition of similarity.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We then infer the SC of a common noun as follows: (1) we compute the probability that the common noun co-occurs with each of the eight NE types 6 based on the extracted appositive relations, and (2) if the most likely NE type has a co-occurrence probability above a certain threshold (we set it to 0.7), we create a INDUCED CLASS fea-ture for NP i whose value is the most likely NE type. ", "mid_sen": "(7) NEIGHBOR: Research in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs (see Lin (1998a) ). ", "after_sen": "Motivated by this observation, we create for each of NP i 's ten most semantically similar NPs a NEIGH-BOR feature whose value is the surface string of the NP. "}
{"citeStart": 57, "citeEnd": 115, "citeStartToken": 57, "citeEndToken": 115, "sectionName": "UNKNOWN SECTION NAME", "string": "We have been concerned with investigating the lexical . ['unctions (IJTs) of Mel'0,uk (Mel'6uk and Zolkovsky, 1984) as a candidate interllngual device for tbe translation of adjectival and verbal collocates. Our work is related to research by (Heid and Raab, /989). In some respects it is an extension of some of their suggestions. Our work differs fi'om theirs in scope and also in the exploration of wtrious other directions.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, collocations are not only considered usefnl, but also a problem both in certain applications (e.g. generation, (Nirenburg et al., 1988) , machine translation, (Heid and Raab, 1989) ) and fiom a more theoretical point of view (e.g. (Abeill6 and Schabes, 1989) , (Krenn and Erbach, to appear) ).", "mid_sen": "We have been concerned with investigating the lexical . ['unctions (IJTs) of Mel'0,uk (Mel'6uk and Zolkovsky, 1984) as a candidate interllngual device for tbe translation of adjectival and verbal collocates. ", "after_sen": "Our work is related to research by (Heid and Raab, /989). "}
{"citeStart": 274, "citeEnd": 286, "citeStartToken": 274, "citeEndToken": 286, "sectionName": "UNKNOWN SECTION NAME", "string": "Recently, the concept of valency has gained considerable attention. Not only do all linguistic theories refer to some reformulation of the traditional notion of valency (in the form of 0grid, subcategorization list, argument list, or extended domain of locality); there is a growing number of parsers based on binary relations between words (Eisner, 1997; Maruyama, 1990) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Recently, the concept of valency has gained considerable attention. ", "mid_sen": "Not only do all linguistic theories refer to some reformulation of the traditional notion of valency (in the form of 0grid, subcategorization list, argument list, or extended domain of locality); there is a growing number of parsers based on binary relations between words (Eisner, 1997; Maruyama, 1990) .", "after_sen": "Given this interest in the valency concept, and the fact that word order is one of the main difference between phrase-structure based approaches (henceforth PSG) and dependency grammar (DG), it is valid to ask whether DG can capture word order phenomena without recourse to phrasal nodes, traces, slashed categories, etc. "}
{"citeStart": 69, "citeEnd": 94, "citeStartToken": 69, "citeEndToken": 94, "sectionName": "UNKNOWN SECTION NAME", "string": "The AdaBoost algorithm was presented by Freund and Schapire in 1996 (Freund and Schapire, 1996; Freund and Schapire, 1997) and has become a widely-known successful method in machine learning. The AdaBoost algorithm imposes one constraint on its underlying learner: it may abstain from making predictions about labels of some samples, 1This is the balanced version ofF-measure, where precision and recall are weighted equally. but it must consistently be able to get more than 50°-/o accuracy on the samples for which it commits to a decision. That accuracy is measured according to the distribution describing the importance of samples that it is given. The learner must be able to get more correct samples than incorrect samples by mass of importance on those that it labels. This statement of the restriction comes from Schapire and Singer's study (1998) . It is called the weak learning criterion. Schapire and Singer (1998) extended AdaBoost by describing how to choose the hypothesis mixing coefficients in certain circumstances and how to incorporate a general notion of confidence scores. They also provided a better characterization of its theoretical performance. The version of AdaBoost used in their work is shown in Algorithm 3, as it is the version that most amenable to parsing.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The AdaBoost algorithm was presented by Freund and Schapire in 1996 (Freund and Schapire, 1996; Freund and Schapire, 1997) and has become a widely-known successful method in machine learning. ", "after_sen": "The AdaBoost algorithm imposes one constraint on its underlying learner: it may abstain from making predictions about labels of some samples, 1This is the balanced version ofF-measure, where precision and recall are weighted equally. "}
{"citeStart": 111, "citeEnd": 134, "citeStartToken": 111, "citeEndToken": 134, "sectionName": "UNKNOWN SECTION NAME", "string": "In order to handle the non-linear phenomenon of Arabic, our model adopts the two-level formalism presented by (Pulman and Hepple, 1993) , with the multi tape extensions in (Kiraz, 1994) . Their forrealism appears in (2).", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "In order to handle the non-linear phenomenon of Arabic, our model adopts the two-level formalism presented by (Pulman and Hepple, 1993) , with the multi tape extensions in (Kiraz, 1994) . ", "after_sen": "Their forrealism appears in (2)."}
{"citeStart": 44, "citeEnd": 55, "citeStartToken": 44, "citeEndToken": 55, "sectionName": "UNKNOWN SECTION NAME", "string": "We asked human judges (not including the authors) to rate the coherence and readability of a number of summaries for each of dataset2 papers. For each paper we evaluated 3 summaries. The sum- Table 7 : Coherence Evaluation mary that our system produced, the human summary, and a summary produced by Qazvinian and Radev (2008) summarizer (the best baseline -after our system and its variations -in terms of extraction quality as shown in the previous subsection.) The summaries were randomized and given to the judges without telling them how each summary was produced. The judges were not given access to the source text. They were asked to use a five pointscale to rate how coherent and readable the summaries are, where 1 means that the summary is totally incoherent and needs significant modifications to improve its readability, and 5 means that the summary is coherent and no modifications are needed to improve its readability. We gave each summary to 5 different judges and took the average of their ratings for each summary. We used Weighted Kappa with linear weights (Cohen, 1968) to measure the interrater agreement. The Weighted Kappa measure between the five groups of ratings was 0.72. Table 7 shows the number of summaries in each rating range. The results show that our approach significantly improves the coherence of citation-based summarization. Table 5 shows two sample summaries (each 5 sentences long) for the Voutilainen (1995) paper. One summary was produced using our system and the other was produced using Qazvinian and Radev (2008) system.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We gave each summary to 5 different judges and took the average of their ratings for each summary. ", "mid_sen": "We used Weighted Kappa with linear weights (Cohen, 1968) to measure the interrater agreement. ", "after_sen": "The Weighted Kappa measure between the five groups of ratings was 0.72. "}
{"citeStart": 66, "citeEnd": 77, "citeStartToken": 66, "citeEndToken": 77, "sectionName": "UNKNOWN SECTION NAME", "string": "4. Purely rule-based techniques seemed too brittle for dealing with the variety of constructions, the long sentences (averaging 29 words per sentence), and the degree of unexpected input. Statistical models based on local information (e.g., DeRose 1988; Church 1988 ) might operate effectively in spite of sentence length and unexpected input.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Purely rule-based techniques seemed too brittle for dealing with the variety of constructions, the long sentences (averaging 29 words per sentence), and the degree of unexpected input. ", "mid_sen": "Statistical models based on local information (e.g., DeRose 1988; Church 1988 ) might operate effectively in spite of sentence length and unexpected input.", "after_sen": "To see whether our four hypotheses (in italics above) effectively addressed the four concerns above, we chose to test the hypotheses on two well-known problems: ambiguity (both at the structural level and at the part-of-speech level) and inferring syntactic and semantic information about unknown words."}
{"citeStart": 18, "citeEnd": 36, "citeStartToken": 18, "citeEndToken": 36, "sectionName": "UNKNOWN SECTION NAME", "string": "where S(n) is a set of candidate similar words and sim(n, m) is a function of the similarity between n and m. We focus on distributional rather than semantic similarity (e.g., Resnik (1995) ) because the goal of distance-weighted averaging is to smooth probability distributions --although the words \"chance\" and \"probability\" are synonyms, the former may not be a good model for predicting what cooccurrences the latter is likely to participate in. There are many plausible measures of distributional similarity. In previous work (Dagan et al., 1999) , we compared the performance of three different functions: the Jensen-Shannon divergence (total divergence to the average), the L1 norm, and the confusion probability. Our experiments on a frequency-controlled pseudoword disambiguation task showed that using any of the three in a distance-weighted averaging scheme yielded large improvements over Katz's backoff smoothing method in predicting unseen coocurrences. Furthermore, by using a restricted version of model (1) that stripped incomparable parameters, we were able to empirically demonstrate that the confusion probability is fundamentally worse at selecting useful similar words. D. Lin also found that the choice of similarity function can affect the quality of automatically-constructed thesauri to a statistically significant degree (1998a) and the ability to determine common morphological roots by as much as 49% in precision (1998b).", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There are many plausible measures of distributional similarity. ", "mid_sen": "In previous work (Dagan et al., 1999) , we compared the performance of three different functions: the Jensen-Shannon divergence (total divergence to the average), the L1 norm, and the confusion probability. ", "after_sen": "Our experiments on a frequency-controlled pseudoword disambiguation task showed that using any of the three in a distance-weighted averaging scheme yielded large improvements over Katz's backoff smoothing method in predicting unseen coocurrences. "}
{"citeStart": 38, "citeEnd": 84, "citeStartToken": 38, "citeEndToken": 84, "sectionName": "UNKNOWN SECTION NAME", "string": "The centering algorithm as defined by Brennan, Friedman and Pollard, (BFP algorithm) , is derived from a set of rules and constraints put forth by Grosz, Joshi and Weinstein [GJW83, GJW86] . We shall not reproduce this algorithm here (See [BFP87]). There are two main structures in the centering algorithm, the CB, the BACKWARD LOOKING CENTER, which is what the discourse is 'about', and an ordered list, CF, of FORWARD LOOKING CENTERS, which are the discourse entities available to the next utterance for pronorninalization. The centering framework predicts that in a local coherent stretch of dialogue, speakers will prefer to CONTINUE talking about the same discourse entity, that the CB will be the highest ranked entity of the previous utterance's forward centers that is realized in the current utterance, and that if anything is pronominalized the CB must be.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The centering algorithm as defined by Brennan, Friedman and Pollard, (BFP algorithm) , is derived from a set of rules and constraints put forth by Grosz, Joshi and Weinstein [GJW83, GJW86] . ", "after_sen": "We shall not reproduce this algorithm here (See [BFP87]). "}
{"citeStart": 154, "citeEnd": 170, "citeStartToken": 154, "citeEndToken": 170, "sectionName": "UNKNOWN SECTION NAME", "string": "We use another technique to speed up direct search by storing and re-using search graphs, which consist of lattices in the case of phrase-based decoding (Och et al., 1999) and hypergraphs in the case of hierarchical decoding (Chiang, 2005) . The successive expansion of translation options in order to construct the search graph is generally done from scratch, but this can be wasteful when the same sentences are translated multiple times, as it is the case with direct search. Even when the parameters of the decoder change across function evaluations, some partial translation are likely to be constructed multiple times, and this is more likely to happen when changes in parameters are relatively small. To overcome this inefficiency, we memoize hypotheses expansions made in all function evaluations, which then allows us to reuse some edges (or hyperedges) from previous iterations to construct the current graph (or hypergraph). Since feature values-including expensive features like language model score-are stored into each edge, the speedup is roughly proportional to the percentage of edges we can reuse.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We use another technique to speed up direct search by storing and re-using search graphs, which consist of lattices in the case of phrase-based decoding (Och et al., 1999) and hypergraphs in the case of hierarchical decoding (Chiang, 2005) . ", "after_sen": "The successive expansion of translation options in order to construct the search graph is generally done from scratch, but this can be wasteful when the same sentences are translated multiple times, as it is the case with direct search. "}
{"citeStart": 102, "citeEnd": 117, "citeStartToken": 102, "citeEndToken": 117, "sectionName": "UNKNOWN SECTION NAME", "string": "The advantages of the AWM model is that it was shown to reproduce, in simulation, mlmy results on human memory ~md lem'ning. Because search st~n'ts from the current pointer location, items that have been stored most recently are more likely to be retrieved, predicting recency effects [BMdeley, 19861. Because items that are stored in multiple locations are more likely to be retrieved, tbe model predicts fiequency effects [Hiutzmmm and Block, 1971 I. Because items are stored in chrono-IogicN sequence, the model produces natural associativity effects [Landaner, 19751 . Because deliberation and means-end re~tsoning can only operate on salient belietls, limited attention produces a concomitlmt inl)rential limitation, i.e. if a belief is nol salient it cannot be used in deliberation or mcans-end-reltsoniug. This means that mistakes that agents make in their planning process have a plansible cognitive basis. Agents can both fail to access a belief that would idlow them to produce ,an optim~d plan, its well as make a mistake in pl~mning if a belief about bow the world has changed its a result of pllmning is not sldicnt. I)epending on the preceding discourse, and the agent's attentionld capacity, the propositions that im agent knows may or may not be salient when a proposed is made.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Because items that are stored in multiple locations are more likely to be retrieved, tbe model predicts fiequency effects [Hiutzmmm and Block, 1971 I. ", "mid_sen": "Because items are stored in chrono-IogicN sequence, the model produces natural associativity effects [Landaner, 19751 . ", "after_sen": "Because deliberation and means-end re~tsoning can only operate on salient belietls, limited attention produces a concomitlmt inl)rential limitation, i.e. if a belief is nol salient it cannot be used in deliberation or mcans-end-reltsoniug. "}
{"citeStart": 53, "citeEnd": 81, "citeStartToken": 53, "citeEndToken": 81, "sectionName": "UNKNOWN SECTION NAME", "string": "We use AOL search log data for experiments. It includes 20 million web queries collected covering 500K users over three months in 2006. We preprocess the query log by keeping urls occurring more than 3 times and queries with 2 to 40 characters, then extract sessions considering 25 minutes duration. While user session segmentation can be improved with more sophisticated algorithms, this simple low-cost heuristic performs adequately for our purposes. We then move on to map queries to Freebase and empirically filter sessions that are less entity-centric. We use an annotation tool especially for short text (Ferragina and Scaiella, 2012) called Tagme 3 to recognize entities and observe only 16% of all the queries are exactly an entity itself, which means most of queries do have refiner words to convey information need. To ensure the precision of recognized entities, we set a significant threshold and bottom line threshold , queries should have at least one recognized entity with a likelihood above significant level, and those below bottom line are ignored. They are 0.19 and 0.05 in our work, which may vary with entity recognition method. The normalized likelihood is used as w q (e). Then we drop sessions where tagged entity words weight less than refiners as well as the ones with too many entity words spotted indicating disperse intents. For each recognized entity, only Freebase topics with relevance over 0.3 are kept. The query set we finally get is shown in Table 1 .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We then move on to map queries to Freebase and empirically filter sessions that are less entity-centric. ", "mid_sen": "We use an annotation tool especially for short text (Ferragina and Scaiella, 2012) called Tagme 3 to recognize entities and observe only 16% of all the queries are exactly an entity itself, which means most of queries do have refiner words to convey information need. ", "after_sen": "To ensure the precision of recognized entities, we set a significant threshold and bottom line threshold , queries should have at least one recognized entity with a likelihood above significant level, and those below bottom line are ignored. "}
{"citeStart": 128, "citeEnd": 154, "citeStartToken": 128, "citeEndToken": 154, "sectionName": "UNKNOWN SECTION NAME", "string": "We evaluated methods for self-training high accuracy products of latent variable grammars with large amounts of genre-matched data. We demonstrated empirically on newswire and broadcast news genres that very high accuracies can be achieved by training grammars on disjoint sets of automatically labeled data. Two primary factors appear to be determining the efficacy of our self-training approach. First, the accuracy of the model used for parsing the unlabeled data is important for the accuracy of the resulting single self-trained grammars. Second, the diversity of the individual grammars controls the gains that can be obtained by combining multiple grammars into a product model. Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set, rivaling discriminative reranking approaches (Charniak and Johnson, 2005) and products of latent variable grammars (Petrov, 2010) , despite being a single generative PCFG. Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set (Zhang et al., 2009) .", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Second, the diversity of the individual grammars controls the gains that can be obtained by combining multiple grammars into a product model. ", "mid_sen": "Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set, rivaling discriminative reranking approaches (Charniak and Johnson, 2005) and products of latent variable grammars (Petrov, 2010) , despite being a single generative PCFG. ", "after_sen": "Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set (Zhang et al., 2009) ."}
{"citeStart": 96, "citeEnd": 118, "citeStartToken": 96, "citeEndToken": 118, "sectionName": "UNKNOWN SECTION NAME", "string": "Viewed in this way, gradable adjectives are an extreme example of the \"efficiency of language\" (Barwise and Perry 1983) : Far from meaning something concrete like \"larger than 8 cm\"-a concept that would have very limited applicability-or even something more general like \"larger than the average N,\" a word like large is applicable across a wide range of different situations.", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The large mouse = The largest mouse.", "mid_sen": "Viewed in this way, gradable adjectives are an extreme example of the \"efficiency of language\" (Barwise and Perry 1983) : ", "after_sen": "Far from meaning something concrete like \"larger than 8 cm\"-a concept that would have very limited applicability-or even something more general like \"larger than the average N,\" a word like large is applicable across a wide range of different situations."}
{"citeStart": 156, "citeEnd": 181, "citeStartToken": 156, "citeEndToken": 181, "sectionName": "UNKNOWN SECTION NAME", "string": "To build a semantic lexicon, one has to identify the relation between words within a semantic hierarchy, and to group similar words together into a class. Previous work on automatic methods for building semantic lexicons could be divided into two main groups. One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity (e.g. Riloff and Shepherd, 1997; Lin, 1998; Caraballo, 1999; Thelen and Riloff, 2002; You and Chen, 2006) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Previous work on automatic methods for building semantic lexicons could be divided into two main groups. ", "mid_sen": "One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity (e.g. Riloff and Shepherd, 1997; Lin, 1998; Caraballo, 1999; Thelen and Riloff, 2002; You and Chen, 2006) .", "after_sen": "Another line of research, which is more closely related to the current study, is to extend existing thesauri by classifying new words with respect to their given structures (e.g. Tokunaga et al., 1997; Pekar, 2004) . "}
{"citeStart": 234, "citeEnd": 256, "citeStartToken": 234, "citeEndToken": 256, "sectionName": "UNKNOWN SECTION NAME", "string": "Even moderately long documents typically address sew~ral topics or different aspects of the same topic. The aim of linear text segmentation is to discover the topic boundaries. The uses of this procedure include information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999) , summarization (Reynar, 1998 ), text understanding, anaphora resolution (Kozima, 1993) , language modelling (Morris and Hirst, 1991; Beeferman et al., 199717) and improving document navigation for the visually disabled (Choi, 2000) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The aim of linear text segmentation is to discover the topic boundaries. ", "mid_sen": "The uses of this procedure include information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999) , summarization (Reynar, 1998 ), text understanding, anaphora resolution (Kozima, 1993) , language modelling (Morris and Hirst, 1991; Beeferman et al., 199717) and improving document navigation for the visually disabled (Choi, 2000) .", "after_sen": "This paper focuses on domain independent methods for segmenting written text. "}
{"citeStart": 118, "citeEnd": 132, "citeStartToken": 118, "citeEndToken": 132, "sectionName": "UNKNOWN SECTION NAME", "string": "Second, since there has been a marked improvement in the quality of full parsers, now achieving an F in the high 80s (Magerman, 1995) , we believe it is now feasible to consider using full parsers again.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For example, statistical techniques may have suggested the importance of \"hire,\" a verb which many groups did not happen to define.", "mid_sen": "Second, since there has been a marked improvement in the quality of full parsers, now achieving an F in the high 80s (Magerman, 1995) , we believe it is now feasible to consider using full parsers again.", "after_sen": "The rationale is straightforward: for full templates (e.g., ST) scores have been mired with an F in the 50s ever since MUC-3 in 1991. "}
{"citeStart": 129, "citeEnd": 147, "citeStartToken": 129, "citeEndToken": 147, "sectionName": "UNKNOWN SECTION NAME", "string": "Other previous NLP research has used features similar to ours for other NLP tasks. Low-frequency words have been used as features in information extraction (Weeber, Vos, and Baayen 2000) and text categorization (Copeck et al. 2000) . A number of researchers have worked on mining collocations from text to extend lexicographic resources for machine translation and word sense disambiguation (e.g., Smajda 1993; Lin 1999; Biber 1993) .", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Other previous NLP research has used features similar to ours for other NLP tasks. ", "mid_sen": "Low-frequency words have been used as features in information extraction (Weeber, Vos, and Baayen 2000) and text categorization (Copeck et al. 2000) . ", "after_sen": "A number of researchers have worked on mining collocations from text to extend lexicographic resources for machine translation and word sense disambiguation (e.g., Smajda 1993; Lin 1999; Biber 1993) ."}
{"citeStart": 1, "citeEnd": 18, "citeStartToken": 1, "citeEndToken": 18, "sectionName": "UNKNOWN SECTION NAME", "string": "Recently, holistic approaches combining such similarities have been studied (Shao and Ng, 2004; You et al., 2010; Kim et al., 2011) . (Shao and Ng, 2004) rank translation candidates using PH and CX independently and return results with the highest average rank. (You et al., 2010) compute initial translation scores using PH and iteratively update the scores using relationship feature (called R). (Kim et al., 2011) boost You's approach by additionally leveraging CX.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Recently, holistic approaches combining such similarities have been studied (Shao and Ng, 2004; You et al., 2010; Kim et al., 2011) . ", "mid_sen": "(Shao and Ng, 2004) rank translation candidates using PH and CX independently and return results with the highest average rank. ", "after_sen": "(You et al., 2010) compute initial translation scores using PH and iteratively update the scores using relationship feature (called R). "}
{"citeStart": 105, "citeEnd": 124, "citeStartToken": 105, "citeEndToken": 124, "sectionName": "UNKNOWN SECTION NAME", "string": "In addition, the relative frequencies of the English word and its translation were checked. In order to calculate relative frequencies of the English words, the English sense-tagged corpus SemCor (Miller et al., 1993) was used. For Dutch, such a resource was not available. We are aware of the fact that the Dutch sense-tagged corpus Dutch-SemCor (Vossen et al., 2012) exists. However, an effort was made to provide an equal number of examples for each meaning in this corpus. Although this is very useful for WSD-experiments, this makes this corpus less useful for Information Content calculations. Therefore the frequencies of the lemmas in the Dutch corpus called SoNaR (Oostdijk et al., 2008) were used. It was checked whether or not the English word and its Dutch counterpart were located in the same class of relative frequency. A word is placed in the category high if its relative frequency is higher than 0.05%, middle if its relative frequency is between 0.015% and 0.05% and low if its relative frequency is lower than 0.015%. If two words are located in the same relative frequency class, the pair receives the value True, else False. If no frequency data was available for a word, the value of the pair was set to True. Eight word pairs received the value False. Since this step was performed to remove outliers, we claim this to be acceptable.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In addition, the relative frequencies of the English word and its translation were checked. ", "mid_sen": "In order to calculate relative frequencies of the English words, the English sense-tagged corpus SemCor (Miller et al., 1993) was used. ", "after_sen": "For Dutch, such a resource was not available. "}
{"citeStart": 173, "citeEnd": 190, "citeStartToken": 173, "citeEndToken": 190, "sectionName": "UNKNOWN SECTION NAME", "string": "We have shown that a tagger based on Markov models yields state-of-the-art results, despite contrary claims found in the literature. For example, the Markov model tagger used in the comparison of (van Halteren et al., 1998) yielded worse results than all other taggers. In our opinion, a reason for the wrong claim is that the basic algorithms leave several decisions to the implementor. The rather large amount of freedom was not handled in detail in previous publications: handling of start-and end-of-sequence, the exact smoothing technique, how to determine the weights for context probabilities, details on handling unknown words, and how to determine the weights for unknown words. Note that the decisions we made yield good results for both the German and the English Corpus. They do so for several other corpora as well. The architecture remains applicable to a large variety of languages. According to current tagger comparisons (van Halteren et al., 1998; Zavrel and Daelemans, 1999) , and according to a comparsion of the results presented here with those in (Ratnaparkhi, 1996) , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here. It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The architecture remains applicable to a large variety of languages. ", "mid_sen": "According to current tagger comparisons (van Halteren et al., 1998; Zavrel and Daelemans, 1999) , and according to a comparsion of the results presented here with those in (Ratnaparkhi, 1996) , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here. ", "after_sen": "It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both."}
{"citeStart": 31, "citeEnd": 49, "citeStartToken": 31, "citeEndToken": 49, "sectionName": "UNKNOWN SECTION NAME", "string": "In the rest of the paper, we first introduce the Trains corpus. We then introduce a statistical language model that incorporates POS tagging and the identification of discourse markers. We then augmeat this model with speech repair detection and correction and intonational boundary tone detection. We then present the results of this model on the Trains corpus and show that it can better account for these discourse events than can be achieved by modeling them individually. We also show that by modeling these two phenomena that we can increase our POS tagging performance by 8.6%, and improve our ability to predict the next word. As part of the TRAINS project (Allen et al., 1995) , which is a long term research project to build a conversationally proficient planning assistant, we have collected a corpus of problem solving dialogs (Heeman and . The dialogs involve two human participants, one who is playing the role of a user and has a certain task to accomplish, and another who is playing the role of the system by acting as a planning assistant. The collection methodology was designed to make the setting as close to humancomputer interaction as possible, but was not a wizard scenario, where one person pretends to be a computer. Rathor, the user knows that he is talking to another person. The TaAINS corpus consists of about six and half hours of speech. Table 1 gives some general statistics about the corpus, including the number of dialogs, speakers, words, speaker turns, and occurrences of discourse markers, boundary tones and speech repairs.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We also show that by modeling these two phenomena that we can increase our POS tagging performance by 8.6%, and improve our ability to predict the next word. ", "mid_sen": "As part of the TRAINS project (Allen et al., 1995) , which is a long term research project to build a conversationally proficient planning assistant, we have collected a corpus of problem solving dialogs (Heeman and . ", "after_sen": "The dialogs involve two human participants, one who is playing the role of a user and has a certain task to accomplish, and another who is playing the role of the system by acting as a planning assistant. "}
{"citeStart": 113, "citeEnd": 140, "citeStartToken": 113, "citeEndToken": 140, "sectionName": "UNKNOWN SECTION NAME", "string": "Much of the Arabic parsing research to date uses the pipeline approach, either running a tokenizer prior to parsing or simply assuming the existence of gold tokenization (Bikel, 2004; Buchholz and Marsi, 2006; Kulick et al., 2006; Marton et al., 2010; Marton et al., 2011; Marton et al., 2013) . Of course, using gold tokenization results in optimistic evaluation figures. 13 Other methods exist however. For example, to parse Modern Hebrew, Cohen and Smith (2007) combine a morphological model with a syntactic model using a product of experts. Another alternative is lattice parsing, which can be used to jointly model both tokenization and parsing (Chappelier et al., 1999) . Curiously, while researchers of Modern Hebrew parsing find lattice parsers outperforming their pipeline systems (Goldberg and Tsarfaty, 2008; Goldberg and Elhadad, 2011; Goldberg and Elhadad, 2013) , Green and Manning (2010) obtain the opposite result in their Arabic parsing experiments, with the lattice parser underperforming the pipeline system by over 3 points (76.01 F1 vs 79.17 F1) . Why lattice parsing may help in some cases but not others is not clear.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Another alternative is lattice parsing, which can be used to jointly model both tokenization and parsing (Chappelier et al., 1999) . ", "mid_sen": "Curiously, while researchers of Modern Hebrew parsing find lattice parsers outperforming their pipeline systems (Goldberg and Tsarfaty, 2008; Goldberg and Elhadad, 2011; Goldberg and Elhadad, 2013) , Green and Manning (2010) obtain the opposite result in their Arabic parsing experiments, with the lattice parser underperforming the pipeline system by over 3 points (76.01 F1 vs 79.17 F1) . ", "after_sen": "Why lattice parsing may help in some cases but not others is not clear."}
{"citeStart": 1, "citeEnd": 22, "citeStartToken": 1, "citeEndToken": 22, "sectionName": "UNKNOWN SECTION NAME", "string": "This indicates that some degree of unlexicalized initialization is necessary, if a good lexica]ized model is to be obtained. (Skut and Brants, 1998) report 84.4% recall and 84.2% for NP and PP chunking without case labels. While these are numbers for a simpler problem and are slightly below ours, they are figures for an experiment on unrestricted sentences. A genuine comparison has to await extension of our model to free text. Figure 9 gives results for verb frame recognition under the same training conditions. Again, we achieve best results by lexicalising the second unlexicalized model. Of a total of 584 annotated verb frames, 384 are correctly recognized in the best unlexicalized model and 397 through subsequent lexicalized training. Precision for the best unlexicalized model is 68.4%. This is raised by 2% to 70.4% through lexicalized training; recall is 65.7%/68%; adjustment by 41 unparsed misses makes for 70.4%/72.8% in recall. The rather small improvements are in contrast to 88 differences in parser markup, i.e. 15.7%, between the unlexicalized and second lexicalized model. The main gain is observed within the first two iterations (cf. Figure 9 ; for readability, we dropped the recall curves when more or less parallel to the precision curves).", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This indicates that some degree of unlexicalized initialization is necessary, if a good lexica]ized model is to be obtained. ", "mid_sen": "(Skut and Brants, 1998) report 84.4% recall and 84.2% for NP and PP chunking without case labels. ", "after_sen": "While these are numbers for a simpler problem and are slightly below ours, they are figures for an experiment on unrestricted sentences. "}
{"citeStart": 60, "citeEnd": 71, "citeStartToken": 60, "citeEndToken": 71, "sectionName": "UNKNOWN SECTION NAME", "string": "The methodology we employed is similar to that endorsed by (Biber, 1995) . It is summarised as follows:", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The methodology we employed is similar to that endorsed by (Biber, 1995) . ", "after_sen": "It is summarised as follows:"}
{"citeStart": 118, "citeEnd": 132, "citeStartToken": 118, "citeEndToken": 132, "sectionName": "UNKNOWN SECTION NAME", "string": "Our model is thus a simplification of more sophisticated models which integrate PCFGs with features, such as those in Magerman(1995) , Collins(1997) and Goodman(1997) . Compared with these models, our model is more practical when only small training data is available, since we assume the independence between features. For example, in Goodman's probabilistic feature grammar (PFG), each symbol in a PCFG is replaced by a set of features, so it can describe specific constraints on the rule. In the PFG model the generation of each feature is dependent on all the previously generated features, thus likely leading to severe sparse data problem in parameter estimation. Our simplified model assumes independence between the features, thus data sparseness problem can be significantly alleviated.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": ") | , ( max arg ) | ( 1 A FS i i i n i T P S T Score β ∏ = = (6)", "mid_sen": "Our model is thus a simplification of more sophisticated models which integrate PCFGs with features, such as those in Magerman(1995) , Collins(1997) and Goodman(1997) . ", "after_sen": "Compared with these models, our model is more practical when only small training data is available, since we assume the independence between features. "}
{"citeStart": 91, "citeEnd": 109, "citeStartToken": 91, "citeEndToken": 109, "sectionName": "UNKNOWN SECTION NAME", "string": "To find a smaller set of effective features, we start with all the features considered in (Jiang and Ng, 2006) , in (Xue and Palmer, 2004) , and various combinations of them, for a total of 52 features. These features are then pruned by the following algorithm:", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In this work, the number of features is pruned to 11, so that we can work with reasonably many auxiliary problems in later experiments with ASO.", "mid_sen": "To find a smaller set of effective features, we start with all the features considered in (Jiang and Ng, 2006) , in (Xue and Palmer, 2004) , and various combinations of them, for a total of 52 features. ", "after_sen": "These features are then pruned by the following algorithm:"}
{"citeStart": 132, "citeEnd": 151, "citeStartToken": 132, "citeEndToken": 151, "sectionName": "UNKNOWN SECTION NAME", "string": "Specifically, each clustering was tested against 1,354 hypothesis lists output by a version of the DECIPHER (TM) speech recognizer (Murveit et al, 1993) that itself used a (rather simpler) bigram model. Where more then ten hypothesis were output for a sentence, only the top ten were considered. These 1,354 lists were the subset of two 1,000 sentence sets (the February and November 1992 ATIS evaluation sets) for which the reference sentence itself occurred in the top ten hypotheses. The clustered language model was used to select the most likely hypothesis from the list without paying any attention either to the score that DECIPHER assigned to each hypothesis on the basis of acoustic information or its own bigram model, or to the ordering of the list. In a real system, the DECIPHER scores would of course be taken into account, but they were ignored here in order to maximize the discriminatory power of the test in the presence of only a few thousand test utterances.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The improvement (if any) due to clustering was measured by using the various language models to make selections from N-best sentence hypothesis lists; this choice of test was made for convenience rather than out of any commitment to the N-best paradigm, and the techniques described here could equally well be used with other forms of speechlanguage interface.", "mid_sen": "Specifically, each clustering was tested against 1,354 hypothesis lists output by a version of the DECIPHER (TM) speech recognizer (Murveit et al, 1993) that itself used a (rather simpler) bigram model. ", "after_sen": "Where more then ten hypothesis were output for a sentence, only the top ten were considered. "}
{"citeStart": 214, "citeEnd": 226, "citeStartToken": 214, "citeEndToken": 226, "sectionName": "UNKNOWN SECTION NAME", "string": "CRFs share many of the advantageous properties of standard maximum entropy models, including their convex likelihood function, which guarantees that the learning procedure converges to the global maximum. Traditional maximum entropy learning algorithms, such as GIS and IIS (Pietra et al., 1995) , can be used to train CRFs, however, it has been found that a quasi-Newton gradient-climber, BFGS, converges much faster (Malouf, 2002; Sha and Pereira, 2003) . We use BFGS for optimization. In our experiments, we shall focus instead on two other aspects of CRF deployment, namely regularization and selection of different model structure and feature types.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "CRFs share many of the advantageous properties of standard maximum entropy models, including their convex likelihood function, which guarantees that the learning procedure converges to the global maximum. ", "mid_sen": "Traditional maximum entropy learning algorithms, such as GIS and IIS (Pietra et al., 1995) , can be used to train CRFs, however, it has been found that a quasi-Newton gradient-climber, BFGS, converges much faster (Malouf, 2002; Sha and Pereira, 2003) . ", "after_sen": "We use BFGS for optimization. "}
{"citeStart": 0, "citeEnd": 25, "citeStartToken": 0, "citeEndToken": 25, "sectionName": "UNKNOWN SECTION NAME", "string": "The results, the central results of this paper, are shown in Figure 1 . Clegg and Shepherd (2005) do not provide separate precision and recall numbers. However we can see that the reranker) modified to use an in-domain tagger.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The results, the central results of this paper, are shown in Figure 1 . ", "mid_sen": "Clegg and Shepherd (2005) do not provide separate precision and recall numbers. ", "after_sen": "However we can see that the reranker) modified to use an in-domain tagger."}
{"citeStart": 95, "citeEnd": 105, "citeStartToken": 95, "citeEndToken": 105, "sectionName": "UNKNOWN SECTION NAME", "string": "The optimal values for the A~ functions can be estimated using the forward-backward algorithm (Baum, 1972) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Deleted interpolation es- where ~'~)q(hlh2h3) = 1 for all histories hlhshs.", "mid_sen": "The optimal values for the A~ functions can be estimated using the forward-backward algorithm (Baum, 1972) .", "after_sen": "A decision-tree model can be represented by an interpolated n-gram model as follows. "}
{"citeStart": 31, "citeEnd": 50, "citeStartToken": 31, "citeEndToken": 50, "sectionName": "UNKNOWN SECTION NAME", "string": "A second observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots. This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002) , which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (Böhmová et al., 2003) , Dutch (van der Beek et al., 2002) and Slovene (Džeroski et al., 2006) , where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively. On the other hand, all three languages behave like high-accuracy languages with respect to attachment score. A very similar pattern is found for Spanish (Civit Torruella and Martí Antonín, 2002) , although this cannot be explained by a high proportion of non-projective structures. One possible explanation in this case may be the fact that dependency graphs in the Spanish data are sparsely labeled, which may cause problem for a parser that relies on dependency labels as features.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A second observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots. ", "mid_sen": "This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002) , which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (Böhmová et al., 2003) , Dutch (van der Beek et al., 2002) and Slovene (Džeroski et al., 2006) , where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively. ", "after_sen": "On the other hand, all three languages behave like high-accuracy languages with respect to attachment score. "}
{"citeStart": 60, "citeEnd": 82, "citeStartToken": 60, "citeEndToken": 82, "sectionName": "UNKNOWN SECTION NAME", "string": "The parameters of subspace model in Equation 2, S and C were estimated to minimize the negative log-likelihood of the correct class. Training employed conventional Stochastic Gradient Descent (Rumelhart et al., 1985) with mini-batch size 1 and random uniform initialization similar to (Glorot and Bengio, 2010) . After some initial experiments, it was determined that a learning rate of 0.01 and selecting the model with the best accuracy on the 20% set after 8 iterations led to the best results.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The parameters of subspace model in Equation 2, S and C were estimated to minimize the negative log-likelihood of the correct class. ", "mid_sen": "Training employed conventional Stochastic Gradient Descent (Rumelhart et al., 1985) with mini-batch size 1 and random uniform initialization similar to (Glorot and Bengio, 2010) . ", "after_sen": "After some initial experiments, it was determined that a learning rate of 0.01 and selecting the model with the best accuracy on the 20% set after 8 iterations led to the best results."}
{"citeStart": 106, "citeEnd": 119, "citeStartToken": 106, "citeEndToken": 119, "sectionName": "UNKNOWN SECTION NAME", "string": "When the articles were completely annotated by the three annotators, the results were analyzed and the differences were reconciled. Differences in annotation could be due to the differences in interpretations of the event; however, we found that the vast majority of radically different judgments can be categorized into a relatively small number of classes. Some of these correspond to aspectual features of events, which have been intensively investigated (e.g., Vendler, 1967; Dowty, 1979; Moens and Steedman, 1988; Passonneau, 1988) . We then developed guidelines to cover those cases (see the next section).", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Differences in annotation could be due to the differences in interpretations of the event; however, we found that the vast majority of radically different judgments can be categorized into a relatively small number of classes. ", "mid_sen": "Some of these correspond to aspectual features of events, which have been intensively investigated (e.g., Vendler, 1967; Dowty, 1979; Moens and Steedman, 1988; Passonneau, 1988) . ", "after_sen": "We then developed guidelines to cover those cases (see the next section)."}
{"citeStart": 115, "citeEnd": 127, "citeStartToken": 115, "citeEndToken": 127, "sectionName": "UNKNOWN SECTION NAME", "string": "The above restriction does not in any way constrain adjunction at nodes that are not in the st)ine of ass auxiliary tree. Similarly, there is no restriction on the adjunction of left or right trees at the spines of wrapping trees. Our restriction is fundamentally different from those in (Schabes and Waters, 1993; Schabes and Waters, 1995) and (Rogers, 1994) , in that we allow wrapping auxiliary trees to nest inside each other an unbounded number of times, so long as they only adjoin at one place its each others' spines. Rogers, in contrast, restricts the nesting of wrapping auxiliaries to a number of times bounded by the size of the grammar, and Sehabes and Waters forbid wrapping auxiliaries altogether, at any node in the grammar.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Similarly, there is no restriction on the adjunction of left or right trees at the spines of wrapping trees. ", "mid_sen": "Our restriction is fundamentally different from those in (Schabes and Waters, 1993; Schabes and Waters, 1995) and (Rogers, 1994) , in that we allow wrapping auxiliary trees to nest inside each other an unbounded number of times, so long as they only adjoin at one place its each others' spines. ", "after_sen": "Rogers, in contrast, restricts the nesting of wrapping auxiliaries to a number of times bounded by the size of the grammar, and Sehabes and Waters forbid wrapping auxiliaries altogether, at any node in the grammar."}
{"citeStart": 134, "citeEnd": 160, "citeStartToken": 134, "citeEndToken": 160, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper we present a linguistically motivated framework for uniform lexicostructural processing. It has been used for transformations of conceptual and syntactic structures during generation in monolingual and multilingual natural language generation (NLG) and for transfer in machine translation (MT). Our work extends directions taken in systems such as Ariane (Vauquois and Boitet, 1985) , FoG (Kittredge and Polgu6re, 1991) , JOYCE (Rainbow and Korelsky, 1992) , and LFS (Iordanskaja et al., 1992) . Although it adopts the general principles found in the abovementioned systems, the approach presented in this paper is more practical, and we believe, would eventually integrate better with emerging statistics-based approaches to MT. * The work performed on the framework by this coauthor was done while at CoGenTex, Inc.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It has been used for transformations of conceptual and syntactic structures during generation in monolingual and multilingual natural language generation (NLG) and for transfer in machine translation (MT). ", "mid_sen": "Our work extends directions taken in systems such as Ariane (Vauquois and Boitet, 1985) , FoG (Kittredge and Polgu6re, 1991) , JOYCE (Rainbow and Korelsky, 1992) , and LFS (Iordanskaja et al., 1992) . ", "after_sen": "Although it adopts the general principles found in the abovementioned systems, the approach presented in this paper is more practical, and we believe, would eventually integrate better with emerging statistics-based approaches to MT. * The work performed on the framework by this coauthor was done while at CoGenTex, Inc."}
{"citeStart": 16, "citeEnd": 35, "citeStartToken": 16, "citeEndToken": 35, "sectionName": "UNKNOWN SECTION NAME", "string": "The MUC scorer (Vilain et al., 1995) is a popular coreference evaluation metric, but we found it to be fatally flawed. As observed by Luo et al. (2004) , if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78.9% precision, and 88.2% F1 score -significantly higher than any published system. The b 3 scorer (Amit and Baldwin, 1998) was proposed to overcome several shortcomings of the MUC scorer. However, coreference resolution is a clustering task, and many cluster scorers already exist. In addition to the MUC and b 3 scorers, we also evaluate using cluster f-measure (Ghosh, 2003) , which is the standard f-measure computed over true/false coreference decisions for pairs of mentions; the Rand index (Rand, 1971) , which is pairwise accuracy of the clustering; and variation of information (Meila, 2003) , which utilizes the entropy of the clusterings and their mutual information (and for which lower values are better).", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The MUC scorer (Vilain et al., 1995) is a popular coreference evaluation metric, but we found it to be fatally flawed. ", "after_sen": "As observed by Luo et al. (2004) , if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78.9% precision, and 88.2% F1 score -significantly higher than any published system. "}
{"citeStart": 242, "citeEnd": 259, "citeStartToken": 242, "citeEndToken": 259, "sectionName": "UNKNOWN SECTION NAME", "string": "Recently, work in computational semantics and lexical semantics has made an interesting shift. Motivated by a concern for lexical organization and global coherence in the structure of lexicon, some researchers have moved towards nlore expressive semantic descriptions, as well as more powerful methods of combining them (see for example Pustejovsky, 1991 Pustejovsky, , 1995 Briscoe, 1993) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Recently, work in computational semantics and lexical semantics has made an interesting shift. ", "mid_sen": "Motivated by a concern for lexical organization and global coherence in the structure of lexicon, some researchers have moved towards nlore expressive semantic descriptions, as well as more powerful methods of combining them (see for example Pustejovsky, 1991 Pustejovsky, , 1995 Briscoe, 1993) .", "after_sen": "This article will exploit one of these theories, The Generative Lezicon (GL: Pustejovsky, 1995) , and extend it for the treatment of French mental adjectives. "}
{"citeStart": 58, "citeEnd": 72, "citeStartToken": 58, "citeEndToken": 72, "sectionName": "UNKNOWN SECTION NAME", "string": "If parsing is taken to be the first step in taming the natural language understanding task, then broad coverage NLP remains a jungle inhabited by wild beasts. For instance, parsing noun compounds appears to require detailed world knowledge that is unavailable outside a limited domain (Sparek Jones, 1983 ). Yet, far from being an obscure, endangered species, the noun compound is flourishing in modern language. It has already made five appearances in this paragraph and at least one diachronic study shows a veritable population explosion (Leonard, 1984) . While substantial work on noun compounds exists in both linguistics (e.g. Levi, 1978; Ryder, 1994) and computational linguistics (Finin, 1980; McDonald, 1982; Isabelle, 1984) , techniques suitable for broad coverage parsing remain unavailable. This paper explores the application of corpus statistics (Charniak, 1993) to noun compound parsing (other computational problems are addressed in Arens el al, 1987; Vanderwende, 1993 and Sproat, 1994) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "While substantial work on noun compounds exists in both linguistics (e.g. Levi, 1978; Ryder, 1994) and computational linguistics (Finin, 1980; McDonald, 1982; Isabelle, 1984) , techniques suitable for broad coverage parsing remain unavailable. ", "mid_sen": "This paper explores the application of corpus statistics (Charniak, 1993) to noun compound parsing (other computational problems are addressed in Arens el al, 1987; Vanderwende, 1993 and Sproat, 1994) .", "after_sen": "The task is illustrated in example 1: Example 1 The parses assigned to these two compounds differ, even though the sequence of parts of speech are identical. "}
{"citeStart": 32, "citeEnd": 46, "citeStartToken": 32, "citeEndToken": 46, "sectionName": "UNKNOWN SECTION NAME", "string": "Since the domain plan reasoner [Ferguson, 1994] performs both plan recognition and plan elaboration in an incremental fashion, proposals from system and user can be integrated naturally in a mixed-initiative fashion. The termination condition will be a shared executable plan which achieves the goal, and each next action in the collaborative planning process will be based on local considerations.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "If a proposal is rejected, the system can negotiate and offer a counterproposal or accept a counter proposal from the user.", "mid_sen": "Since the domain plan reasoner [Ferguson, 1994] performs both plan recognition and plan elaboration in an incremental fashion, proposals from system and user can be integrated naturally in a mixed-initiative fashion. ", "after_sen": "The termination condition will be a shared executable plan which achieves the goal, and each next action in the collaborative planning process will be based on local considerations."}
{"citeStart": 43, "citeEnd": 55, "citeStartToken": 43, "citeEndToken": 55, "sectionName": "UNKNOWN SECTION NAME", "string": "Our system, PROFILE, processes WWWaccessible newswire on a round-the-clock basis and extracts entities (people, places, and organizations) along with related descriptions. The extraction grammar, developed in CREP (Duford, 1993) , covers a variety of pre-modifier and appositional noun phrases.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Our system, PROFILE, processes WWWaccessible newswire on a round-the-clock basis and extracts entities (people, places, and organizations) along with related descriptions. ", "mid_sen": "The extraction grammar, developed in CREP (Duford, 1993) , covers a variety of pre-modifier and appositional noun phrases.", "after_sen": "For each word wi in a description, we use a version of WordNet to extract the synset offset of the immediate parent of wi."}
{"citeStart": 72, "citeEnd": 83, "citeStartToken": 72, "citeEndToken": 83, "sectionName": "UNKNOWN SECTION NAME", "string": "In a categorial formulation, grammatical functions of preverbal and postverbal NPs in (2) can be made explicit by type shifting 2 the subject to S/(S\\NP1) and the object to (S\\NP1)\\((S\\NP1)/NP2). These categories follow from the order-preserving type shifting scheme (Dowty, 1988) :", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In a categorial formulation, grammatical functions of preverbal and postverbal NPs in (2) can be made explicit by type shifting 2 the subject to S/(S\\NP1) and the object to (S\\NP1)\\((S\\NP1)/NP2). ", "mid_sen": "These categories follow from the order-preserving type shifting scheme (Dowty, 1988) :", "after_sen": "(3) NP ~ T/(T~NP) or TVT/NP)"}
{"citeStart": 62, "citeEnd": 84, "citeStartToken": 62, "citeEndToken": 84, "sectionName": "UNKNOWN SECTION NAME", "string": "An overview of the NLG component of Genpex is given in Figure 3 . Its architecture reflects the language generation pipeline of Reiter and Dale (2000) , with three modules: Document Planner, Microplanner and Surface Realizer. Information between the modules is exchanged in the form of a list of sentence trees, each defining the content and grammatical structure of a sentence. The Document Planner creates basic sentence trees. These are manipulated by the Microplanner to create variations. The microplanning stage can in principle be skipped, but that will result in very monotonous texts. Finally, the Surface Realizer applies the correct morphology to the sentence trees and creates the layout of the text. Below, we discuss each module in turn.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "An overview of the NLG component of Genpex is given in Figure 3 . ", "mid_sen": "Its architecture reflects the language generation pipeline of Reiter and Dale (2000) , with three modules: Document Planner, Microplanner and Surface Realizer. ", "after_sen": "Information between the modules is exchanged in the form of a list of sentence trees, each defining the content and grammatical structure of a sentence. "}
{"citeStart": 10, "citeEnd": 36, "citeStartToken": 10, "citeEndToken": 36, "sectionName": "UNKNOWN SECTION NAME", "string": "Following Christiansen et al. (1998) and Doyle and Levy (2013) , we use the Korman corpus (Korman, 1984) as one of our corpora. It comprises childdirected speech for very young infants, aged between 6 and 16 weeks and, like all other corpora used in this paper, is available through the CHILDES database (MacWhinney, 2000) . We derive a phonemicized version of the corpus using an extended version of CMUDict (Carnegie Mellon University, 2008) 4 , as we were unable to obtain the stress-annotated version of this corpus used in previous experiments. The phonemicized version is produced by replacing each orthographic word in the transcript with the first pronunciation given by the dictionary. CMUDict also annotates lexical stress, and we use this information to add stress cues to the corpus. We only code primary lexical stresses in the input, ignoring secondary stresses in line with experimental work that indicates that human listeners are capable of reliably distinguishing primary and secondary stress . Due to the very low frequency of words with 3 or more syllables in these corpora, this choice has very little effect on the number of stress cues available in the input. Our version of the Korman corpus contains, in total, 11413 utterances. Unlike Christiansen et al. (1998) , Yang (2004) , and Doyle and Levy (2013), we follow Lignos and Yang (2010) in making the more realistic assumption that the 94 mono-syllabic function words listed by Selkirk (1984) never surface with lexical stress. As function words account for roughly 50% of the tokens but only roughly 5% of the types in our corpora, this means that the type and token distribution of stress patterns differs dramatically in all our corpora, as can be seen from Table 2 .", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Following Christiansen et al. (1998) and Doyle and Levy (2013) , we use the Korman corpus (Korman, 1984) as one of our corpora. ", "after_sen": "It comprises childdirected speech for very young infants, aged between 6 and 16 weeks and, like all other corpora used in this paper, is available through the CHILDES database (MacWhinney, 2000) . "}
{"citeStart": 158, "citeEnd": 182, "citeStartToken": 158, "citeEndToken": 182, "sectionName": "UNKNOWN SECTION NAME", "string": "An overall error analysis is beyond the scope of this paper, but we will offer a few general observations 5 Detailed specifications of the feature models and learning algorithm parameters can be found on the MaltParser web page. before we turn to Swedish and Turkish, focusing on recall and precision of root nodes, as a reflection of global syntactic structure, and on attachment score as a function of arc length. If we start by considering languages with a labeled attachment score of 85% or higher, they are characterized by high precision and recall for root nodes, typically 95/90, and by a graceful degradation of attachment score as arcs grow longer, typically 95-90-85, for arcs of length 1, 2 and 3-6. Typical examples are Bulgarian (Simov et al., 2005; Simov and Osenova, 2003) , Chinese (Chen et al., 2003) , Danish (Kromann, 2003) , and Swedish . Japanese (Kawata and Bartels, 2000) , despite a very high accuracy, is different in that attachment score drops from 98% to 85%, as we go from length 1 to 2, which may have something to do with the data consisting of transcribed speech with very short utterances.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "If we start by considering languages with a labeled attachment score of 85% or higher, they are characterized by high precision and recall for root nodes, typically 95/90, and by a graceful degradation of attachment score as arcs grow longer, typically 95-90-85, for arcs of length 1, 2 and 3-6. ", "mid_sen": "Typical examples are Bulgarian (Simov et al., 2005; Simov and Osenova, 2003) , Chinese (Chen et al., 2003) , Danish (Kromann, 2003) , and Swedish . Japanese (Kawata and Bartels, 2000) , despite a very high accuracy, is different in that attachment score drops from 98% to 85%, as we go from length 1 to 2, which may have something to do with the data consisting of transcribed speech with very short utterances.", "after_sen": "A second observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots. "}
{"citeStart": 0, "citeEnd": 20, "citeStartToken": 0, "citeEndToken": 20, "sectionName": "UNKNOWN SECTION NAME", "string": "Previous research has identified three means by which speakers signal information about discourse structure to listeners: Cue words and phrases (5, 10); Intonation (7); Pronomi-nalisation (6, 2). In the cue words approach, Reichman'(10) has claimed that phrases like \"because\", \"so\", and \"but\" offer explicit information to listeners about how the speaker's current contribution to the discourse relates to what has gone previously. For example a speaker might use the expression \"so\" to signal that s/he is about to conclude what s/he has just said. Grosz and Sidner (5) relate the use of such phrases to changes in attentional state. An example would be that \"and\" or \"but\" signal to the listener that a new topic and set of referents is being introduced whereas \"anyway\" and \"in any case\" indicate a return to a previous topic and referent set. A second indirect way of signalling discourse structure is intonation. Hirschberg and Pierrehumbert (7) showed that intonational contour is closely related to discourse segmentation with new topics being signalled by changes in intonational contour. A final more indirect cue to discourse structure is the speaker's choice of referring expressions and grammatical structure. A number of researchers (4, 2, 6, 10) have given accounts of how these relate to the continuing, retaining or shifting of focus.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For example a speaker might use the expression \"so\" to signal that s/he is about to conclude what s/he has just said. ", "mid_sen": "Grosz and Sidner (5) relate the use of such phrases to changes in attentional state. ", "after_sen": "An example would be that \"and\" or \"but\" signal to the listener that a new topic and set of referents is being introduced whereas \"anyway\" and \"in any case\" indicate a return to a previous topic and referent set. "}
{"citeStart": 113, "citeEnd": 123, "citeStartToken": 113, "citeEndToken": 123, "sectionName": "UNKNOWN SECTION NAME", "string": "We tried to map source language f-structures to target language f-structure in a connectionist transfer project (Wang, 1994) . Functionally, there were two sub-tasks: 1. finding the target sub-structures, their phrasal categories and their corresponding source structures; 2. finding the head of a target structure. The second subtask is a problem of lexical selection. It was first implemented with a back-propagation network.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We tried to map source language f-structures to target language f-structure in a connectionist transfer project (Wang, 1994) . ", "after_sen": "Functionally, there were two sub-tasks: "}
{"citeStart": 99, "citeEnd": 112, "citeStartToken": 99, "citeEndToken": 112, "sectionName": "UNKNOWN SECTION NAME", "string": "Lexically-based rules could be written and exception lists used to disambiguate the difficult cases described above. However, the lists will never be exhaustive, and multiple rules may interact badly since punctuation marks exhibit absorption properties. Sites which logically should be marked with multiple punctuation marks will often only have one ( (Nunberg, 1990) as summarized in (White, 1995) ). For example, a sentence-ending abbreviation will most likely not be followed by an additional period if the abbreviation already contains one (e.g. note that D. C is followed by only a single . in The president lives in Washington, D.C.).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, the lists will never be exhaustive, and multiple rules may interact badly since punctuation marks exhibit absorption properties. ", "mid_sen": "Sites which logically should be marked with multiple punctuation marks will often only have one ( (Nunberg, 1990) as summarized in (White, 1995) ). ", "after_sen": "For example, a sentence-ending abbreviation will most likely not be followed by an additional period if the abbreviation already contains one (e.g. note that D. C is followed by only a single . in The president lives in Washington, D.C.)."}
{"citeStart": 29, "citeEnd": 55, "citeStartToken": 29, "citeEndToken": 55, "sectionName": "UNKNOWN SECTION NAME", "string": "as features in a CRF-based NE tagger. We follow the method used by Kazama and Torisawa (2007) , which encodes the matching with a gazetteer entity using IOB tags, with the modification for Japanese. They describe using two types of gazetteer features. The first is a matching-only feature, which uses bare IOB tags to encode only matching information. The second uses IOB tags that are augmented with classes (e.g., B-country and I-country). 11 When there are several possibilities for making a match, the left-most longest match is selected. The small differences from their work are: (1) We used characters as the unit as we described above, (2) While Kazama and Torisawa (2007) checked only the word sequences that start with a capitalized word and thus exploited the characteristics of English language, we checked the matching at every character, 3We used a TRIE to make the look-up efficient.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "as features in a CRF-based NE tagger. ", "mid_sen": "We follow the method used by Kazama and Torisawa (2007) , which encodes the matching with a gazetteer entity using IOB tags, with the modification for Japanese. ", "after_sen": "They describe using two types of gazetteer features. "}
{"citeStart": 217, "citeEnd": 243, "citeStartToken": 217, "citeEndToken": 243, "sectionName": "UNKNOWN SECTION NAME", "string": "The only trainable approaches (known to the author) to surface generation are the purely statistical machine translation (MT) systems such as (Berger et al., 1996) and the corpus-based generation system described in (Langkilde and Knight, 1998) . The MT systems of (Berger et al., 1996) learn to generate text in the target language straight from the source language, without the aid of an explicit semantic representation. In contrast, (Langkilde and Knight, 1998) uses corpus-derived statistical knowledge to rank plausible hypotheses from a grammarbased surface generation component.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "These packages require linguistic sophistication in order to write the abstract semantic representation, but they are flexible because minor changes to the input can accomplish major changes to the generated text.", "mid_sen": "The only trainable approaches (known to the author) to surface generation are the purely statistical machine translation (MT) systems such as (Berger et al., 1996) and the corpus-based generation system described in (Langkilde and Knight, 1998) . ", "after_sen": "The MT systems of (Berger et al., 1996) learn to generate text in the target language straight from the source language, without the aid of an explicit semantic representation. "}
{"citeStart": 0, "citeEnd": 24, "citeStartToken": 0, "citeEndToken": 24, "sectionName": "UNKNOWN SECTION NAME", "string": "One problem with applying lexical association to noun compounds is the enormous number of parameters required, one for every possible pair of nouns. Not only does this require a vast amount of memory space, it creates a severe data sparseness problem since we require at least some data about each parameter. Resnik and Hearst (1993) coined the term CONCEPTUAL ASSOCIATION to refer to association values computed between groups of words. By assuming that all words within a group behave similarly, the parameter space can be built in terms of the groups rather than in terms of the words.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Not only does this require a vast amount of memory space, it creates a severe data sparseness problem since we require at least some data about each parameter. ", "mid_sen": "Resnik and Hearst (1993) coined the term CONCEPTUAL ASSOCIATION to refer to association values computed between groups of words. ", "after_sen": "By assuming that all words within a group behave similarly, the parameter space can be built in terms of the groups rather than in terms of the words."}
{"citeStart": 19, "citeEnd": 44, "citeStartToken": 19, "citeEndToken": 44, "sectionName": "UNKNOWN SECTION NAME", "string": "In this situation, Brown et al. (1993b, 293) recommend \"evaluating the expectations using only a single, probable alignment.\" The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This is why we must make do with approximations to the EM algorithm.", "mid_sen": "In this situation, Brown et al. (1993b, 293) recommend \"evaluating the expectations using only a single, probable alignment.\" The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:", "after_sen": "EQUATION"}
{"citeStart": 70, "citeEnd": 89, "citeStartToken": 70, "citeEndToken": 89, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper, we make direct search reasonably fast thanks to two speedup techniques. First, we use a model selection acceleration technique called racing (Moore and Lee, 1994) in conjunction with randomization tests (Riezler and Maxwell, 2005) to avoid decoding the entire development set at each function evaluation. This approach discards the current model whenever performance on the translated subset of the development data is deemed significantly worse in comparison to the current best model. Second, we store and re-use search graphs across function evaluations, which eliminates some of the redundancy of regenerating the same translations in different optimization steps.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In this paper, we make direct search reasonably fast thanks to two speedup techniques. ", "mid_sen": "First, we use a model selection acceleration technique called racing (Moore and Lee, 1994) in conjunction with randomization tests (Riezler and Maxwell, 2005) to avoid decoding the entire development set at each function evaluation. ", "after_sen": "This approach discards the current model whenever performance on the translated subset of the development data is deemed significantly worse in comparison to the current best model. "}
{"citeStart": 131, "citeEnd": 148, "citeStartToken": 131, "citeEndToken": 148, "sectionName": "UNKNOWN SECTION NAME", "string": "This problem is analyzed in (de Swart, 1991) as an instance of the proportion problem and given a solution from a Generalized Quantifier approach. We were led to seek a solution for this problem within DRT, because of DRT's advantages as a general theory of discourse, and its choice as the underlying formalism in another research project of ours, which deals with sentences such as 1-4, in the context of natural language specifications of computerized systems. In this paper, we propose such a solution, based on a careful distinction between different roles of Reichenbach's reference time (Reichenbach, 1947) , adapted from (Kamp and Reyle, 1993) . Figure 1 shows a 'minimal pair' of DRS's for sentence 1, one according to Partee's(1984) analysis and one according to ours.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We were led to seek a solution for this problem within DRT, because of DRT's advantages as a general theory of discourse, and its choice as the underlying formalism in another research project of ours, which deals with sentences such as 1-4, in the context of natural language specifications of computerized systems. ", "mid_sen": "In this paper, we propose such a solution, based on a careful distinction between different roles of Reichenbach's reference time (Reichenbach, 1947) , adapted from (Kamp and Reyle, 1993) . ", "after_sen": "Figure 1 shows a 'minimal pair' of DRS's for sentence 1, one according to Partee's(1984) analysis and one according to ours."}
{"citeStart": 129, "citeEnd": 163, "citeStartToken": 129, "citeEndToken": 163, "sectionName": "UNKNOWN SECTION NAME", "string": "The algorithm used to compute the actual mappings from the F-measure table is briefly described here. In each row of the table, mark the cell with the highest F-measure as a potential mapping. In general, conflicts arise when more than one class generated by the system maps to a given class provided by the expert. In other words, whenever a column in the table has more than one cell marked as a potential mapping, a conflict is said to exist. To resolve a conflict, one of the system classes must be re-mapped. The heuristic used here is that the class for which such a re-mapping results in minimal loss of F-measure is the one that must be re-mapped. Several such conflicts may exist, and re-mapping may lead to further conflicts. The mapping algorithm iteratively searches for conflicts and resolves them till no more conflicts exist. Note also that a system class may map to an expert class only if the F-measure between them exceeds a certain threshold value. This ensures that a certain degree of similarity must exist between two classes for them to map to each other. We have used a threshold value of 0.20. This value is obtained purely by observations made on the F-measures between different pairs of classes with varying degrees of similarity. Table 2 ). Once all the mapped classes have been incorporated into this contingency table, add every element of all unmapped classes generated by the system to the YES-NO cell and every element of all unmapped classes provided by the expert to the NO-YES cell of this table. Once all classes in the two clusterings have been accounted for, calculate the precision, recall, and F-measure as explained in (Hatzivassiloglou and McKeown, 1993) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Table 2 ). Once all the mapped classes have been incorporated into this contingency table, add every element of all unmapped classes generated by the system to the YES-NO cell and every element of all unmapped classes provided by the expert to the NO-YES cell of this table. ", "mid_sen": "Once all classes in the two clusterings have been accounted for, calculate the precision, recall, and F-measure as explained in (Hatzivassiloglou and McKeown, 1993) .", "after_sen": ""}
{"citeStart": 152, "citeEnd": 164, "citeStartToken": 152, "citeEndToken": 164, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper we propose a new, simple model for selectional preference induction that uses corpus-based semantic similarity metrics, such as Cosine or Lin's (1998) mutual informationbased metric, for the generalization step. This model does not require any manually created lexical resources. In addition, the corpus for computing the similarity metrics can be freely chosen, allowing greater variation in the domain of generalization than a fixed lexical resource.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Some approaches have used WordNet for the generalization step (Resnik, 1996; Clark and Weir, 2001; Abe and Li, 1993) , others EM-based clustering (Rooth et al., 1999) .", "mid_sen": "In this paper we propose a new, simple model for selectional preference induction that uses corpus-based semantic similarity metrics, such as Cosine or Lin's (1998) mutual informationbased metric, for the generalization step. ", "after_sen": "This model does not require any manually created lexical resources. "}
{"citeStart": 160, "citeEnd": 180, "citeStartToken": 160, "citeEndToken": 180, "sectionName": "UNKNOWN SECTION NAME", "string": "The interest in the 80's begun to turn considering grammar checking as an enterprise of its own right (Carbonell & Hayes, 1983) , (Ilayes & Mouradian, 1981) , (Heidorn et al., 1982) , (.lensen at al., 1983) , though many of the approaches were still in I;t1(: NLU tradition ((]harniak, 198a), (Granger, 1983) , (Kwasny & Sondheimer, 1981) , (Weischedel & Black, ] 980), (Weisehedel & Sondheimer, 1983) . A 1985 Ovum report on nal;llral language applications (.lohnson, 1985) already identifies grammar and style checking as one of the seven major apt)lications of NLP. Currently, every project in grammar checking has as its goal the creation of a writing aid rather than a robust man-machine interface (Adriaens, 1994) , (llolioli ctal., 1992) , (Vosse, 1992) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Many of the NLU systems developed in the 70's indu(le(l a kind of error recovery Inechanisln ranging flom the treatment only of spelling e.rrors, PARRY (1)arkinson c 't al., 1977) , to tile inclusion also of incomplete int)ut containing some kind of ellipsis, LAD-DEll,/LIFEll (Hendrix et al., 1977) .", "mid_sen": "The interest in the 80's begun to turn considering grammar checking as an enterprise of its own right (Carbonell & Hayes, 1983) , (Ilayes & Mouradian, 1981) , (Heidorn et al., 1982) , (.lensen at al., 1983) , though many of the approaches were still in I;t1(: NLU tradition ((]harniak, 198a), (Granger, 1983) , (Kwasny & Sondheimer, 1981) , (Weischedel & Black, ] 980), (Weisehedel & Sondheimer, 1983) . ", "after_sen": "A 1985 Ovum report on nal;llral language applications (.lohnson, 1985) already identifies grammar and style checking as one of the seven major apt)lications of NLP. "}
{"citeStart": 60, "citeEnd": 82, "citeStartToken": 60, "citeEndToken": 82, "sectionName": "UNKNOWN SECTION NAME", "string": "• Our initial experiments with the integration of GermaNet (Hamp and Feldweg, 1997) , the evolving German version of WordNet, seem to confirm the positive results described for Word-Net (de Buenaga Rodriguez et al., 1997) and will thus be extended.", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This includes heuristics for the identification of multiple requests in a single e-mail that could be based on key words and key phrases as well as on the analysis of the document structure.", "mid_sen": "• Our initial experiments with the integration of GermaNet (Hamp and Feldweg, 1997) , the evolving German version of WordNet, seem to confirm the positive results described for Word-Net (de Buenaga Rodriguez et al., 1997) and will thus be extended.", "after_sen": "• A reorganization of the existing three-level category system into a semantically consistent tree structure would allow us to explore the nonterminal nodes of the tree for multi-layered SML. "}
{"citeStart": 41, "citeEnd": 61, "citeStartToken": 41, "citeEndToken": 61, "sectionName": "UNKNOWN SECTION NAME", "string": "SNoW uses the Open Close model, described in Muñoz et al. 1999 Table 1 : The e ects of system-internal combination by using di erent output representations. A straight-forward majority v ote of the output yields better bracket accuracies and F =1 rates than any included individual classi er. The bracket accuracies in the columns O and C show what percentage of words was correctly classi ed as baseNP start, baseNP end or neither. model produced better results than the other paradigm evaluated there, the Inside Outside paradigm. The Open Close model consists of two SNoW predictors, one of which predicts the beginning of baseNPs Open predictor, and the other predicts the end of the phrase Close predictor. The Open predictor is learned using SNoW Carlson et al., 1999; Roth, 1998 as a function of features that utilize words and POS tags in the sentence and, given a new sentence, will predict for each w ord whether it is the rst word in the phrase or not. For each Open, the Close predictor is learned using SNoW as a function of features that utilize the words in the sentence, the POS tags and the open prediction. It will predict, for each word, whether it can be the end of the phrase, given the previously predicted Open. Each pair of predicted Open and Close forms a candidate of a baseNP. These candidates may con ict due to overlapping; at this stage, a graph-based constraint satisfaction algorithm that uses the con dence values SNoW associates with its predictions is employed. This algorithm \"the combinator\" produces the list of the nal baseNPs for each sentence. Details of SNoW, its application in shallow parsing and the combinator's algorithm are in Muñoz et al. 1999.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The Open Close model consists of two SNoW predictors, one of which predicts the beginning of baseNPs Open predictor, and the other predicts the end of the phrase Close predictor. ", "mid_sen": "The Open predictor is learned using SNoW Carlson et al., 1999; Roth, 1998 as a function of features that utilize words and POS tags in the sentence and, given a new sentence, will predict for each w ord whether it is the rst word in the phrase or not. ", "after_sen": "For each Open, the Close predictor is learned using SNoW as a function of features that utilize the words in the sentence, the POS tags and the open prediction. "}
{"citeStart": 60, "citeEnd": 78, "citeStartToken": 60, "citeEndToken": 78, "sectionName": "UNKNOWN SECTION NAME", "string": "Word compositions have long been a concern in lexicography (Benson et al. 1986; Miller et al. 1995) , and now as a specific kind of lexical knowledge, it has been shown that they have an important role in many areas in natural language processing, e.g., parsing, generation, lexicon building, word sense disambiguation, and information retrieving, etc.(e.g., Abney 1989 Abney , 1990 Benson et al. 1986; Yarowsky 1995; Church, Gale, Hans, and Hindle 1989) . But due to the huge number of words, it is impossible to list all compositions between words by hand in dictionaries. So an urgent problem occurs: how to automatically acquire word compositions? In general, word compositions fall into two categories: free compositions and bound compositions, i.e., collocations. Free compositions refer to those in which words can be replaced by other similar ones, while in bound compositions, words cannot be replaced freely (Benson 1990) . Free compositions are predictable, i.e., their reasonableness can be determined according to the syntactic and semantic properties of the words in them. While bound compositions are not predictable, i.e., their reasonableness cannot be derived from the syntactic and semantic properties of the words in them (Smadja 1993) . Now with the availability of large-scale corpus, automatic acquisition of word compositions, especially word collocations from them have been extensively studied(e.g., Choueka et al. 1988; Smadja 1993) . The key of their methods is to make use of some statistical means, e.g., frequencies or mutual information, to quantify the compositional strength between words. These methods are more appropriate for retrieving bound compositions, while less appropriate for retrieving free ones. This is because in free compositions, words are related with each other in a more loose way, which may result in the invalidity of mutual information and other statistical means in distinguishing reasonable compositions from unreasonable ones. In this paper, we start from a different point to explore the problem of automatic acquisition of free compositions. Although we cannot list all free compositions, we can select some typical ones as those specified in some dictionaries(e.g., Benson 1986; Zhang et al. 1994) . According to the properties held by free compositions, we can reasonably suppose that selected compositions can provide strong clues for others. Furthermore we suppose that words can be classified into clusters, with the members in each cluster similar in their compositional ability, which can be characterized as the set of the words able to combined with them to form meaningful phrases. Thus any given composition, although specifying the relation between two words literally, suggests the relation between two clusters. So for each word(or clus-ter), there exist some word clusters, the word (or the words in the cluster) can and only can combine with the words in the clusters to form meaningful phrases. We call the set of these clusters compositional frame of the word (or the cluster). A seemingly plausible method to determine compositional frames is to make use of pre-defined semantic classes in some thesauri(e.g., Miller et al. 1993; Mei et al. 1996) . The rationale behind the method is to take such an assumption that if one word can be combined with another one to form a meaningful phrase, the words similar to them in meaning can also be combined with each other. But it has been shown that the similarity between words in meaning doesn't correspond to the similarity in compositional ability (Zhu 1982) . So adopting semantic classes to construct compositional frames will result in considerable redundancy. An alternative to semantic class is word cluster based on distributional environment (Brown et al., 1992) , which in general refers to the surrounding words distributed around certain word (e.g., Hatzivassiloglou et al., 1993; Pereira et al., 1993) , or the classes of them (Bensch et al., 1995) , or more complex statistical means (Dagan et al., 1993) . According to the properties of the clusters in compositional frames, the clusters should be based on the environment, which, however, is narrowed in the given compositions. Because the given compositions are listed by hand, it is impossible to make use of statistical means to form the environment, the remaining choices are surrounding words or classes of them. Pereira et a1.(1993) put forward a method to cluster nouns in V-N compositions, taking the verbs which can combine with a noun as its environment. Although its goal is to deal with the problem of data sparseness, it suffers from the problem itself.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Word compositions have long been a concern in lexicography (Benson et al. 1986; Miller et al. 1995) , and now as a specific kind of lexical knowledge, it has been shown that they have an important role in many areas in natural language processing, e.g., parsing, generation, lexicon building, word sense disambiguation, and information retrieving, etc.(e.g., Abney 1989 Abney , 1990 Benson et al. 1986; Yarowsky 1995; Church, Gale, Hans, and Hindle 1989) . ", "after_sen": "But due to the huge number of words, it is impossible to list all compositions between words by hand in dictionaries. "}
{"citeStart": 174, "citeEnd": 202, "citeStartToken": 174, "citeEndToken": 202, "sectionName": "UNKNOWN SECTION NAME", "string": "This paper has shown how adaptor grammars can be used to study a variety of different linguistic hy-potheses about the interaction of morphology and syllable structure with word segmentation. Technically, adaptor grammars are a way of specifying a variety of Hierarchical Dirichlet Processes (HDPs) that can spread their support over an unbounded number of distinct subtrees, giving them the ability to learn which subtrees are most useful for describing the training corpus. Thus adaptor grammars move beyond simple parameter estimation and provide a principled approach to the Bayesian estimation of at least some types of linguistic structure. Because of this, less linguistic structure needs to be \"built in\" to an adaptor grammar compared to a comparable PCFG. For example, the adaptor grammars for syllable structure presented in sections 3.3 and 3.6 learn more information about syllable onsets and codas than the PCFGs presented in Goldwater and Johnson (2005) .", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Because of this, less linguistic structure needs to be \"built in\" to an adaptor grammar compared to a comparable PCFG. ", "mid_sen": "For example, the adaptor grammars for syllable structure presented in sections 3.3 and 3.6 learn more information about syllable onsets and codas than the PCFGs presented in Goldwater and Johnson (2005) .", "after_sen": "We used adaptor grammars to study the effects of modeling morphological structure, syllabification and collocations on the accuracy of a standard unsupervised word segmentation task. "}
{"citeStart": 61, "citeEnd": 90, "citeStartToken": 61, "citeEndToken": 90, "sectionName": "UNKNOWN SECTION NAME", "string": "This paper presents a simple but high-performance method for text categorization. The method assigns domain tags to words in an article, and categorizes the article as the most dominant domain. In this study, the 12 domains in Table 1 are used following (Hashimoto and Kurohashi, 2007) (H&K hereafter) 1 . Fundamental words are assigned with a do- main tag by H&K's domain dictionary, while the domains of non-fundamental words (i.e. unknown words) are dynamically estimated, which makes the method different from previous ones. Another hallmark of the method is that it requires no machine learning. All you need is the domain dictionary and the access to the Web.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The method assigns domain tags to words in an article, and categorizes the article as the most dominant domain. ", "mid_sen": "In this study, the 12 domains in Table 1 are used following (Hashimoto and Kurohashi, 2007) (H&K hereafter) 1 . Fundamental words are assigned with a do- main tag by H&K's domain dictionary, while the domains of non-fundamental words (i.e. unknown words) are dynamically estimated, which makes the method different from previous ones. ", "after_sen": "Another hallmark of the method is that it requires no machine learning. "}
{"citeStart": 29, "citeEnd": 55, "citeStartToken": 29, "citeEndToken": 55, "sectionName": "UNKNOWN SECTION NAME", "string": "For implicit citation extraction, Kaplan et al. (2009) explore co-reference chains for citation extraction using a combination of co-reference resolution techniques. However, their corpus consists of only 94 sentences of citations to 4 papers which is likely to be too small to be representative. The most relevant work is by Qazvinian and Radev (2010) who extract only the non-explicit citations for a given paper. They model each sentence as a node in a graph and experiment with various window boundaries to create edges between neighbouring nodes. However, their dataset consists of only 10 papers and their annotation scheme differs from our four-class annotation as they do not deal with any sentiment.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, their corpus consists of only 94 sentences of citations to 4 papers which is likely to be too small to be representative. ", "mid_sen": "The most relevant work is by Qazvinian and Radev (2010) who extract only the non-explicit citations for a given paper. ", "after_sen": "They model each sentence as a node in a graph and experiment with various window boundaries to create edges between neighbouring nodes. "}
{"citeStart": 0, "citeEnd": 15, "citeStartToken": 0, "citeEndToken": 15, "sectionName": "UNKNOWN SECTION NAME", "string": "The second reason that the connection to TBLs is important is that it shows us that probabilistic decision lists are a natural way to probabilize TBLs. Florian et al. (2000) showed one way to make probabilistic versions of TBLs, but the technique is somewhat complicated. It involved conversion to a decision tree, and then further growing of the tree. Their technique does have the advantage that it correctly handles the multi-class case. That is, by using a decision tree, it is relatively easy to incorporate the current state, while the decision list learner ignores that state. However, this is not clearly an advantage -adding extra dependencies introduces data sparseness, and it is an empirical question whether dependencies on the current state are actually helpful. Our probabilistic decision lists can thus be thought of as a competitive way to probabilize TBLs, with the advantage of preserving the list-structure and simplicity of TBL, and the possible disadvantage of losing the dependency on the current state. Yarowsky (1994) suggests two improvements to the standard algorithm. First, he suggests an optional, more complex smoothing algorithm than the one we applied. His technique involves estimating both a probability based on the global probability distribution for a question, and a local probability, given that no questions higher in the list were TRUE, and then interpolating between the two probabilities. He also suggests a pruning technique that eliminates 90% of the questions while losing 3% accuracy; as we will show in Section 4, our technique or variations eliminate an even larger percentage of questions while increasing accuracy. Yarowsky (2000) also considered changing the structure of decision lists to include a few splits at the top, thus combining the advantages of decision trees and decision lists. The combination of this hybrid decision list and the improved smoothing was the best performer for participating systems in the 1998 senseval evaluation. Our technique could easily be combined with these techniques, presumably leading to even better results. However, since we build our decision lists from last to first, rather than first to last, the local probability is not available as the list is being built. But there is no reason we could not interpolate the local probability into a final list. Similarly, in Yarowsky's technique, the local probability is also not available at the time the questions are sorted.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Our probabilistic decision lists can thus be thought of as a competitive way to probabilize TBLs, with the advantage of preserving the list-structure and simplicity of TBL, and the possible disadvantage of losing the dependency on the current state. ", "mid_sen": "Yarowsky (1994) suggests two improvements to the standard algorithm. ", "after_sen": "First, he suggests an optional, more complex smoothing algorithm than the one we applied. "}
{"citeStart": 107, "citeEnd": 121, "citeStartToken": 107, "citeEndToken": 121, "sectionName": "UNKNOWN SECTION NAME", "string": "The output of the parser is a combinatory form. The combinators in this form may arise from the CCG schema, i.e., the compositor B, and the substitutor S (Steedman, 1987) . They may also be projected from the PAS of a lexical item, such as the duplicator W (with the reduction rule Wfa>faa) for re-n+l flexives, and B C for predicate composition with the causative suffix. For instance, the combinatory form for (13a) is the expression (13b). B~'~\"c AU s E Although B works in a binary manner in CCG to achieve abstraction, it requires 3 arguments for full evaluation (its order is 3). Revealing the PAS amounts to stripping off all combinators from the combinatory form by evaluating the reducible expressions (redexes). Bfg is not a redex but Bfga is.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The output of the parser is a combinatory form. ", "mid_sen": "The combinators in this form may arise from the CCG schema, i.e., the compositor B, and the substitutor S (Steedman, 1987) . ", "after_sen": "They may also be projected from the PAS of a lexical item, such as the duplicator W (with the reduction rule Wfa>faa) for re-n+l flexives, and B C for predicate composition with the causative suffix. "}
{"citeStart": 100, "citeEnd": 115, "citeStartToken": 100, "citeEndToken": 115, "sectionName": "UNKNOWN SECTION NAME", "string": "Thus if we try to build the prediction table in the obvious way, we get an infinite set of pairs of terms. The key to this problem is to recognize that it is not necessary or even useful to predict every possible feature of the next input. It makes sense to predict the presence of traces, but predicting the subcategorization frame of a verb will cost more than it saves. To avoid predicting certain features, we use a weak prediction dr(i,k) that the ideal prediction table would remove, but it may also cost less to use. Sato and Tamaki (1984) proposed to analyze the behavior of Prolog programs, including parsers, by using something much like a weak prediction table. To guarantee that the table was finite, they restricted the depth of terms occurring in the table • Shieber (1985b) offered a more selective approach--his program predicts only those features chosen by the user as most useful for prediction. Pereira and Shieber (1987) discuss both approaches. We will present a variation of Shieber's ideas that depends on using a sorted language.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Sato and Tamaki (1984) proposed to analyze the behavior of Prolog programs, including parsers, by using something much like a weak prediction table. ", "mid_sen": "To guarantee that the table was finite, they restricted the depth of terms occurring in the table • Shieber (1985b) offered a more selective approach--his program predicts only those features chosen by the user as most useful for prediction. ", "after_sen": "Pereira and Shieber (1987) discuss both approaches. "}
{"citeStart": 14, "citeEnd": 38, "citeStartToken": 14, "citeEndToken": 38, "sectionName": "UNKNOWN SECTION NAME", "string": "In this approach we do not try to resolve each ambiguous word occurrence individually. Instead, the system scans the entire document for the contexts in which the words in question are used unambiguously, and this gives it grounds, acting by analogy, for resolving ambiguous contexts. We deliberately shaped our approach so that it largely does not rely on precompiled statistics, because the most interesting events are inherently infrequent and hence are difficult to collect reliable statistics for. At the same time precompiled statistics would be smoothed across multiple documents rather than targeted to a specific document. By collecting suggestive instances of usage for target words from each particular document on the fly, rather than relying on preacquired resources smoothed across the entire document collection, our approach is robust to domain shifts and new lexica and closely targeted to each document. A significant advantage of this approach is that it can be targeted to new domains completely automatically, without human intervention. The four word lists that our system uses for its operation can be generated automatically from a raw corpus and require no human annotation. Although some SBD systems can be trained on relatively small sets of labeled examples, their performance in such cases is somewhat lower than their optimal performance. For instance, Palmer and Hearst (1997) report that the SATZ system (decision tree variant) was trained on a set of about 800 labeled periods, which corresponds to a corpus of about 16,000 words. This is a relatively small training set that can be manually marked in a few hours' time. But the error rate (1.5%) of the decision tree classifier trained on this small sample was about 50% higher than that when trained on 6,000 labeled examples (1.0%).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Although some SBD systems can be trained on relatively small sets of labeled examples, their performance in such cases is somewhat lower than their optimal performance. ", "mid_sen": "For instance, Palmer and Hearst (1997) report that the SATZ system (decision tree variant) was trained on a set of about 800 labeled periods, which corresponds to a corpus of about 16,000 words. ", "after_sen": "This is a relatively small training set that can be manually marked in a few hours' time. "}
{"citeStart": 308, "citeEnd": 319, "citeStartToken": 308, "citeEndToken": 319, "sectionName": "UNKNOWN SECTION NAME", "string": "The concept of a domain, however, is not precisely defined across existing domain adaptation methods. Different domains typically correspond to different subcorpora, in which documents exhibit a particular combination of genre and topic, and optionally other textual characteristics such as dialect and register. This definition, however, has two major shortcomings. First, subcorpusbased domains depend on provenance information, which might not be available, or on manual grouping of documents into subcorpora, which is labor intensive and often carried out according to arbitrary criteria. Second, the commonly used notion of a domain neglects the fact that topic and genre are two distinct properties of text (Stein and Meyer Zu Eissen, 2006) . While this distinction has long been acknowledged in text classification literature (Lee, 2001; Dewdney et al., 2001; Lee and Myaeng, 2002) , most work on domain adaptation in SMT uses in-domain and out-of-domain data that differs on both the topic and the genre level (e.g., Europarl political proceedings (Koehn, 2005) versus EMEA medical text (Tiedemann, 2009) ), making it unclear whether the proposed solutions address topic or genre differences.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Second, the commonly used notion of a domain neglects the fact that topic and genre are two distinct properties of text (Stein and Meyer Zu Eissen, 2006) . ", "mid_sen": "While this distinction has long been acknowledged in text classification literature (Lee, 2001; Dewdney et al., 2001; Lee and Myaeng, 2002) , most work on domain adaptation in SMT uses in-domain and out-of-domain data that differs on both the topic and the genre level (e.g., Europarl political proceedings (Koehn, 2005) versus EMEA medical text (Tiedemann, 2009) ), making it unclear whether the proposed solutions address topic or genre differences.", "after_sen": "In this work, we follow text classification literature for definitions of the concepts topic and genre. "}
{"citeStart": 84, "citeEnd": 107, "citeStartToken": 84, "citeEndToken": 107, "sectionName": "UNKNOWN SECTION NAME", "string": "Though several studies with similar objectives have been reported [Church, 1988] , [Zernik and Jacobs, 1990] , [Calzolari and Bindi, 1990] , [Garside and Leech, 1985] , [Hindle and Rooth, 1991] , [Brown et al., 1990] , they require that sample corpora be correctly analyzed or tagged in advance. It must be a training corpus, which is tagged or parsed by human or it needs correspondence between two language corpora. Because their preparation needs a lot of manual assistance or an unerring tagger or parser, this requirement makes their algorithm~, troublesome in actual application environments. On the other hand, the algorithm in this paper has no such requirement, it requires only a minimum of linguistic knowledge, including parts-of-speech of words, simple inflection rules, and a small number of general syntactic rules which lexicon based syntactic theories like HPSG CC etc. normally assume. The parser is not a deterministic parser, but a parser which produces all possible analyses. All of the results are used for calculation ant the system assumes that there is a correct answer among them. The algorithm builds correct structural descriptions of sentences and discovers semantic collocations at the same time. It works as a relaxation process.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We expect that the knowledge to be extracted will not only be useful for disambiguating sentences but also will contribute to discovering ontological classes in given subject domains.", "mid_sen": "Though several studies with similar objectives have been reported [Church, 1988] , [Zernik and Jacobs, 1990] , [Calzolari and Bindi, 1990] , [Garside and Leech, 1985] , [Hindle and Rooth, 1991] , [Brown et al., 1990] , they require that sample corpora be correctly analyzed or tagged in advance. ", "after_sen": "It must be a training corpus, which is tagged or parsed by human or it needs correspondence between two language corpora. "}
{"citeStart": 79, "citeEnd": 102, "citeStartToken": 79, "citeEndToken": 102, "sectionName": "UNKNOWN SECTION NAME", "string": "For semantic tasks, words are obviously important. In addition to considering 'content words', we also explored specific word lists. Group 11 uses 2 lists of 1636 positive and 2008 negative words, obtained from (Di Cicco et al., online) . Group 12 uses lexical lists extracted from WordNet (Fellbaum, 1998) , on the basis of the primary emotion words in their adjectival and nominal forms. For the adjectives, Py-WordNet's (Steele et al., 2004 ) SIMI-LAR feature was used to retrieve similar items of the primary emotion adjectives, exploring one additional level in the hierarchy (i.e. similar items of all senses of all words in the synset). For the nouns and any identical verbal homonyms, synonyms and hyponyms were extracted manually. 3 Feature group 13 used a short list of 22 interjections collected manually by browsing educational ESL sites, whereas the affective word list of 771 words consisted of a combination of the non-neutral words from (Johnson-Laird and Oatley, 1989) and (Siegle, online) . Only a subset of these lexical lists actually occurred. 4 The above feature set is henceforth referred to as all features, whereas content BOW is just group 14. The content BOW is a more interesting baseline than the naïve one, P(Neutral), i.e. always assigning the most likely NEUTRAL category. Lastly, emotions blend and transform (Liu, Lieberman and Selker, 2003) . Thus, emotion and background mood of immediately adjacent sentences, i.e. the sequencing, seems important. At this point, it is not implemented automatically. Instead, it was extracted from the manual emotion and mood annotations. If sequencing seemed important, an automatic method using sequential target activation could be added next.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In addition to considering 'content words', we also explored specific word lists. ", "mid_sen": "Group 11 uses 2 lists of 1636 positive and 2008 negative words, obtained from (Di Cicco et al., online) . ", "after_sen": "Group 12 uses lexical lists extracted from WordNet (Fellbaum, 1998) , on the basis of the primary emotion words in their adjectival and nominal forms. "}
{"citeStart": 163, "citeEnd": 180, "citeStartToken": 163, "citeEndToken": 180, "sectionName": "UNKNOWN SECTION NAME", "string": "One of the earliest approaches is performed in the context of the Genia project and corpus of medical texts from MEDLINE. In a first stage, only MEDLINE abstracts are used (Yang et al., 2004) , later other-anaphora, a very specific sub-task, are investigated using full paper content (Chen et al., 2008) . Gasperin (2009) presents a full annotation of anaphora and coreference in biomedical text, but only noun phrases referring to biomedical entities are considered. On the basis of this annotation, she implements a probabilistic anaphora resolution system. In contrast, Cohen et al. (2010) build a corpus of 97 full-text journal articles in the biomedical domain where every co-referring noun phrase is annotated (CRAFT -Colorado Richly Annotated Full Text). Their annotation guidelines follow those of the OntoNotes project (Hovy et al., 2006) , adapted to the biomedical domain. OntoNotes itself is a text corpus of approx. one million words from mainly news texts (newswire, magazines, broadcast conversations, web pages). It also contains general anaphoric coreference annotations (Pradhan et al., 2007) : events and (like in our annotation) unlimited noun phrase entity types. Kim and Webber (2006) investigate a special aspect, citation sentences where a pronoun such as \"they\" refers to a previous citation. The study is performed on astronomy journal articles and a maximum-entropy classifier is trained. Kaplan et al. (2009) investigate coreferences and citations as well, but only at a very small scale (4 articles from the Computational Linguistics journal). They focus on so-called c-sites which are the sentences following a citation that also refer to the same paper (typically by anaphora). The authors train a specific coreference model for this phenomenon. They show that exploitation of coreference chains improves the extraction of citation contexts which they then use for research paper summarization.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "One of the earliest approaches is performed in the context of the Genia project and corpus of medical texts from MEDLINE. ", "mid_sen": "In a first stage, only MEDLINE abstracts are used (Yang et al., 2004) , later other-anaphora, a very specific sub-task, are investigated using full paper content (Chen et al., 2008) . Gasperin (2009) presents a full annotation of anaphora and coreference in biomedical text, but only noun phrases referring to biomedical entities are considered. ", "after_sen": "On the basis of this annotation, she implements a probabilistic anaphora resolution system. "}
{"citeStart": 59, "citeEnd": 87, "citeStartToken": 59, "citeEndToken": 87, "sectionName": "UNKNOWN SECTION NAME", "string": "Ron Kaplan and Hadar Shemtov at Xerox PArtC provided us with two LFG parsed corpora. The Verbmobil corpus contains appointment planning dialogs, while the Homecentre corpus is drawn from Xerox printer documentation. Table 1 summarizes the basic properties of these corpora. These corpora contain packed c/fstructure representations (Maxwell III and Kaplan, 1995) of the grammatical parses of each sentence with respect to Lexical-Functional grammars. The corpora also indicate which of these parses is in fact the correct parse (this information was manually entered). Because slightly different grammars were used for each corpus we chose not to combine the two corpora, although we used the set of features described in section 2 for both in the experiments described below. Table describes the properties of the features used for each corpus.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Table 1 summarizes the basic properties of these corpora. ", "mid_sen": "These corpora contain packed c/fstructure representations (Maxwell III and Kaplan, 1995) of the grammatical parses of each sentence with respect to Lexical-Functional grammars. ", "after_sen": "The corpora also indicate which of these parses is in fact the correct parse (this information was manually entered). "}
{"citeStart": 109, "citeEnd": 123, "citeStartToken": 109, "citeEndToken": 123, "sectionName": "UNKNOWN SECTION NAME", "string": "At two points in our noun phrase recognition process we will use system combination. We will start with system-internal combination: apply the same learning algorithm to variants of the task and combine the results. The approach we have chosen here is the same as in Tjong Kim Sang 2000: generate di erent variants of the task by using di erent representations of the output IOB1, IOB2, IOE1, IOE2 and O+C. The ve outputs will converted to the open bracket representation O and the close bracket representation C and after this, the most frequent of the ve analyses of each w ord will chosen majority voting, see below. We expect the systems which use this combination phase to perform better than their individual members Tjong Kim Sang, 2000. Our seven learners will generate di erent classi cations of the training data and we need to nd out which combination techniques are most appropriate. For the system-external combination experiment, we have evaluated di erent voting mechanisms, e ectively the voting methods as described in Van Halteren et al. 1998. In the rst method each classi cation receives the same weight and the most frequent classication is chosen Majority. The second method regards as the weight of each individual classi cation algorithm its accuracy on some part of the data, the tuning data TotPrecision. The third voting method computes the precision of each assigned tag per classi er and uses this value as a weight for the classi er in those cases that it chooses the tag TagPrecision. The fourth method uses both the precision of each assigned tag and the recall of the competing tags Precision-Recall. Finally, the fth method uses not only a weight for the current classi cation but it also computes weights for other possible classi cations. The other classications are determined by examining the tun-ing data and registering the correct values for every pair of classi er results pair-wise voting, see Van Halteren et al. 1998 for an elaborate explanation. Apart from these ve v oting methods we h a ve also processed the output streams with two classi ers: MBL and IGTree. This approach is called classi er stacking. Like Van Halteren et al. 1998, we have used di erent input versions: one containing only the classi er output and another containing both classi er output and a compressed representation of the data item under consideration. For the latter purpose we h a ve used the part-of-speech tag of the current w ord.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The ve outputs will converted to the open bracket representation O and the close bracket representation C and after this, the most frequent of the ve analyses of each w ord will chosen majority voting, see below. ", "mid_sen": "We expect the systems which use this combination phase to perform better than their individual members Tjong Kim Sang, 2000. ", "after_sen": "Our seven learners will generate di erent classi cations of the training data and we need to nd out which combination techniques are most appropriate. "}
{"citeStart": 167, "citeEnd": 181, "citeStartToken": 167, "citeEndToken": 181, "sectionName": "UNKNOWN SECTION NAME", "string": "max The auxiliary constraint g * (•) can take on many forms and the one we used in this work is an L 2 penalty function (Dudík, 2007) . We trained the model with L-BFGS (Nocedal, 1980) in supervised, semi-supervised and unsupervised fashions on labeled and/or unlabeled data, using the Mallet software (McCallum, 2002) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "max The auxiliary constraint g * (•) can take on many forms and the one we used in this work is an L 2 penalty function (Dudík, 2007) . ", "mid_sen": "We trained the model with L-BFGS (Nocedal, 1980) in supervised, semi-supervised and unsupervised fashions on labeled and/or unlabeled data, using the Mallet software (McCallum, 2002) .", "after_sen": ""}
{"citeStart": 162, "citeEnd": 181, "citeStartToken": 162, "citeEndToken": 181, "sectionName": "UNKNOWN SECTION NAME", "string": "In order to build our computational model, we combine a linguistic scheme opinion frames (Somasundaran et al., 2008 ) with a collective classification framework (Bilgic et al., 2007) . According to this scheme, two opinions are related in the discourse when their targets (what they are about) are related. Further, these pair-wise discourse-level relations between opinions are either reinforcing or non-reinforcing frames. Reinforcing frames capture reinforcing discourse scenarios where the individual opinions reinforce one another, contributing to the same opinion polarity or stance. Non-reinforcing frames, on the other hand, capture discourse scenarios where the individual opinions do not support the same stance. The individual opinion polarities and the type of relation between their targets determine whether the discourse frame is reinforcing or non-reinforcing.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "To capture this information, we propose discourse-level opinion graphs for classifying opinion polarity.", "mid_sen": "In order to build our computational model, we combine a linguistic scheme opinion frames (Somasundaran et al., 2008 ) with a collective classification framework (Bilgic et al., 2007) . ", "after_sen": "According to this scheme, two opinions are related in the discourse when their targets (what they are about) are related. "}
{"citeStart": 84, "citeEnd": 95, "citeStartToken": 84, "citeEndToken": 95, "sectionName": "UNKNOWN SECTION NAME", "string": "To avoid penalizing longer hypotheses, the probabilities assigned to hypotheses were normalized by sentence length. The probability assigned by a cluster to an N-gram was taken to be the simple maximum likelihood (relative frequency) value where this was non-zero. When an N-gram in the test data had not been observed at all in the training sentences assigned to a given cluster, a \"failure\", representing a vanishingly small probability, was assigned. A number of backoff schemes of various degrees of sophistication, including that of Katz (1987) , were tried, but none produced any improvement in performance, and several actuMly worsened it.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "When an N-gram in the test data had not been observed at all in the training sentences assigned to a given cluster, a \"failure\", representing a vanishingly small probability, was assigned. ", "mid_sen": "A number of backoff schemes of various degrees of sophistication, including that of Katz (1987) , were tried, but none produced any improvement in performance, and several actuMly worsened it.", "after_sen": "The average percentages of sentences correctly identified by clusterings for each condition were as given in Table 1 . "}
{"citeStart": 224, "citeEnd": 246, "citeStartToken": 224, "citeEndToken": 246, "sectionName": "UNKNOWN SECTION NAME", "string": "An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors (log probabilities of observing entire sentences based on our language models), as opposed to sequences of terms, as done in (Barzilay and Lee, 2004) . This technique provides two important advantages. First, Gaussian modeling adds an extra degree of freedom during training, by capturing second-order statistics. This is not possible when modeling word sequences, where only the probability of a sentence is actually used in the HMM training. Second, using continuous distributions allows us to leverage a variety of tools (e.g., LDA) that have been shown to be successful in other fields, such as speech recognition (Evermann et al., 2004) . Table 2 (b) represents the closest head-to-head comparison between our generative approach (HMM with LDA) and state-of-the-art results reported by M&S using SVMs. In some ways, the results reported by M&S have an advantage because they use significantly more training examples. Yet, we can see that generative techniques for the modeling of content structure are at least competitive-we even outperform SVMs on detecting \"methods\" and \"results\". Moreover, the fact that the training and testing of HMMs have linear complexity (as opposed to the quadratic complexity of SVMs) makes our approach a very attractive alternative, given the amount of training data that is available for such experiments.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors (log probabilities of observing entire sentences based on our language models), as opposed to sequences of terms, as done in (Barzilay and Lee, 2004) . ", "after_sen": "This technique provides two important advantages. "}
{"citeStart": 116, "citeEnd": 127, "citeStartToken": 116, "citeEndToken": 127, "sectionName": "UNKNOWN SECTION NAME", "string": "The morphologic analyzer (Marziali, 1992) derives from the work on a generative approach to the Italian morphology (Russo, 1987) , first used in DANTE, a NLP system for analysis of short narrative texts in the financial domain (Antonacci et al. 1989) . Tile analyzer includes over 7000 elementary lemmata (stems without affixes, e.g. flex is the elementary lemma for de-flex, in-flex, re-fiex) anti has been experimented since now on economic, financial, commercial and legal domains. Elementary lemmata cover much more than 70(}0 words, since many words have an affix.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The morphologic analyzer (Marziali, 1992) derives from the work on a generative approach to the Italian morphology (Russo, 1987) , first used in DANTE, a NLP system for analysis of short narrative texts in the financial domain (Antonacci et al. 1989) . ", "after_sen": "Tile analyzer includes over 7000 elementary lemmata (stems without affixes, e.g. flex is the elementary lemma for de-flex, in-flex, re-fiex) anti has been experimented since now on economic, financial, commercial and legal domains. "}
{"citeStart": 139, "citeEnd": 161, "citeStartToken": 139, "citeEndToken": 161, "sectionName": "UNKNOWN SECTION NAME", "string": "In the past five years, important research on the automatic acquisition of word classes based on lex-ical distribution has been published (Church and Hanks, 1990; Hindle, 1990; Smadja, 1993; Grei~nstette, 1994; Grishman and Sterling, 1994) . Most of these approaches, however, need large or even very large corpora in order for word classes to be discovered 1 whereas it is often the case that the data to be processed are insufficient to provide reliable lexical intbrmation. In other words, it is not always possible to resort to statistical methods. On the other hand, medium size corpora (between 100,000 and 500,000 words: typically a reference manual) are already too complex and too long to rely on reading only, even with concordances. For this range of corpora, a pure symbolic approach, which recycles and simplifies analyses produced by robust parsers in order to classify words, offers a viable alternative to statistical methods. We present this approach in section 2. Section 3 describes the results on two technical corpora with two different robust parsers. Section 4 compares our results to Itindle's ones (Hindle, 1990 ).", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Automatic exploration of a sublanguage corpus constitutes a first step towards identifying the semantic classes and relationships which are relevant for this sublanguage.", "mid_sen": "In the past five years, important research on the automatic acquisition of word classes based on lex-ical distribution has been published (Church and Hanks, 1990; Hindle, 1990; Smadja, 1993; Grei~nstette, 1994; Grishman and Sterling, 1994) . ", "after_sen": "Most of these approaches, however, need large or even very large corpora in order for word classes to be discovered 1 whereas it is often the case that the data to be processed are insufficient to provide reliable lexical intbrmation. "}
{"citeStart": 56, "citeEnd": 66, "citeStartToken": 56, "citeEndToken": 66, "sectionName": "UNKNOWN SECTION NAME", "string": "The domain of our work was the Conference Registration Telephony Conversations. The lexicon for the task contained about 500 English and 500 German words. There were 300 English/German f-structurepairs available from other research tasks (Osterholtz, 1992) . A separate set of 154 sentential f-structures was used to test the generalization performance of the system. The testing data was collected for an independent task (Jain, 1991) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A separate set of 154 sentential f-structures was used to test the generalization performance of the system. ", "mid_sen": "The testing data was collected for an independent task (Jain, 1991) .", "after_sen": "From the 300 sentential f-structure pairs, every German VP sub-structure is extracted and labeled with its English counterpart. "}
{"citeStart": 162, "citeEnd": 175, "citeStartToken": 162, "citeEndToken": 175, "sectionName": "UNKNOWN SECTION NAME", "string": "In the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types [Black, 1992] [Briscoe, 1993] [Brown, 1991] [Charniak, 1997] [Collins, 1996] [Collins, 1997] [Magerman, 1995] [Eisner, 1996] . How to evaluate the different feature types' effects for syntactic parsing? The paper proposes an information-theory-based feature types analysis model, which uses the measures of predictive information quantity, predictive information gain, predictive information redundancy and predictive information summation to quantitatively analyse the different contextual feature types' or feature types combination's predictive power for syntactic structure.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "In the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types [Black, 1992] [Briscoe, 1993] [Brown, 1991] [Charniak, 1997] [Collins, 1996] [Collins, 1997] [Magerman, 1995] [Eisner, 1996] . ", "after_sen": "How to evaluate the different feature types' effects for syntactic parsing? "}
{"citeStart": 236, "citeEnd": 249, "citeStartToken": 236, "citeEndToken": 249, "sectionName": "UNKNOWN SECTION NAME", "string": "This paper investigates the relationship between Context-Free Grammar (CFG) parsing and the Eisner/Satta PBDG parsing algorithms, including their extension to second-order PBDG parsing (McDonald, 2006; McDonald and Pereira, 2006) . Specifically, we show how to use an off-line preprocessing step, the Unfold-Fold transformation, to transform a PBDG into an equivalent CFG that can be parsed in O(n 3 ) time using a version of the CKY algorithm with suitable indexing (Younger, 1967) , and extend this transformation so that it captures second-order PBDG dependencies as well. The transformations are ambiguity-preserving, i.e., there is a one-toone mapping between dependency parses and CFG parses, so it is possible to map the CFG parses back to the PBDG parses they correspond to.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This paper investigates the relationship between Context-Free Grammar (CFG) parsing and the Eisner/Satta PBDG parsing algorithms, including their extension to second-order PBDG parsing (McDonald, 2006; McDonald and Pereira, 2006) . ", "mid_sen": "Specifically, we show how to use an off-line preprocessing step, the Unfold-Fold transformation, to transform a PBDG into an equivalent CFG that can be parsed in O(n 3 ) time using a version of the CKY algorithm with suitable indexing (Younger, 1967) , and extend this transformation so that it captures second-order PBDG dependencies as well. ", "after_sen": "The transformations are ambiguity-preserving, i.e., there is a one-toone mapping between dependency parses and CFG parses, so it is possible to map the CFG parses back to the PBDG parses they correspond to."}
{"citeStart": 120, "citeEnd": 134, "citeStartToken": 120, "citeEndToken": 134, "sectionName": "UNKNOWN SECTION NAME", "string": "It is worth noting that while we have presented the use of edge-based best-first chart parsing in the service of a rather pure form of PCFG parsing, there is no particular reason to assume that the technique is so limited in its domain of applicability. One can imagine the same techniques coupled with more informative probability distributions, such as lexicalized PCFGs (Charniak, 1997) , or even grammars not based upon literal rules, but probability distributions that describe how rules are built up from smaller components (Magerman, 1995; Collins, 1997) . Clearly further research is warranted. Be this as it may, the take-home lesson from this paper is simple: combining an edge-based agenda with the figure of merit from C&C", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It is worth noting that while we have presented the use of edge-based best-first chart parsing in the service of a rather pure form of PCFG parsing, there is no particular reason to assume that the technique is so limited in its domain of applicability. ", "mid_sen": "One can imagine the same techniques coupled with more informative probability distributions, such as lexicalized PCFGs (Charniak, 1997) , or even grammars not based upon literal rules, but probability distributions that describe how rules are built up from smaller components (Magerman, 1995; Collins, 1997) . ", "after_sen": "Clearly further research is warranted. "}
{"citeStart": 63, "citeEnd": 81, "citeStartToken": 63, "citeEndToken": 81, "sectionName": "UNKNOWN SECTION NAME", "string": "Another L 1 penalizer is the hyperbolic-L prior, described in (Pinto et al., 2003) . The hyperbolic distribution has log-linear tails. Consequently the class of hyperbolic distribution is an important alternative to the class of normal distributions and has been used for analyzing data from various scientific areas such as finance, though less frequently used in natural language processing.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Another L 1 penalizer is the hyperbolic-L prior, described in (Pinto et al., 2003) . ", "after_sen": "The hyperbolic distribution has log-linear tails. "}
{"citeStart": 162, "citeEnd": 171, "citeStartToken": 162, "citeEndToken": 171, "sectionName": "UNKNOWN SECTION NAME", "string": "We used the TDT2 collection for preliminary classification experiments. We used a k-nn classifier to classify documents from the 10 most frequent topics. We used tf-idf document vectors indexed with 55,729 general vocabulary words as our baseline. The set of the content bearing words was much smaller and had 13,818 nouns and adjectives. The GLSA document vectors improved the classification accuracy over the baseline and outperformed LSA document vectors. This validates our approach to selecting the content bearing terms and shows the advantage of using the GLSA framework. We are going to extend the set of content bearing words and to include verbs. We will take advantage of the flexibility provided by our framework and use syntax based measure of similarity in the computation of the verb vectors, following (Lin, 1998) .", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We are going to extend the set of content bearing words and to include verbs. ", "mid_sen": "We will take advantage of the flexibility provided by our framework and use syntax based measure of similarity in the computation of the verb vectors, following (Lin, 1998) .", "after_sen": "Currently we are using string matching to compute the named entity based measure of similarity. "}
{"citeStart": 170, "citeEnd": 196, "citeStartToken": 170, "citeEndToken": 196, "sectionName": "UNKNOWN SECTION NAME", "string": "In the first experiment, we use an induction algorithm (Hwa 2001a ) based on the expectation-maximization (EM) principle that induces parsers for PLTIGs. The algorithm performs heuristic search through an iterative reestimation procedure to find local optima: sets of values for the grammar parameters that maximizes the grammar's likelihood of generating the training data. In principle, the algorithm supports unsupervised learning; however, because the search space has too many local optima, the algorithm tends to converge on a model that is unsuitable for parsing. Here, we consider a partially supervised variant in which we assume that the learner is given the phrasal boundaries of the training sentences but not the label of the constituent units. For example, the sentence Several fund managers expect a rough market this morning before prices stabilize. would be labeled as \"((Several fund managers) (expect ((a rough market) (this morning)) (before (prices stabilize))).)\" Our algorithm is similar to the approach taken by Pereira and Schabes (1992) for inducing PCFG parsers.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For example, the sentence Several fund managers expect a rough market this morning before prices stabilize. ", "mid_sen": "would be labeled as \"((Several fund managers) (expect ((a rough market) (this morning)) (before (prices stabilize))).)\" Our algorithm is similar to the approach taken by Pereira and Schabes (1992) for inducing PCFG parsers.", "after_sen": "Because the EM algorithm itself is an iterative procedure, performing sample selection on top of an EM-based learner is an extremely computational-intensive process. "}
{"citeStart": 110, "citeEnd": 122, "citeStartToken": 110, "citeEndToken": 122, "sectionName": "UNKNOWN SECTION NAME", "string": "Our segmentation algorithm takes a list of tokenized sentences as input. A tokenizer (Grefenstette and Tapanainen, 1994 ) and a sentence boundary disambiguation algorithm (Palmer and Hearst, 1994; Reynar and Ratnaparkhi, 1997) or EAGLE ) may be used to convert a plain text document into the acceptable input format.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Our segmentation algorithm takes a list of tokenized sentences as input. ", "mid_sen": "A tokenizer (Grefenstette and Tapanainen, 1994 ) and a sentence boundary disambiguation algorithm (Palmer and Hearst, 1994; Reynar and Ratnaparkhi, 1997) or EAGLE ) may be used to convert a plain text document into the acceptable input format.", "after_sen": ""}
{"citeStart": 110, "citeEnd": 121, "citeStartToken": 110, "citeEndToken": 121, "sectionName": "UNKNOWN SECTION NAME", "string": "Background Existing work falls into one of two categories, lexical cohesion methods and multi-source methods (Yaari, 1997) . The former stem from the work of Halliday and Hasan (Halliday and Hasan, 1976) . They proposed that text segments with similar vocabulary are likely to be part of a coherent topic segment. hnplementations of this idea use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997) , context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999) , entity repetition (Kan et al., 1998) , semantic similarity (Morris and Hirst, 1991; Kozima, 1993) , word distance model (Beeferman et al., 1997a ) and word frequency model (Reynar, 1999) to detect cohesion. Methods for finding the topic boundaries include sliding window (Hearst, 1994) , lexical chains (Morris, 1988; Kan et al., 1998) , dynamic programming (Ponte and Croft, 1997; Heinonen, 1998) , agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994) . Lexical cohesion methods are typically used for segmenting written text in a collection to improve information retrieval (Hearst, 1994; Reynat, 1998) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Background Existing work falls into one of two categories, lexical cohesion methods and multi-source methods (Yaari, 1997) . ", "after_sen": "The former stem from the work of Halliday and Hasan (Halliday and Hasan, 1976) . "}
{"citeStart": 26, "citeEnd": 51, "citeStartToken": 26, "citeEndToken": 51, "sectionName": "UNKNOWN SECTION NAME", "string": "The point is this. Although the LFG equations discussed so far were defining equations, LFG also allows so-called constraining equations (written =e). Kaplan and Bresnan explain the difference as follows. Defining equations allow a feature-value pair to be inserted into an f-structure providing no conflicting information is present. That is, they add a feature value pair to any consistent fstructure. In contrast, constraining equations are intended to constrain the value of an already existing feature-value pair. The essential difference is that constraining equations require that the feature under consideration already has a value, whereas defining equations apply independently of the feature value instantiation level. In short, constraining equations are essentially a global check on completed structures which require the presence of certain feature values. They have an eminently procedural character, and there is no obvious way to handle this idea in the present set up. The bulk of LFG involves stating constraints about a single model, and /: is well equipped for this task, but constraining equations involve looking at the structure of other possible parse trees. (In this respect they are reminiscent of the feature specification defaults of GPSG.) The approach of the present paper has been driven by the view that (a) models capture the essence of LFG ontology, and, (b) the task of the linguist is to explain, in terms of the relations that exist within a single model, what grammatical structure is. Most of the discussion in Kaplan and Bresnan (1982) is conducted in such terms. However constraining equations broaden the scope of the permitted discourse; basically, they allow implicit appeal to possible derivational structure. In short, in. common with most of the grammatical formalisms with which we are familiar, LFG seems to have a dynamic residue that resists a purely declarative analysis. What should be done?", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "(In this respect they are reminiscent of the feature specification defaults of GPSG.) The approach of the present paper has been driven by the view that (a) models capture the essence of LFG ontology, and, (b) the task of the linguist is to explain, in terms of the relations that exist within a single model, what grammatical structure is. ", "mid_sen": "Most of the discussion in Kaplan and Bresnan (1982) is conducted in such terms. ", "after_sen": "However constraining equations broaden the scope of the permitted discourse; basically, they allow implicit appeal to possible derivational structure. "}
{"citeStart": 91, "citeEnd": 106, "citeStartToken": 91, "citeEndToken": 106, "sectionName": "UNKNOWN SECTION NAME", "string": "Northwest Airlines settled the remaining lawsuits filed on behalf of 156 people killed in a 1987 crash, but claims against the jetliner's maker are being pursued, a federal judge said. (\"Northwest Airlines Settles Rest of Suits,\" Wall Street Journal, November 1, 1989) A particular model of linguistic subjectivity underlies the current and past research in this area by Wiebe and colleagues. It is most fully presented in Wiebe and Rapaport (1986 , 1988 , 1991 and Wiebe (1990 Wiebe ( , 1994 . It was developed to support NLP research and combines ideas from several sources in fields outside NLP, especially linguistics and literary theory. The most direct influences on the model were Dolezel (1973) (types of subjectivity clues), Uspensky (1973) (types of point of view), Kuroda (1973 Kuroda ( , 1976 ) (pragmatics of point of view), Chatman (1978) (story versus discourse), Cohn (1978) (linguistic styles for presenting consciousness), Fodor (1979) (linguistic description of opaque contexts), and especially Banfield (1982) ", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It was developed to support NLP research and combines ideas from several sources in fields outside NLP, especially linguistics and literary theory. ", "mid_sen": "The most direct influences on the model were Dolezel (1973) (types of subjectivity clues), Uspensky (1973) (types of point of view), Kuroda (1973 Kuroda ( , 1976 ) (pragmatics of point of view), Chatman (1978) (story versus discourse), Cohn (1978) (linguistic styles for presenting consciousness), Fodor (1979) (linguistic description of opaque contexts), and especially Banfield (1982) ", "after_sen": ""}
{"citeStart": 188, "citeEnd": 211, "citeStartToken": 188, "citeEndToken": 211, "sectionName": "UNKNOWN SECTION NAME", "string": "Ellipsis interpretations are represented as simple sets of substitutions on semantic representations of the antecedent. The substitutions can be built up in an order-independent way (i.e. before, after or during scoping), and without recourse to higherorder unification. The treatment is similar to the discourse copying analysis of (Kehler, 1993a) , and to the substitutional treatment suggested by Kamp within Discourse Representation Theory, described in (Gawron and Peters, 1990) . However, we extend the notion of strict and sloppy identity to deal with more than just pronouns. In doing so, we readily deal with phenomena like scope parallelism.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The substitutions can be built up in an order-independent way (i.e. before, after or during scoping), and without recourse to higherorder unification. ", "mid_sen": "The treatment is similar to the discourse copying analysis of (Kehler, 1993a) , and to the substitutional treatment suggested by Kamp within Discourse Representation Theory, described in (Gawron and Peters, 1990) . ", "after_sen": "However, we extend the notion of strict and sloppy identity to deal with more than just pronouns. "}
{"citeStart": 109, "citeEnd": 134, "citeStartToken": 109, "citeEndToken": 134, "sectionName": "UNKNOWN SECTION NAME", "string": "In our experiments, we used the IREX dataset (Sekine and Isahara, 2000) to demonstrate the usefulness of cluster gazetteers. We also compared the cluster gazetteers with the Wikipedia gazetteer constructed by following the method of (Kazama and Torisawa, 2007) . The improvement was larger for the cluster gazetteer than for the Wikipedia gazetteer. We also investigated whether these gazetteers improve the accuracies further when they are used in combination. The experimental results indicated that the accuracy improved further in several cases and showed that these gazetteers complement each other.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In our experiments, we used the IREX dataset (Sekine and Isahara, 2000) to demonstrate the usefulness of cluster gazetteers. ", "mid_sen": "We also compared the cluster gazetteers with the Wikipedia gazetteer constructed by following the method of (Kazama and Torisawa, 2007) . ", "after_sen": "The improvement was larger for the cluster gazetteer than for the Wikipedia gazetteer. "}
{"citeStart": 103, "citeEnd": 126, "citeStartToken": 103, "citeEndToken": 126, "sectionName": "UNKNOWN SECTION NAME", "string": "The interest in the 80's begun to turn considering grammar checking as an enterprise of its own right (Carbonell & Hayes, 1983) , (Ilayes & Mouradian, 1981) , (Heidorn et al., 1982) , (.lensen at al., 1983) , though many of the approaches were still in I;t1(: NLU tradition ((]harniak, 198a), (Granger, 1983) , (Kwasny & Sondheimer, 1981) , (Weischedel & Black, ] 980), (Weisehedel & Sondheimer, 1983) . A 1985 Ovum report on nal;llral language applications (.lohnson, 1985) already identifies grammar and style checking as one of the seven major apt)lications of NLP. Currently, every project in grammar checking has as its goal the creation of a writing aid rather than a robust man-machine interface (Adriaens, 1994) , (llolioli ctal., 1992) , (Vosse, 1992) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Many of the NLU systems developed in the 70's indu(le(l a kind of error recovery Inechanisln ranging flom the treatment only of spelling e.rrors, PARRY (1)arkinson c 't al., 1977) , to tile inclusion also of incomplete int)ut containing some kind of ellipsis, LAD-DEll,/LIFEll (Hendrix et al., 1977) .", "mid_sen": "The interest in the 80's begun to turn considering grammar checking as an enterprise of its own right (Carbonell & Hayes, 1983) , (Ilayes & Mouradian, 1981) , (Heidorn et al., 1982) , (.lensen at al., 1983) , though many of the approaches were still in I;t1(: NLU tradition ((]harniak, 198a), (Granger, 1983) , (Kwasny & Sondheimer, 1981) , (Weischedel & Black, ] 980), (Weisehedel & Sondheimer, 1983) . ", "after_sen": "A 1985 Ovum report on nal;llral language applications (.lohnson, 1985) already identifies grammar and style checking as one of the seven major apt)lications of NLP. "}
{"citeStart": 190, "citeEnd": 205, "citeStartToken": 190, "citeEndToken": 205, "sectionName": "UNKNOWN SECTION NAME", "string": "The majority of NLG focuses on the satisfaction of a communicative goal, with examples such as Belz (2008) which produces weather reports from structured data or Mitchell et al. (2013) which generates descriptions of objects from images. Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry (Greene et al., 2010) (Colton et al., 2012) (Jiang and Zhou, 2008) or song lyrics (Wu et al., 2013) (Ramakrishnan A et al., 2009) , where specified meter or rhyme schemes are enforced. In these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The majority of NLG focuses on the satisfaction of a communicative goal, with examples such as Belz (2008) which produces weather reports from structured data or Mitchell et al. (2013) which generates descriptions of objects from images. ", "mid_sen": "Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry (Greene et al., 2010) (Colton et al., 2012) (Jiang and Zhou, 2008) or song lyrics (Wu et al., 2013) (Ramakrishnan A et al., 2009) , where specified meter or rhyme schemes are enforced. ", "after_sen": "In these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric."}
{"citeStart": 166, "citeEnd": 188, "citeStartToken": 166, "citeEndToken": 188, "sectionName": "UNKNOWN SECTION NAME", "string": "Knowledge-based approaches to representing the potentially subtle differences between synonyms have suffered from a serious lexical acquisition bottleneck (Di-Marco, Hirst, and Stede, 1993; Hirst, 1995) . Statistical approaches, which have sought to explicitly represent differences between pairs of synonyms with respect to their occurrence with other specific words (Church et al., 1994) , are inefficient in time and space. This paper presents a new statistical approach to modeling context that provides a preliminary solution to an important sub-problem, that of determining the nearsynonym that is most typical, or expected, if any, in a given context. Although weaker than full lexical choice, because it doesn't choose the 'best' word, we believe that it is a necessary first step, because it would allow one to determine the effects of choosing a non-typical word in place of the typical word. The approach relies on a generalization of lexical co-occurrence that allows for an implicit representation of the differences between two (or more) words with respect to any actual context. For example, our implemented lexical choice program selects mistake as most typical for the 'gap' in sentence (1), and error in (2).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "When the same concept admits more than one lexicalization, it is often difficult to choose which of these 'synonyms' is the most appropriate for achieving the desired pragmatic goals: but this is necessary for highquality machine translation and natural language generation.", "mid_sen": "Knowledge-based approaches to representing the potentially subtle differences between synonyms have suffered from a serious lexical acquisition bottleneck (Di-Marco, Hirst, and Stede, 1993; Hirst, 1995) . ", "after_sen": "Statistical approaches, which have sought to explicitly represent differences between pairs of synonyms with respect to their occurrence with other specific words (Church et al., 1994) , are inefficient in time and space. "}
{"citeStart": 302, "citeEnd": 313, "citeStartToken": 302, "citeEndToken": 313, "sectionName": "UNKNOWN SECTION NAME", "string": "We also added manually-developed features found by other researchers. We created 14 feature sets representing some classes from (Levin, 1993; Ballmer and Brennenstuhl, 1981) , some Framenet lemmas with frame element experiencer (Baker et al., 1998) , adjectives manually annotated for polarity (Hatzivassiloglou and McKeown, 1997) , and some subjectivity clues listed in (Wiebe, 1990) . We represented each set as a three-valued feature based on the presence of 0, 1, or ≥ 2 members of the set. We will refer to these as the manual features.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We also added manually-developed features found by other researchers. ", "mid_sen": "We created 14 feature sets representing some classes from (Levin, 1993; Ballmer and Brennenstuhl, 1981) , some Framenet lemmas with frame element experiencer (Baker et al., 1998) , adjectives manually annotated for polarity (Hatzivassiloglou and McKeown, 1997) , and some subjectivity clues listed in (Wiebe, 1990) . ", "after_sen": "We represented each set as a three-valued feature based on the presence of 0, 1, or ≥ 2 members of the set. "}
{"citeStart": 193, "citeEnd": 204, "citeStartToken": 193, "citeEndToken": 204, "sectionName": "UNKNOWN SECTION NAME", "string": "Current work on citation sentiment detection works under the assumption that the sentiment present in the citation sentence represents the true sentiment of the author towards the cited paper (Athar, 2011; Piao et al., 2007; Pham and Hoffmann, 2004) . This assumption is so dominant because current citation identification methods (Councill et al., 2008; Ritchie et al., 2008; Radev et al., 2009) can readily identify the citation sentence, whereas it is much harder to determine the relevant context. However, this assumption most certainly does not hold true when the citation context spans more than one sentence.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It can also help expert researchers who are in the process of preparing opinion based summaries for survey papers by providing them with motivations behind as well as positive and negative comments about different approaches (Qazvinian and Radev, 2008) .", "mid_sen": "Current work on citation sentiment detection works under the assumption that the sentiment present in the citation sentence represents the true sentiment of the author towards the cited paper (Athar, 2011; Piao et al., 2007; Pham and Hoffmann, 2004) . ", "after_sen": "This assumption is so dominant because current citation identification methods (Councill et al., 2008; Ritchie et al., 2008; Radev et al., 2009) can readily identify the citation sentence, whereas it is much harder to determine the relevant context. "}
{"citeStart": 7, "citeEnd": 11, "citeStartToken": 7, "citeEndToken": 11, "sectionName": "UNKNOWN SECTION NAME", "string": "The two senses of well also differ in their word class. The word class has been studied as a difficulty indicator by several researchers but with mixed results. Brown (1989) finds that function words are easier to solve, while Klein-Braley (1996) claims that prepositions are often harder for learners. Sigott (1995) could not confirm any effect of the word class on C-test difficulty.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The word class has been studied as a difficulty indicator by several researchers but with mixed results. ", "mid_sen": "Brown (1989) finds that function words are easier to solve, while Klein-Braley (1996) claims that prepositions are often harder for learners. ", "after_sen": "Sigott (1995) could not confirm any effect of the word class on C-test difficulty."}
{"citeStart": 197, "citeEnd": 220, "citeStartToken": 197, "citeEndToken": 220, "sectionName": "UNKNOWN SECTION NAME", "string": "The use of linear logic provides a flexible mechanism for deducing meanings of sentences based on their f-structure representations. Accounts of various linguistic phenomena have been developed within the framework on which our extension is based, including quantifiers and anaphora (Dalrymple et al., 1994a) , intensional verbs (Dalrympie et al., 1994b) , and complex predicates (Dalrymple et al., !993b). The logic fits well with the 'resource-sensitivity' of natural language semantics: there is a one-to-one correspondence between f-structure relationships and meanings; the multiple use of resources arises from multiple paths to them in the f-structure. In the next section, we show how this system applies to several cases of right-node raising.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The use of linear logic provides a flexible mechanism for deducing meanings of sentences based on their f-structure representations. ", "mid_sen": "Accounts of various linguistic phenomena have been developed within the framework on which our extension is based, including quantifiers and anaphora (Dalrymple et al., 1994a) , intensional verbs (Dalrympie et al., 1994b) , and complex predicates (Dalrymple et al., !993b). ", "after_sen": "The logic fits well with the 'resource-sensitivity' of natural language semantics: there is a one-to-one correspondence between f-structure relationships and meanings; the multiple use of resources arises from multiple paths to them in the f-structure. "}
{"citeStart": 253, "citeEnd": 287, "citeStartToken": 253, "citeEndToken": 287, "sectionName": "UNKNOWN SECTION NAME", "string": "Many of the subjective clues are from manually developed resources, including entries from (Levin, 1993; Ballmer and Brennenstuhl, 1981) , Framenet lemmas with frame element experiencer (Baker et al., 1998) , adjectives manually annotated for polarity (Hatzivassiloglou and McKeown, 1997) , and subjectivity clues listed in (Wiebe, 1990) . Others were derived from corpora, including subjective nouns learned from unannotated data using bootstrapping (Riloff et al., 2003) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Any data used to develop this vocabulary does not overlap with the test sets or the unannotated data used in this paper.", "mid_sen": "Many of the subjective clues are from manually developed resources, including entries from (Levin, 1993; Ballmer and Brennenstuhl, 1981) , Framenet lemmas with frame element experiencer (Baker et al., 1998) , adjectives manually annotated for polarity (Hatzivassiloglou and McKeown, 1997) , and subjectivity clues listed in (Wiebe, 1990) . ", "after_sen": "Others were derived from corpora, including subjective nouns learned from unannotated data using bootstrapping (Riloff et al., 2003) ."}
{"citeStart": 108, "citeEnd": 120, "citeStartToken": 108, "citeEndToken": 120, "sectionName": "UNKNOWN SECTION NAME", "string": "The word in focus is first passed through a twolevel morphological analysis stage, based on an adaption of (Pulman, 1991) . Two purposes are served here: checking the word is lexica] (i.e. in the lexicon or a permissible inflection of a word in the lexicon) and collecting the possible categories, which are represented as sets of feature specifications (Grover, 1993) .", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The word in focus is first passed through a twolevel morphological analysis stage, based on an adaption of (Pulman, 1991) . ", "after_sen": "Two purposes are served here: checking the word is lexica] (i.e. in the lexicon or a permissible inflection of a word in the lexicon) and collecting the possible categories, which are represented as sets of feature specifications (Grover, 1993) ."}
{"citeStart": 152, "citeEnd": 177, "citeStartToken": 152, "citeEndToken": 177, "sectionName": "UNKNOWN SECTION NAME", "string": "We employ a set of verbal features that is similar to the features used by state-of-the-art coreference resolution systems that operate on text (e.g., (Cardie and Wagstaff, 1999) ). Pairwise verbal features include: several string-match variants; distance features, measured in terms of the number of intervening noun phrases and sentences between the candidate NPs; and some syntactic features that can be computed from part of speech tags. Single-phrase verbal features describe the type of the noun phrase (definite, indefinite, demonstrative (e.g., this ball), or pronoun), the number of times it appeared in the document, and whether there were any adjecti-", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We employ a set of verbal features that is similar to the features used by state-of-the-art coreference resolution systems that operate on text (e.g., (Cardie and Wagstaff, 1999) ). ", "after_sen": "Pairwise verbal features include: several string-match variants; distance features, measured in terms of the number of intervening noun phrases and sentences between the candidate NPs; and some syntactic features that can be computed from part of speech tags. "}
{"citeStart": 124, "citeEnd": 140, "citeStartToken": 124, "citeEndToken": 140, "sectionName": "UNKNOWN SECTION NAME", "string": "Removing the direct or indirect cycles from the magic part of the compiled grammar does eliminate the necessity of subsumption checking in many cases. However, consider the magic rules 14 and 15 in figure 2. Rule 15 is more general than rule 14. Without subsumption checking this leads to spurious ambiguity: Both rules produce a magic fact with which a subject np can be built. A possible solution to this problem is to couple magic rules with the modified version of the original grammar rule that instigated it. To accomplish this I propose a technique that can be considered the off-line variant of an index-ing technique described in Gerdemann (1991) . 3 The indexing technique is illustrated on the basis of the running example: Rule 14 in figure 1 is coupled to the modified version of the original s rule that instigated it, i.e., rule 2. Both rules receive an index: The modified versions of the rules defining nps are adapted such that they percolate up the index of the guarding magic fact that licensed its application. This is illustrated on the basis of the adapted version of rule 14: As is illustrated in section 3.3 this allows the avoidance of spurious ambiguities in the absence of subsumption check in case of the example grammar.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A possible solution to this problem is to couple magic rules with the modified version of the original grammar rule that instigated it. ", "mid_sen": "To accomplish this I propose a technique that can be considered the off-line variant of an index-ing technique described in Gerdemann (1991) . ", "after_sen": "3 The indexing technique is illustrated on the basis of the running example: "}
{"citeStart": 194, "citeEnd": 218, "citeStartToken": 194, "citeEndToken": 218, "sectionName": "UNKNOWN SECTION NAME", "string": "Grammar extraction algorithm Systemic Functional Grammar (SFG) (Halliday, 1985) is based on the assumption that the differentiation of syntactic phenomena is always deter-mined by its function in the communicative context. This functional orientation has lead to the creation of detailed linguistic resources that are characterized by an integrated treatment of content-related, textual and pragmatic aspects. Computational instances of systemic grammar are successfully employed in some of the largest and most influential text generation projects--such as, for example, PENMAN (Mann, 1983) , COMMUNAL (Fawcett and Tucker, 1990) , TECHDOC (KSsner and Stede, 1994) , Drafter (Paris and Vander Linden , 1996) , and Gist (Not and Stock, 1994) . For our present purposes, however, it is the formal characteristics of systemic grammar and its implementations that are more important. Systemic grammar assumes multifunctional constituent structuresrepresentable as feature structures with coreferences. As shown in the following function structure example for the sentence \"The people that buy silver love it.\", different functions can be filled by one and the same constituent: Given the notational equivalence of HPSG and systemic grammar first mentioned by (Carpenter, 1992) and (Zajac, 1992) , and further elaborated in (Henschel, 1995) , one can characterize a systemic grammar as a large type hierarchy with multiple (conjunctive and disjunctive) and multi-dimensional inheritance with an open-world semantics. The basic element of a systemic grammar--a so-called system--is a type axiom of the form (adopting the notation of CUF (DSrre et al., 1996) ):", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This functional orientation has lead to the creation of detailed linguistic resources that are characterized by an integrated treatment of content-related, textual and pragmatic aspects. ", "mid_sen": "Computational instances of systemic grammar are successfully employed in some of the largest and most influential text generation projects--such as, for example, PENMAN (Mann, 1983) , COMMUNAL (Fawcett and Tucker, 1990) , TECHDOC (KSsner and Stede, 1994) , Drafter (Paris and Vander Linden , 1996) , and Gist (Not and Stock, 1994) . ", "after_sen": "For our present purposes, however, it is the formal characteristics of systemic grammar and its implementations that are more important. "}
{"citeStart": 143, "citeEnd": 157, "citeStartToken": 143, "citeEndToken": 157, "sectionName": "UNKNOWN SECTION NAME", "string": "Whereas Shieber et al. (1990) have discussed similar techniques in the context of semantichead-driven generation, we are concerned here with parsing. We view the linking relation not simply as a filter to increase efficiency within the domain of syntactic analysis--this aspect is stressed by Shieber (1985) and other investigators such as Bouma (1991)--but rather as a device for the top-down predictive instantiation of information, as Shieber et al. (1990) have shown for semantic-head-driven generation. In this paper we are concerned especially with morphosyntactic information and illustrate the relevance of predictive linking for morphological analysis and for the analysis of \"unknown\" or \"new\" lexical items.", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Whereas Shieber et al. (1990) have discussed similar techniques in the context of semantichead-driven generation, we are concerned here with parsing. ", "mid_sen": "We view the linking relation not simply as a filter to increase efficiency within the domain of syntactic analysis--this aspect is stressed by Shieber (1985) and other investigators such as Bouma (1991)--but rather as a device for the top-down predictive instantiation of information, as Shieber et al. (1990) have shown for semantic-head-driven generation. ", "after_sen": "In this paper we are concerned especially with morphosyntactic information and illustrate the relevance of predictive linking for morphological analysis and for the analysis of \"unknown\" or \"new\" lexical items."}
{"citeStart": 42, "citeEnd": 58, "citeStartToken": 42, "citeEndToken": 58, "sectionName": "UNKNOWN SECTION NAME", "string": "whereతதจmeans \"'s Chinese\". This regular expression matched 1579 unique queries in the logs. We manually judged the translation for 200 of them. A small random sample of the 200 is shown in Table 8 . The empty cells indicate that the English term is missing from our translation pairs. We use * to mark incorrect translations. When compared with the sample queries in (Cao et al., 2007) , the queries in our sample seem to contain more phrasal words and technical terminology. It is interesting to see that even though parenthetical translations tend to be out-of-vocabulary words, as we have remarked in the introduction, the sheer size of the web means that occasionally translations of common words such as 'use' are sometimes included as well.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We use * to mark incorrect translations. ", "mid_sen": "When compared with the sample queries in (Cao et al., 2007) , the queries in our sample seem to contain more phrasal words and technical terminology. ", "after_sen": "It is interesting to see that even though parenthetical translations tend to be out-of-vocabulary words, as we have remarked in the introduction, the sheer size of the web means that occasionally translations of common words such as 'use' are sometimes included as well."}
{"citeStart": 123, "citeEnd": 137, "citeStartToken": 123, "citeEndToken": 137, "sectionName": "UNKNOWN SECTION NAME", "string": "By implementing our own version of the publicly available Collins parser (Collins, 1996) , we also learned a dependency model that enables the mapping of parse trees into sets of binary relations between the head-word of each constituent and its sibling-words. For example, the parse tree of TREC-9 question Q210: \"How many dogs pull a sled in the Iditarod ?\" is: For each possible constituent in a parse tree, rules first described in (Magerman, 1995) and (Jelinek et al., 1994 ) identify the head-child and propagate the head-word to its parent. For the parse of question Q210 the propagation is:", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For example, the parse tree of TREC-9 question Q210: ", "mid_sen": "\"How many dogs pull a sled in the Iditarod ?\" is: For each possible constituent in a parse tree, rules first described in (Magerman, 1995) and (Jelinek et al., 1994 ) identify the head-child and propagate the head-word to its parent. ", "after_sen": "For the parse of question Q210 the propagation is:"}
{"citeStart": 61, "citeEnd": 75, "citeStartToken": 61, "citeEndToken": 75, "sectionName": "UNKNOWN SECTION NAME", "string": "There have been many approachs to automatic detection of similar words from text. Our method is similar to (Hindle, 1990) , (Lin, 1998) , and (Gasperin, 2001) in the use of dependency relationships as the word features. Another approach used the words' distribution to cluster the words (Pereira, 1993) , and Inoue (Inoue, 1991) also used the word distributional information in the Japanese-English word pairs to resolve the polysemous word problem.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There have been many approachs to automatic detection of similar words from text. ", "mid_sen": "Our method is similar to (Hindle, 1990) , (Lin, 1998) , and (Gasperin, 2001) in the use of dependency relationships as the word features. ", "after_sen": "Another approach used the words' distribution to cluster the words (Pereira, 1993) , and Inoue (Inoue, 1991) also used the word distributional information in the Japanese-English word pairs to resolve the polysemous word problem."}
{"citeStart": 71, "citeEnd": 97, "citeStartToken": 71, "citeEndToken": 97, "sectionName": "UNKNOWN SECTION NAME", "string": "For N-rule modeling, clustering increases the success rate for both N = 1 and N = 2, although only by about half as much as for N-grams. This suggests that conditioning the occurrence of a grammar rule on the identity of its mother (as in the 2-rule case) accounts for some, but not all, of the contextual influences that operate. From this it is sensible to conclude, consistently with the results of Briscoe and Carroll (1993) , that a more complex model of grammar rule interaction might yield better results. Either conditioning on other parts of the parse tree than the mother node could be included, or a rather different scheme such as Briscoe and Carroll's could be used.", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This suggests that conditioning the occurrence of a grammar rule on the identity of its mother (as in the 2-rule case) accounts for some, but not all, of the contextual influences that operate. ", "mid_sen": "From this it is sensible to conclude, consistently with the results of Briscoe and Carroll (1993) , that a more complex model of grammar rule interaction might yield better results. ", "after_sen": "Either conditioning on other parts of the parse tree than the mother node could be included, or a rather different scheme such as Briscoe and Carroll's could be used."}
{"citeStart": 91, "citeEnd": 103, "citeStartToken": 91, "citeEndToken": 103, "sectionName": "UNKNOWN SECTION NAME", "string": "(4) The two algorithms we employed in our dependency parsing model are the Eisner parsing (Eisner, 1996) and Chu-Lius algorithm (Chu and Liu, 1965 ).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The following sentences are two examples.", "mid_sen": "(4) The two algorithms we employed in our dependency parsing model are the Eisner parsing (Eisner, 1996) and Chu-Lius algorithm (Chu and Liu, 1965 ).", "after_sen": "(5) This type of model has been used by, among others, Eisner (1996) ."}
{"citeStart": 42, "citeEnd": 61, "citeStartToken": 42, "citeEndToken": 61, "sectionName": "UNKNOWN SECTION NAME", "string": "There is a well-known debate in psycholinguistics concerning the bilingual mental representation: independence position assumes that bilingual memory is represented by two functionally independent storage and retrieval systems, whereas interdependence position hypothesizes that all information of languages exists in a common memory store. Studies on crosslanguage transfer and cross-language priming have *This work was partly supported by ARPA and ATR Interpreting Telephony Research Laboratorie. provided evidence for both hypotheses (de Groot and Nas, 1991; Lambert, 1958) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Studies on crosslanguage transfer and cross-language priming have *This work was partly supported by ARPA and ATR Interpreting Telephony Research Laboratorie. ", "mid_sen": "provided evidence for both hypotheses (de Groot and Nas, 1991; Lambert, 1958) .", "after_sen": "Dual-coding theory explains the coexistence of independent and interdependent phenomena with separate but connected structures. "}
{"citeStart": 44, "citeEnd": 61, "citeStartToken": 44, "citeEndToken": 61, "sectionName": "UNKNOWN SECTION NAME", "string": "The closest related work we are aware of is McAllester (1999) , which also describes a reduction of PBDGs to efficiently-parsable CFGs and directly inspired this work. However, the CFGs produced by McAllester's transformation include epsilon-productions so they require a specialized CFG parsing algorithm, while the CFGs produced by the transformations described here have binary productions so they can be parsed with standard CFG parsing algorithms. Further, our approach extends to second-order PBDG parsing, while McAllester only discusses first-order PBDGs.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A system that uses these schemata (such as the one described in section 8) can implement these schemata directly, so the Unfold-Fold transformation plays a theoretical role in this work, justifying the resulting CFG schemata.", "mid_sen": "The closest related work we are aware of is McAllester (1999) , which also describes a reduction of PBDGs to efficiently-parsable CFGs and directly inspired this work. ", "after_sen": "However, the CFGs produced by McAllester's transformation include epsilon-productions so they require a specialized CFG parsing algorithm, while the CFGs produced by the transformations described here have binary productions so they can be parsed with standard CFG parsing algorithms. "}
{"citeStart": 38, "citeEnd": 55, "citeStartToken": 38, "citeEndToken": 55, "sectionName": "UNKNOWN SECTION NAME", "string": "The paradigm of two-level morphology (Koskenniemi, 1983) has become popular for handling word formation phenomena in a variety of languages. The original formulation has been extended to allow morphotactic constraints to be expressed by feature specification (Trost, 1990; A1shawi et al, 1991) rather than Koskenniemi's less perspicuous device of continuation classes. Methods for the automatic compilation of rules from a notation convenient for the rule-writer into finitestate automata have also been developed, allowing the efficient analysis and synthesis of word forms. The automata may be derived from the rules alone (Trost, 1990) , or involve composition with the lexicon (Karttunen, Kaplan and Zaenen, 1992) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The paradigm of two-level morphology (Koskenniemi, 1983) has become popular for handling word formation phenomena in a variety of languages. ", "after_sen": "The original formulation has been extended to allow morphotactic constraints to be expressed by feature specification (Trost, 1990; A1shawi et al, 1991) rather than Koskenniemi's less perspicuous device of continuation classes. "}
{"citeStart": 163, "citeEnd": 176, "citeStartToken": 163, "citeEndToken": 176, "sectionName": "UNKNOWN SECTION NAME", "string": "Conventional approaches to subcategorization, such as Definite Clause Grammar (Pereira and Warren, 1980) , Categorial Grammar (Ades and Steedman, 1982) , PATR-II (Shieber, 1986) , and lexicalized TAG (Schabes et al, 1988) all deal with complementation by including in one form or another a notion of \"subcategorization frame\" that specifies a sequence of complement phrases and constraints on them. Handling all the possible variations in complement distribution in such formalisms inevitably leads to an explosion in the number of such frames, and a correspondingly more difficult task in porting to a new domain.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "which cannot be felicitously uttered except in a context where there is something in the discourse that a restriction could \"apply\" to.", "mid_sen": "Conventional approaches to subcategorization, such as Definite Clause Grammar (Pereira and Warren, 1980) , Categorial Grammar (Ades and Steedman, 1982) , PATR-II (Shieber, 1986) , and lexicalized TAG (Schabes et al, 1988) all deal with complementation by including in one form or another a notion of \"subcategorization frame\" that specifies a sequence of complement phrases and constraints on them. ", "after_sen": "Handling all the possible variations in complement distribution in such formalisms inevitably leads to an explosion in the number of such frames, and a correspondingly more difficult task in porting to a new domain."}
{"citeStart": 61, "citeEnd": 86, "citeStartToken": 61, "citeEndToken": 86, "sectionName": "UNKNOWN SECTION NAME", "string": "We also experimented with appending POS tags to every word via Oliver Mason's Qtag program. 12 This serves as a crude form of word sense disambiguation (Wilks and Stevenson, 1998) : for example, it would distinguish the different usages of \"love\" in \"I love this movie\" (indicating sentiment orientation) versus \"This is a love story\" (neutral with respect to sentiment). However, the effect of this information seems to be a wash: as depicted in line (5) of Figure 3 , the accuracy improves slightly for Naive Bayes but declines for SVMs, and the performance of MaxEnt is unchanged.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We also experimented with appending POS tags to every word via Oliver Mason's Qtag program. ", "mid_sen": "12 This serves as a crude form of word sense disambiguation (Wilks and Stevenson, 1998) : for example, it would distinguish the different usages of \"love\" in \"I love this movie\" (indicating sentiment orientation) versus \"This is a love story\" (neutral with respect to sentiment). ", "after_sen": "However, the effect of this information seems to be a wash: as depicted in line (5) of Figure 3 , the accuracy improves slightly for Naive Bayes but declines for SVMs, and the performance of MaxEnt is unchanged."}
{"citeStart": 59, "citeEnd": 72, "citeStartToken": 59, "citeEndToken": 72, "sectionName": "UNKNOWN SECTION NAME", "string": "The third proposal based on the adjacency model appears in Resnik (1993) and is rather more complex again. The SELECTIONAL ASSOCIATION between a predicate and a word is defined based on the contribution of the word to the conditional entropy of the predicate. The association between each pair of words in the compound is then computed by taking the maximum selectional association from all possible ways of regarding the pair as predicate and argument. Whilst this association metric is complicated, the decision procedure still follows the outline devised by Marcus (1980) above. Resnik (1993) used unambiguous noun compounds from the parsed Wall Stree~ Journal (WSJ) corpus to estimate the association ~alues and analysed a test set of around 160 compounds. After some tuning, the accuracy was about 73%, as compared with a baseline of 64% achieved by always bracketing the first two nouns together.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Again, there is no evaluation of the method other than a demonstration that four examples work correctly.", "mid_sen": "The third proposal based on the adjacency model appears in Resnik (1993) and is rather more complex again. ", "after_sen": "The SELECTIONAL ASSOCIATION between a predicate and a word is defined based on the contribution of the word to the conditional entropy of the predicate. "}
{"citeStart": 89, "citeEnd": 108, "citeStartToken": 89, "citeEndToken": 108, "sectionName": "UNKNOWN SECTION NAME", "string": "The segmental structure of discourse has been claimed to constrain and be constrained by disparate phenomena, e.g., cue phrases (Hirschberg and Litman 1993; Grosz and Sidner 1986; Reichman 1985; Cohen 1984) , plans and intentions (Carberry 1990; Litman and Allen 1990; Grosz and Sidner 1986) , prosody (Hirschberg and Pierrehumbert 1986; Butterworth 1980) , nominal reference (Webber 1991; Grosz and Sidner 1986; Linde 1979) , and tense (Webber 1988; Hwang and Schubert 1992; Song and Cohen 1991) . However, just as with the early proposals regarding segmentation, many of these proposals are based on fairly informal studies. It is only recently that attempts have been made to quantitatively evaluate how utterance features correlate with independently justified segmentations. Many of the studies discussed in the preceding subsection take this approach. The types of linguistic features investigated indude prosody (Grosz and Hirschberg 1992; Nakatani, Hirschberg, and Grosz 1995; Hirschberg and Nakatani 1996; Swerts 1995; Swerts and Ostendorf 1995) , term repetition (Hearst 1994) , cue words Whittaker and Stenton 1988) , and discourse anaphora (Walker and Whittaker 1990) . Grosz and Hirschberg (1992) investigate the prosodic structuring of discourse. The correlation of various prosodic features with their independently obtained consensus codings of segmental structure (codings on which all labelers agreed) is analyzed using t-tests; the results support the hypothesis that discourse structure is marked intonationally in read speech. For example, pauses tended to precede phrases that initiated segments (independent of hierarchical structure) and to follow phrases that ended segments. Similar results are reported in Nakatani, Hirschberg, and Grosz (1995) and Hirschberg and Nakatani (1996) for spontaneous speech as well. Grosz and Hirschberg (1992) also use the classification and regression tree system CART (Brieman et al. 1984) to automatically construct and evaluate decision trees for classifying aspects of discourse structure from intonational feature values.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Similar results are reported in Nakatani, Hirschberg, and Grosz (1995) and Hirschberg and Nakatani (1996) for spontaneous speech as well. ", "mid_sen": "Grosz and Hirschberg (1992) also use the classification and regression tree system CART (Brieman et al. 1984) to automatically construct and evaluate decision trees for classifying aspects of discourse structure from intonational feature values.", "after_sen": "The studies of Swerts (1995) and Swerts and Ostendorf (1995) also investigate the prosodic structuring of discourse. "}
{"citeStart": 121, "citeEnd": 145, "citeStartToken": 121, "citeEndToken": 145, "sectionName": "UNKNOWN SECTION NAME", "string": "Despite its simplicity, the performance of our approach was on the level with the previously highest reported results on the same test collections. The error rate on sentence boundaries in the Brown corpus was not significantly worse than the lowest quoted before (Riley 1989 : 0.28% vs. 0.20% error rate). On the WSJ corpus our system performed slightly better than the combination of the Alembic and SATZ systems described in Palmer and Hearst (1997) (0.44% vs. 0.5% error rate). Although these error rates seem to be very small, they are quite significant. Unlike general POS tagging, in which it is unfair to expect an error rate of less than 2% because even human annotators have a disagreement rate of about 3%, sentence boundaries are much less ambiguous (with a disagreement of about 1 in 5,000). This shows that an error rate of 1 in 200 (0.5%) is still far from reaching the disagreement level. On the other hand, one error in 200 periods means that there is one error in every two documents in the Brown corpus and one error in every four documents in the WSJ corpus.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The error rate on sentence boundaries in the Brown corpus was not significantly worse than the lowest quoted before (Riley 1989 : 0.28% vs. 0.20% error rate). ", "mid_sen": "On the WSJ corpus our system performed slightly better than the combination of the Alembic and SATZ systems described in Palmer and Hearst (1997) (0.44% vs. 0.5% error rate). ", "after_sen": "Although these error rates seem to be very small, they are quite significant. "}
{"citeStart": 137, "citeEnd": 157, "citeStartToken": 137, "citeEndToken": 157, "sectionName": "UNKNOWN SECTION NAME", "string": "Previous systems to assist in the development of spoken-langnage systems (SLSs) have focused on building stand-alone, customized applications, such as (Sutton et al., 1996) and (Pargellis et al., 1999) . The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -this is similar to the goals of the MELISSA project (Schmidt et al., 1998) . It is intended to both speed the development of SLSs and to localize the speech-specific code within the application. JAVOX allows developers to add speech interfaces to applications at the end of the development process; SLSs no longer need to be built from the ground up.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Previous systems to assist in the development of spoken-langnage systems (SLSs) have focused on building stand-alone, customized applications, such as (Sutton et al., 1996) and (Pargellis et al., 1999) . ", "mid_sen": "The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -this is similar to the goals of the MELISSA project (Schmidt et al., 1998) . ", "after_sen": "It is intended to both speed the development of SLSs and to localize the speech-specific code within the application. "}
{"citeStart": 27, "citeEnd": 51, "citeStartToken": 27, "citeEndToken": 51, "sectionName": "UNKNOWN SECTION NAME", "string": "In the system described in Dalrymple et al. (1993a) , the ~ relation associates expressions in the meaning language with f-structures. As a result, each f-structure contributed a single meaning constructor as a resource to be used in a derivation. Because linear logic does not have any form of logical contraction (as is inherent in 2For discussion of c-structure and its relation to f-structure, see, for example, Kaplan and Bresnan (1982) . the approaches discussed earlier), cases where resources are shared appear to be problematic in this framework. Intuitively. however, the need for the multiple use of an f-structure meaning results not from the appearance of a particular lexical item (e.g., a conjunction) or a particular syntactic construction (e.g., parasitic gap constructions), but instead results from multiple paths to it from within the f-structure that contains it, where structure sharing is motivated on syntactic grounds. We therefore revise the earlier framework to model what we will term occurrences of f-structures as resources explicitly in the logic.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For instance, the meaning constructor for the verb supported is a glue language formula paraphrasable as: \"If my SUBJ means X and (®) my OBJ means Y, then ( ---o ) my sentence means supported(X, Y)\".", "mid_sen": "In the system described in Dalrymple et al. (1993a) , the ~ relation associates expressions in the meaning language with f-structures. ", "after_sen": "As a result, each f-structure contributed a single meaning constructor as a resource to be used in a derivation. "}
{"citeStart": 201, "citeEnd": 231, "citeStartToken": 201, "citeEndToken": 231, "sectionName": "UNKNOWN SECTION NAME", "string": "During the last few years large treebanks have become available to many researchers, which has resulted in researches applying a range of new techniques for parsing systems. Most of the methods that are being suggested include some kind of Machine Learning, such as history based grammars and decision tree models Magerman, 1995) , training or inducing statistical grammars (Black, Garside and Leech, 1993; Pereira and Schabes, 1992; Schabes et al., 1993) , or other techniques (Bod, 1993) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "During the last few years large treebanks have become available to many researchers, which has resulted in researches applying a range of new techniques for parsing systems. ", "mid_sen": "Most of the methods that are being suggested include some kind of Machine Learning, such as history based grammars and decision tree models Magerman, 1995) , training or inducing statistical grammars (Black, Garside and Leech, 1993; Pereira and Schabes, 1992; Schabes et al., 1993) , or other techniques (Bod, 1993) .", "after_sen": "Consequently, syntactical analysis has become an area with a wide variety of (a) algorithms and methods for learning and parsing, and (b) type of information used for learning and parsing (sometimes referred to as feature set). "}
{"citeStart": 96, "citeEnd": 107, "citeStartToken": 96, "citeEndToken": 107, "sectionName": "UNKNOWN SECTION NAME", "string": "These axioms are based on the lexieal semantics of CoL verbs and of spatial prepositions. They also take into account the syntactic structure of the sentence (we have supposed an X-bar syntax with a VP internal subject, though this is not essential) and the links which exist at the level of diseours between this sentence and the previous and following sentences of the text. These links, called discourse relations, are basic concepts on which texts are structured (cf. (Asher, 1993) ).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "They also take into account the syntactic structure of the sentence (we have supposed an X-bar syntax with a VP internal subject, though this is not essential) and the links which exist at the level of diseours between this sentence and the previous and following sentences of the text. ", "mid_sen": "These links, called discourse relations, are basic concepts on which texts are structured (cf. (Asher, 1993) ).", "after_sen": ""}
{"citeStart": 142, "citeEnd": 157, "citeStartToken": 142, "citeEndToken": 157, "sectionName": "UNKNOWN SECTION NAME", "string": "Our experiments have shown that training an unlexicalized model first is worth the effort. Despite our use of a manually developed grammar that does not have to be pruned of superfluous rules like an automatically generated grammar, Charniak (1995) for related observations). A comparison of immediate lexicalized training (without prior training of an unlexicalized model) and our standard training regime that involves preliminary unlexicalized training speaks in favor of our strategy (cf. the different 'lex 0' and 'lex 2' curves in figures 8 and 9). However, the amount of unlexicalized training has to be controlled in some way.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Our experiments have shown that training an unlexicalized model first is worth the effort. ", "mid_sen": "Despite our use of a manually developed grammar that does not have to be pruned of superfluous rules like an automatically generated grammar, Charniak (1995) for related observations). ", "after_sen": "A comparison of immediate lexicalized training (without prior training of an unlexicalized model) and our standard training regime that involves preliminary unlexicalized training speaks in favor of our strategy (cf. the different 'lex 0' and 'lex 2' curves in figures 8 and 9). "}
{"citeStart": 184, "citeEnd": 204, "citeStartToken": 184, "citeEndToken": 204, "sectionName": "UNKNOWN SECTION NAME", "string": "WIT has been implemented in Common Lisp and C on UNIX, and we have built several experimental and demonstration dialogue systems using it, including a meeting room reservation system (Nakano et al., 1999b) , a video-recording programming system, a schedule management system (Nakano et al., 1999a) , and a weather information system (Dohsaka et al., 2000) . The meeting room reservation system has vocabulary of about 140 words, around 40 phrase structure rules, nine attributes in the semantic frame, and around 100 speech files. A sample dialogue between this system and a naive user is shown in Figure 2 . This system employs HTK as the speech recognition engine. The weather information system can answer the user's questions about weather forecasts in Japan. The vocabulary size is around 500, and the number of phrase structure rules is 31. The number of attributes in the semantic flame is 11, and the number of the files of the pre-recorded speech is about 13,000.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "WIT has been implemented in Common Lisp and C on UNIX, and we have built several experimental and demonstration dialogue systems using it, including a meeting room reservation system (Nakano et al., 1999b) , a video-recording programming system, a schedule management system (Nakano et al., 1999a) , and a weather information system (Dohsaka et al., 2000) . ", "after_sen": "The meeting room reservation system has vocabulary of about 140 words, around 40 phrase structure rules, nine attributes in the semantic frame, and around 100 speech files. "}
{"citeStart": 110, "citeEnd": 140, "citeStartToken": 110, "citeEndToken": 140, "sectionName": "UNKNOWN SECTION NAME", "string": "Previous evaluations of CCG parsers have used the predicate-argument dependencies from CCGbank as a test set (Hockenmaier and Steedman, 2002; Clark and Curran, 2004b) , with impressive results of over 84% F-score on labelled dependencies. In this paper we reinforce the earlier results with the first evaluation of a CCG parser outside of CCGbank.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Numerical subscripts on the argument categories represent dependency relations; the head of the final declarative sentence is persuade; and the head of the infinitival complement's subject is identified with the head of the object, using the variable X, as in standard unification-based accounts of control.", "mid_sen": "Previous evaluations of CCG parsers have used the predicate-argument dependencies from CCGbank as a test set (Hockenmaier and Steedman, 2002; Clark and Curran, 2004b) , with impressive results of over 84% F-score on labelled dependencies. ", "after_sen": "In this paper we reinforce the earlier results with the first evaluation of a CCG parser outside of CCGbank."}
{"citeStart": 260, "citeEnd": 270, "citeStartToken": 260, "citeEndToken": 270, "sectionName": "UNKNOWN SECTION NAME", "string": "The most relevant prior work is (Wiebe et al. 98) , who dealt with meeting scheduling dialogs (see also (Alexandersson et al. 97) , (Busemann et al. 97)) , where the goal is to schedule a time for the meeting. The temporal references in meeting scheduling are somewhat more constrained than in news, where (e.g., in a historical news piece on toxic dumping) dates and times may be relatively unconstrained. In addition, their model requires the maintenance of a focus stack. They obtained roughly .91 Precision and .80 Recall on one test set, and .87 Precision and .68 Recall on another. However, they adjust the reference time during processing, which is something that we have not yet addressed. More recently, (Setzer and Gaizauskas 2000) have independently developed an annotation scheme which represents both time values and more fine-grained interevent and event-time temporal relations. Although our work is much more limited in scope, and doesn't exploit the internal structure of events, their annotation scheme may be leveraged in evaluating aspects of our work. The MUC-7 task (MUC-7 98) did not require VALs, but did test TIMEX recognition accuracy. Our 98 F-measure on NYT can be compared for just TIMEX with MUC-7 (MUC-7 1998) results on similar news stories, where the best performance was .99 Precision and .88 Recall. (The MUC task required recognizing a wider variety of TIMEXs, including event-dependent ones. However, at least 30% of the dates and times in the MUC test were fixed-format ones occurring in document headers, trailers, and copyright notices. ) Finally, there is a large body of work, e.g., (Moens and Steedman 1988) , (Passoneau 1988) , (Webber 1988) , (Hwang 1992) , (Song and Cohen 1991) , that has focused on a computational analysis of tense and aspect. While the work on event chronologies is based on some of the notions developed in that body of work, we hope to further exploit insights from previous work.", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "(The MUC task required recognizing a wider variety of TIMEXs, including event-dependent ones. ", "mid_sen": "However, at least 30% of the dates and times in the MUC test were fixed-format ones occurring in document headers, trailers, and copyright notices. ) Finally, there is a large body of work, e.g., (Moens and Steedman 1988) , (Passoneau 1988) , (Webber 1988) , (Hwang 1992) , (Song and Cohen 1991) , that has focused on a computational analysis of tense and aspect. ", "after_sen": "While the work on event chronologies is based on some of the notions developed in that body of work, we hope to further exploit insights from previous work."}
{"citeStart": 303, "citeEnd": 323, "citeStartToken": 303, "citeEndToken": 323, "sectionName": "UNKNOWN SECTION NAME", "string": "WSD is usually approached as an independent task, however, it has been argued that different applications may have specific requirements (Resnik and Yarowsky, 1997) . For example, in machine translation, WSD, or translation disambiguation, is responsible for identifying the correct translation for an ambiguous source word. There is not always a direct relation between the possible senses for a word in a (monolingual) lexicon and its translations to a particular language, so this represents a different task to WSD against a (monolingual) lexicon (Hutchins and Somers, 1992) . Although it has been argued that WSD does not yield better translation quality than a machine translation system alone, it has been recently shown that a WSD module that is developed following specific multilingual requirements can significantly improve the performance of a machine translation system (Carpuat et al., 2006) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There is not always a direct relation between the possible senses for a word in a (monolingual) lexicon and its translations to a particular language, so this represents a different task to WSD against a (monolingual) lexicon (Hutchins and Somers, 1992) . ", "mid_sen": "Although it has been argued that WSD does not yield better translation quality than a machine translation system alone, it has been recently shown that a WSD module that is developed following specific multilingual requirements can significantly improve the performance of a machine translation system (Carpuat et al., 2006) .", "after_sen": "This paper focuses on the application of our approach to the translation of verbs in English to Portuguese translation, specifically for a set of 10 mainly light and highly ambiguous verbs. "}
{"citeStart": 92, "citeEnd": 107, "citeStartToken": 92, "citeEndToken": 107, "sectionName": "UNKNOWN SECTION NAME", "string": "Many researches have been done in relation extraction. Among them, feature-based methods (Kambhatla 2004; Zhou et al., 2005) achieve certain success by employing a large amount of diverse linguistic features, varying from lexical knowledge, e ntityrelated information to syntactic parse trees, dependency trees and semantic information. However, it is difficult for them to effectively capture structured parse tree information (Zhou et al 2005) , which is critical for further performance improvement in relation extraction.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Among them, feature-based methods (Kambhatla 2004; Zhou et al., 2005) achieve certain success by employing a large amount of diverse linguistic features, varying from lexical knowledge, e ntityrelated information to syntactic parse trees, dependency trees and semantic information. ", "mid_sen": "However, it is difficult for them to effectively capture structured parse tree information (Zhou et al 2005) , which is critical for further performance improvement in relation extraction.", "after_sen": "As an alternative to feature-based methods, tree kernel-based methods provide an elegant solution to explore implicitly structured features by directly computing the similarity between two trees. "}
{"citeStart": 79, "citeEnd": 104, "citeStartToken": 79, "citeEndToken": 104, "sectionName": "UNKNOWN SECTION NAME", "string": "The MUC-6 system took the destructive option. The nondestructive option has been implemented in a more recent system. These basic steps of \"COLLECT, FILTER, and ORDER by salience\" are analogous to Lappin and Leass's (1994) pronoun resolution algorithm, but each step in FASTUS relies on considerably poorer syntactic input. The present algorithm thus provides an interesting case of what happens with extremely poor syntactic input, even poorer than in Kennedy and Boguraev's (1996) system. This comparison will be discussed later.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The nondestructive option has been implemented in a more recent system. ", "mid_sen": "These basic steps of \"COLLECT, FILTER, and ORDER by salience\" are analogous to Lappin and Leass's (1994) pronoun resolution algorithm, but each step in FASTUS relies on considerably poorer syntactic input. ", "after_sen": "The present algorithm thus provides an interesting case of what happens with extremely poor syntactic input, even poorer than in Kennedy and Boguraev's (1996) system. "}
{"citeStart": 310, "citeEnd": 329, "citeStartToken": 310, "citeEndToken": 329, "sectionName": "UNKNOWN SECTION NAME", "string": "Grammar extraction algorithm Systemic Functional Grammar (SFG) (Halliday, 1985) is based on the assumption that the differentiation of syntactic phenomena is always deter-mined by its function in the communicative context. This functional orientation has lead to the creation of detailed linguistic resources that are characterized by an integrated treatment of content-related, textual and pragmatic aspects. Computational instances of systemic grammar are successfully employed in some of the largest and most influential text generation projects--such as, for example, PENMAN (Mann, 1983) , COMMUNAL (Fawcett and Tucker, 1990) , TECHDOC (KSsner and Stede, 1994) , Drafter (Paris and Vander Linden , 1996) , and Gist (Not and Stock, 1994) . For our present purposes, however, it is the formal characteristics of systemic grammar and its implementations that are more important. Systemic grammar assumes multifunctional constituent structuresrepresentable as feature structures with coreferences. As shown in the following function structure example for the sentence \"The people that buy silver love it.\", different functions can be filled by one and the same constituent: Given the notational equivalence of HPSG and systemic grammar first mentioned by (Carpenter, 1992) and (Zajac, 1992) , and further elaborated in (Henschel, 1995) , one can characterize a systemic grammar as a large type hierarchy with multiple (conjunctive and disjunctive) and multi-dimensional inheritance with an open-world semantics. The basic element of a systemic grammar--a so-called system--is a type axiom of the form (adopting the notation of CUF (DSrre et al., 1996) ):", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This functional orientation has lead to the creation of detailed linguistic resources that are characterized by an integrated treatment of content-related, textual and pragmatic aspects. ", "mid_sen": "Computational instances of systemic grammar are successfully employed in some of the largest and most influential text generation projects--such as, for example, PENMAN (Mann, 1983) , COMMUNAL (Fawcett and Tucker, 1990) , TECHDOC (KSsner and Stede, 1994) , Drafter (Paris and Vander Linden , 1996) , and Gist (Not and Stock, 1994) . ", "after_sen": "For our present purposes, however, it is the formal characteristics of systemic grammar and its implementations that are more important. "}
{"citeStart": 433, "citeEnd": 443, "citeStartToken": 433, "citeEndToken": 443, "sectionName": "UNKNOWN SECTION NAME", "string": "There have been successful attempts at using machine learning in search of a solution for linguistic tasks, e.g. discriminating between discourse and sentential senses of cues ( [Litman 1996]) or resolution of coreferences in texts ([McCarthy & Lehnert 1995] ). Like our work, these problems are cast as classification problems, and then machine learning (mainly C4.5) techniques are used to induce classifiers for each class. What makes these applications different from ours is that they have worked on surface linguistic or mixed surface linguistic and intonational representation, and that the classes are relatively balanced, while in our case the class of compound sentences is much less numerous than the class of non-composite sentences. Such unbalanced classes create problems for the majority of inductive learning systems. A distinctive feature of our work is the fact that we used machine learning techniques to improve an existing rule-based natural language processor from the inside. This contrasts with approaches where there are essentially no explicit rules, such as neural networks (e.g. [Buo 1996]) , or approaches where the machine learning algorithms attempt to infer--via deduction (e.g. [Samuelsson 1994 ]), induction (e.g. [Theeramunkong et al. 1997] ; [Zelle & Mooney 1994] ) under user cooperation (e.g. [Simmons & Yu 1992] ; [Hermjakob & Mooney 1997] ), transformation-based error-driven learning (e.g. [Brill 1993]) , or even decision trees (e.g. [Magerman 1995] )--a grammar from raw or preprocessed data. In our work, we do not wish to acquire a grammar: we have one and want to devise a mechanism to make some of its parts adaptable to the corpus at hand or, to improve some aspect of its performance. Other researchers, such as [Lawrence et al. 1996] , have compared neural networks and machine learning methods at the task of sentence classification. In this task, the system must classify a string as either grammatical or not. We do not content ourselves with results based on a grammatical/ungrammatical dichotomy. We are looking for heuristics, using relevant features, that will do better than the current ones and improve the overall performance of a natural language processor: this is a very difficult problem (see, e.g., [Huyck & Lytinen 1993] ). One could also look at this problem as one of optimisation of a rule-based system.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A distinctive feature of our work is the fact that we used machine learning techniques to improve an existing rule-based natural language processor from the inside. ", "mid_sen": "This contrasts with approaches where there are essentially no explicit rules, such as neural networks (e.g. [Buo 1996]) , or approaches where the machine learning algorithms attempt to infer--via deduction (e.g. [Samuelsson 1994 ]), induction (e.g. [Theeramunkong et al. 1997] ; [Zelle & Mooney 1994] ) under user cooperation (e.g. [Simmons & Yu 1992] ; [Hermjakob & Mooney 1997] ), transformation-based error-driven learning (e.g. [Brill 1993]) , or even decision trees (e.g. [Magerman 1995] )--a grammar from raw or preprocessed data. ", "after_sen": "In our work, we do not wish to acquire a grammar: we have one and want to devise a mechanism to make some of its parts adaptable to the corpus at hand or, to improve some aspect of its performance. "}
{"citeStart": 36, "citeEnd": 58, "citeStartToken": 36, "citeEndToken": 58, "sectionName": "UNKNOWN SECTION NAME", "string": "Researchers including Dras (2009), Wong et al. (2011; 2012) , and Koppel et al. (2005) work on native language identification and show that machine learning-based methods are effective. Wong and Dras (2009) propose using information about grammatical errors such as errors in determiners to achieve better performance while they show that its use does not improve the performance, contrary to the expectation. Related to this, other researchers (Koppel and Ordan, 2011; van Halteren, 2008) show that machine learning-based methods can also predict the source language of a given translated text although it should be emphasized that it is a different task from native language identification because translation is not typically performed by non-native speakers but rather native speakers of the target language 11 . The experimental results show that n-grams containing articles are predictive for identifying native languages. This indicates that they should be used in the native language identification task. Importantly, all n-grams containing articles should be used in the classifier unlike the previous methods that are based only on ngrams containing article errors. Besides, no articles should be explicitly coded in n-grams for taking the overuse/underuse of articles into consideration. We can achieve this by adding a special symbol such as φ to the beginning of each NP whose head noun is a common noun and that has no determiner in it as in \"I like φ orange juice.\"", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Wong and Dras (2009) propose using information about grammatical errors such as errors in determiners to achieve better performance while they show that its use does not improve the performance, contrary to the expectation. ", "mid_sen": "Related to this, other researchers (Koppel and Ordan, 2011; van Halteren, 2008) show that machine learning-based methods can also predict the source language of a given translated text although it should be emphasized that it is a different task from native language identification because translation is not typically performed by non-native speakers but rather native speakers of the target language 11 . ", "after_sen": "The experimental results show that n-grams containing articles are predictive for identifying native languages. "}
{"citeStart": 116, "citeEnd": 133, "citeStartToken": 116, "citeEndToken": 133, "sectionName": "UNKNOWN SECTION NAME", "string": "We use the dataset from Athar (2011) as our starting point, which consists of 8,736 citations in the ACL Anthology (Bird et al., 2008) that cite a target set of 310 ACL Anthology papers. The citation summary data from the ACL Anthology Network 1 (Radev et al., 2009) is used. This dataset is rather large, and since manual annotation of context for each citation is a time consuming task, a subset of 20 target papers (i.e., all citations to these) has been selected for annotation. These 20 papers correspond to approximately 20% of incoming citations in the original dataset. They contain a total of 1,555 citations from 854 citing papers.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We use the dataset from Athar (2011) as our starting point, which consists of 8,736 citations in the ACL Anthology (Bird et al., 2008) that cite a target set of 310 ACL Anthology papers. ", "after_sen": "The citation summary data from the ACL Anthology Network 1 (Radev et al., 2009) is used. "}
{"citeStart": 266, "citeEnd": 296, "citeStartToken": 266, "citeEndToken": 296, "sectionName": "UNKNOWN SECTION NAME", "string": "Grammar extraction algorithm Systemic Functional Grammar (SFG) (Halliday, 1985) is based on the assumption that the differentiation of syntactic phenomena is always deter-mined by its function in the communicative context. This functional orientation has lead to the creation of detailed linguistic resources that are characterized by an integrated treatment of content-related, textual and pragmatic aspects. Computational instances of systemic grammar are successfully employed in some of the largest and most influential text generation projects--such as, for example, PENMAN (Mann, 1983) , COMMUNAL (Fawcett and Tucker, 1990) , TECHDOC (KSsner and Stede, 1994) , Drafter (Paris and Vander Linden , 1996) , and Gist (Not and Stock, 1994) . For our present purposes, however, it is the formal characteristics of systemic grammar and its implementations that are more important. Systemic grammar assumes multifunctional constituent structuresrepresentable as feature structures with coreferences. As shown in the following function structure example for the sentence \"The people that buy silver love it.\", different functions can be filled by one and the same constituent: Given the notational equivalence of HPSG and systemic grammar first mentioned by (Carpenter, 1992) and (Zajac, 1992) , and further elaborated in (Henschel, 1995) , one can characterize a systemic grammar as a large type hierarchy with multiple (conjunctive and disjunctive) and multi-dimensional inheritance with an open-world semantics. The basic element of a systemic grammar--a so-called system--is a type axiom of the form (adopting the notation of CUF (DSrre et al., 1996) ):", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This functional orientation has lead to the creation of detailed linguistic resources that are characterized by an integrated treatment of content-related, textual and pragmatic aspects. ", "mid_sen": "Computational instances of systemic grammar are successfully employed in some of the largest and most influential text generation projects--such as, for example, PENMAN (Mann, 1983) , COMMUNAL (Fawcett and Tucker, 1990) , TECHDOC (KSsner and Stede, 1994) , Drafter (Paris and Vander Linden , 1996) , and Gist (Not and Stock, 1994) . ", "after_sen": "For our present purposes, however, it is the formal characteristics of systemic grammar and its implementations that are more important. "}
{"citeStart": 88, "citeEnd": 107, "citeStartToken": 88, "citeEndToken": 107, "sectionName": "UNKNOWN SECTION NAME", "string": "One way to connect theory to data in this manner uses a parser's probability model to work out the surprisal or log-probability of the next word. Hale (2001) suggests this quantity as an index of psycholinguistic difficulty. When the transition from previous word to current word is lowprobability, from the parser's perspective, the surprisal is high and the psycholinguistic claim is that behavioral measures should register increased cognitive difficulty. In other words, rare parser actions are cognitively costly. This basic notion has proved remarkably applicable across sentence types and languages (Park and Brew, 2006; Demberg and Keller, 2007; Levy, 2008) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In other words, rare parser actions are cognitively costly. ", "mid_sen": "This basic notion has proved remarkably applicable across sentence types and languages (Park and Brew, 2006; Demberg and Keller, 2007; Levy, 2008) .", "after_sen": "The present work uses the time spent looking at a word during reading as an empirical measure of sentence processing difficulty. "}
{"citeStart": 0, "citeEnd": 24, "citeStartToken": 0, "citeEndToken": 24, "sectionName": "UNKNOWN SECTION NAME", "string": "Since the hallmark of the linear logic approach is to ensure that f-structure contributions are ulilized exactly once in a derivation, such constructions would at first glance appear to be problematic for the approach. We argue that the resource sharing that is commonly manifest in the treatment of coordination in other approaches is appropriately handled by exploiting the structure-sharing in LF(', f-structures. We refine our previous analysis to account for cases where an f-structure is reached by multiple paths from an enclosing f-structure. Dalrymple et al. (199aa) provides an account of LFG semantics that represents the meaning of lexical items with linear logic formulas. These formulas manipulate basic assertions of the form f~,r'.~M, for f-structures f and meaning logzc terms M. Here (r is a mapping, the semantic projectign, that relates f-structures to semantic structures. To distinguish between multiple paths entering an f-structure, we now take cr to map from sets of paths in f-structures to semantic structures. Further, the paths between f-structures are made available in the semantic space as resources. This makes it possible for the semantic formulas to exploit information about the multiple paths into an f-structure in order to account for the multiple uses of the f-structure's semantic contribution. The resulting system is sufficiently restricted in cases where other approaches overgenerate; the very property of resource-sensitivity for which resource sharing appears to be problematic actually provides explanatory advantages over systems that more freely replicate resources during derivation.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We refine our previous analysis to account for cases where an f-structure is reached by multiple paths from an enclosing f-structure. ", "mid_sen": "Dalrymple et al. (199aa) provides an account of LFG semantics that represents the meaning of lexical items with linear logic formulas. ", "after_sen": "These formulas manipulate basic assertions of the form f~,r'.~M, for f-structures f and meaning logzc terms M. Here (r is a mapping, the semantic projectign, that relates f-structures to semantic structures. "}
{"citeStart": 187, "citeEnd": 211, "citeStartToken": 187, "citeEndToken": 211, "sectionName": "UNKNOWN SECTION NAME", "string": "Identifying transliteration pairs is an important component in many linguistic applications such as machine translation and information retrieval, which require identifying out-of-vocabulary words. In our settings, we have access to source language NE and the ability to label the data upon request. We introduce a new active sampling paradigm that aims to guide the learner toward informative samples, allowing learning from a small number of representative examples. After the data is obtained it is analyzed to identify repeating patterns which can be used to focus the training process of the model. Previous works usually take a generative approach, (Knight and Graehl, 1997) . Other approaches exploit similarities in aligned bilingual corpora; for example, (Tao et al., 2006) combine two unsupervised methods. (Klementiev and Roth, 2006) bootstrap with a classifier used interchangeably with an unsupervised temporal alignment method. Although these approaches alleviate the problem of obtaining annotated data, other resources are still required, such as a large aligned bilingual corpus. The idea of selectively sampling training samples has been wildly discussed in machine learning theory (Seung et al., 1992) and has been applied successfully to several NLP applications (McCallum and Nigam, 1998) . Unlike other approaches,our approach is based on minimizing the distance between the feature distribution of a comprehensive reference set and the sampled set.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Although these approaches alleviate the problem of obtaining annotated data, other resources are still required, such as a large aligned bilingual corpus. ", "mid_sen": "The idea of selectively sampling training samples has been wildly discussed in machine learning theory (Seung et al., 1992) and has been applied successfully to several NLP applications (McCallum and Nigam, 1998) . ", "after_sen": "Unlike other approaches,our approach is based on minimizing the distance between the feature distribution of a comprehensive reference set and the sampled set."}
{"citeStart": 122, "citeEnd": 143, "citeStartToken": 122, "citeEndToken": 143, "sectionName": "UNKNOWN SECTION NAME", "string": "Word alignment models in general and the HMM in particular are very gross oversimplifications of the translation process and the optimal likelihood parameters learned often do not correspond to sensible alignments. One solution to this problem is to add more complexity to the model to better reflect the translation process. This is the approach taken by IBM Models 4+ (Brown et al. 1993b; Och and Ney 2003) , and more recently by the LEAF model (Fraser and Marcu 2007) . Unfortunately, these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors. Instead, we propose to use a learning framework called Posterior Regularization (Graça, Ganchev, and Taskar 2007) that incorporates side information into unsupervised estimation in the form of constraints on the model's posteriors. The constraints are expressed as inequalities on the expected values under the posterior distribution of user-defined constraint features (not necessarily the same features used by the model). Because in most applications what we are interested in are the latent variables (in this case the alignments), constraining the posteriors allows a more direct way to achieve the desired behavior. On the other hand, constraining the expected value of the features instead of adding them to the model allows us to express features that would otherwise make the model intractable. For example, enforcing that each hidden state of an HMM model should be used at most once per sentence would break the Markov property and make the model intractable. In contrast, we will show how to enforce the constraint that each hidden state is used at most once in expectation. The underlying model remains unchanged, but the learning method changes. During learning, our method is similar to the EM algorithm with the addition of solving an optimization problem similar to a maximum entropy problem inside the E Step. The following subsections present the Posterior Regularization framework, followed by a description of how to encode two pieces of prior information aimed at solving the problems described at the end of Section 2.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "One solution to this problem is to add more complexity to the model to better reflect the translation process. ", "mid_sen": "This is the approach taken by IBM Models 4+ (Brown et al. 1993b; Och and Ney 2003) , and more recently by the LEAF model (Fraser and Marcu 2007) . ", "after_sen": "Unfortunately, these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors. "}
{"citeStart": 188, "citeEnd": 189, "citeStartToken": 188, "citeEndToken": 189, "sectionName": "UNKNOWN SECTION NAME", "string": "There are several researches that are attacking this problem, l)'uzisaki et al. applied the ItMM model to scg,nentatimt and probabilistic CFG to analyzing the structure of compound nouns [3] . The accuracy of their method is 73% in identifying correct structures of kanzi character sequences with average length is 4.2 characters. In their approach, word boundaries are identified through tmrely statistical information (the IIMM model) without regarding such linguistic knowledge, as dictionaries. Therefore, the HMM nrodel may suggest an improper character sequence as a word. Purthermore, since nonterminal symbols of CFG are derived from a statistical analysis of word collocations, their number tends to be large and so the muuber of CFG rules are also large. They assumed COml)ound nouns consist of only one character words and two character words. It is questionable whether this method can be extended to handle cases that include nmre than two character words without lowering accuracy.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The information of structures is also expected to improve segmentation accuracy.", "mid_sen": "There are several researches that are attacking this problem, l)'uzisaki et al. applied the ItMM model to scg,nentatimt and probabilistic CFG to analyzing the structure of compound nouns [3] . ", "after_sen": "The accuracy of their method is 73% in identifying correct structures of kanzi character sequences with average length is 4.2 characters. "}
{"citeStart": 147, "citeEnd": 159, "citeStartToken": 147, "citeEndToken": 159, "sectionName": "UNKNOWN SECTION NAME", "string": "1 Introduction Shallow parsing is studied as an alternative to full-sentence parsers. Rather than producing a complete analysis of sentences, the alternative is to perform only partial analysis of the syntactic structures in a text (Harris, 1957; Abney, 1991; Greffenstette, 1993) . Shallow parsing information such as NPs and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization. A lot of the work on shallow parsing over the past years has concentrated on manual construction of rules. The observation that shallow syntactic information can be extracted using local information -by examining the pattern itself, its nearby context and the local part-of-speech information -has motivated the use of learning methods to recognize these patterns (Church, 1988; Ramshaw and Marcus, 1995; Argamon et al., 1998; Cardie and Pierce, 1998) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "1 Introduction Shallow parsing is studied as an alternative to full-sentence parsers. ", "mid_sen": "Rather than producing a complete analysis of sentences, the alternative is to perform only partial analysis of the syntactic structures in a text (Harris, 1957; Abney, 1991; Greffenstette, 1993) . ", "after_sen": "Shallow parsing information such as NPs and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization. "}
{"citeStart": 92, "citeEnd": 104, "citeStartToken": 92, "citeEndToken": 104, "sectionName": "UNKNOWN SECTION NAME", "string": "Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie (Hindle, 1990) , although Hindle did not apply it to information retrieval. Instead, he used mutual information statistics as a Similarity coefficient, wheras we used the Dice coefficient for normalization purposes. Hindle only extracted the subject-verb and the object-verb predicatearguments, while we also extract adjective-noun predicate-arguments.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Although Stairmand (Stairmand, 1997) and Richardson (Richardson and Smeaton, 1995) have proposed the use of WordNet in information retrieval, they did not used WordNet in the query expansion framework.", "mid_sen": "Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie (Hindle, 1990) , although Hindle did not apply it to information retrieval. ", "after_sen": "Instead, he used mutual information statistics as a Similarity coefficient, wheras we used the Dice coefficient for normalization purposes. "}
{"citeStart": 149, "citeEnd": 162, "citeStartToken": 149, "citeEndToken": 162, "sectionName": "UNKNOWN SECTION NAME", "string": "Though there can be little doubt that the ruling system of bakeoffs actively encourages a degree of oneupmanship, our paper and our software are not offered in a competitive spirit. As we said at the out-set, we don't necessarily believe HunPos to be in any way better than TnT, and certainly the main ideas have been pioneered by DeRose (1988) , Church (1988) , and others long before this generation of HMM work. But to improve the results beyond what a basic HMM can achieve one needs to tune the system, and progress can only be made if the experiments are end to end replicable. There is no doubt many other systems could be tweaked further and improve on our results -what matters is that anybody could now also tweak Hun-Pos without any restriction to improve the state of the art. Such tweaking can bring surprising results, e.g. the conclusion, strongly supported by the results presented here, that HMM tagging is actually quite competitive with, and orders of magnitude faster than, the current generation of learning algorithms including SVM and MaxEnt. No matter how good TnT was to begin with, the closed source has hindered its progress to the point that inherently clumsier, but better tweakable algorithms could overtake HMMs, a situation that HunPos has now hopefully changed at least for languages with more complex morphologies.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Though there can be little doubt that the ruling system of bakeoffs actively encourages a degree of oneupmanship, our paper and our software are not offered in a competitive spirit. ", "mid_sen": "As we said at the out-set, we don't necessarily believe HunPos to be in any way better than TnT, and certainly the main ideas have been pioneered by DeRose (1988) , Church (1988) , and others long before this generation of HMM work. ", "after_sen": "But to improve the results beyond what a basic HMM can achieve one needs to tune the system, and progress can only be made if the experiments are end to end replicable. "}
{"citeStart": 0, "citeEnd": 13, "citeStartToken": 0, "citeEndToken": 13, "sectionName": "UNKNOWN SECTION NAME", "string": "Among prior authors, Gamon's (2004) research is perhaps closest to the work described here, in that he uses some features based on a sentence's logical form, generated using a proprietary system. However, his features are templatic in nature in that they do not couple specific lexical entries with their logical form. Hearst (1992) and Mulder et al. (2004) describe systems that make use of argument structure features coupled with lexical information, though neither provides implementation details or experimental results.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, his features are templatic in nature in that they do not couple specific lexical entries with their logical form. ", "mid_sen": "Hearst (1992) and Mulder et al. (2004) describe systems that make use of argument structure features coupled with lexical information, though neither provides implementation details or experimental results.", "after_sen": "In terms of computational experimentation, work by Thomas et al. (2006) , predicting yes and no votes in corpus of United States Congressional floor debate speeches, is quite relevant. "}
{"citeStart": 113, "citeEnd": 125, "citeStartToken": 113, "citeEndToken": 125, "sectionName": "UNKNOWN SECTION NAME", "string": "Several types of research have involved document-level subjectivity classification. Some work identifies inflammatory texts (e.g., (Spertus, 1997)) or classifies reviews as positive or negative ( (Turney, 2002; Pang et al., 2002) ). Tong's system (Tong, 2001) generates sentiment timelines, tracking online discussions and creating graphs of positive and negative opinion messages over time. Research in genre classification may include recognition of subjective genres such as editorials (e.g., (Karlgren and Cutting, 1994; Kessler et al., 1997; Wiebe et al., 2001) ). In contrast, our work classifies individual sentences, as does the research in (Wiebe et al., 1999) . Sentence-level subjectivity classification is useful because most documents contain a mix of subjective and objective sentences. For example, newspaper articles are typically thought to be relatively objective, but (Wiebe et al., 2001) reported that, in their corpus, 44% of sentences (in arti-cles that are not editorials or reviews) were subjective.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Several types of research have involved document-level subjectivity classification. ", "mid_sen": "Some work identifies inflammatory texts (e.g., (Spertus, 1997)) or classifies reviews as positive or negative ( (Turney, 2002; Pang et al., 2002) ). ", "after_sen": "Tong's system (Tong, 2001) generates sentiment timelines, tracking online discussions and creating graphs of positive and negative opinion messages over time. "}
{"citeStart": 146, "citeEnd": 175, "citeStartToken": 146, "citeEndToken": 175, "sectionName": "UNKNOWN SECTION NAME", "string": "When considering the prior probability, the more independent of the context it is the better to measure actual associations. A sensible modification of the measure would be to consider p(c) as the prior distribution: (;'(;; s) Using the chain rule on mutual information (Cover and Thomas, 1991, p. 22) we can mathematically relate the different versions of Assoc, mssoc'(v, s, c) ", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "When considering the prior probability, the more independent of the context it is the better to measure actual associations. ", "mid_sen": "A sensible modification of the measure would be to consider p(c) as the prior distribution: (;'(;; s) Using the chain rule on mutual information (Cover and Thomas, 1991, p. 22) we can mathematically relate the different versions of Assoc, mssoc'(v, s, c) ", "after_sen": "Assoc'(v,s,c) = p(c,v,s) logP"}
{"citeStart": 60, "citeEnd": 80, "citeStartToken": 60, "citeEndToken": 80, "sectionName": "UNKNOWN SECTION NAME", "string": "For the gold standard we chose the version of Dep-Bank reannotated by , consisting of 700 sentences from Section 23 of the Penn Treebank. The B&C scheme is similar to the original DepBank scheme (King et al., 2003) , but overall contains less grammatical detail; describes the differences. We chose this resource for the following reasons: it is publicly available, allowing other researchers to compare against our results; the GRs making up the annotation share some similarities with the predicateargument dependencies output by the CCG parser; and we can directly compare our parser against a non-CCG parser, namely the RASP parser. We chose not to use the corpus based on the Susanne corpus (Carroll et al., 1998) because the GRs are less like the CCG dependencies; the corpus is not based on the Penn Treebank, making comparison more difficult because of tokenisation differences, for example; and the latest results for RASP are on DepBank.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We chose this resource for the following reasons: it is publicly available, allowing other researchers to compare against our results; the GRs making up the annotation share some similarities with the predicateargument dependencies output by the CCG parser; and we can directly compare our parser against a non-CCG parser, namely the RASP parser. ", "mid_sen": "We chose not to use the corpus based on the Susanne corpus (Carroll et al., 1998) because the GRs are less like the CCG dependencies; the corpus is not based on the Penn Treebank, making comparison more difficult because of tokenisation differences, for example; and the latest results for RASP are on DepBank.", "after_sen": "The GRs are described in and . "}
{"citeStart": 14, "citeEnd": 37, "citeStartToken": 14, "citeEndToken": 37, "sectionName": "UNKNOWN SECTION NAME", "string": "The input to reference resolution in the theoretical literature is assumed to be fully parsed sentences, often with syntactic attributes such as grammatical functions and thematic roles on the constituents (Webber, 1978; Sidner, 1979; Hobbs, 1978; Grosz, Joshi, and Weinstein, 1995) . In implemented reference resolution systems, for pronoun resolution in particular, there seems to be a trade-off between the completeness of syntactic input and the robustness with real-world sentences. In short, more robust and partial parsing gives us wider coverage, but less syntactic information also leads to less accuyate reference resolution. For instance, Lappin and Leass (1994) report an 86% accuracy for a resolution algorithm for third-person pronouns using fully parsed sentences as input. Kennedy and Boguraev (1996) then report a 75% accuracy for an algorithm that approximates Lappin and Leass's with more robust and coarse-grained syntactic input. After describing the algorithm in the next section, I will briefly compare the present approach with these pronoun resolution approaches.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In short, more robust and partial parsing gives us wider coverage, but less syntactic information also leads to less accuyate reference resolution. ", "mid_sen": "For instance, Lappin and Leass (1994) report an 86% accuracy for a resolution algorithm for third-person pronouns using fully parsed sentences as input. ", "after_sen": "Kennedy and Boguraev (1996) then report a 75% accuracy for an algorithm that approximates Lappin and Leass's with more robust and coarse-grained syntactic input. "}
{"citeStart": 10, "citeEnd": 33, "citeStartToken": 10, "citeEndToken": 33, "sectionName": "UNKNOWN SECTION NAME", "string": "In order to generate English correctly, it is necessary to know whether a given noun phrase is countable or uncountable and, if countable, whether it is singular or plural. Deciding this is a problem even for humans translating from Japanese to English, but they have their own knowledge of both languages t Japanese does not have obligatory plural morphemes. Plurality can be marked but only rarely is, for example by adding a suffix such as tachi \"and others\" (this can normally only be used with people or mfimals). tO draw on. A machine translation system needs to have this knowledge codilied in some way. As generating articles and number is only important when the rest of the sentence has been correctly generated, them has not been a lot of research devoted to it. Recently, Murata and Nagao (1993) have proposed a method of determining the referentiality property and number of nouns in Japanese sentences for machine translation into English, but tim research has not yet been extended to include the actual English generation. This paper describes a method that extracts information relevant to countability and number from the Japanese text and combines it with knowledge about countability and number in English. First countability in English is discussed at the noun phrase and then the noun level. As a noun phrase's countability in English is affected by its referential property (generic, referential or ascriptive) we present a method of determining the referential use of Japanese noun phrases. Next the process of actually determining noun phrase countability and number is described. This is followed by some examples of sentences translated by the proposed method and a discussion of the results.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "As generating articles and number is only important when the rest of the sentence has been correctly generated, them has not been a lot of research devoted to it. ", "mid_sen": "Recently, Murata and Nagao (1993) have proposed a method of determining the referentiality property and number of nouns in Japanese sentences for machine translation into English, but tim research has not yet been extended to include the actual English generation. ", "after_sen": "This paper describes a method that extracts information relevant to countability and number from the Japanese text and combines it with knowledge about countability and number in English. "}
{"citeStart": 208, "citeEnd": 230, "citeStartToken": 208, "citeEndToken": 230, "sectionName": "UNKNOWN SECTION NAME", "string": "R1 When the referential property of a noun phrase (an anaphor) is definite, and the same noun phrase A has already appeared, =¢, { (the noun phrase A, 30)} A referential property is estimated by this method (Murata and Naga~, 1993) . This is a rule for direct anaphora.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Some of the rules are given below:", "mid_sen": "R1 When the referential property of a noun phrase (an anaphor) is definite, and the same noun phrase A has already appeared, =¢, { (the noun phrase A, 30)} A referential property is estimated by this method (Murata and Naga~, 1993) . ", "after_sen": "This is a rule for direct anaphora."}
{"citeStart": 1, "citeEnd": 12, "citeStartToken": 1, "citeEndToken": 12, "sectionName": "UNKNOWN SECTION NAME", "string": "In the first processing stage we have used the five data representations with majority voting. This approach did not work as well for other stages. The O+C representation outperformed the other four representations by a large margin for the validation data 5. This caused the combined output of all five representations being worse than the O+C result. Therefore we have only used the O+C representation for recognizing nombaseNPs. The overall system reached an F~=I score of 83.79 and this is slightly better than the best rate reported at the 5The validation data is the test set we have used for estimating the best parameters for the CoNLL experiment: WSJ section 21. CoNLL-99 workshop (82.98 (CoNLL-99, 1999) , an error reduction of 5%). (Abney, 1991) has proposed to approach parsing by starting with finding correlated chunks of words. The chunks can be combined to trees by a second processing stage, the attacher.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "CoNLL-99 workshop (82.98 (CoNLL-99, 1999) , an error reduction of 5%). ", "mid_sen": "(Abney, 1991) has proposed to approach parsing by starting with finding correlated chunks of words. ", "after_sen": "The chunks can be combined to trees by a second processing stage, the attacher."}
{"citeStart": 54, "citeEnd": 81, "citeStartToken": 54, "citeEndToken": 81, "sectionName": "UNKNOWN SECTION NAME", "string": "Helgadóttir 2004evaluated several data-driven models for Icelandic, including MXPost, a maximum entropy tagger, and TnT, a trigram HMM; both did considerably worse than on English. Icelandic poses significant challenges: data sparseness, nonlocal tag dependencies, and 136,264 observed trigram sequences make discriminative sequence models, such as CRFs, prohibitively expensive. Given these challenges, the most successful tagger is Ic-eTagger (Loftsson, 2007) , a linguistic rule based system with several linguistic resources: a morphological analyzer, a series of local rules and heuristics for handling PPs, verbs, and forcing agreement. Loftsson also improves TnT by integrating a mor-phological analyzer (TnT*).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Icelandic poses significant challenges: data sparseness, nonlocal tag dependencies, and 136,264 observed trigram sequences make discriminative sequence models, such as CRFs, prohibitively expensive. ", "mid_sen": "Given these challenges, the most successful tagger is Ic-eTagger (Loftsson, 2007) , a linguistic rule based system with several linguistic resources: a morphological analyzer, a series of local rules and heuristics for handling PPs, verbs, and forcing agreement. ", "after_sen": "Loftsson also improves TnT by integrating a mor-phological analyzer (TnT*)."}
{"citeStart": 74, "citeEnd": 88, "citeStartToken": 74, "citeEndToken": 88, "sectionName": "UNKNOWN SECTION NAME", "string": "In recent years, the success of statistical parsing techniques can be attributed to several factors, such as the increasing size of computing machinery to accommodate larger models, the availability of resources such as the Penn Treebank (Marcus et al., 1993) and the success of machine learning techniques for lowerlevel NLP problems, such as part-of-speech tagging (Church, 1988; Brill, 1995) , and PPattachment (Brill and Resnik, 1994; Collins and Brooks, 1995) . However, perhaps even more significant has been the lexicalization of the grammar formalisms being probabilistically modeled: crucially, all the recent, successful statistical parsers have in some way made use of bilexical dependencies. This includes both the parsers that attach probabilities to parser moves (Magerman, 1995; Ratnaparkhi, 1997) , but also those of the lexicalized PCFG variety (Collins, 1997; Charniak, 1997) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, perhaps even more significant has been the lexicalization of the grammar formalisms being probabilistically modeled: crucially, all the recent, successful statistical parsers have in some way made use of bilexical dependencies. ", "mid_sen": "This includes both the parsers that attach probabilities to parser moves (Magerman, 1995; Ratnaparkhi, 1997) , but also those of the lexicalized PCFG variety (Collins, 1997; Charniak, 1997) .", "after_sen": "Even more crucially, the bilexical dependencies involve head-modifier relations (hereafter referred to simply as \"head relations\"). "}
{"citeStart": 91, "citeEnd": 115, "citeStartToken": 91, "citeEndToken": 115, "sectionName": "UNKNOWN SECTION NAME", "string": "The grammar employed is a partial characterisation of Chomsky's Government-Binding theory [Chomsky1981, Chomsky1986] and only takes account of very local constralnts (i.e. X-bar, Theta and Case); a way of encoding all constraints in the proper branch formalism (e.g. [Crocker1992] ) will be needed before a grammar of sufficient coverage to be useful in corpora analysis can be formulated. The problem with using results obtained from the implementation given here is that the grammar is sufficiently underspecified and so leaves too great a task for the probabilistic information.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The grammar employed is a partial characterisation of Chomsky's Government-Binding theory [Chomsky1981, Chomsky1986] and only takes account of very local constralnts (i.e. X-bar, Theta and Case); a way of encoding all constraints in the proper branch formalism (e.g. [Crocker1992] ) will be needed before a grammar of sufficient coverage to be useful in corpora analysis can be formulated. ", "after_sen": "The problem with using results obtained from the implementation given here is that the grammar is sufficiently underspecified and so leaves too great a task for the probabilistic information."}
{"citeStart": 111, "citeEnd": 137, "citeStartToken": 111, "citeEndToken": 137, "sectionName": "UNKNOWN SECTION NAME", "string": "In the current experiments we make use of three corpora. The first is the LOB corpus (Johansson 1986 ), which we used in the earlier experiments as well (van Halteren, Zavrel, and Daelemans 1998) and which has proved to be a good testing ground. We then switch to Wall Street Journal material (WSJ), tagged with the Penn Treebank II tagset (Marcus, Santorini, and Marcinkiewicz 1993) . Like LOB, it consists of approximately 1M words, but unlike LOB, it is American English. Furthermore, it is of a different structure (only newspaper text) and tagged with a rather different tagset. The experiments with WSJ will also let us compare our results with those reported by Brill and Wu (1998) , which show a much less pronounced accuracy increase than ours with LOB. The final corpus is the slightly smaller (750K words) Eindhoven corpus (Uit den Boogaart 1975) tagged with the Wotan tagset (Berghmans 1994 ). This will let us examine the tagging of a language other than English (namely, Dutch). Furthermore, the Wotan tagset is a very detailed one, so that the error rate of the individual taggers 9 Compare this to the \"tune\" set in van Halteren, Zavrel, and Daelemans (1998) . This consisted of 114K tokens, but, because of a 92.5% agreement over all four taggers, it yielded less than 9K tokens of useful training material to resolve disagreements. This was suspected to be the main reason for the relative lack of performance by the more sophisticated combiners.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In the current experiments we make use of three corpora. ", "mid_sen": "The first is the LOB corpus (Johansson 1986 ), which we used in the earlier experiments as well (van Halteren, Zavrel, and Daelemans 1998) and which has proved to be a good testing ground. ", "after_sen": "We then switch to Wall Street Journal material (WSJ), tagged with the Penn Treebank II tagset (Marcus, Santorini, and Marcinkiewicz 1993) . "}
{"citeStart": 150, "citeEnd": 168, "citeStartToken": 150, "citeEndToken": 168, "sectionName": "UNKNOWN SECTION NAME", "string": "Rec (1) Bag-Of-Words 73.3 81.7 70.9 (2) WBO 72.1 76.0 77.4 (3) Most-Frequent 59.0 59.0 100.0 Table 7: Baselines for Comparison   Table 7 shows three baseline experiments. Row (3) represents the common baseline of assigning every sentence to the most frequent class. The Most-Frequent baseline achieves 59% accuracy because 59% of the sentences in the gold-standard are subjective. Row (2) is a Naive Bayes classifier that uses the WBO features, which performed well in prior research on sentence-level subjectivity classification (Wiebe et al., 1999) . Row (1) shows a Naive Bayes classifier that uses unigram bag-ofwords features, with one binary feature for the absence or presence in the sentence of each word that appeared during training. Pang et al. (2002) reported that a similar experiment produced their best results on a related classification task. The difference in accuracy between Rows (1) and (2) is not statistically significant (Bag-of-Word's higher precision is balanced by WBO's higher recall).", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The Most-Frequent baseline achieves 59% accuracy because 59% of the sentences in the gold-standard are subjective. ", "mid_sen": "Row (2) is a Naive Bayes classifier that uses the WBO features, which performed well in prior research on sentence-level subjectivity classification (Wiebe et al., 1999) . Row (1) shows a Naive Bayes classifier that uses unigram bag-ofwords features, with one binary feature for the absence or presence in the sentence of each word that appeared during training. ", "after_sen": "Pang et al. (2002) reported that a similar experiment produced their best results on a related classification task. "}
{"citeStart": 75, "citeEnd": 96, "citeStartToken": 75, "citeEndToken": 96, "sectionName": "UNKNOWN SECTION NAME", "string": "The basic task we consider in this paper is that of using spoken language to give commands to a semiautonomous robot or other similar system. As evidence of the importance of this task in the NLP community note that the early, influential system SHRDLU (Winograd, 1973) was intended to address just this type of problem. More recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot (Konolige et al., 1993) and NCARArs InterBOT project (Perzanowski et al., 1998; Perzanowski et al., 1999) . A number of other systems have addressed part of the task. Com-mandTalk (Moore et al., 1997) , Circuit Fix-It Shop (Smith, 1997) and (Traum and Allen, 1994; Tranm and Andersen, 1999) are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents. Jack's MOOse Lodge (Badler et al., 1999 ) takes text rather than speech as natural language input and the avatars being controlled are not semi-autonomous. Other researchers have considered particular aspects of the problem such as accounting for various aspects of actions (Webber, 1995; Pyre et al., 1995) . In most of this and other related work the treatment is some variant of the following. If there is a speech interface, the input speech signal is converted into text. Text either from the recognizer or directly input by the user is then converted into some kind of logical formula, which abstractly represents the user's intended command; this formula is then fed into a command interpreter, which executes the command.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A number of other systems have addressed part of the task. ", "mid_sen": "Com-mandTalk (Moore et al., 1997) , Circuit Fix-It Shop (Smith, 1997) and (Traum and Allen, 1994; Tranm and Andersen, 1999) are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents. ", "after_sen": "Jack's MOOse Lodge (Badler et al., 1999 ) takes text rather than speech as natural language input and the avatars being controlled are not semi-autonomous. "}
{"citeStart": 25, "citeEnd": 35, "citeStartToken": 25, "citeEndToken": 35, "sectionName": "UNKNOWN SECTION NAME", "string": "Some researchers, e.g., [Mann, 1988; KowtkoetaL, 1991] , assume a library of discourse level actions, sometimes called dialogue games, which encode common communicative interactions. To be co-operative, an agent must always be participating in one of these games. So if a question is asked, only a fixed number of activities, namely those introduced by a question, are cooperative responses. Games provide a better explanation of coherence, but still require the agent's to recognize each other's intentions to perform the dialogue game. As a result, this work can be viewed as a special case of the intentional view. An interesting model is described by [Airenti et al., 1993] , which separates out the conversational games from the task-related games in a way similar way to [Litman and Allen, 1987] . Because of this separation, they do not have to assume co-operation on the tasks each agent is performing, but still require recognition of intention and cooperation at the conversational level. It is left unexplained what goals motivate conversational co-operation.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Questions do more than just provide evidence of a speaker's goals, and something more than adoption of the goals of an interlocutor is involved in the formulating a response to a question.", "mid_sen": "Some researchers, e.g., [Mann, 1988; KowtkoetaL, 1991] , assume a library of discourse level actions, sometimes called dialogue games, which encode common communicative interactions. ", "after_sen": "To be co-operative, an agent must always be participating in one of these games. "}
{"citeStart": 78, "citeEnd": 91, "citeStartToken": 78, "citeEndToken": 91, "sectionName": "UNKNOWN SECTION NAME", "string": "Similarly, we call the reordering model, a 'context dependent block distortion model'. For training, we use the maximum entropy software library Llama presented in (Haffner, 2006) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Similarly, we call the reordering model, a 'context dependent block distortion model'. ", "mid_sen": "For training, we use the maximum entropy software library Llama presented in (Haffner, 2006) .", "after_sen": ""}
{"citeStart": 105, "citeEnd": 120, "citeStartToken": 105, "citeEndToken": 120, "sectionName": "UNKNOWN SECTION NAME", "string": "In computational linguistic literature, much effort has been devoted to phonetic transliteration, such as English-Arabic, English-Chinese (Li et al., 2004) , English-Japanese (Knight and Graehl, 1998) and English-Korean. In G2P studies, Font Llitjos and Black 2001showed how knowledge of language of origin may improve conversion accuracy. Unfortunately semantic transliteration, which is considered as a good tradition in translation practice (Hu and Xu, 2003; Hu, 2004) , has not been adequately addressed computationally in the literature. Some recent work Xu et al., 2006) has attempted to introduce preference into a probabilistic framework for selection of Chinese characters in phonetic transliteration. However, there is neither analytical result nor semantic-motivated transliteration solution being reported.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In G2P studies, Font Llitjos and Black 2001showed how knowledge of language of origin may improve conversion accuracy. ", "mid_sen": "Unfortunately semantic transliteration, which is considered as a good tradition in translation practice (Hu and Xu, 2003; Hu, 2004) , has not been adequately addressed computationally in the literature. ", "after_sen": "Some recent work Xu et al., 2006) has attempted to introduce preference into a probabilistic framework for selection of Chinese characters in phonetic transliteration. "}
{"citeStart": 251, "citeEnd": 267, "citeStartToken": 251, "citeEndToken": 267, "sectionName": "UNKNOWN SECTION NAME", "string": "We developed a compiler for off-line optimization of phrase structure rule-based typed feature structure grammars which generalizes the techniques developed in the context of the DIA, and we advanced a typed extension of the Earley-style generator of Gerdemann (1991) . Off-line compilation (section 3) is used to produce grammars for the Earley-style generator (section 2). We show that our use of offline grammar optimization overcomes problems with empty or displaced heads. The developed techniques are extensively tested with a large HPSG grammar for partial vP topicallzation in German (iiinrichs et al., 1994) . This uncovered some important constraints on the form of the phrase structure rules (phrase structure rules) in a grammar imposed by the compiler (section 4).", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In this paper we adopt the latter theoretically more interesting perspective.", "mid_sen": "We developed a compiler for off-line optimization of phrase structure rule-based typed feature structure grammars which generalizes the techniques developed in the context of the DIA, and we advanced a typed extension of the Earley-style generator of Gerdemann (1991) . ", "after_sen": "Off-line compilation (section 3) is used to produce grammars for the Earley-style generator (section 2). "}
{"citeStart": 89, "citeEnd": 117, "citeStartToken": 89, "citeEndToken": 117, "sectionName": "UNKNOWN SECTION NAME", "string": "Our approach is based on the assumption that each collocation is unambiguous in the source language and has a unique translation in the target language (at least in a clear majority of the cases). In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus. This approach is quite different from those adopted for the translation of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996) , since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994) . The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993) , and was verified during our evaluation of Champollion (Section 7).", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus. ", "mid_sen": "This approach is quite different from those adopted for the translation of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996) , since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994) . ", "after_sen": "The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993) , and was verified during our evaluation of Champollion (Section 7)."}
{"citeStart": 0, "citeEnd": 26, "citeStartToken": 0, "citeEndToken": 26, "sectionName": "UNKNOWN SECTION NAME", "string": "The work presented in this section highlights a number of issues associated with the evaluation of automatically induced subcategorization frames against an existing external gold standard, in this case COMLEX. While this evaluation approach is arguably less labor-intensive than the manual construction of a custom-made gold standard, it does introduce a number of difficulties into the evaluation procedure. It is a nontrivial task to convert both the gold standard and the induced resource to a common format in order to facilitate evaluation. In addition, as our results show, the choice of common format and mapping to it can affect the results. In COMLEX-LFG Mapping I (Section 6.2), we found that mapping from the induced lexicon to COMLEX resulted in higher recall scores than those achieved when we (effectively) reversed the mapping ). The first mapping is essentially a conflation of our more fine-grained LFG grammatical functions with the more generic COMLEX functions, while the second mapping tries to maintain as many distinctions as possible. Another drawback to using an existing external gold standard such as COMLEX to evaluate an automatically induced subcategorization lexicon is that the resources are not necessarily constructed from the same source data. As noted above, it is well documented (Roland and Jurafsky 1998 ) that subcategorization frames (and their frequencies) vary across domains. We have extracted frames from two sources (the WSJ and the Brown corpus), whereas COMLEX was built using examples from the San Jose Mercury News, the Brown corpus, several literary works from the Library of America, scientific abstracts from the U.S. Department of Energy, and the WSJ. For this reason, it is likely to contain a greater variety of subcategorization frames than our induced lexicon. It is also possible that because of human error, COMLEX contains subcategorization frames the validity of which are in doubt, for example, the overgeneration of subcategorized-for directional prepositional phrases. This is because the aim of the COMLEX project was to construct as complete a set of subcategorization frames as possible, even for infrequent verbs. Lexicographers were allowed to extrapolate from the citations found, a procedure which is bound to be less certain than the assignment of frames based entirely on existing examples. As a generalization, Briscoe (2001) notes that lexicons such as COMLEX tend to demonstrate high precision but low recall. Briscoe and Carroll (1997) report on manually analyzing an open-class vocabulary of 35,000 head words for predicate subcategorization information and comparing the results against the subcategorization details in COMLEX. Precision was quite high (95%), but recall was low (84%). This has an effect on both the precision and recall scores of our system against COMLEX. In order to ascertain the effect of using COMLEX as a gold standard for our induced lexicon, we carried out some more-detailed error analysis, the results of which are summarized in Table 26 . We randomly selected 80 false negatives (fn) and 80 false positives (fp) across a range of active frame types containing prepositional and particle detail taken from Penn-III and manually examined them in order to classify them as \"correct\" or \"incorrect.\" Of the 80 fps, 33 were manually judged to be legitimate subcategorization frames. For example, as Table 26 shows, there are a number of correct transitive verbs ([subj,obj] ) in our automatically induced lexicon which are not included in COMLEX. This examination was also useful in highlighting to us the frame types on which the lexical extraction procedure was performing poorly, in our case, those containing XCOMPs and those containing OBJ2S. Out of 80 fns, 14 were judged to be incorrect when manually examined. These can be broken down as follows: one intransitive frame, three ditransitive frames, three frames containing a COMP, and seven frames containing an oblique were found to be invalid.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "As a generalization, Briscoe (2001) notes that lexicons such as COMLEX tend to demonstrate high precision but low recall. ", "mid_sen": "Briscoe and Carroll (1997) report on manually analyzing an open-class vocabulary of 35,000 head words for predicate subcategorization information and comparing the results against the subcategorization details in COMLEX. ", "after_sen": "Precision was quite high (95%), but recall was low (84%). "}
{"citeStart": 265, "citeEnd": 292, "citeStartToken": 265, "citeEndToken": 292, "sectionName": "UNKNOWN SECTION NAME", "string": "Once we know more about the effects of the textual variations, Genpex can be of great value to test developers, given that there exists a great need for large amounts of learning and assessment materials with a controlled level of difficulty (Enright et al., 2002; Fairon and Williamson, 2002; Deane and Sheehan, 2003; Arendasy et al., 2006; Holling et al., 2008; Holling et al., 2009) . The initial development and testing of the system is a one-time investment, which we expect will pay off afterward when large amounts of test items can be created with little effort. In particular, we think Genpex can be very useful in combination with Computerized Adaptive Testing (CAT). The system could be used for on-the-fly generation of new items for each individual student, adapted to that student's skill level estimated from his or her previous answers. Because every student gets custom exercises, the risk of frequently used items becoming known among students is reduced, thus increasing test security.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Also, the exercises used by Holling et al. (2009) mentioned probabilities instead of counts in the statements.", "mid_sen": "Once we know more about the effects of the textual variations, Genpex can be of great value to test developers, given that there exists a great need for large amounts of learning and assessment materials with a controlled level of difficulty (Enright et al., 2002; Fairon and Williamson, 2002; Deane and Sheehan, 2003; Arendasy et al., 2006; Holling et al., 2008; Holling et al., 2009) . ", "after_sen": "The initial development and testing of the system is a one-time investment, which we expect will pay off afterward when large amounts of test items can be created with little effort. "}
{"citeStart": 195, "citeEnd": 219, "citeStartToken": 195, "citeEndToken": 219, "sectionName": "UNKNOWN SECTION NAME", "string": "Strong empirical evidence has been presented over the past 15 years indicating that the human sentence processing mechanism makes online use of contextual information in the preceding discourse (Crain and Steedman, 1985; Altmann and Steedman, 1988; Britt, 1994) and in the visual environment (Tanenhaus et al., 1995) . These results lend support to Mark Steedman's (1989) \"intuition\" that sentence interpretation takes place incrementally, and that partial interpretations are being built while the sentence is being perceived. This is a very commonly held view among psycholinguists today.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Strong empirical evidence has been presented over the past 15 years indicating that the human sentence processing mechanism makes online use of contextual information in the preceding discourse (Crain and Steedman, 1985; Altmann and Steedman, 1988; Britt, 1994) and in the visual environment (Tanenhaus et al., 1995) . ", "after_sen": "These results lend support to Mark Steedman's (1989) \"intuition\" that sentence interpretation takes place incrementally, and that partial interpretations are being built while the sentence is being perceived. "}
{"citeStart": 117, "citeEnd": 137, "citeStartToken": 117, "citeEndToken": 137, "sectionName": "UNKNOWN SECTION NAME", "string": "To find a smaller set of effective features, we start with all the features considered in (Jiang and Ng, 2006) , in (Xue and Palmer, 2004) , and various combinations of them, for a total of 52 features. These features are then pruned by the following algorithm:", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In this work, the number of features is pruned to 11, so that we can work with reasonably many auxiliary problems in later experiments with ASO.", "mid_sen": "To find a smaller set of effective features, we start with all the features considered in (Jiang and Ng, 2006) , in (Xue and Palmer, 2004) , and various combinations of them, for a total of 52 features. ", "after_sen": "These features are then pruned by the following algorithm:"}
{"citeStart": 74, "citeEnd": 92, "citeStartToken": 74, "citeEndToken": 92, "sectionName": "UNKNOWN SECTION NAME", "string": "Our baseline word alignment model is the word-toword Hidden Markov Model (Vogel et al., 1996) . Basic models in two translation directions are trained simultaneously where statistics of two directions are shared to learn symmetric translation lexicon and word alignments with high precision motivated by (Zens et al., 2004) and (Liang et al., 2006) . The baseline translation results (BLEU and TER) on the dev and test set are presented in the line \"HMM\" of Table 1 . We also compare with results of IBM Model-4 word alignments implemented in GIZA++ toolkit (Och and Ney, 2003) .", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Our baseline word alignment model is the word-toword Hidden Markov Model (Vogel et al., 1996) . ", "after_sen": "Basic models in two translation directions are trained simultaneously where statistics of two directions are shared to learn symmetric translation lexicon and word alignments with high precision motivated by (Zens et al., 2004) and (Liang et al., 2006) . "}
{"citeStart": 161, "citeEnd": 182, "citeStartToken": 161, "citeEndToken": 182, "sectionName": "UNKNOWN SECTION NAME", "string": "However, such methods so far are usually designed for generic summarization and do not take into account the impact of users' interests on summary generation. Besides, in the existing studies, personalized summarization is often conducted with the help of a query (Sun, 2008; You et al., 2011) or a static user profile (Díaz and Gervás, 2007) , and most studies only use the local content from target document(s) or the user profile, with little attention paid to the rich social contextual information affiliated with them.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, such methods so far are usually designed for generic summarization and do not take into account the impact of users' interests on summary generation. ", "mid_sen": "Besides, in the existing studies, personalized summarization is often conducted with the help of a query (Sun, 2008; You et al., 2011) or a static user profile (Díaz and Gervás, 2007) , and most studies only use the local content from target document(s) or the user profile, with little attention paid to the rich social contextual information affiliated with them.", "after_sen": "Currently, an increasing number of social websites allow users to enrich the source content. "}
{"citeStart": 17, "citeEnd": 40, "citeStartToken": 17, "citeEndToken": 40, "sectionName": "UNKNOWN SECTION NAME", "string": "Stanford parser (Klein and Manning, 2003) is used for extracting features from dependency parse trees. For resolving Markov logic network, we use the toolkit thebeast 7 . The detailed setting of thebeast engine is as follows: The inference algorithm is the MAP inference with a cutting plane approach. For parameter learning, the weights for formulas are updated by an online learning algorithm with MIRA update rule. All the initial weights are set to zeros. The number of iterations is set to 10 epochs. Evaluation metrics used for subjectivity classification and relation extraction throughout the experiments include: Precision, Recall, and F1-score. We randomly select 80% reviews as training set and the others as testing set.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Stanford parser (Klein and Manning, 2003) is used for extracting features from dependency parse trees. ", "after_sen": "For resolving Markov logic network, we use the toolkit thebeast 7 . "}
{"citeStart": 73, "citeEnd": 94, "citeStartToken": 73, "citeEndToken": 94, "sectionName": "UNKNOWN SECTION NAME", "string": "This article will exploit one of these theories, The Generative Lezicon (GL: Pustejovsky, 1995) , and extend it for the treatment of French mental adjectives. The following section summarizes the problematic behaviour of these adjectives. The GL approach is then described, and a GL analysis of the data.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Motivated by a concern for lexical organization and global coherence in the structure of lexicon, some researchers have moved towards nlore expressive semantic descriptions, as well as more powerful methods of combining them (see for example Pustejovsky, 1991 Pustejovsky, , 1995 Briscoe, 1993) .", "mid_sen": "This article will exploit one of these theories, The Generative Lezicon (GL: Pustejovsky, 1995) , and extend it for the treatment of French mental adjectives. ", "after_sen": "The following section summarizes the problematic behaviour of these adjectives. "}
{"citeStart": 92, "citeEnd": 111, "citeStartToken": 92, "citeEndToken": 111, "sectionName": "UNKNOWN SECTION NAME", "string": "We made heuristic rules for demonstratives by consulting the papers (NLRI 81) (Hayashi 83) (Takahashi et al. 90 ) (Kinsui & Takubo 92) and by examining Japanese sentences by hand. Demonstratives have three categories: demonstrative pronouns, demonstrative adjectives, and demonstrative adverbs. In the following sections, we explain the rules for analyzing demonstratives. Rule in the case when the referent is a noun  phrase   Candidate enumerating rule 1 When a pronoun is a demonstrative pronoun or \"8ono (of it) / k0no (of this) ] an0 (of that)\", {(A topic which has weight W and distance D, W-D-2) (A focus which has weight W and distance D, W -D + 4)} This bracketed expression represents the lists of proposals in Figure 1 . The definition and weight W of the topic and focus are shown in Tables 1 and 2. The distance (D) is the number of topics and loci between the demonstrative and the possible referent. Since a demonstrative more often refers to loci than a zero pronoun does, we add the coefficient -2 or +4 as compared with the heuristic rules in zero pronoun resolution.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Heuristic Rules for Demonstratives", "mid_sen": "We made heuristic rules for demonstratives by consulting the papers (NLRI 81) (Hayashi 83) (Takahashi et al. 90 ) (Kinsui & Takubo 92) and by examining Japanese sentences by hand. ", "after_sen": "Demonstratives have three categories: demonstrative pronouns, demonstrative adjectives, and demonstrative adverbs. "}
{"citeStart": 64, "citeEnd": 89, "citeStartToken": 64, "citeEndToken": 89, "sectionName": "UNKNOWN SECTION NAME", "string": "Much work has been done on both detecting boundary tones (e.g. (Wang and Hirschberg, 1992; Wightman and Ostendorf, 1994; Stolcke and Shriberg, 1996a; Kompe et al., 1994; Mast et al., 1996) ) and on speech repair detection and correction (e.g. (Hindle, 1983; Bear, Dowding, and Shriberg, 1992; Nakatani and Hirschberg, 1994; Heeman and Allen, 1994; Stolcke and Shriberg, 1996b) ). This work has focused on one of the issues in isolation of the other. However, these two issues are intertwined. Cues such as the presence of silence, final syllable lengthening, and presence of filled pauses tend to mark both events. Even the presence of word correspondences, a tradition cue for detecting and correcting speech repairs, sometimes marks boundary tones as well, as illustrated by the following example where the intonational phrase boundary is marked with the ToBI symbol %.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Much work has been done on both detecting boundary tones (e.g. (Wang and Hirschberg, 1992; Wightman and Ostendorf, 1994; Stolcke and Shriberg, 1996a; Kompe et al., 1994; Mast et al., 1996) ) and on speech repair detection and correction (e.g. (Hindle, 1983; Bear, Dowding, and Shriberg, 1992; Nakatani and Hirschberg, 1994; Heeman and Allen, 1994; Stolcke and Shriberg, 1996b) ). ", "after_sen": "This work has focused on one of the issues in isolation of the other. "}
{"citeStart": 64, "citeEnd": 76, "citeStartToken": 64, "citeEndToken": 76, "sectionName": "UNKNOWN SECTION NAME", "string": "Design-World is an experimentld enviro|unent for testiug the relationship hetween discourse strategies, task p~u'ameters ,and agents' cognitive capabilities, similar to the single ,agent TileWorld simnlalion environment [Pollack and Ringuette, 1990; Hanks et al., 199311. Design-World agents can be parametrized as to discourse strategy, and tilt elfecls of this strategy can he me~Lsured against a |'imge of cognitive and task p~u'ameters. This paper compares [l~e Explicit-Winrant strategy to the All-lmplicil strategy as strategies lot supporting deliberation. Other strategies tested in Design-World me presented elsewhere [W~dker, 1993; Walker, 1994a; Riunbow ~md Walker, 19941. 3.1 Design World l)omain and task Both agents know whal tile I)ESI(;N-IIOUSE pl~ requires and stm'l out with a set of fnmiture pieces that can he used to design each room.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This paper compares [l~e Explicit-Winrant strategy to the All-lmplicil strategy as strategies lot supporting deliberation. ", "mid_sen": "Other strategies tested in Design-World me presented elsewhere [W~dker, 1993; Walker, 1994a; Riunbow ~md Walker, 19941. ", "after_sen": "3.1 Design World l)omain and task Both agents know whal tile I)ESI(;N-IIOUSE pl~ requires and stm'l out with a set of fnmiture pieces that can he used to design each room."}
{"citeStart": 145, "citeEnd": 164, "citeStartToken": 145, "citeEndToken": 164, "sectionName": "UNKNOWN SECTION NAME", "string": "• even a highest ranked pattern for i is only a probabilistic cue for membership of i, so membership should only be inferred if there are enough occurrences of patterns for i in the data to outweigh the error probability for i. This simple automated, hybrid linguistic/statistical approach contrasts with the manual linguistic analysis of the COMLEX Syntax lexicographers (Meyers et al., 1994) , who propose five criteria and five heuristics for argument-hood and six criteria and two heuristics for adjunct-hood, culled mostly from the linguistics literature. Many of these are not exploitable automatically because they rest on semantic judgements which cannot (yet) be made automatically: for example, optional arguments are often 'understood' or implied if missing. Others are syntactic tests involving diathesis alternation possibilities (e.g. passive, dative movement, Levin (1993) ) which require recognition that the 'same' argument, defined usually by semantic class / thematic role, is occurring across argument positions. We hope to exploit this information where possible at a later stage in the development of our approach. However, recognizing same/similar arguments requires considerable quantities of lexical data or the ability to back-off to lexical semantic classes. At the moment, we exploit linguistic information about the syntactic type, obligatoriness and position of arguments, as well as the set of possible subcategorization classes, and combine this with statistical inference based on the probability of class membership and the frequency and reliability of patterns for classes.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "• even a highest ranked pattern for i is only a probabilistic cue for membership of i, so membership should only be inferred if there are enough occurrences of patterns for i in the data to outweigh the error probability for i. ", "mid_sen": "This simple automated, hybrid linguistic/statistical approach contrasts with the manual linguistic analysis of the COMLEX Syntax lexicographers (Meyers et al., 1994) , who propose five criteria and five heuristics for argument-hood and six criteria and two heuristics for adjunct-hood, culled mostly from the linguistics literature. ", "after_sen": "Many of these are not exploitable automatically because they rest on semantic judgements which cannot (yet) be made automatically: for example, optional arguments are often 'understood' or implied if missing. "}
{"citeStart": 85, "citeEnd": 97, "citeStartToken": 85, "citeEndToken": 97, "sectionName": "UNKNOWN SECTION NAME", "string": "Selecting ellipsis antecedents and parallel elements within them is an open problem (Priist, 1992; Prfist et al., 1994; Kehler, 1993b; Grover et al., 1994) . Our approach to parallelism is perhaps heavy-handed, but in the absence of a clear solutions, possibly more flexible. The QLFs shown above omitted category information present in terms and ~orms. s Categories are sets of feature value equations containing syntactic information relevant to determining how uninstantiated meta-variables can be resolved.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Selecting ellipsis antecedents and parallel elements within them is an open problem (Priist, 1992; Prfist et al., 1994; Kehler, 1993b; Grover et al., 1994) . ", "after_sen": "Our approach to parallelism is perhaps heavy-handed, but in the absence of a clear solutions, possibly more flexible. "}
{"citeStart": 99, "citeEnd": 110, "citeStartToken": 99, "citeEndToken": 110, "sectionName": "UNKNOWN SECTION NAME", "string": "Reversible realisers. The realiser presented here differs in mainly two ways from existing reversible realisers such as (White, 2004 )'s CCG system or the HPSG ERG based realiser (Carroll and Oepen, 2005) .", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Reversible realisers. ", "mid_sen": "The realiser presented here differs in mainly two ways from existing reversible realisers such as (White, 2004 )'s CCG system or the HPSG ERG based realiser (Carroll and Oepen, 2005) .", "after_sen": "First, it permits a symbolic selection of the output paraphrase. "}
{"citeStart": 287, "citeEnd": 311, "citeStartToken": 287, "citeEndToken": 311, "sectionName": "UNKNOWN SECTION NAME", "string": "1. the set of closed class words, ex: of, to, in, and; 2. relations extracted via defining formulas ex: partof, made-of, instrument; defining formulas correspond to phrasal patterns that occur often through the dictionary suggesting particular semantic relations (ix. A is a part of B) (Ahlswede and Evens, 1988; Dolan et al., 1993) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Table 1 shows some examples for each type.", "mid_sen": "1. the set of closed class words, ex: of, to, in, and; 2. relations extracted via defining formulas ex: partof, made-of, instrument; defining formulas correspond to phrasal patterns that occur often through the dictionary suggesting particular semantic relations (ix. A is a part of B) (Ahlswede and Evens, 1988; Dolan et al., 1993) .", "after_sen": "3. the relations that are extracted from the syntactic structure of a sentence, ex: subject, object, goal, attribute, modifier."}
{"citeStart": 116, "citeEnd": 137, "citeStartToken": 116, "citeEndToken": 137, "sectionName": "UNKNOWN SECTION NAME", "string": "We use the following baselines: SVMTool (Giménez and Màrquez, 2004) , an SVM-based discriminative tagger; RFTagger (Schmid and Laws, 2008) , an n-gram Hidden Markov Model (HMM) tagger developed for POS+MORPH tagging; Morfette (Chrupała et al., 2008) , an averaged perceptron with beam search decoder; CRFSuite (Okazaki, 2007) , a fast CRF implementation; and the Stanford Tagger (Toutanova et al., 2003) , a bidirectional Maximum Entropy Markov Model. For POS+MORPH tagging, all baselines are trained on the concatenation of POS tag and MORPH tag. We run SVM-Tool with the standard feature set and the optimal c-values ∈ {0.1, 1, 10}. Morfette is run with the default options. For CRFSuite we use l 2 -regularized SGD training. We use the optimal regularization parameter ∈ {0.01, 0.1, 1.0} and stop after iterations where we reach a relative improvement in regularized likelihood of at most 0.01 for all languages. The feature set is identical to our model except for some restrictions: we only use concatenations with the full tag and we do not use the binary feature that indicates whether a word-tag combination has been observed. We also had to restrict the combinations of tag and features to those observed in the training set 5 . Otherwise the memory requirements would exceed the memory of our test machine (144 GB) for Czech and Hungarian. The Stanford Tagger is used 5 We set the CRFSuite option possible states = 0 as a bidirectional 2 nd -order model and trained using OWL-BFGS. For Arabic, German and English we use the language specific feature sets and for the other languages the English feature set.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We use the following baselines: SVMTool (Giménez and Màrquez, 2004) , an SVM-based discriminative tagger; RFTagger (Schmid and Laws, 2008) , an n-gram Hidden Markov Model (HMM) tagger developed for POS+MORPH tagging; Morfette (Chrupała et al., 2008) , an averaged perceptron with beam search decoder; CRFSuite (Okazaki, 2007) , a fast CRF implementation; and the Stanford Tagger (Toutanova et al., 2003) , a bidirectional Maximum Entropy Markov Model. ", "after_sen": "For POS+MORPH tagging, all baselines are trained on the concatenation of POS tag and MORPH tag. "}
{"citeStart": 415, "citeEnd": 433, "citeStartToken": 415, "citeEndToken": 433, "sectionName": "UNKNOWN SECTION NAME", "string": "In addition, a χ 2 dependency analysis showed that the NM presence interacts significantly with both AsrMis (p<0.02) and SemMis (p<0.001), with fewer than expected AsrMis and SemMis in the 3 Due to random assignment to conditions, before the first problem the F and S populations are similar (e.g. no difference in pretest); thus any differences in metrics can be attributed to the NM presence/absence. However, in the second problem, the two populations are not similar anymore as they have received different forms of instruction; thus any difference has to be attributed to the NM presence/absence in this problem as well as to the NM absence/presence in the previous problem. 4 Due to logging issues, 2 S users are excluded from this analysis (13 F and 13 S users remaining). We run the subjective metric analysis from Section 5.1 on this subset and the results are similar. NM condition. The fact that in the second problem the differences are much smaller (e.g. 2% for AsrMis) and that the NM-AsrMis and NM-SemMis interactions are not significant anymore, suggests that our observations can not be attributed to a difference in population with respect to system's ability to recognize their speech. We hypothesize that these differences are due to the NM text influencing users' lexical choice. Discourse structure has been successfully used in non-interactive settings (e.g. understanding specific lexical and prosodic phenomena (Hirschberg and Nakatani, 1996) , natural language generation (Hovy, 1993) , essay scoring (Higgins et al., 2004) as well as in interactive settings (e.g. predictive/generative models of postural shifts (Cassell et al., 2001) , generation/interpretation of anaphoric expressions (Allen et al., 2001) , performance modeling (Rotaru and Litman, 2006) ).", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We hypothesize that these differences are due to the NM text influencing users' lexical choice. ", "mid_sen": "Discourse structure has been successfully used in non-interactive settings (e.g. understanding specific lexical and prosodic phenomena (Hirschberg and Nakatani, 1996) , natural language generation (Hovy, 1993) , essay scoring (Higgins et al., 2004) as well as in interactive settings (e.g. predictive/generative models of postural shifts (Cassell et al., 2001) , generation/interpretation of anaphoric expressions (Allen et al., 2001) , performance modeling (Rotaru and Litman, 2006) ).", "after_sen": "In this paper, we study the utility of the discourse structure on the user side of a dialogue system. "}
{"citeStart": 200, "citeEnd": 211, "citeStartToken": 200, "citeEndToken": 211, "sectionName": "UNKNOWN SECTION NAME", "string": "Besides, an increasing concern in current projects is that of linguistic relevance of the analysis t)erformed by the grammar correction system. In this sense, the adequate integration of error detection and correction techniques within mainstream grammm\" formalisms has l)een addressed by a nunl|)er of these projects ([Iolioli eta/., 1992) , (Vosse, 1992) , ((]enthia.l ctal., t992), (O(~uthial et al., 1994) . l~bllowing this concern, this paper presents resuits fl'om the project GramCheck (A Grammar and Style Checker, MLAP93-11), flmded by the CEC. GramCheck has developed a grammar checker demonstrator for Spanish and Greek native writers using ALEP (ET6/1, 1991), (Simpkins, 1994) as the NLP development platform, a client-server architeeUlre as implenmnted in the X Windows system, Motif as the 'look ~md fe, el' interface and Xminfo as the kllowh!dge t)ase, storage format. Generalized use of extensions to the highly typed and unifi(:ation based formalism imi)Iemented in ALEP has been 1)erformed. These extensions (called Constraint Solvers, CSs) are nothing but pieces of PR()I,OG code l)erforlning different l)oolean and relational operations over feature wdues. Besides, GramCheck has used ongoing results Dora LS-GRAM (LRE61029), a project alining at the implementation of middle coverage ALEP grammars for a number of European languages.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Besides, an increasing concern in current projects is that of linguistic relevance of the analysis t)erformed by the grammar correction system. ", "mid_sen": "In this sense, the adequate integration of error detection and correction techniques within mainstream grammm\" formalisms has l)een addressed by a nunl|)er of these projects ([Iolioli eta/., 1992) , (Vosse, 1992) , ((]enthia.l ctal., t992), (O(~uthial et al., 1994) . l~bllowing this concern, this paper presents resuits fl'om the project GramCheck (A Grammar and Style Checker, MLAP93-11), flmded by the CEC. ", "after_sen": "GramCheck has developed a grammar checker demonstrator for Spanish and Greek native writers using ALEP (ET6/1, 1991), (Simpkins, 1994) as the NLP development platform, a client-server architeeUlre as implenmnted in the X Windows system, Motif as the 'look ~md fe, el' interface and Xminfo as the kllowh!"}
{"citeStart": 158, "citeEnd": 183, "citeStartToken": 158, "citeEndToken": 183, "sectionName": "UNKNOWN SECTION NAME", "string": "Experiment and Discussion Before the antecedents in indirect anaphora were determined, sentences were transformed into a case structure by the case analyzer (Kurohashi and Nagao, 1994) . The errors made by the analyzer were corrected by hand. We used the IPAL dictionary (IPAL, 1987) as a verb case frame dictionary. We used the Japanese Co-occurrence Dictionary (EDR, 1995) as a source of examples for \"X no Y.\"", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Experiment and Discussion Before the antecedents in indirect anaphora were determined, sentences were transformed into a case structure by the case analyzer (Kurohashi and Nagao, 1994) . ", "after_sen": "The errors made by the analyzer were corrected by hand. "}
{"citeStart": 154, "citeEnd": 176, "citeStartToken": 154, "citeEndToken": 176, "sectionName": "UNKNOWN SECTION NAME", "string": "Recently, combination techniques have been investigated for part of speech tagging with positive results (van Halteren et al., 1998; Brill and Wu, 1998) . In both cases the investigators were able to achieve significant improvements over the previous best tagging results. Similar advances have been made in machine translation (Frederking and Nirenburg, 1994) , speech recognition (Fiscus, 1997) and named entity recognition (Borthwick et al., 1998) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In both cases the investigators were able to achieve significant improvements over the previous best tagging results. ", "mid_sen": "Similar advances have been made in machine translation (Frederking and Nirenburg, 1994) , speech recognition (Fiscus, 1997) and named entity recognition (Borthwick et al., 1998) .", "after_sen": "The corpus-based statistical parsing community has many fast and accurate automated parsing systems, including systems produced by Collins (1997) , Charniak (1997) and Ratnaparkhi (1997) . "}
{"citeStart": 55, "citeEnd": 73, "citeStartToken": 55, "citeEndToken": 73, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper, we view source identification as an information extraction task and tackle the problem using sequence tagging and pattern matching techniques simultaneously. Using syntactic, semantic, and orthographic lexical features, dependency parse features, and opinion recognition features, we train a linear-chain Conditional Random Field (CRF) (Lafferty et al., 2001) to identify opinion sources. In addition, we employ features based on automatically learned extraction patterns and perform feature induction on the CRF model. We evaluate our hybrid approach using the NRRC corpus (Wiebe et al., 2005) , which is manually annotated with direct and indirect opinion source information. Experimental results show that the CRF model performs well, and that both the extraction patterns and feature induction produce performance gains. The resulting system identifies opinion sources with 79.3% precision and 59.5% recall using a head noun matching measure, and 81.2% precision and 60.6% recall using an overlap measure.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In addition, we employ features based on automatically learned extraction patterns and perform feature induction on the CRF model. ", "mid_sen": "We evaluate our hybrid approach using the NRRC corpus (Wiebe et al., 2005) , which is manually annotated with direct and indirect opinion source information. ", "after_sen": "Experimental results show that the CRF model performs well, and that both the extraction patterns and feature induction produce performance gains. "}
{"citeStart": 107, "citeEnd": 120, "citeStartToken": 107, "citeEndToken": 120, "sectionName": "UNKNOWN SECTION NAME", "string": "The third proposal based on the adjacency model appears in Resnik (1993) and is rather more complex again. The SELECTIONAL ASSOCIATION between a predicate and a word is defined based on the contribution of the word to the conditional entropy of the predicate. The association between each pair of words in the compound is then computed by taking the maximum selectional association from all possible ways of regarding the pair as predicate and argument. Whilst this association metric is complicated, the decision procedure still follows the outline devised by Marcus (1980) above. Resnik (1993) used unambiguous noun compounds from the parsed Wall Stree~ Journal (WSJ) corpus to estimate the association ~alues and analysed a test set of around 160 compounds. After some tuning, the accuracy was about 73%, as compared with a baseline of 64% achieved by always bracketing the first two nouns together.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The association between each pair of words in the compound is then computed by taking the maximum selectional association from all possible ways of regarding the pair as predicate and argument. ", "mid_sen": "Whilst this association metric is complicated, the decision procedure still follows the outline devised by Marcus (1980) above. ", "after_sen": "Resnik (1993) used unambiguous noun compounds from the parsed Wall Stree~ Journal (WSJ) corpus to estimate the association ~alues and analysed a test set of around 160 compounds. "}
{"citeStart": 126, "citeEnd": 151, "citeStartToken": 126, "citeEndToken": 151, "sectionName": "UNKNOWN SECTION NAME", "string": "Lexical-Functional Grammar (SLFG) is a stochastic extension of Lexical-Functional Grammar (LFG), a UBG formalism developed by Kaplan and Bresnan (1982) . Given a base LFG, an SLFG is constructed by defining features which identify salient constructions in a linguistic structure (in LFG this is a c-structure/f-structure pair and its associated mapping; see Kaplan (1995) ). Apart from the auxiliary distributions, we based our features on those used in Johnson et al. (1999) , which should be consulted for further details. Most of these feature values range over the natural numbers, counting the number of times that a particular construction appears in a linguistic structure. For example, adjunct and argument features count the number of adjunct and argument attachments, permitting SLFG to capture a general argument attachment preference, while more specialized features count the number of attachments to each grammatical function (e.g., SUB J, OBJ, COMP, etc.). The flexibility of features in stochastic UBGs permits us to include features for relatively complex constructions, such as date expressions (it seems that date interpretations, if possible, are usually preferred), right-branching constituent structures (usually preferred) and non-parallel coordinate structures (usually dispreferred). Johnson et al. remark that they would have liked to have included features for lexical selectional preferences. While such features are perfectly acceptable in a SLFG, they felt that their corpora were so small that the large number of lexical dependency parameters could not be accurately estimated. The present paper proposes a method to address this by using an auxiliary distribution estimated from a corpus large enough to (hopefully) provide reliable estimates for these parameters.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Lexical-Functional Grammar (SLFG) is a stochastic extension of Lexical-Functional Grammar (LFG), a UBG formalism developed by Kaplan and Bresnan (1982) . ", "after_sen": "Given a base LFG, an SLFG is constructed by defining features which identify salient constructions in a linguistic structure (in LFG this is a c-structure/f-structure pair and its associated mapping; see Kaplan (1995) ). "}
{"citeStart": 14, "citeEnd": 32, "citeStartToken": 14, "citeEndToken": 32, "sectionName": "UNKNOWN SECTION NAME", "string": "A paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings. For instance, Sells (1985, p. 8) says that the sentence \"Reagan thinks bananas,\" which is otherwise strange, is in fact acceptable if it occurs as an answer to the question \"What is Kissinger's favorite fruit?\" The pairing of these two sentences may be said to create a small paragraph. Our point is that an acceptable structure can be assigned to the utterance \"Reagan thinks bananas\" only within the paragraph in which this utterance occurs. We believe that, in general, no unit larger than a paragraph is necessary to assign a functional structure to a sentence, and that no smaller discourse fragment, such as two (or one) neighboring sentences, will be sufficient for this task. That is, we can ask in the first sentence of a paragraph about Kissinger's favorite fruit, elaborate the question and the circumstances in the next few sentences, and give the above answer at the end. We do not claim that a paragraph is necessarily described by a set of grammar rules in some grammar formalism (although it may be); rather, it has the grammatical role of providing functional structures that can be assigned to strings.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings. ", "mid_sen": "For instance, Sells (1985, p. 8) says that the sentence \"Reagan thinks bananas,\" which is otherwise strange, is in fact acceptable if it occurs as an answer to the question \"What is Kissinger's favorite fruit?\" The pairing of these two sentences may be said to create a small paragraph. ", "after_sen": "Our point is that an acceptable structure can be assigned to the utterance \"Reagan thinks bananas\" only within the paragraph in which this utterance occurs. "}
{"citeStart": 223, "citeEnd": 247, "citeStartToken": 223, "citeEndToken": 247, "sectionName": "UNKNOWN SECTION NAME", "string": "For supervised methods, summarization is often regarded as a classification task or a sequence labeling task at sentence level, and many supervised learning algorithms have been investigated including Hidden Markov Models (Conroy and O'leary, 2001) , Support Vector Regression (You et al., 2011) , Factor Graph Model (Yang et al., 2011) , etc. However, such a supervised learning paradigm often requires a large amount of labeled data, which are not available in most cases.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004) are representative methods adopting models like PageRank and HITS to estimate the importance of sentences via the computation of the stationary distribution of a Markov chain or a mutual reinforcement process (Zha, 2002) .", "mid_sen": "For supervised methods, summarization is often regarded as a classification task or a sequence labeling task at sentence level, and many supervised learning algorithms have been investigated including Hidden Markov Models (Conroy and O'leary, 2001) , Support Vector Regression (You et al., 2011) , Factor Graph Model (Yang et al., 2011) , etc. ", "after_sen": "However, such a supervised learning paradigm often requires a large amount of labeled data, which are not available in most cases."}
{"citeStart": 39, "citeEnd": 58, "citeStartToken": 39, "citeEndToken": 58, "sectionName": "UNKNOWN SECTION NAME", "string": "Features We extracted the following features from each sentence and used them in the featurebased classifiers: (1) Discourse features: location in the article/section/paragraph. For this feature each text batch was divided to ten equal size parts and the corresponding feature value identifies the relevant part; (2) Lexical features: number of citations and references to tables and figures (0, 1, or more), word, bi-gram, verb, and verb class (obtained by spectral clustering (Sun and Korhonen, 2009) ); (3) Syntactic features: tense and voice (POS tags of main and auxiliary verbs), grammatical relation, subject and object. The lexical and the syntactic features were extracted for the represented sentence as well as for its surrounding sentences. We used the C&C POS tagger and parser (Curran et al., 2007) for extracting the lexical and the syntactic features. Note that all the information encoded into our constraints is also encoded in the features and is thus available to the feature-based model. This enables us to properly evaluate the impact of our modeling decision which augments a feature-based model with constraints.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The lexical and the syntactic features were extracted for the represented sentence as well as for its surrounding sentences. ", "mid_sen": "We used the C&C POS tagger and parser (Curran et al., 2007) for extracting the lexical and the syntactic features. ", "after_sen": "Note that all the information encoded into our constraints is also encoded in the features and is thus available to the feature-based model. "}
{"citeStart": 125, "citeEnd": 144, "citeStartToken": 125, "citeEndToken": 144, "sectionName": "UNKNOWN SECTION NAME", "string": "Previous work in NER has been aware of this problem of dealing with words without accurate case information, and various workarounds have been exploited. Most commonly, feature-based classifiers use a set of capitalisation features and a sentence-initial feature (Bikel et al., 1997) . Chieu and Ng used global information such as the occurrence of the same word with other capitalisation in the same document (Chieu and Ng, 2002a) , and have also used a mixed-case classifier to teach a \"weaker\" classifier that did not use case information at all (Chieu and Ng, 2002b) .", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Most commonly, feature-based classifiers use a set of capitalisation features and a sentence-initial feature (Bikel et al., 1997) . ", "mid_sen": "Chieu and Ng used global information such as the occurrence of the same word with other capitalisation in the same document (Chieu and Ng, 2002a) , and have also used a mixed-case classifier to teach a \"weaker\" classifier that did not use case information at all (Chieu and Ng, 2002b) .", "after_sen": "We propose a different solution to the problem of caseless words. "}
{"citeStart": 45, "citeEnd": 69, "citeStartToken": 45, "citeEndToken": 69, "sectionName": "UNKNOWN SECTION NAME", "string": "Both methods we study here -Inside/Outside and Open/Close -have been evaluated before (using different learning methods) on similar tasks. However, in this work we have allowed for a fair comparison between two different models by using the same basic learning method and the same features. Our main conclusion is with respect to the robustness of the methods to sequences of different lengths. While both methods give good results for the base NP problem, they differ significantly on the SV tasks. Furthermore, our investigation revealed that the Inside/Outside method is very sensitive to the length of the phrases. Table 6 shows a breakdown of the performance of the two methods on SV phrases of different lengths. Perhaps this was not observed earlier since (Ramshaw and Marcus, 1995) studied only base NPs, most of which are short. The conclusion is therefore that the Open/Close method is more robust, especially when the target sequences are longer than a few tokens.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Table 6 shows a breakdown of the performance of the two methods on SV phrases of different lengths. ", "mid_sen": "Perhaps this was not observed earlier since (Ramshaw and Marcus, 1995) studied only base NPs, most of which are short. ", "after_sen": "The conclusion is therefore that the Open/Close method is more robust, especially when the target sequences are longer than a few tokens."}
{"citeStart": 143, "citeEnd": 155, "citeStartToken": 143, "citeEndToken": 155, "sectionName": "UNKNOWN SECTION NAME", "string": "To estimate the quality of a feature, we use Information Gain (IG) because that has been shown to work well as a metric for feature selection (Forman, 2003) . We will say that feature A behaviorally subsumes feature B if two criteria are met: (1) A representationally subsumes B, and (2) IG(A) ≥ IG(B)δ, where δ is a parameter representing an acceptable margin of performance difference. For example, if δ=0 then condition (2) means that feature A is just as valuable as feature B because its information gain is the same or higher. If δ>0 then feature A is allowed to be a little worse than feature B, but within an acceptable margin. For example, δ=.0001 means that A's information gain may be up to .0001 lower than B's information gain, and that is considered to be an acceptable performance difference (i.e., A is good enough that we are comfortable discarding B in favor of the more general feature A).", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For example, all bigrams would be discarded if their component unigrams were also present in the hierarchy.", "mid_sen": "To estimate the quality of a feature, we use Information Gain (IG) because that has been shown to work well as a metric for feature selection (Forman, 2003) . ", "after_sen": "We will say that feature A behaviorally subsumes feature B if two criteria are met: (1) A representationally subsumes B, and (2) IG(A) ≥ IG(B)δ, where δ is a parameter representing an acceptable margin of performance difference. "}
{"citeStart": 0, "citeEnd": 32, "citeStartToken": 0, "citeEndToken": 32, "sectionName": "UNKNOWN SECTION NAME", "string": "Previous research has identified three means by which speakers signal information about discourse structure to listeners: Cue words and phrases (5, 10); Intonation (7); Pronomi-nalisation (6, 2). In the cue words approach, Reichman'(10) has claimed that phrases like \"because\", \"so\", and \"but\" offer explicit information to listeners about how the speaker's current contribution to the discourse relates to what has gone previously. For example a speaker might use the expression \"so\" to signal that s/he is about to conclude what s/he has just said. Grosz and Sidner (5) relate the use of such phrases to changes in attentional state. An example would be that \"and\" or \"but\" signal to the listener that a new topic and set of referents is being introduced whereas \"anyway\" and \"in any case\" indicate a return to a previous topic and referent set. A second indirect way of signalling discourse structure is intonation. Hirschberg and Pierrehumbert (7) showed that intonational contour is closely related to discourse segmentation with new topics being signalled by changes in intonational contour. A final more indirect cue to discourse structure is the speaker's choice of referring expressions and grammatical structure. A number of researchers (4, 2, 6, 10) have given accounts of how these relate to the continuing, retaining or shifting of focus.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A second indirect way of signalling discourse structure is intonation. ", "mid_sen": "Hirschberg and Pierrehumbert (7) showed that intonational contour is closely related to discourse segmentation with new topics being signalled by changes in intonational contour. ", "after_sen": "A final more indirect cue to discourse structure is the speaker's choice of referring expressions and grammatical structure. "}
{"citeStart": 59, "citeEnd": 76, "citeStartToken": 59, "citeEndToken": 76, "sectionName": "UNKNOWN SECTION NAME", "string": "We compute the most probable sequence by performing a left-to-right decoding using a beam search. The algorithm is exactly the same as the one described in (Ratnaparkhi, 1996) to find the most probable part-of-speech sequence. We used a large beam of size =100, which is not computationally prohibitive, since the tagset contains only four ele- 8 The transitivity dependency is conditioned on two tags, while all others on only one. These five contextual tags are defaulted to OTHER when dependency spans exceed the threshold of 6 © 8 7 4 9 . ments. Note however that this algorithm can lead to search errors. An alternative would be to use a variant of the Viterbi algorithm, which was successfully used in (McCallum et al., 2000) to decode the most probable sequence in a CMM.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We compute the most probable sequence by performing a left-to-right decoding using a beam search. ", "mid_sen": "The algorithm is exactly the same as the one described in (Ratnaparkhi, 1996) to find the most probable part-of-speech sequence. ", "after_sen": "We used a large beam of size =100, which is not computationally prohibitive, since the tagset contains only four ele- 8 The transitivity dependency is conditioned on two tags, while all others on only one. "}
{"citeStart": 10, "citeEnd": 14, "citeStartToken": 10, "citeEndToken": 14, "sectionName": "UNKNOWN SECTION NAME", "string": "However, the situation changes dramatically if we enforce non-local or context-sensitive constraints on linguistic structures of the kind that can be expressed by a UBG. As Abney (1997) showed, under these circumstances the relative frequency estimator is in general inconsistent, even if one restricts attention to rule features. Consequently, maximum likelihood estimation is much more complicated, as discussed in section 2.2. Moreover, while rule features are natural for PCFGs given their context-free independence properties, there is no particular reason to use only rule features in Stochastic UBGs (SUBGs). Thus an SUBG is a triple (G, f, A), where G is a UBG which generates a set of wellformed linguistic structures i2, and f and A are vectors of feature functions and feature parameters as above. The probability of a structure w E ~ is given by (1) with Q(w) = 1. Given a base UBG, there are usually infinitely many different ways of selecting the features f to make a SUBG, and each of these makes an empirical claim about the class of possible distributions of structures.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, the situation changes dramatically if we enforce non-local or context-sensitive constraints on linguistic structures of the kind that can be expressed by a UBG. ", "mid_sen": "As Abney (1997) showed, under these circumstances the relative frequency estimator is in general inconsistent, even if one restricts attention to rule features. ", "after_sen": "Consequently, maximum likelihood estimation is much more complicated, as discussed in section 2.2. "}
{"citeStart": 389, "citeEnd": 408, "citeStartToken": 389, "citeEndToken": 408, "sectionName": "UNKNOWN SECTION NAME", "string": "Some examples of English words and the top three ranking candidates among all of the potential target-language candidates were given in Tables 4,  5 To evaluate the proposed transliteration methods quantitatively, the Mean Reciprocal Rank (MRR), a measure commonly used in information retrieval when there is precisely one correct answer (Kandor and Vorhees, 2000) was measured, following Tao and Zhai (2005) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The candidate with the highest node activation score was selected as the transliteration of the given English name.", "mid_sen": "Some examples of English words and the top three ranking candidates among all of the potential target-language candidates were given in Tables 4,  5 To evaluate the proposed transliteration methods quantitatively, the Mean Reciprocal Rank (MRR), a measure commonly used in information retrieval when there is precisely one correct answer (Kandor and Vorhees, 2000) was measured, following Tao and Zhai (2005) .", "after_sen": "Since the evaluation data obtained from the comparable corpus was small, the systems were evaluated using both held-out data from the transliteration dictionary and comparable corpus."}
{"citeStart": 61, "citeEnd": 83, "citeStartToken": 61, "citeEndToken": 83, "sectionName": "UNKNOWN SECTION NAME", "string": "Another important construct of LFG is functional uncertainty Kaplan & Maxwell, 1995) . Very often (most notably, in extraction or control constructions) the path of f-structure attributes to write down is indeterminate. In this case, one may write down a description of this path (using a regular language over attribute names) and let the parser check every path described (possibly resulting in ambiguities warranted by f-structure differences only). Our little grammar may be extended to take advantage of functional uncertainty in two ways. First, if you want to permute subject and object (as is possible in German), you might change the S rule to the following:", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Note that unspecified feature structures are displayed as [ ] in the figure, and that much more information (esp. predicate-argument information) will come from the lexical entries.", "mid_sen": "Another important construct of LFG is functional uncertainty Kaplan & Maxwell, 1995) . ", "after_sen": "Very often (most notably, in extraction or control constructions) the path of f-structure attributes to write down is indeterminate. "}
{"citeStart": 92, "citeEnd": 106, "citeStartToken": 92, "citeEndToken": 106, "sectionName": "UNKNOWN SECTION NAME", "string": "To deal with these issues we propose a multicomponent architecture where individual components specialize in identifying one particular type of unknown word. For example, the misspelling identifier will specialize in identifying misspellings, the abbreviation component will specialize in identifying abbreviations, etc. Each component will return a confidence measure of the reliability of its prediction, c.f. (Elworthy, 1998) . The results from each component are evaluated to determine the final category of the word.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For example, the misspelling identifier will specialize in identifying misspellings, the abbreviation component will specialize in identifying abbreviations, etc. ", "mid_sen": "Each component will return a confidence measure of the reliability of its prediction, c.f. (Elworthy, 1998) . ", "after_sen": "The results from each component are evaluated to determine the final category of the word."}
{"citeStart": 130, "citeEnd": 149, "citeStartToken": 130, "citeEndToken": 149, "sectionName": "UNKNOWN SECTION NAME", "string": "To systematically assess the impact of the multiple heuristic decisions made during training and decoding, we propose, following (Dreyer et al., 2007; Auli et al., 2009) , to work out oracle scores, that is to evaluate the best achievable performances of a PBTS. We aim at both studying the expressive power of PBTS and at providing tools for identifying and quantifying causes of failure.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "To systematically assess the impact of the multiple heuristic decisions made during training and decoding, we propose, following (Dreyer et al., 2007; Auli et al., 2009) , to work out oracle scores, that is to evaluate the best achievable performances of a PBTS. ", "after_sen": "We aim at both studying the expressive power of PBTS and at providing tools for identifying and quantifying causes of failure."}
{"citeStart": 117, "citeEnd": 139, "citeStartToken": 117, "citeEndToken": 139, "sectionName": "UNKNOWN SECTION NAME", "string": "Common Topic Inference Understanding segments of utterances standing in a Common Topic relation requires the determination of points of commonality (parallelism) and departure (contrast) between sets of corresponding entities and properties within the utterances. This process is reliant on performing comparison and generalization operations on the corresponding representations (Scha and Polanyi, 1988; Hobbs, 1990; Priist, 1992; Asher, 1993) . Table 2 sketches definitions for some Common Topic relations, some taken from and others adapted from Hobbs (1990) . In each case, the hearer is to understand the relation by inferring po (al,..., a,) from sentence So and inferring p1(bl, ..., bn) from sentence $1 under the listed constraints. 9 In order to meet these constraints, the identification of p0 and Pl may require arbitrary levels of generalization from the relations explicitly stated in the utterances. Examples of these relations are given in sentences (13a-d). 13cis likewise coherent by virtue of the inferences resulting from identifying parallel elements and properties, including that John is a young aspiring politician and that he's a Democrat (since Clinton is identified with his party's candidate). The characteristic that Common Topic relations share is that they require the identification of parallel entities (i.e., the al and bi) and relations (P0 and Px) as arguments to the constraints. We posit that the syntactic representation is used both to guide the identification of parallel elements and to retrieve their semantic representations.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Common Topic Inference Understanding segments of utterances standing in a Common Topic relation requires the determination of points of commonality (parallelism) and departure (contrast) between sets of corresponding entities and properties within the utterances. ", "mid_sen": "This process is reliant on performing comparison and generalization operations on the corresponding representations (Scha and Polanyi, 1988; Hobbs, 1990; Priist, 1992; Asher, 1993) . ", "after_sen": "Table 2 sketches definitions for some Common Topic relations, some taken from and others adapted from Hobbs (1990) . "}
{"citeStart": 82, "citeEnd": 91, "citeStartToken": 82, "citeEndToken": 91, "sectionName": "UNKNOWN SECTION NAME", "string": "Very interestingly, the distributional methods based on intra-sentence relations (Lin, 1998; Padó and Lapata, 2003) outperformed Garera and Yarowsky's (2006) association measure when used for ranking, which may due to sparse data problems or simply too much noise for the latter. For the association measures, the fact that they are relation-free also means that they can profit from added semantic filtering.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "While none of the information sources can match the precision of the hypernymy information encoded in GermaNet, or that of using a combination of high-precision patterns with the World Wide Web as a very large corpus, it is possible to achieve a considerable improvement in terms of recall without sacrificing too much precision by combining these methods.", "mid_sen": "Very interestingly, the distributional methods based on intra-sentence relations (Lin, 1998; Padó and Lapata, 2003) outperformed Garera and Yarowsky's (2006) association measure when used for ranking, which may due to sparse data problems or simply too much noise for the latter. ", "after_sen": "For the association measures, the fact that they are relation-free also means that they can profit from added semantic filtering."}
{"citeStart": 106, "citeEnd": 129, "citeStartToken": 106, "citeEndToken": 129, "sectionName": "UNKNOWN SECTION NAME", "string": "We also express our gratitude to the treebank providers for each language: Arabic (Maamouri et al., 2004; Green and Manning, 2010) , Basque (Aduriz et al., 2003) , French (Abeillé et al., 2003) , Hebrew (Sima'an et al., 2001; Tsarfaty, 2010; Goldberg, 2011; Tsarfaty, 2013) , German (Brants et al., 2002; Seeker and Kuhn, 2012) , Hungarian (Csendes et al., 2005; Vincze et al., 2010) , Korean (Choi et al., 1994; Choi, 2013), Polish (Świdziński and Woliński, 2010) , and Swedish (Nivre et al., 2006) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The remaining authors are funded by the Deutsche Forschungsgemeinschaft (DFG) via the SFB 732, projects D2 and D8 (PI: Jonas Kuhn).", "mid_sen": "We also express our gratitude to the treebank providers for each language: Arabic (Maamouri et al., 2004; Green and Manning, 2010) , Basque (Aduriz et al., 2003) , French (Abeillé et al., 2003) , Hebrew (Sima'an et al., 2001; Tsarfaty, 2010; Goldberg, 2011; Tsarfaty, 2013) , German (Brants et al., 2002; Seeker and Kuhn, 2012) , Hungarian (Csendes et al., 2005; Vincze et al., 2010) , Korean (Choi et al., 1994; Choi, 2013), Polish (Świdziński and Woliński, 2010) , and Swedish (Nivre et al., 2006) .", "after_sen": "Although, for Hebrew and Swedish only 5k sentences were available for training, and the two settings thus coincide."}
{"citeStart": 52, "citeEnd": 65, "citeStartToken": 52, "citeEndToken": 65, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper, we proposed a framework for exploiting contextual information in a process of grammar refinement. In this framework, a rough grammar is first learned from a bracketed corpus and then the grammar is refined by the combination of rulebased and corpus-based methods. Unlike stochastic parsing such as (Magerman, 1995) (Collins, 1996) , our approach can parse sentences which fall out the current grammar and suggest the plausible hypothesis rules and the best parses. The grammar is not acquired from scratch like the approaches shown in Table 3 : Parsing Accuracy (Pereira and Schabes, 1992) (Mort and Nagao, 1995) . Through some experiments, our method can achieve effective hypothesis selection and parsing accuracy to some extent. As our further work, we are on the way to consider the correctness of the selected hypothesis of the most plausible parses proposed by the parser. Some improvements are needed to grade up the parsing accuracy. Another work is to use an existing grammar, instead of an automatically learned one, to investigate the effectiveness of contextual information. By providing a user interface, this method will be useful for grammar developers.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In this framework, a rough grammar is first learned from a bracketed corpus and then the grammar is refined by the combination of rulebased and corpus-based methods. ", "mid_sen": "Unlike stochastic parsing such as (Magerman, 1995) (Collins, 1996) , our approach can parse sentences which fall out the current grammar and suggest the plausible hypothesis rules and the best parses. ", "after_sen": "The grammar is not acquired from scratch like the approaches shown in Table 3 : Parsing Accuracy (Pereira and Schabes, 1992) (Mort and Nagao, 1995) . "}
{"citeStart": 65, "citeEnd": 81, "citeStartToken": 65, "citeEndToken": 81, "sectionName": "UNKNOWN SECTION NAME", "string": "The key components of OPINE described in this paper are the PMI feature assessment which leads to high-precision feature extraction and the use of relaxation-labeling in order to find the semantic orientation of potential opinion words. The review-mining work most relevant to our research is that of (Hu and Liu, 2004) and (Kobayashi et al., 2004) . Both identify product features from reviews, but OPINE significantly improves on both. (Hu and Liu, 2004) doesn't assess candidate features, so its precision is lower than OPINE's. (Kobayashi et al., 2004) employs an iterative semi-automatic approach which requires human input at every iteration. Neither model explicitly addresses composite (feature of feature) or implicit features. Other systems (Morinaga et al., 2002; Kushal et al., 2003) also look at Web product reviews but they do not extract opinions about particular product features. OPINE's use of meronymy lexico-syntactic patterns is similar to that of many others, from (Berland and Charniak, 1999) to (Almuhareb and Poesio, 2004) . Recognizing the subjective character and polarity of words, phrases or sentences has been addressed by many authors, including (Turney, 2003; Riloff et al., 2003; Wiebe, 2000; Hatzivassiloglou and McKeown, 1997) . Most recently, (Takamura et al., 2005) reports on the use of spin models to infer the semantic orientation of words. The paper's global optimization approach and use of multiple sources of constraints on a word's semantic orientation is similar to ours, but the mechanism differs and they currently omit the use of syntactic information. Subjective phrases are used by (Turney, 2002; Pang and Vaithyanathan, 2002; Kushal et al., 2003; Kim and Hovy, 2004) and others in order to classify reviews or sentences as positive or negative. So far, OPINE's focus has been on extracting and analyzing opinion phrases corresponding to specific features in specific sentences, rather than on determining sentence or review polarity.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The key components of OPINE described in this paper are the PMI feature assessment which leads to high-precision feature extraction and the use of relaxation-labeling in order to find the semantic orientation of potential opinion words. ", "mid_sen": "The review-mining work most relevant to our research is that of (Hu and Liu, 2004) and (Kobayashi et al., 2004) . ", "after_sen": "Both identify product features from reviews, but OPINE significantly improves on both. "}
{"citeStart": 197, "citeEnd": 215, "citeStartToken": 197, "citeEndToken": 215, "sectionName": "UNKNOWN SECTION NAME", "string": "Though several studies with similar objectives have been reported [Church, 1988] , [Zernik and Jacobs, 1990] , [Calzolari and Bindi, 1990] , [Garside and Leech, 1985] , [Hindle and Rooth, 1991] , [Brown et al., 1990] , they require that sample corpora be correctly analyzed or tagged in advance. It must be a training corpus, which is tagged or parsed by human or it needs correspondence between two language corpora. Because their preparation needs a lot of manual assistance or an unerring tagger or parser, this requirement makes their algorithm~, troublesome in actual application environments. On the other hand, the algorithm in this paper has no such requirement, it requires only a minimum of linguistic knowledge, including parts-of-speech of words, simple inflection rules, and a small number of general syntactic rules which lexicon based syntactic theories like HPSG CC etc. normally assume. The parser is not a deterministic parser, but a parser which produces all possible analyses. All of the results are used for calculation ant the system assumes that there is a correct answer among them. The algorithm builds correct structural descriptions of sentences and discovers semantic collocations at the same time. It works as a relaxation process.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We expect that the knowledge to be extracted will not only be useful for disambiguating sentences but also will contribute to discovering ontological classes in given subject domains.", "mid_sen": "Though several studies with similar objectives have been reported [Church, 1988] , [Zernik and Jacobs, 1990] , [Calzolari and Bindi, 1990] , [Garside and Leech, 1985] , [Hindle and Rooth, 1991] , [Brown et al., 1990] , they require that sample corpora be correctly analyzed or tagged in advance. ", "after_sen": "It must be a training corpus, which is tagged or parsed by human or it needs correspondence between two language corpora. "}
{"citeStart": 23, "citeEnd": 36, "citeStartToken": 23, "citeEndToken": 36, "sectionName": "UNKNOWN SECTION NAME", "string": "Other pronominal resolution approaches promote knowledge-poor methods (Mitkov , 1998) , either by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents. The CogNIAC algorithm (Baldwin, 1997) uses six heuristic rules to resolve coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, lexical reiteration or immediate reference). Both these algorithm rely only on part-of-speech tagging of texts and on patterns for NP identification. Their performance (dose to 90% for certain types of pronouns) indicates that full syntactic knowledge is not required by certain forms of pronominal coreference.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Other pronominal resolution approaches promote knowledge-poor methods (Mitkov , 1998) , either by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents. ", "mid_sen": "The CogNIAC algorithm (Baldwin, 1997) uses six heuristic rules to resolve coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, lexical reiteration or immediate reference). ", "after_sen": "Both these algorithm rely only on part-of-speech tagging of texts and on patterns for NP identification. "}
{"citeStart": 31, "citeEnd": 51, "citeStartToken": 31, "citeEndToken": 51, "sectionName": "UNKNOWN SECTION NAME", "string": "Our motivation in providing a new DA annotation scheme is that our focus differs from much of this prior work. We aim for a relatively abstract annotation scheme in order to make comparisons across interactions of widely differing properties. Our initial focus is less on speech act types and more on the patterns of local alternation be-tween an initiating speech act and a responding one-the analog of adjacency pairs (Sacks et al., 1974) . The most closely related effort is (Galley et al., 2004) , which aims to automatically identify adjacency pairs in the ICSI Meeting corpus, a large corpus of 75 meetings, using a small tagset. Their maximum entropy ranking approach achieved 90% accuracy on the 4-way classification into agreement, disagreement, backchannel and other. Using the switchboard corpus, (Stolcke et al., 2000) achieved good dialogue act labeling accuracy (71% on manual transcriptions) for a set of 42 dialogue act types, and constructed probabilistic models of dialogue act sequencing in order to test the hypothesis that dialogue act sequence information could boost speech recognition performance.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Their maximum entropy ranking approach achieved 90% accuracy on the 4-way classification into agreement, disagreement, backchannel and other. ", "mid_sen": "Using the switchboard corpus, (Stolcke et al., 2000) achieved good dialogue act labeling accuracy (71% on manual transcriptions) for a set of 42 dialogue act types, and constructed probabilistic models of dialogue act sequencing in order to test the hypothesis that dialogue act sequence information could boost speech recognition performance.", "after_sen": "There has been far less work on developing manual and automatic dialogue act annotation schemes for email. "}
{"citeStart": 61, "citeEnd": 72, "citeStartToken": 61, "citeEndToken": 72, "sectionName": "UNKNOWN SECTION NAME", "string": "We implemented Cubit, a Python clone of the Pharaoh decoder (Koehn, 2004) , and adapted cube pruning to it as follows. As in Pharaoh, each bin i contains hypotheses (i.e., +LM items) covering i words on the source-side. But at each bin (see Figure 5) , all +LM items from previous bins are first partitioned into −LM items; then the hyperedges leading from those −LM items are further grouped into hyperedge bundles ( Figure 6 ), which are placed into the priority queue of the current bin. Our data preparation follows Huang et al. (2006) : the training data is a parallel corpus of 28.3M words on the English side, and a trigram language model is trained on the Chinese side. We use the same test set as (Huang et al., 2006) , which is a 140-sentence subset of the NIST 2003 test set with 9-36 words on the English side. The weights for the log-linear model are tuned on a separate development set. We set the decoder phrase-table limit to 100 as suggested in (Koehn, 2004) and the distortion limit to 4. Figure 7 (a) compares cube pruning against fullintegration in terms of search quality vs. search efficiency, under various pruning settings (threshold beam set to 0.0001, stack size varying from 1 to 200). Search quality is measured by average model cost per sentence (lower is better), and search efficiency is measured by the average number of hypotheses generated (smaller is faster). At each level of search quality, the speed-up is always better than a factor of 10. The speed-up at the lowest searcherror level is a factor of 32. Figure 7 (b) makes a similar comparison but measures search quality by BLEU, which shows an even larger relative speed-up for a given BLEU score, because translations with very different model costs might have similar BLEU scores. It also shows that our full-integration implementation in Cubit faithfully reproduces Pharaoh's performance. Fixing the stack size to 100 and varying the threshold yielded a similar result.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We implemented Cubit, a Python clone of the Pharaoh decoder (Koehn, 2004) , and adapted cube pruning to it as follows. ", "after_sen": "As in Pharaoh, each bin i contains hypotheses (i.e., +LM items) covering i words on the source-side. "}
{"citeStart": 107, "citeEnd": 123, "citeStartToken": 107, "citeEndToken": 123, "sectionName": "UNKNOWN SECTION NAME", "string": "'l'hm'v were 37 (Se~' exmr@es in 'l'al)lc 2) verbs whose depen-(h>l]cy I)cl,w(>en ;u:g2 and ol, hcr slots is positAv (, atl (l (~x(:o,,d.'-; a COl;t.ailt threshold, i.e. Play92l,pr+p = J) 2> 0.25. '1'11 (> depend(moles [ound :1_3 by our method seem to agree with human intuition in most cases. There were 93 examples in the test data ((verb, nounl,prcp, no'an2) pattern) in which tile two slots 'a.rg2' and prep of verb are determined to be positively dependent and their dependencies are stronger than tile threshold of 0.25. We forcibly attached prep nou~t2 to verb for these 93 examples. For comparison, we also tested the disambiguation method based on the independence assumption proposed by (Li and Abe, 1995) on these examples. Table 3 shows the results of these experiments, where 'Dendroid' stands for the former method and 'Independent' the latter. We see that using tile information on dependency we can significantly improve the disambiguation accuracy on this part of the data Since we can use existing methods to perform disambiguation for the rest of the data, we can improve the disambiguation accuracy for the entire test data using this knowledge. Furthermore, we found that there were 140 verbs having inter-dependent preposition slots. There were 22 (See examples in Table 4 ) out of these 140 verbs such that their ease slots hawe positive dependency that exceeds a certain threshold, i.e. P(prepl = 1,prep2 = 1) > 0.25. Again the dependencies found by our method seem to agree with human intuition. In the test data (which are of verb,prep:t,nount,prep~, nou~ pattern), there were 21 examples that involw? one of the above 22 verbs whose preposition slots show dependency exceeding 0.25. We forcibly attached bot.h prep, no'unl and prep2 noun2 to verb on these 21 examples, since the two slots prept and prep~ are judged to be dependent. Table 5 shows the results of this experimentation, where 'Dendroid' and 'Independent' respectively represent for to from to from to from to fi'om to from to fl'om to to for", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We forcibly attached prep nou~t2 to verb for these 93 examples. ", "mid_sen": "For comparison, we also tested the disambiguation method based on the independence assumption proposed by (Li and Abe, 1995) on these examples. ", "after_sen": "Table 3 shows the results of these experiments, where 'Dendroid' stands for the former method and 'Independent' the latter. "}
{"citeStart": 170, "citeEnd": 200, "citeStartToken": 170, "citeEndToken": 200, "sectionName": "UNKNOWN SECTION NAME", "string": "One makes the latter test by seeing if the assumption that the ratios for the two techniques are the same (the null hypothesis) leads to a statistically significant result when using a χ 2 distribution with one degree of freedom. A 2×2 table has 4 cells. The top 2 cells are filled with the R and S of one technique and the bottom 2 cells get the R and S of the other technique. In this test, the value in each cell is assumed to have a Poisson distribution. When the cell values are not too small, these Poisson distributions are approximately Normal (Gaussian). As a result, when the cell values are independent, summing the normalized squares of the difference between each cell and its expected value leads to a χ 2 distribution (Box et al., 1978, Sec. 2.5-2.6 ).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "When the cell values are not too small, these Poisson distributions are approximately Normal (Gaussian). ", "mid_sen": "As a result, when the cell values are independent, summing the normalized squares of the difference between each cell and its expected value leads to a χ 2 distribution (Box et al., 1978, Sec. 2.5-2.6 ).", "after_sen": "How well does this test work in our experiments? "}
{"citeStart": 200, "citeEnd": 219, "citeStartToken": 200, "citeEndToken": 219, "sectionName": "UNKNOWN SECTION NAME", "string": "Understanding utterances standing in a Coherent Situation relation requires that hearers convince themselves that the utterances describe a coherent situation given their knowledge of the world. This process requires that a path of inference be established between the situations (i.e., events or states) described in the participating utterances as a whole, without regard to any constraints on parMlelism between sub-sententiM constituents. Four such relations are summarized in Table 3 . l° In all four cases, the hearer is to infer A from sentence $1 and B from sentence $2 under the constraint that the presuppositions listed be abduced (ttobbs et al., 1993) : 11", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This process requires that a path of inference be established between the situations (i.e., events or states) described in the participating utterances as a whole, without regard to any constraints on parMlelism between sub-sententiM constituents. ", "mid_sen": "Four such relations are summarized in Table 3 . l° In all four cases, the hearer is to infer A from sentence $1 and B from sentence $2 under the constraint that the presuppositions listed be abduced (ttobbs et al., 1993) : ", "after_sen": "11"}
{"citeStart": 225, "citeEnd": 255, "citeStartToken": 225, "citeEndToken": 255, "sectionName": "UNKNOWN SECTION NAME", "string": "Collaborative negoti~ion occurs when conflicts arise among agents developing a shared plan 1 during collaborative planning. A collaborative agent is driven by the goal of developing a plan that best satisfies the interests of all the agents as a group, instead of one that maximizes his own interest. This results in several distinctive features of collaborative negotiation: 1) A collaborative agent does not insist on winning an argument, and may change his beliefs ff another agent presents convincing justification for an opposing belief. This differentiates collaborative negotiation from argumentation (Birnbaum et al., 1980; Reichman, 1981; Cohen, 1987; Quilici, 1992) . 2) Agents involved in collaborative negotiation are open and honest with one another; they will not deliberately present false information to other agents, present information in such a way as to mislead the other agents, or strategically hold back information from other agents for later use. This distinguishes collaborative negotiation from non-collaborative negotiation such as labor negotiation (Sycara, 1989) . 3) Collaborative agents are interested in 1The notion of shared plan has been used in (Grosz and Sidner, 1990; Allen, 1991) . others' beliefs in order to decide whether to revise their own beliefs so as to come to agreement (Chu-Carroll and Carberry, 1995) . Although agents involvedin argumentation and non-collaborative negotiation take other agents' beliefs into consideration, they do so mainly to find weak points in their opponents' beliefs and attack them to win the argument.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This distinguishes collaborative negotiation from non-collaborative negotiation such as labor negotiation (Sycara, 1989) . ", "mid_sen": "3) Collaborative agents are interested in 1The notion of shared plan has been used in (Grosz and Sidner, 1990; Allen, 1991) . others' beliefs in order to decide whether to revise their own beliefs so as to come to agreement (Chu-Carroll and Carberry, 1995) . ", "after_sen": "Although agents involvedin argumentation and non-collaborative negotiation take other agents' beliefs into consideration, they do so mainly to find weak points in their opponents' beliefs and attack them to win the argument."}
{"citeStart": 156, "citeEnd": 168, "citeStartToken": 156, "citeEndToken": 168, "sectionName": "UNKNOWN SECTION NAME", "string": "Tense interpretation has received much attention in linguistics (Partee, 1984; Hinrichs, 1986; Nerbonne, 1986, inter alia) and natural language processing (Webber, 1988; Kameyama et al., 1993; Lascarides and Asher, 1993, inter alia) . Several researchers (Partee, 1984; Hinrichs, 1986; Nerbonne, 1986; Webber, 1988) have sought to explain the temporal relations induced by tense by treating it as anaphoric, drawing on Reichenbach's separation between event, speech, and reference times (Reichenbach, 1947) . Specifically, to account for the forward progression of time induced by successive simple past tenses in a narrative, they treat the simple past as referring to a time evoked by a previous past tense. For instance, in Hinrichs's (1986) proposal, accomplishments and achievements x introduce a new reference point that is temporally ordered after the time of the event itself, \"ensuring that two consecutive accomplishments or achievements in a discourse are always ordered in a temporal sequence.\" On the other hand, Lascarides and Asher (1993) take the view that temporal relations are resolved purely as a by-product of reasoning about coherence relations holding between utterances, and in doing so, argue that treating simple and complex tenses as anaphoric is unnecessary. This approach parallels the treatment of pronoun resolution espoused by Hobbs (1979) , in which pronouns are modeled as free variables that are bound as a byproduct of coherence resolution. The Temporal Centering framework (Kameyama et al., 1993) integrates lWe will limit the scope of this paper by restricting the discussion to accomplishments and achievements. aspects of both approaches, but patterns with the first in treating tense as anaphoric.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Tense interpretation has received much attention in linguistics (Partee, 1984; Hinrichs, 1986; Nerbonne, 1986, inter alia) and natural language processing (Webber, 1988; Kameyama et al., 1993; Lascarides and Asher, 1993, inter alia) . ", "after_sen": "Several researchers (Partee, 1984; Hinrichs, 1986; Nerbonne, 1986; Webber, 1988) have sought to explain the temporal relations induced by tense by treating it as anaphoric, drawing on Reichenbach's separation between event, speech, and reference times (Reichenbach, 1947) . "}
{"citeStart": 75, "citeEnd": 89, "citeStartToken": 75, "citeEndToken": 89, "sectionName": "UNKNOWN SECTION NAME", "string": "Our position will be that dependency relations are motivated semantically (Tesni~re, 1959) , and need not be projective. We argue for so-called word order domains, consisting of partially ordered sets of words and associated with nodes in the dependency tree. These order domains constitute a tree defined by set inclusion, and surface word order is determined by traversing this tree. A syntactic analysis therefore consists of two linked, but dissimilar trees.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Second, we will briefly sketch Lexical-Functional Grammar (LFG), and then show in detail how one might use the formal constructs provided by LFG to encode the proposed DG architecture.", "mid_sen": "Our position will be that dependency relations are motivated semantically (Tesni~re, 1959) , and need not be projective. ", "after_sen": "We argue for so-called word order domains, consisting of partially ordered sets of words and associated with nodes in the dependency tree. "}
{"citeStart": 75, "citeEnd": 104, "citeStartToken": 75, "citeEndToken": 104, "sectionName": "UNKNOWN SECTION NAME", "string": "Let us call a rule A(M) :− B 1 (X 1 ), . . . , B n (X n ) in a CFLG an -rule if n = 0 and M does not contain any constants. We can eliminate -rules from an almost linear CFLG by the same method that Kanazawa and Yoshinaka (2005) used for linear grammars, noting that for any Γ and α, there are only finitely many almost linear λ-terms M such that Γ M : α. If a grammar has no -rule, any derivation tree for the input λ-term N that has a λ-term P at its root node corresponds to a Datalog derivation tree whose number of leaves is equal to the number of occurrences of constants in P, which cannot exceed the number of occurrences of constants in N.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Let us call a rule A(M) :− B 1 (X 1 ), . . . , B n (X n ) in a CFLG an -rule if n = 0 and M does not contain any constants. ", "mid_sen": "We can eliminate -rules from an almost linear CFLG by the same method that Kanazawa and Yoshinaka (2005) used for linear grammars, noting that for any Γ and α, there are only finitely many almost linear λ-terms M such that Γ M : α. If a grammar has no -rule, any derivation tree for the input λ-term N that has a λ-term P at its root node corresponds to a Datalog derivation tree whose number of leaves is equal to the number of occurrences of constants in P, which cannot exceed the number of occurrences of constants in N.", "after_sen": "A Datalog program P is said to have the polynomial fringe property relative to a class D of databases if there is a polynomial p(n) such that for every database D in D of n facts and every query q such that P∪D derives q, there is a derivation tree for q whose fringe (i.e., sequence of leaves) is of length at most p(n). "}
{"citeStart": 65, "citeEnd": 89, "citeStartToken": 65, "citeEndToken": 89, "sectionName": "UNKNOWN SECTION NAME", "string": "By construction we have ensured that the following theorem from (Booth and Thompson, 1973 ) applies to probabilistic TAGs. A formal justification for this claim is given in the next section by showing a reduction of the TAG derivation process to a multitype Galton-Watson branching process (Harris, 1963) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "By inspecting the values of A4 in terms of the grammar probabilities indicates that .h4ij contains the values we wanted, i.e. expectation of obtaining node Aj when node Ai is rewritten by adjunction at each level of the TAG derivation process.", "mid_sen": "By construction we have ensured that the following theorem from (Booth and Thompson, 1973 ) applies to probabilistic TAGs. ", "after_sen": "A formal justification for this claim is given in the next section by showing a reduction of the TAG derivation process to a multitype Galton-Watson branching process (Harris, 1963) ."}
{"citeStart": 118, "citeEnd": 143, "citeStartToken": 118, "citeEndToken": 143, "sectionName": "UNKNOWN SECTION NAME", "string": "Our method resorts to some translation examples, which is similar as example-based translation or translation memory (Watanabe and Sumita, 2003; He et al., 2010; Ma et al., 2011) . Instead of using translation examples to construct translation rules for enlarging the decoding space, we employed them to discriminatively learn local weights. Similar to (Hildebrand et al., 2005; Lü et al., 2007) , our method also employes IR methods to retrieve examples for a given test set. Their methods utilize the retrieved examples to acquire translation model and can be seen as the adaptation of translation model. However, ours uses the retrieved examples to tune the weights and thus can be considered as the adaptation of tuning. Furthermore, since ours does not change the translation model which needs to run GIZA++ and it incrementally trains local weights, our method can be applied for online translation service.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "One of the advantages is that it can adapt the weights for each of the test sentences.", "mid_sen": "Our method resorts to some translation examples, which is similar as example-based translation or translation memory (Watanabe and Sumita, 2003; He et al., 2010; Ma et al., 2011) . ", "after_sen": "Instead of using translation examples to construct translation rules for enlarging the decoding space, we employed them to discriminatively learn local weights. "}
{"citeStart": 13, "citeEnd": 39, "citeStartToken": 13, "citeEndToken": 39, "sectionName": "UNKNOWN SECTION NAME", "string": "For our features we used large-margin classifiers trained using the online algorithm described in (Crammer et al., 2006) . The code for the classifier was generously provided by Daisuke Okanohara. This code was extensively optimized to take advantage of the very sparse sentence representation described above. As shown in (Okanohara and Tsujii, 2007) , using this representation, a linear classifier cannot distinguish sentences sampled from a trigram and real sentences. Therefore, we used a 3rd order polynomial kernel, which was found to give good results. No special effort was otherwise made in order to optimize the parameters of the classifiers.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This code was extensively optimized to take advantage of the very sparse sentence representation described above. ", "mid_sen": "As shown in (Okanohara and Tsujii, 2007) , using this representation, a linear classifier cannot distinguish sentences sampled from a trigram and real sentences. ", "after_sen": "Therefore, we used a 3rd order polynomial kernel, which was found to give good results. "}
{"citeStart": 162, "citeEnd": 189, "citeStartToken": 162, "citeEndToken": 189, "sectionName": "UNKNOWN SECTION NAME", "string": "There is a large body of psycholinguistic evidence which suggests that meaning can be extracted before the end of a sentence, and before the end of phrasal constituents (e.g. Marslen-Wilson 1973 , Tanenhaus et al. 1990 ). There is also recent evidence suggesting that, during speech processing, partial interpretations can be built extremely rapidly, even before words are completed (Spivey-Knowlton et al. 1994) 1. There are also potential computational applications for incremental interpretation, including early parse filtering using statistics based on logical form plausibility, and interpretation of fragments of dialogues (a survey is provided by Milward and Cooper, 1994 , henceforth referred to as M&:C).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There is a large body of psycholinguistic evidence which suggests that meaning can be extracted before the end of a sentence, and before the end of phrasal constituents (e.g. Marslen-Wilson 1973 , Tanenhaus et al. 1990 ). ", "mid_sen": "There is also recent evidence suggesting that, during speech processing, partial interpretations can be built extremely rapidly, even before words are completed (Spivey-Knowlton et al. 1994) 1. There are also potential computational applications for incremental interpretation, including early parse filtering using statistics based on logical form plausibility, and interpretation of fragments of dialogues (a survey is provided by Milward and Cooper, 1994 , henceforth referred to as M&:C).", "after_sen": "In the current computational and psycholinguistic literature there are two main approaches to the incremental construction of logical forms. "}
{"citeStart": 165, "citeEnd": 186, "citeStartToken": 165, "citeEndToken": 186, "sectionName": "UNKNOWN SECTION NAME", "string": "Initiatives such as PropBank (PB) (Kingsbury and Palmer, 2002) have made possible the design of accurate automatic Semantic Role Labeling (SRL) systems like ASSERT (Hacioglu et al., 2003 In order to calculate the semantic similarity between the sentences, we first represent the annotated sentence using the tree structures like Figure 1 which we call Semantic Tree (ST). In the semantic tree, arguments are replaced with the most important wordoften referred to as the semantic head.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Given a sentence (or query), we first parse it into a syntactic tree using a syntactic parser (i.e. Charniak parser) and then we calculate the similarity between the two trees using the general tree kernel function (Section 4.1).", "mid_sen": "Initiatives such as PropBank (PB) (Kingsbury and Palmer, 2002) have made possible the design of accurate automatic Semantic Role Labeling (SRL) systems like ASSERT (Hacioglu et al., 2003 In order to calculate the semantic similarity between the sentences, we first represent the annotated sentence using the tree structures like Figure 1 which we call Semantic Tree (ST). ", "after_sen": "In the semantic tree, arguments are replaced with the most important wordoften referred to as the semantic head."}
{"citeStart": 89, "citeEnd": 124, "citeStartToken": 89, "citeEndToken": 124, "sectionName": "UNKNOWN SECTION NAME", "string": "By combining Pierrehumbert and Hirschberg's (1990) analysis of intonational meaning with Grosz, Joshi and Weinstein's (1989) theory of centering in discourse, the attentional affect of pitch accents becomes evident, and the paradox of pitch accented pronominals unravels. My goal here is to develop an analysis and a line of inquiry and to suggest that my derivative claims are plausible, and even extensible to an attentional analysis of pitch accents on nonpronominals. The proof, of course, will come from investigation by multiple means --constructed examples (e.g., Cahn, 1990) , computer simulation, empirical analysis of speech data (e.g., Nakatani, 1993) , and psycholinguistic experiments.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "By combining Pierrehumbert and Hirschberg's (1990) analysis of intonational meaning with Grosz, Joshi and Weinstein's (1989) theory of centering in discourse, the attentional affect of pitch accents becomes evident, and the paradox of pitch accented pronominals unravels. ", "after_sen": "My goal here is to develop an analysis and a line of inquiry and to suggest that my derivative claims are plausible, and even extensible to an attentional analysis of pitch accents on nonpronominals. "}
{"citeStart": 112, "citeEnd": 124, "citeStartToken": 112, "citeEndToken": 124, "sectionName": "UNKNOWN SECTION NAME", "string": "words that have high mutual information values 5The nominator in our metric resembles the similarity metric in (Hindle, 1990) . We found, however, that the difference between the two metrics is important, because the denominator serves as a normalization factor. with both wl and w2 make the largest contributions to the value of the similarity measure. Also, high and reliable mutual information values are typically associated with relatively high frequencies of the involved cooccurrence pairs. We therefore search first for all the \"strong neighbors\" of w, which are defined as words whose cooccurrence with w has high mutual information and high frequency, and then search for all their \"strong neighbors\". The words found this way (\"the strong neighbors of the strong neighbors of w\") are considered as candidates for being similar words of w, and the similarity value with w is then computed only for these words. We thus get an approximation for the set of words that are most similar to w. For the example given in Table 3, the exhaustive method required 17 minutes of CPU time on a Sun 4 workstation, while the approximation required only 7 seconds.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The search is based on the property that when computing sim(wl, w2),", "mid_sen": "words that have high mutual information values 5The nominator in our metric resembles the similarity metric in (Hindle, 1990) . ", "after_sen": "We found, however, that the difference between the two metrics is important, because the denominator serves as a normalization factor. "}
{"citeStart": 84, "citeEnd": 103, "citeStartToken": 84, "citeEndToken": 103, "sectionName": "UNKNOWN SECTION NAME", "string": "The two rule-based systems we evaluated, the ETI 4 morphological system and SMOR 5 (Schmid et al., 2004) , are both high-quality systems with large lexica that have been developed over several years. Their performance results can help to estimate what can realistically be expected from an automatic segmentation system. Both of the rule-based systems achieved an F-score of approx. 80% morphological boundaries correct with respect to CELEX manual annotation.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Drawbacks of using such a system are the high development costs, limited coverage and problems with ambiguity resolution between alternative analyses of a word.", "mid_sen": "The two rule-based systems we evaluated, the ETI 4 morphological system and SMOR 5 (Schmid et al., 2004) , are both high-quality systems with large lexica that have been developed over several years. ", "after_sen": "Their performance results can help to estimate what can realistically be expected from an automatic segmentation system. "}
{"citeStart": 127, "citeEnd": 141, "citeStartToken": 127, "citeEndToken": 141, "sectionName": "UNKNOWN SECTION NAME", "string": "This method for correcting misconceptions suggests a model of natural language generation that is similar to that put forth by McKeown (1982) but which differs from McKeown's model in several ways.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The highlighting and similarity metric used by ROMPER will be discussed below.", "mid_sen": "This method for correcting misconceptions suggests a model of natural language generation that is similar to that put forth by McKeown (1982) but which differs from McKeown's model in several ways.", "after_sen": "Both McKeown and this work concentrate on determining the content and textual shape of a response."}
{"citeStart": 123, "citeEnd": 132, "citeStartToken": 123, "citeEndToken": 132, "sectionName": "UNKNOWN SECTION NAME", "string": "Our approach is strictly empirical; the similarity of verbs is determined by examining the syntactic contexts in which they appear in a large text corpus. Our approach is analogous to previous work in extracting collocations from large text corpora using syntactic information (Lin, 1998) . In our work, we utilized the GigaWord corpus of English newswire text (Linguistic Data Consortium, 2003) , consisting of nearly 12 gigabytes of textual data. To prepare this corpus for analysis, we extracted the body text from each of the 4.1 million entries in the corpus and applied a maximum-entropy algorithm to identify sentence boundaries (Reynar and Ratnaparkhi, 1997 ).", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Our approach is strictly empirical; the similarity of verbs is determined by examining the syntactic contexts in which they appear in a large text corpus. ", "mid_sen": "Our approach is analogous to previous work in extracting collocations from large text corpora using syntactic information (Lin, 1998) . ", "after_sen": "In our work, we utilized the GigaWord corpus of English newswire text (Linguistic Data Consortium, 2003) , consisting of nearly 12 gigabytes of textual data. "}
{"citeStart": 63, "citeEnd": 93, "citeStartToken": 63, "citeEndToken": 93, "sectionName": "UNKNOWN SECTION NAME", "string": "The use of terms and indices has parallels to proposals due to Kehler and Kamp (Kehler, 1993a; Gawron and Peters, 1990) . Kehler adopts an analysis where (referential) arguments to verbs are represented as related to a Davidsonian event via thematic role functions, e.g. agent(e)--john). Pronouns typically refer to these functions, e.g. he-agent(e). In VP ellipsis, strict identity corresponds to copying the entire role assignment from the antecedent. Sloppy identity corresponds to copying the function, but applying it to the event of the ellided clause.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The use of terms and indices has parallels to proposals due to Kehler and Kamp (Kehler, 1993a; Gawron and Peters, 1990) . ", "after_sen": "Kehler adopts an analysis where (referential) arguments to verbs are represented as related to a Davidsonian event via thematic role functions, e.g. agent(e)--john). "}
{"citeStart": 125, "citeEnd": 136, "citeStartToken": 125, "citeEndToken": 136, "sectionName": "UNKNOWN SECTION NAME", "string": "• We generalize cube pruning and adapt it to two systems very different from Hiero: a phrasebased system similar to Pharaoh (Koehn, 2004) and a tree-to-string system (Huang et al., 2006) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We push the idea behind this method further and make the following contributions in this paper:", "mid_sen": "• We generalize cube pruning and adapt it to two systems very different from Hiero: a phrasebased system similar to Pharaoh (Koehn, 2004) and a tree-to-string system (Huang et al., 2006) .", "after_sen": "• We also devise a faster variant of cube pruning, called cube growing, which uses a lazy version of k-best parsing (Huang and Chiang, 2005) that tries to reduce k to the minimum needed at each node to obtain the desired number of hypotheses at the root."}
{"citeStart": 206, "citeEnd": 220, "citeStartToken": 206, "citeEndToken": 220, "sectionName": "UNKNOWN SECTION NAME", "string": "Linguistic research has documented a wide range of regularities across the sound systems of the world's languages. It has been postulated earlier by functional phonologists that such regularities are the consequences of certain general principles like maximal perceptual contrast (Liljencrants and Lindblom, 1972) , which is desirable between the phonemes of a language for proper perception of each individ-ual phoneme in a noisy environment, ease of articulation (Lindblom and Maddieson, 1988; de Boer, 2000) , which requires that the sound systems of all languages are formed of certain universal (and highly frequent) sounds, and ease of learnability (de Boer, 2000) , which is necessary for a speaker to learn the sounds of a language with minimum effort. In fact, the organization of the vowel inventories (especially those with a smaller size) across languages has been satisfactorily explained in terms of the single principle of maximal perceptual contrast (Jakobson, 1941; Liljencrants and Lindblom, 1972; de Boer, 2000) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It has been postulated earlier by functional phonologists that such regularities are the consequences of certain general principles like maximal perceptual contrast (Liljencrants and Lindblom, 1972) , which is desirable between the phonemes of a language for proper perception of each individ-ual phoneme in a noisy environment, ease of articulation (Lindblom and Maddieson, 1988; de Boer, 2000) , which requires that the sound systems of all languages are formed of certain universal (and highly frequent) sounds, and ease of learnability (de Boer, 2000) , which is necessary for a speaker to learn the sounds of a language with minimum effort. ", "mid_sen": "In fact, the organization of the vowel inventories (especially those with a smaller size) across languages has been satisfactorily explained in terms of the single principle of maximal perceptual contrast (Jakobson, 1941; Liljencrants and Lindblom, 1972; de Boer, 2000) .", "after_sen": "On the other hand, in spite of several attempts (Lindblom and Maddieson, 1988; Boersma, 1998; Clements, 2004) the organization of the consonant inventories lacks a satisfactory explanation. "}
{"citeStart": 173, "citeEnd": 191, "citeStartToken": 173, "citeEndToken": 191, "sectionName": "UNKNOWN SECTION NAME", "string": "In the training stage, a feature vector is constructed for each sense-annotated word covered by a semantic model. The features are model-specific, and feature vectors are added to the training set pertaining to the corresponding model. The label of each such feature vector consists of the target word and the corresponding sense, represented as word#sense. Table 1 shows the number of feature vectors constructed in this learning stage for each semantic model. To annotate new text, similar vectors are created for all content-words in the raw text. Similar to the training stage, feature vectors are created and stored separately for each semantic model. Next, word sense predictions are made for all test examples, with a separate learning process run for each semantic model. For learning, we are using the Timbl memory based learning algorithm (Daelemans et al., 2001) , which was previously found useful for the task of word sense disambiguation (Hoste et al., 2002) , (Mihalcea, 2002) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Next, word sense predictions are made for all test examples, with a separate learning process run for each semantic model. ", "mid_sen": "For learning, we are using the Timbl memory based learning algorithm (Daelemans et al., 2001) , which was previously found useful for the task of word sense disambiguation (Hoste et al., 2002) , (Mihalcea, 2002) .", "after_sen": "Following the learning stage, each vector in the test data set is labeled with a predicted word and sense. "}
{"citeStart": 13, "citeEnd": 25, "citeStartToken": 13, "citeEndToken": 25, "sectionName": "UNKNOWN SECTION NAME", "string": "As noted in (Partee, 1984) , this analysis does not extend in a straightforward manner to cases in which the operator when is replaced by (an unrestricted) before or after, in such quantified contexts. Constructing a similar DRS for such sentences gives the wrong truth conditions. For example, Figure la shows a DRS for sentence 1, according to the principles above, rl -the reference time, used for the interpretation of the main clause is placed in the universe of the antecedent box. Because the temporal connective is 'before', rl is restricted to lie before el. The embedding conditions determine, that this reference time be universally quantified over, causing an erroneous reading in which for each event, el, of John's calling, for each earlier time rl, he lights up a cigarette. Paraphrasing this, we could say that John lights up cigarettes at all times preceding each phone call, not just once preceding each phone call. We did not encounter this problem in the DRS in Figure 4 , since although the reference time rl, is universally quantified over in that DRS as well, it is also restricted, to immediately follow el. It is similarly restricted if 'before' is replaced with 'just before' or 'ten minutes before'. But, (unrestricted) 'before' is analyzed as 'some time before', and thus the problem arises. We will henceforth informally refer to this problem as Partee's quantification problem. Partee (1984) suggests that in these cases we somehow have to insure that the reference time, rz, appears in the universe of the consequent DRS, causing it to be existentially quantified over, giving the desired interpretation. De Swart (1991) notes that simply moving rl to the right-hand box does not agree with Hinrichs' assumption, that temporal clauses are processed before the main clause, since they update the reference time, with respect to which the main clause will be inter-preted. In our proposed solution, the 'reference time' is indeed moved to the right box, but it is a different notion of reference time, and (as will be shown) exempt from this criticism.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "As noted in (Partee, 1984) , this analysis does not extend in a straightforward manner to cases in which the operator when is replaced by (an unrestricted) before or after, in such quantified contexts. ", "after_sen": "Constructing a similar DRS for such sentences gives the wrong truth conditions. "}
{"citeStart": 186, "citeEnd": 200, "citeStartToken": 186, "citeEndToken": 200, "sectionName": "UNKNOWN SECTION NAME", "string": "This paper investigates the relationship between Context-Free Grammar (CFG) parsing and the Eisner/Satta PBDG parsing algorithms, including their extension to second-order PBDG parsing (McDonald, 2006; McDonald and Pereira, 2006) . Specifically, we show how to use an off-line preprocessing step, the Unfold-Fold transformation, to transform a PBDG into an equivalent CFG that can be parsed in O(n 3 ) time using a version of the CKY algorithm with suitable indexing (Younger, 1967) , and extend this transformation so that it captures second-order PBDG dependencies as well. The transformations are ambiguity-preserving, i.e., there is a one-toone mapping between dependency parses and CFG parses, so it is possible to map the CFG parses back to the PBDG parses they correspond to.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Second, Eisner-Satta O(n 3 ) PBDG parsing algorithms are extremely fast (Eisner, 1996; Eisner and Satta, 1999; Eisner, 2000) .", "mid_sen": "This paper investigates the relationship between Context-Free Grammar (CFG) parsing and the Eisner/Satta PBDG parsing algorithms, including their extension to second-order PBDG parsing (McDonald, 2006; McDonald and Pereira, 2006) . ", "after_sen": "Specifically, we show how to use an off-line preprocessing step, the Unfold-Fold transformation, to transform a PBDG into an equivalent CFG that can be parsed in O(n 3 ) time using a version of the CKY algorithm with suitable indexing (Younger, 1967) , and extend this transformation so that it captures second-order PBDG dependencies as well. "}
{"citeStart": 68, "citeEnd": 81, "citeStartToken": 68, "citeEndToken": 81, "sectionName": "UNKNOWN SECTION NAME", "string": "For compound splitting, we follow Fritzinger and Fraser (2010), using linguistic knowledge en-coded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. Other approaches use less deep linguistic resources (e.g., POS-tags Stymne (2008) ) or are (almost) knowledge-free (e.g., Koehn and Knight (2003) ). Compound merging is less well studied. Popovic et al. (2006) used a simple, list-based merging approach, merging all consecutive words included in a merging list. This approach resulted in too many compounds. We follow Stymne and Cancedda (2011), for compound merging. We trained a CRF using (nearly all) of the features they used and found their approach to be effective (when combined with inflection and portmanteau merging) on one of our two test sets.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For compound splitting, we follow Fritzinger and Fraser (2010), using linguistic knowledge en-coded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. ", "mid_sen": "Other approaches use less deep linguistic resources (e.g., POS-tags Stymne (2008) ) or are (almost) knowledge-free (e.g., Koehn and Knight (2003) ). ", "after_sen": "Compound merging is less well studied. "}
{"citeStart": 206, "citeEnd": 226, "citeStartToken": 206, "citeEndToken": 226, "sectionName": "UNKNOWN SECTION NAME", "string": "Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31) . A similar method is included in PATR-II (Shieber et al. 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994 ). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31) . ", "mid_sen": "A similar method is included in PATR-II (Shieber et al. 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994 ). ", "after_sen": "The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules."}
{"citeStart": 111, "citeEnd": 132, "citeStartToken": 111, "citeEndToken": 132, "sectionName": "UNKNOWN SECTION NAME", "string": "Question Answering (QA) is an IR task where the major complexity resides in question processing and answer extraction (Chen et al., 2006; Collins-Thompson et al., 2004) rather than document retrieval (a step usually carried out by off-the shelf IR engines). In question processing, useful information is gathered from the question and a query is created. This is submitted to an IR module, which provides a ranked list of relevant documents. From these, the QA system extracts one or more candidate answers, which can then be re-ranked following various criteria. Although typical methods are based exclusively on word similarity between query and answer, recent work, e.g. (Shen and Lapata, 2007) has shown that shallow semantic information in the form of predicate argument structures (PASs) improves the automatic detection of correct answers to a target question. In (Moschitti et al., 2007) , we proposed the Shallow Semantic Tree Kernel (SSTK) designed to encode PASs 1 in SVMs. 1 in PropBank format, (www.cis.upenn.edu/˜ace).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "From these, the QA system extracts one or more candidate answers, which can then be re-ranked following various criteria. ", "mid_sen": "Although typical methods are based exclusively on word similarity between query and answer, recent work, e.g. (Shen and Lapata, 2007) has shown that shallow semantic information in the form of predicate argument structures (PASs) improves the automatic detection of correct answers to a target question. ", "after_sen": "In (Moschitti et al., 2007) , we proposed the Shallow Semantic Tree Kernel (SSTK) designed to encode PASs 1 in SVMs. "}
{"citeStart": 10, "citeEnd": 32, "citeStartToken": 10, "citeEndToken": 32, "sectionName": "UNKNOWN SECTION NAME", "string": "For our simple unigram language model without clustering, the training corpus perplexity is minimized (and its likelihood is maximized) by assigning each word wi a probability Pi = fi/N, where f/ is the frequency of wi and N is the total size of the corpus. The corpus likelihood is then P1 = l-[i P{', and the per-word entropy, -Y'],L,, pilog(pi), is thus minimized. (See e.g. Cover and Thomas, 1991 , chapter 2 for the reasoning behind this).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The corpus likelihood is then P1 = l-[i P{', and the per-word entropy, -Y'],L,, pilog(pi), is thus minimized. ", "mid_sen": "(See e.g. Cover and Thomas, 1991 , chapter 2 for the reasoning behind this).", "after_sen": "If now we model the language as consisting of sentences drawn at random from K different subpopulations, each with its own unigram probability distribution for words, then the estimated corpus probability is P~ = I-I~j ~ck qk l-I~,~j pk,~"}
{"citeStart": 51, "citeEnd": 65, "citeStartToken": 51, "citeEndToken": 65, "sectionName": "UNKNOWN SECTION NAME", "string": "Many theories of semantic interpretation use A-term manipulation to compositionally compute the meaning of a sentence. These theories are usually implemented in a language such as Prolog that can simulate A-term operations with first-order unification. However, there are cases in which this can only be done by obscuring the underlying linguistic theory with the \"tricks\" needed for implementation. For example, Combinatory Categorial Grammar (CCG) (Steedman, 1990 ) is a theory of syntax and semantic interpretation that has the attractive characteristic of handling many coordination constructs that other theories cannot. While many aspects of CCG semantics can be reasonably simulated in first-order unification, the simulation breaks down on some of the most interesting cases that CCG can theoretically handle. The problem in general, and for CCG in particular, is that the implementation language does not have sufficient expressive power to allow a more direct encoding. The solution given in this paper is to show how advances in logic programming allow the implementation of semantic theories in a very direct and natural way, using CCG as a case study.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, there are cases in which this can only be done by obscuring the underlying linguistic theory with the \"tricks\" needed for implementation. ", "mid_sen": "For example, Combinatory Categorial Grammar (CCG) (Steedman, 1990 ) is a theory of syntax and semantic interpretation that has the attractive characteristic of handling many coordination constructs that other theories cannot. ", "after_sen": "While many aspects of CCG semantics can be reasonably simulated in first-order unification, the simulation breaks down on some of the most interesting cases that CCG can theoretically handle. "}
{"citeStart": 224, "citeEnd": 234, "citeStartToken": 224, "citeEndToken": 234, "sectionName": "UNKNOWN SECTION NAME", "string": "Specifically, we examine the strength of association between the verb and the noun constituent of a combination (the target expression or its lexical variants) as an indirect cue to its idiomaticity, an approach inspired by Lin (1999) . We use the automatically built thesaurus of Lin (1998) to find words similar to each constituent, in order to automatically generate variants. Variants are generated by replacing either", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We expect a lexically fixed verb+noun combination to appear much more frequently than its variants in general.", "mid_sen": "Specifically, we examine the strength of association between the verb and the noun constituent of a combination (the target expression or its lexical variants) as an indirect cue to its idiomaticity, an approach inspired by Lin (1999) . ", "after_sen": "We use the automatically built thesaurus of Lin (1998) to find words similar to each constituent, in order to automatically generate variants. "}
{"citeStart": 152, "citeEnd": 168, "citeStartToken": 152, "citeEndToken": 168, "sectionName": "UNKNOWN SECTION NAME", "string": "DICTEX We extend the phrase table with entries from a manually created dictionary -the English glosses of the Buckwalter Arabic morphological analyzer (Buckwalter, 2004) . For each analysis of an OOV word, we expand the English lemma gloss to all its possible surface forms. The newly generated pairs are equally assigned very low translation probabilities that do not interfere with the rest of the phrase table.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We do not handle misspellings involving two words attached to each other or multiple types of single letter errors in the same word.", "mid_sen": "DICTEX We extend the phrase table with entries from a manually created dictionary -the English glosses of the Buckwalter Arabic morphological analyzer (Buckwalter, 2004) . ", "after_sen": "For each analysis of an OOV word, we expand the English lemma gloss to all its possible surface forms. "}
{"citeStart": 91, "citeEnd": 113, "citeStartToken": 91, "citeEndToken": 113, "sectionName": "UNKNOWN SECTION NAME", "string": "Tag Sets. We used the POS tag set described by Kulick, Gabbard, and Marcus (2006) . We previously showed that the \"Kulick\" tag set is very effective for basic Arabic parsing (Green and Manning 2010) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We used the POS tag set described by Kulick, Gabbard, and Marcus (2006) . ", "mid_sen": "We previously showed that the \"Kulick\" tag set is very effective for basic Arabic parsing (Green and Manning 2010) .", "after_sen": "MWE Tagging. "}
{"citeStart": 62, "citeEnd": 87, "citeStartToken": 62, "citeEndToken": 87, "sectionName": "UNKNOWN SECTION NAME", "string": "I now show that the question whether the intersection of a FSA and an off-line parsable DCG is empty is undecidable. A yes-no problem is undecidable (cf. (Hopcroft and Ullman, 1979, pp.178-179) ) if there is no algorithm that takes as its input an instance of the problem and determines whether the answer to that instance is 'yes' or 'no'. An instance of a problem consists of a particular choice of the parameters of that problem. I use Post's Correspondence Problem (PCP) as a well-known undecidable problem. I show that if the above mentioned intersection problem were decidable, then we could solve the PCP too. The following definition and example of a PCP are taken from (Hopcroft and Ullman, 1979) The sequence il, • •., im is a solution to this instance of PCP. As an example, assume that :C = {0,1}. Furthermore, let A = (1, 10111, 10) and B = 011, 10, 0). A solution to this instance of PCP is the sequence 2,1,1,3 (obtaining the sequence 10111Ul0). For an illustration, cf. figure 3.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "I show that if the above mentioned intersection problem were decidable, then we could solve the PCP too. ", "mid_sen": "The following definition and example of a PCP are taken from (Hopcroft and Ullman, 1979) The sequence il, • •., im is a solution to this instance of PCP. ", "after_sen": "As an example, assume that :C = {0,1}. "}
{"citeStart": 9, "citeEnd": 27, "citeStartToken": 9, "citeEndToken": 27, "sectionName": "UNKNOWN SECTION NAME", "string": "Although Schabes (1991:107) claims that the problem of exponential grammar complexity \"is particularly acute for natural language processing since in this context the input length is typically small (10-20 words) and the grammar size very large (hundreds or thousands of rules and symbols)\", the experiments indicate that, with a widecoverage NL grammar, inputs of this length can be parsed quite quickly; however, longer inputs (of more than about 30 words in length)--which occur relatively frequently in written text--are a problem. Unless grammar size takes on proportionately much more significance for such louger inputs, which seems implausible, it appears that in fact the major problems do not lie in the area of grammar size, but in input length.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This suggests that, when considering the complexity of parsers, the issue of parse table size is of minor importance for realistic NL grammars (as long as an implementation rep-resents the table compactly), and that improvements to complexity results with respect to grammar size, although interesting from a theoretical standpoint, may have little practical relevance for the processing of natural language.", "mid_sen": "Although Schabes (1991:107) claims that the problem of exponential grammar complexity \"is particularly acute for natural language processing since in this context the input length is typically small (10-20 words) and the grammar size very large (hundreds or thousands of rules and symbols)\", the experiments indicate that, with a widecoverage NL grammar, inputs of this length can be parsed quite quickly; however, longer inputs (of more than about 30 words in length)--which occur relatively frequently in written text--are a problem. ", "after_sen": "Unless grammar size takes on proportionately much more significance for such louger inputs, which seems implausible, it appears that in fact the major problems do not lie in the area of grammar size, but in input length."}
{"citeStart": 81, "citeEnd": 92, "citeStartToken": 81, "citeEndToken": 92, "sectionName": "UNKNOWN SECTION NAME", "string": "Research on automatic text simplification aims at developing techniques and tools that could make texts more comprehensible for certain types of targeted audience/readers. The mainstream of text simplification is developing methodologies and tools for general types of texts that address people with special needs, such as poor literacy readers (Aluisio et al. 2010) , readers with mild cognitive impairment (Dell'Orletta et al., 2011) , elderly people (Bott et al., 2012) , language learners of different levels (Crossley and McNamara, 2008) or just \"regular\" readers (Graesser et al., 2004) . Text simplification is most often performed on the sentence level. Simplifying texts to provide more comprehensible input to a targeted audience the developers generally work within two approaches: an intuitive approach and a structural approach. An intuitive approach relies mainly on the developers' intuition and experience (Allen, 2009 ) that leads to using less lexical diversity, less sophisticated words, less syntactic complexity, and greater cohesion. A structural approach depends on the use of structure and word lists that are predefined by the intelligence level, as typically found in targeted readers. The latter is defined by readability formulas. Traditional readability formulas are simple algorithms that measure text readability based on sentence length and word length. Later research on readability suggests formulas that reflect the psycholinguistic and cognitive processes of reading (Crossley et al.2011) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Simplifying texts to provide more comprehensible input to a targeted audience the developers generally work within two approaches: an intuitive approach and a structural approach. ", "mid_sen": "An intuitive approach relies mainly on the developers' intuition and experience (Allen, 2009 ) that leads to using less lexical diversity, less sophisticated words, less syntactic complexity, and greater cohesion. ", "after_sen": "A structural approach depends on the use of structure and word lists that are predefined by the intelligence level, as typically found in targeted readers. "}
{"citeStart": 227, "citeEnd": 259, "citeStartToken": 227, "citeEndToken": 259, "sectionName": "UNKNOWN SECTION NAME", "string": "• use of low level knowledge from the speech recognition phase, • use of high level knowledge about the domain in particular and the dialogue task in general, • a \"continue\" facility and an \"auto-loop\" facility as described by Biermann and Krishnaswamy (1976) , • a \"conditioning\" facility as described by Fink et al. (1985) , • implementation of new types of paraphrasing, • checking a larger environment in the expectation acquisition algorithm when deciding if an incoming sentence is the same or similar to one already seen, and • examining inter-speaker dialogue patterns.", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "These include the following:", "mid_sen": "• use of low level knowledge from the speech recognition phase, • use of high level knowledge about the domain in particular and the dialogue task in general, • a \"continue\" facility and an \"auto-loop\" facility as described by Biermann and Krishnaswamy (1976) , • a \"conditioning\" facility as described by Fink et al. (1985) , • implementation of new types of paraphrasing, • checking a larger environment in the expectation acquisition algorithm when deciding if an incoming sentence is the same or similar to one already seen, and • examining inter-speaker dialogue patterns.", "after_sen": "All but two of these areas for expansion are aimed at moving the expectation system from one that finds patterns in a user's dialogues and acquires historical knowledge about them to one that can acquire true procedures. "}
{"citeStart": 66, "citeEnd": 80, "citeStartToken": 66, "citeEndToken": 80, "sectionName": "UNKNOWN SECTION NAME", "string": "Such a rich graphical model can represent many dependencies but there are two dangers-one is that the computational complexity of training the model and searching for the most likely labeling given the tree can be prohibitive, and the other is that if too many dependencies are encoded, the model will over-fit the training data and will not generalize well. We propose a model which circumvents these two dangers and achieves significant performance gains over a similar local model that does not add any dependency arcs among the random variables. To tackle the efficiency problem, we adopt dynamic programming and re-ranking algorithms. To avoid overfitting we encode only a small set of linguistically motivated dependencies in features over sets of the random variables. Our re-ranking approach, like the approach to parse re-ranking of Collins (2000) , employs a simpler model-a local semantic role labeling algorithm-as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes. The joint model is restricted to these n assignments and does not have to search the exponentially large space of all possible joint labelings.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "To avoid overfitting we encode only a small set of linguistically motivated dependencies in features over sets of the random variables. ", "mid_sen": "Our re-ranking approach, like the approach to parse re-ranking of Collins (2000) , employs a simpler model-a local semantic role labeling algorithm-as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes. ", "after_sen": "The joint model is restricted to these n assignments and does not have to search the exponentially large space of all possible joint labelings."}
{"citeStart": 117, "citeEnd": 134, "citeStartToken": 117, "citeEndToken": 134, "sectionName": "UNKNOWN SECTION NAME", "string": "The fact that the annotators are good at determining AIM sentences is an important result: as AIM sentences constitute the best characterisation of the research paper for the summarisation task at a very high compression to 1.8% of the original text length, we are particularly interested in having them annotated consistently in our training material. This result is clearly in contrast to studies which conclude that humans are not very reliable at this kind of task (Rath et al., 1961) . We attribute this difference to a difference in our instructions. Whereas the subjects in Rath et al.'s experiment were asked to look for the most relevant sentences, our annotators had to look for specific argumentative roles which seems to have eased the task. In addition, our guidelines give very specific instructions for ambiguous cases.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The fact that the annotators are good at determining AIM sentences is an important result: as AIM sentences constitute the best characterisation of the research paper for the summarisation task at a very high compression to 1.8% of the original text length, we are particularly interested in having them annotated consistently in our training material. ", "mid_sen": "This result is clearly in contrast to studies which conclude that humans are not very reliable at this kind of task (Rath et al., 1961) . ", "after_sen": "We attribute this difference to a difference in our instructions. "}
{"citeStart": 89, "citeEnd": 100, "citeStartToken": 89, "citeEndToken": 100, "sectionName": "UNKNOWN SECTION NAME", "string": "This line of research was motivated by a series of successful applications of mutual information statistics to other problems in natural language processing. In the last decade, research in speech recognition (Jelinek 1985) , noun classification (Hindle 1988) , predicate argument relations (Church & Hanks 1989) , and other areas have shown that mutual information statistics provide a wealth of information for solving these problems.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This line of research was motivated by a series of successful applications of mutual information statistics to other problems in natural language processing. ", "mid_sen": "In the last decade, research in speech recognition (Jelinek 1985) , noun classification (Hindle 1988) , predicate argument relations (Church & Hanks 1989) , and other areas have shown that mutual information statistics provide a wealth of information for solving these problems.", "after_sen": ""}
{"citeStart": 0, "citeEnd": 15, "citeStartToken": 0, "citeEndToken": 15, "sectionName": "UNKNOWN SECTION NAME", "string": "Starting from a set of texts and a lexicon, the XPOST looks up all words in the texts and assigns to them a set of one or more readings. The words are then classified into so-called ambiguity classes according to which set of readings they have been assigned. The training is performed on ambiguity classes and not on individual word tokens. Kallgren (1996) gives a more covering description of how XPOST is used on the Swedish material and also sketches the major differences between this algorithm and some others used for tagging, such as PARTS (Church 1988) and VOLSUNGA (DeRose 1988) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The training is performed on ambiguity classes and not on individual word tokens. ", "mid_sen": "Kallgren (1996) gives a more covering description of how XPOST is used on the Swedish material and also sketches the major differences between this algorithm and some others used for tagging, such as PARTS (Church 1988) and VOLSUNGA (DeRose 1988) .", "after_sen": "A characteristic tbature of the SUC is its high number of different tags. "}
{"citeStart": 474, "citeEnd": 493, "citeStartToken": 474, "citeEndToken": 493, "sectionName": "UNKNOWN SECTION NAME", "string": "It seems that we should be able to use a function ¢ to assign any probability distribution to the strings in L(G) and then expect that we can assign appropriate probabilites to the adjunctions in G such that the language generated by G has the same distribution as that given by ¢. However a function ¢ that grows smaller by repeated multiplication as the inverse of an exponential function cannot be matched by any TAG because of the constant growth property of TAGs (see (Vijay-Shanker, 1987) , p. 104). An example of such a function ¢ is a simple Poisson distribution (2), which in fact was also used as the counterexample in (Booth and Thompson, 1973) for CFGs, since CFGs also have the constant growth property.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "L(G) = {anbncndnln > 1}", "mid_sen": "It seems that we should be able to use a function ¢ to assign any probability distribution to the strings in L(G) and then expect that we can assign appropriate probabilites to the adjunctions in G such that the language generated by G has the same distribution as that given by ¢. However a function ¢ that grows smaller by repeated multiplication as the inverse of an exponential function cannot be matched by any TAG because of the constant growth property of TAGs (see (Vijay-Shanker, 1987) , p. 104). ", "after_sen": "An example of such a function ¢ is a simple Poisson distribution (2), which in fact was also used as the counterexample in (Booth and Thompson, 1973) for CFGs, since CFGs also have the constant growth property."}
{"citeStart": 46, "citeEnd": 70, "citeStartToken": 46, "citeEndToken": 70, "sectionName": "UNKNOWN SECTION NAME", "string": "The results also show that lexical information improves the performance by nearly 2%. This is similar to results in the literature (Ramshaw and Marcus, 1995) . What we found surprising is that the second predictor, that uses additional information about the OIB status of the local context, did not do much better than the first predictor, which relies only on POS and lexical information. A control experiment has verified that this is not due to the noisy features that the first predictor supplies to the second predictor.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The results also show that lexical information improves the performance by nearly 2%. ", "mid_sen": "This is similar to results in the literature (Ramshaw and Marcus, 1995) . ", "after_sen": "What we found surprising is that the second predictor, that uses additional information about the OIB status of the local context, did not do much better than the first predictor, which relies only on POS and lexical information. "}
{"citeStart": 84, "citeEnd": 98, "citeStartToken": 84, "citeEndToken": 98, "sectionName": "UNKNOWN SECTION NAME", "string": "The grammar-dependent complexity of the LR parser makes it also appear intractable: Johnson (1989) shows that the number of LR(0) states for certain (pathological) grammars is exponentially related to the size of the grammar, and that there are some inputs which force an LR parser to visit all of these states in the course of a parse.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For the ANLT grammar, in which features are nested to a maximum depth of two, ICI is finite but nevertheless extremely large (Briscoe et al., 1987b) 4.", "mid_sen": "The grammar-dependent complexity of the LR parser makes it also appear intractable: Johnson (1989) shows that the number of LR(0) states for certain (pathological) grammars is exponentially related to the size of the grammar, and that there are some inputs which force an LR parser to visit all of these states in the course of a parse.", "after_sen": "aSchabes describes a table with no lookahead; the successful application of this technique supports Schabes' (1991:109) assertion that \"several other methods (such as LR(k)-like and SLR(k)-like) can also be used for constructing the parsing tables [...]\" aBarton, Berwick & Ristad (1987:221) calculate that GPSG, also with a maximum nesting depth of two, licences more than 10 rr5 distinct syntactic categories. "}
{"citeStart": 195, "citeEnd": 209, "citeStartToken": 195, "citeEndToken": 209, "sectionName": "UNKNOWN SECTION NAME", "string": "Northwest Airlines settled the remaining lawsuits filed on behalf of 156 people killed in a 1987 crash, but claims against the jetliner's maker are being pursued, a federal judge said. (\"Northwest Airlines Settles Rest of Suits,\" Wall Street Journal, November 1, 1989) A particular model of linguistic subjectivity underlies the current and past research in this area by Wiebe and colleagues. It is most fully presented in Wiebe and Rapaport (1986 , 1988 , 1991 and Wiebe (1990 Wiebe ( , 1994 . It was developed to support NLP research and combines ideas from several sources in fields outside NLP, especially linguistics and literary theory. The most direct influences on the model were Dolezel (1973) (types of subjectivity clues), Uspensky (1973) (types of point of view), Kuroda (1973 Kuroda ( , 1976 ) (pragmatics of point of view), Chatman (1978) (story versus discourse), Cohn (1978) (linguistic styles for presenting consciousness), Fodor (1979) (linguistic description of opaque contexts), and especially Banfield (1982) ", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It was developed to support NLP research and combines ideas from several sources in fields outside NLP, especially linguistics and literary theory. ", "mid_sen": "The most direct influences on the model were Dolezel (1973) (types of subjectivity clues), Uspensky (1973) (types of point of view), Kuroda (1973 Kuroda ( , 1976 ) (pragmatics of point of view), Chatman (1978) (story versus discourse), Cohn (1978) (linguistic styles for presenting consciousness), Fodor (1979) (linguistic description of opaque contexts), and especially Banfield (1982) ", "after_sen": ""}
{"citeStart": 155, "citeEnd": 166, "citeStartToken": 155, "citeEndToken": 166, "sectionName": "UNKNOWN SECTION NAME", "string": "We take a model-based approach to measure to what degree, if any, two document collections are different. A document is represented as a point in a V -dimensional space, where V is vocabulary size. Each coordinate is the frequency of a word in a document, i.e., term frequency. Although vector representation, commonly known as a bag of words, is oversimplified and ignores rich syntactic and semantic structures, more sophisticated representation requires more data to obtain reliable models. Practically, bag-of-word representation has been very effective in many tasks, including text categorization (Sebastiani, 2002) and information retrieval (Lewis, 1998) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Although vector representation, commonly known as a bag of words, is oversimplified and ignores rich syntactic and semantic structures, more sophisticated representation requires more data to obtain reliable models. ", "mid_sen": "Practically, bag-of-word representation has been very effective in many tasks, including text categorization (Sebastiani, 2002) and information retrieval (Lewis, 1998) .", "after_sen": "We assume that a collection of N documents, y 1 , y 2 , . . . , y N are sampled from the following process,"}
{"citeStart": 51, "citeEnd": 75, "citeStartToken": 51, "citeEndToken": 75, "sectionName": "UNKNOWN SECTION NAME", "string": "The automatic annotations were generateed using the Stanford Parser (Klein and Manning, 2003) in version 1.6.3 for NPs and possessive determiners. Proper nouns are detected using the SProUT system (Drożdżyński et al., 2004) with its generic named entity grammar for English. SProUT robustly recognizes inter alia person names and locations in MUC style in running text, without any domain-specific adaptations or extensions except for citations. For the detection of citations, we have created an elaborate regular expression that reliably matches all kinds of citation patterns.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The automatic annotations were generateed using the Stanford Parser (Klein and Manning, 2003) in version 1.6.3 for NPs and possessive determiners. ", "mid_sen": "Proper nouns are detected using the SProUT system (Drożdżyński et al., 2004) with its generic named entity grammar for English. ", "after_sen": "SProUT robustly recognizes inter alia person names and locations in MUC style in running text, without any domain-specific adaptations or extensions except for citations. "}
{"citeStart": 146, "citeEnd": 169, "citeStartToken": 146, "citeEndToken": 169, "sectionName": "UNKNOWN SECTION NAME", "string": "Secondly, the error analysis suggests that considering non-local dependencies would improve results. Categories that can be induced well (those characterized by local dependencies) could be input into procedures that learn phrase structure (e.g. (Brill and Marcus, 19925; Finch, 1993) ). These phrase constraints could then be incorporated into the distributional tagger to characterize non-local dependencies.", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Secondly, the error analysis suggests that considering non-local dependencies would improve results. ", "mid_sen": "Categories that can be induced well (those characterized by local dependencies) could be input into procedures that learn phrase structure (e.g. (Brill and Marcus, 19925; Finch, 1993) ). ", "after_sen": "These phrase constraints could then be incorporated into the distributional tagger to characterize non-local dependencies."}
{"citeStart": 19, "citeEnd": 42, "citeStartToken": 19, "citeEndToken": 42, "sectionName": "UNKNOWN SECTION NAME", "string": "Starting with (Flickinger et al., 1987) , testsuites have been drawn up from a linguistic viewpoint, \"in-]ormed by [the] study of linguistics and [reflecting] the grammatical issues that linguists have concerned themselves with\" (Flickinger et al., 1987, , p.4) . Although the question is not explicitly addressed in (Balkan et al., 1994) , all the testsuites reviewed there also seem to follow the same methodology. The TSNLP project (Lehmann and Oepen, 1996) and its successor DiET (Netter et al., 1998) , which built large multilingual testsuites, likewise fall into this category. The use of corpora (with various levels of annotation) has been studied, but even here the recommendations are that much manual work is required to turn corpus examples into test cases (e.g., (Balkan and Fouvry, 1995) ). The reason given is that corpus sentences neither contain linguistic phenomena in isolation, nor do they contain systematic variation. Corpora thus are used only as an inspiration. (Oepen and Flickinger, 1998) stress the interdependence between application and testsuite, but don't comment on the relation between grammar and testsuite.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Although the question is not explicitly addressed in (Balkan et al., 1994) , all the testsuites reviewed there also seem to follow the same methodology. ", "mid_sen": "The TSNLP project (Lehmann and Oepen, 1996) and its successor DiET (Netter et al., 1998) , which built large multilingual testsuites, likewise fall into this category. ", "after_sen": "The use of corpora (with various levels of annotation) has been studied, but even here the recommendations are that much manual work is required to turn corpus examples into test cases (e.g., (Balkan and Fouvry, 1995) ). "}
{"citeStart": 153, "citeEnd": 167, "citeStartToken": 153, "citeEndToken": 167, "sectionName": "UNKNOWN SECTION NAME", "string": "lective left-corner transform is followed by a onestep -removal transform i.e., composition or partial evaluation of schema 1b with respect to schema 1d Johnson, 1998a; Abney and Johnson, 1991; Resnik, 1992 , each top-down production from G appears unchanged in the nal grammar. Full -removal yields the grammar given by the schemata below.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "One-step -removal applied to LCLG produces a grammar in which each top-down production A ! corresponds to a production A ! in the transformed grammar.", "mid_sen": "lective left-corner transform is followed by a onestep -removal transform i.e., composition or partial evaluation of schema 1b with respect to schema 1d Johnson, 1998a; Abney and Johnson, 1991; Resnik, 1992 , each top-down production from G appears unchanged in the nal grammar. ", "after_sen": "Full -removal yields the grammar given by the schemata below."}
{"citeStart": 262, "citeEnd": 274, "citeStartToken": 262, "citeEndToken": 274, "sectionName": "UNKNOWN SECTION NAME", "string": "In NL analysis, the syntactic information associated with lexical items makes top-down parsing less attractive than bottom-up (e.g. CKY; Kasami, 1965; Younger, 1967) , although the latter is often augmented with top-down predic-tion to improve performance (e.g. Earley, 1970; Lang, 1974; Pratt, 1975) . Section 2 describes three unification-based parsers which are related to polynomial-complexity bottom-up CF parsing algorithms. Although incorporating unification increases their complexity to exponential on grammar size and input length (section 3), this appears to have little impact on practical performance (section 4). Sections 5 and 6 discuss these findings and present conclusions.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, parsing algorithms assume more importance for grammars having more substantial phrase structure components, such as CLARE (which although employing some HPSGlike analyses still contains several tens of rules) and the ANLT (which uses a formalism derived from GPSG; Gazdar et al., 1985) , sincethe more specific rule set can be used to control which unifications are performed.", "mid_sen": "In NL analysis, the syntactic information associated with lexical items makes top-down parsing less attractive than bottom-up (e.g. CKY; Kasami, 1965; Younger, 1967) , although the latter is often augmented with top-down predic-tion to improve performance (e.g. Earley, 1970; Lang, 1974; Pratt, 1975) . ", "after_sen": "Section 2 describes three unification-based parsers which are related to polynomial-complexity bottom-up CF parsing algorithms. "}
{"citeStart": 106, "citeEnd": 116, "citeStartToken": 106, "citeEndToken": 116, "sectionName": "UNKNOWN SECTION NAME", "string": "Then, a(w, w') is s(w').a(P(w), w'). The word significance s(w) E [0, 1] is defined as the normalized information of the word w in the corpus [West, 1953] . For example, the word red appears 2,308 times in the 5,487,056-word corpus, and the word and appears 106,064 times. So, s(red) and s(and) are computed as follows:", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Then, a(w, w') is s(w').a(P(w), w'). ", "mid_sen": "The word significance s(w) E [0, 1] is defined as the normalized information of the word w in the corpus [West, 1953] . ", "after_sen": "For example, the word red appears 2,308 times in the 5,487,056-word corpus, and the word and appears 106,064 times. "}
{"citeStart": 104, "citeEnd": 121, "citeStartToken": 104, "citeEndToken": 121, "sectionName": "UNKNOWN SECTION NAME", "string": "The probability model in NLG2 is a conditional distribution over V U * stop,, where V is the generation vocabulary and where .stop. is a special \"stop\" symbol. The generation vocabulary V consists of all the words seen in the training data. The form of the maximum entropy probability model is identical to the one used in (Berger et al., 1996; Ratnaparkhi, 1998) :", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The generation vocabulary V consists of all the words seen in the training data. ", "mid_sen": "The form of the maximum entropy probability model is identical to the one used in (Berger et al., 1996; Ratnaparkhi, 1998) :", "after_sen": "k f$(wi ,wi-1 ,wi-2,at~ri) YIj=I Otj p(wilwi-l, wi-2,attri) = Z(Wi-l, wi-2, attri) k to t j=l"}
{"citeStart": 46, "citeEnd": 59, "citeStartToken": 46, "citeEndToken": 59, "sectionName": "UNKNOWN SECTION NAME", "string": "This section introduces key concepts of LFG which are of interest in Sec. 5 and is necessarily very short. Further information can be found in Bresnan & Kaplan (1982) and Dalrymple et al. (1995) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This section introduces key concepts of LFG which are of interest in Sec. 5 and is necessarily very short. ", "mid_sen": "Further information can be found in Bresnan & Kaplan (1982) and Dalrymple et al. (1995) .", "after_sen": "LFG posits several different representation levels, called projections. "}
{"citeStart": 45, "citeEnd": 70, "citeStartToken": 45, "citeEndToken": 70, "sectionName": "UNKNOWN SECTION NAME", "string": "Note that the experiments in (Carpuat and Wu, 2005) did not use a state-of-the-art MT system, while the experiments in (Vickrey et al., 2005) were not done using a full-fledged MT system and the evaluation was not on how well each source sentence was translated as a whole. The relatively small improvement reported by Cabezas and Resnik (2005) without a statistical significance test appears to be inconclusive. Considering the conflicting results reported by prior work, it is not clear whether a WSD system can help to improve the performance of a state-of-the-art statistical MT system.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Note that the experiments in (Carpuat and Wu, 2005) did not use a state-of-the-art MT system, while the experiments in (Vickrey et al., 2005) were not done using a full-fledged MT system and the evaluation was not on how well each source sentence was translated as a whole. ", "mid_sen": "The relatively small improvement reported by Cabezas and Resnik (2005) without a statistical significance test appears to be inconclusive. ", "after_sen": "Considering the conflicting results reported by prior work, it is not clear whether a WSD system can help to improve the performance of a state-of-the-art statistical MT system."}
{"citeStart": 151, "citeEnd": 173, "citeStartToken": 151, "citeEndToken": 173, "sectionName": "UNKNOWN SECTION NAME", "string": "In order to test the accuracy of our system (as developed so far) and to provide empirical feedback for further development, we took the Susanne, SEC (Taylor & Knowles, 1988) and LOB corpora (Garside et al., 1987)--a total of 1.2 million words--and extracted all sentences containing an occurrence of one of fourteen verbs, up to a maximum of 1000 citations of each. These verbs, listed in Figure 2 , were chosen at random, subject to the constraint that they exhibited multiple complementation patterns. The sentences containing these verbs were tagged and parsed automatically, and the extractor, classifier and evaluator were applied to the resulting successful analyses. The citations from which entries were derived totaled approximately 70K words. The results were evaluated against a merged entry for these verbs from the ANLT and COMLEX Syntax dictionaries, and also against a manual analysis of the corpus data for seven of the verbs. The process of evaluating the performance of the system relative to the dictionaries could, in principle, be reduced to an automated report of type precision (percentage of correct subcategorization classes to all classes found) and recall (perCentage of correct classes found in the dictionary entry). However, since there are disagreements between the dictionaries and there are classes found in the corpus data that are not contained in either dictionary, we report results relative both to a manually merged entry from ANLT and COMLEX, and also, for seven of the verbs, to a manual analysis of the actual corpus data. The latter analysis is necessary because precision and recall measures against the merged entry will still tend to yield inaccurate results as the system cannot acquire classes not exemplified in the data, and may acquire classes incorrectly absent from the dictionaries.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "In order to test the accuracy of our system (as developed so far) and to provide empirical feedback for further development, we took the Susanne, SEC (Taylor & Knowles, 1988) and LOB corpora (Garside et al., 1987)--a total of 1.2 million words--and extracted all sentences containing an occurrence of one of fourteen verbs, up to a maximum of 1000 citations of each. ", "after_sen": "These verbs, listed in Figure 2 , were chosen at random, subject to the constraint that they exhibited multiple complementation patterns. "}
{"citeStart": 51, "citeEnd": 72, "citeStartToken": 51, "citeEndToken": 72, "sectionName": "UNKNOWN SECTION NAME", "string": "BP4 marks them as context sentences. Therefore, we build a new corpus in which each explicit citation sentence is replaced with the same sentence attached to at most 4 sentence on each side. After building the context corpus, we use LexRank (Erkan and Radev, 2004) to generate 2 QA and 2 DP surveys using the citation sentences only, and the new context corpus explained above. LexRank is a multidocument summarization system, which first builds a cosine similarity graph of all the candidate sentences. Once the network is built, the system finds the most central sentences by performing a random walk on the graph. We limit these surveys to be of a maximum length of words. Table 8 shows a portion of the survey generated from the QA context corpus. This example shows how context sentences add meaningful and survey-worthy information along with citation sentences. Table 9 shows the Pyramid F β=3 score of automatic surveys of QA and DP data. The QA surveys are evaluated using nuggets drawn from citation texts (CT), or abstracts (AB), and DP surveys are evaluated using nuggets from citation texts (CT). In all evaluation instances the surveys generated with the context corpora excel at covering nuggets drawn from abstracts or citation sentences.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Therefore, we build a new corpus in which each explicit citation sentence is replaced with the same sentence attached to at most 4 sentence on each side. ", "mid_sen": "After building the context corpus, we use LexRank (Erkan and Radev, 2004) to generate 2 QA and 2 DP surveys using the citation sentences only, and the new context corpus explained above. ", "after_sen": "LexRank is a multidocument summarization system, which first builds a cosine similarity graph of all the candidate sentences. "}
{"citeStart": 82, "citeEnd": 97, "citeStartToken": 82, "citeEndToken": 97, "sectionName": "UNKNOWN SECTION NAME", "string": "One major challenge in relation extraction is due to the data sparseness problem (Zhou et al 2005) . As the largest annotated corpus in relation extraction, the ACE RDC 2003 corpus shows that different subtypes/types of relations are much unevenly distributed and a few relation subtypes, such as the subtype \"Founder\" under the type \"ROLE\", suffers from a small amount of annotated data. Further experimentation in this paper (please see Figure 2 ) shows that most relation subtypes suffer from the lack of the training data and fail to achieve steady performance given the current corpus size. Given the relative large size of this corpus, it will be time-consuming and very expensive to further expand the corpus with a reasonable gain in performance. Even if we can somehow expend the corpus and achieve steady performance on major relation subtypes, it will be still far beyond practice for those minor subtypes given the much unevenly distribution among different relation subtypes. While various machine learning approaches, such as generative modeling (Miller et al 2000) , maximum entropy (Kambhatla 2004) and support vector machines (Zhao and Grisman 2005; Zhou et al 2005) , have been applied in the relation extraction task, no explicit learning strategy is proposed to deal with the inherent data sparseness problem caused by the much uneven distribution among different relations.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Extraction of semantic relationships between entities can be very useful for applications such as question answering, e.g. to answer the query \"Who is the president of the United States?\".", "mid_sen": "One major challenge in relation extraction is due to the data sparseness problem (Zhou et al 2005) . ", "after_sen": "As the largest annotated corpus in relation extraction, the ACE RDC 2003 corpus shows that different subtypes/types of relations are much unevenly distributed and a few relation subtypes, such as the subtype \"Founder\" under the type \"ROLE\", suffers from a small amount of annotated data. "}
{"citeStart": 244, "citeEnd": 255, "citeStartToken": 244, "citeEndToken": 255, "sectionName": "UNKNOWN SECTION NAME", "string": "The most relevant prior work is (Wiebe et al. 98) , who dealt with meeting scheduling dialogs (see also (Alexandersson et al. 97) , (Busemann et al. 97)) , where the goal is to schedule a time for the meeting. The temporal references in meeting scheduling are somewhat more constrained than in news, where (e.g., in a historical news piece on toxic dumping) dates and times may be relatively unconstrained. In addition, their model requires the maintenance of a focus stack. They obtained roughly .91 Precision and .80 Recall on one test set, and .87 Precision and .68 Recall on another. However, they adjust the reference time during processing, which is something that we have not yet addressed. More recently, (Setzer and Gaizauskas 2000) have independently developed an annotation scheme which represents both time values and more fine-grained interevent and event-time temporal relations. Although our work is much more limited in scope, and doesn't exploit the internal structure of events, their annotation scheme may be leveraged in evaluating aspects of our work. The MUC-7 task (MUC-7 98) did not require VALs, but did test TIMEX recognition accuracy. Our 98 F-measure on NYT can be compared for just TIMEX with MUC-7 (MUC-7 1998) results on similar news stories, where the best performance was .99 Precision and .88 Recall. (The MUC task required recognizing a wider variety of TIMEXs, including event-dependent ones. However, at least 30% of the dates and times in the MUC test were fixed-format ones occurring in document headers, trailers, and copyright notices. ) Finally, there is a large body of work, e.g., (Moens and Steedman 1988) , (Passoneau 1988) , (Webber 1988) , (Hwang 1992) , (Song and Cohen 1991) , that has focused on a computational analysis of tense and aspect. While the work on event chronologies is based on some of the notions developed in that body of work, we hope to further exploit insights from previous work.", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "(The MUC task required recognizing a wider variety of TIMEXs, including event-dependent ones. ", "mid_sen": "However, at least 30% of the dates and times in the MUC test were fixed-format ones occurring in document headers, trailers, and copyright notices. ) Finally, there is a large body of work, e.g., (Moens and Steedman 1988) , (Passoneau 1988) , (Webber 1988) , (Hwang 1992) , (Song and Cohen 1991) , that has focused on a computational analysis of tense and aspect. ", "after_sen": "While the work on event chronologies is based on some of the notions developed in that body of work, we hope to further exploit insights from previous work."}
{"citeStart": 0, "citeEnd": 12, "citeStartToken": 0, "citeEndToken": 12, "sectionName": "UNKNOWN SECTION NAME", "string": "Recently, many people have looked at cascaded and/or shallow parsing and GR assignment. Abney (1991) is one of the first who proposed to split up parsing into several cascades. He suggests to first find the chunks and then the dependecies between these chunks. Grefenstette (1996) describes a cascade of finite-state transducers, which first finds noun and verb groups, then their heads, and finally syntactic functions. Brants and Skut (1998) describe a partially automated annotation tool which constructs a complete parse of a sentence by recursively adding levels to the tree. (Collins, 1997; Ratnaparkhi, 1997) use cascaded processing for full parsing with good results. Argamon et al. (1998) applied Memory-Based Sequence Learning (MBSL) to NP chunking and subject/object identification. However, their subject and object finders are independent of their chunker (i.e. not cascaded).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Recently, many people have looked at cascaded and/or shallow parsing and GR assignment. ", "mid_sen": "Abney (1991) is one of the first who proposed to split up parsing into several cascades. ", "after_sen": "He suggests to first find the chunks and then the dependecies between these chunks. "}
{"citeStart": 210, "citeEnd": 229, "citeStartToken": 210, "citeEndToken": 229, "sectionName": "UNKNOWN SECTION NAME", "string": "The technique shows practical promise. The territorial nial)s showu in ligm'es 1, 2, and 3 are intuitively une['ul tools for (lisplayiug what type a particular text is, compared with other existing texts. The technique denionstrated above has au obvious application in in-formatiol~ retrieval, for l)ieking out interesting texts, if (cutest based methods select a too large set for easy nlanipulation and browning (Cutting c/ al, 1992) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The territorial nial)s showu in ligm'es 1, 2, and 3 are intuitively une['ul tools for (lisplayiug what type a particular text is, compared with other existing texts. ", "mid_sen": "The technique denionstrated above has au obvious application in in-formatiol~ retrieval, for l)ieking out interesting texts, if (cutest based methods select a too large set for easy nlanipulation and browning (Cutting c/ al, 1992) .", "after_sen": "In any specific application area it will be unlikely t, hat the text datM)ase to be accessed will be completely free form. "}
{"citeStart": 182, "citeEnd": 195, "citeStartToken": 182, "citeEndToken": 195, "sectionName": "UNKNOWN SECTION NAME", "string": "A recent trend in natural language processing has been toward a greater emphasis on statistical approaches, beginning with the success of statistical part-of-speech tagging programs (Church 1988) , and continuing with other work using statistical part-of-speech tagging programs, such as BBN PLUM (Weischedel et al. 1993) and NYU Proteus (Grishman and Sterling 1993) . More recently, statistical methods have been applied to domain-specific semantic parsing (Miller et al. 1994) , and to the more difficult problem of wide-coverage syntactic parsing (Magerman 1995) . Nevertheless, most natural language systems remain primarily rule based, and even systems that do use statistical techniques, such as AT&T Chronus (Levin and Pieraccini 1995) , continue to require a significant rule based component.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A recent trend in natural language processing has been toward a greater emphasis on statistical approaches, beginning with the success of statistical part-of-speech tagging programs (Church 1988) , and continuing with other work using statistical part-of-speech tagging programs, such as BBN PLUM (Weischedel et al. 1993) and NYU Proteus (Grishman and Sterling 1993) . ", "mid_sen": "More recently, statistical methods have been applied to domain-specific semantic parsing (Miller et al. 1994) , and to the more difficult problem of wide-coverage syntactic parsing (Magerman 1995) . ", "after_sen": "Nevertheless, most natural language systems remain primarily rule based, and even systems that do use statistical techniques, such as AT&T Chronus (Levin and Pieraccini 1995) , continue to require a significant rule based component."}
{"citeStart": 0, "citeEnd": 28, "citeStartToken": 0, "citeEndToken": 28, "sectionName": "UNKNOWN SECTION NAME", "string": "Nonetheless, there is some cost that comes with the straightforward use of CRFs as a discriminative classifier in sentence compression; its outputs are often ungrammatical and it allows no control over the length of compression they generates (Nomoto, 2007) . We tackle the issues by harnessing CRFs with what we might call dependency truncation, whose goal is to restrict CRFs to working with candidates that conform to the grammar. Thus, unlike McDonald (2006) , Clarke and Lapata (2006) and Cohn and Lapata (2007) , we do not insist on finding a globally optimal solution in the space of 2 n possible compressions for an n word long sentence. Rather we insist on finding a most plausible compression among those that are explicitly warranted by the grammar.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We tackle the issues by harnessing CRFs with what we might call dependency truncation, whose goal is to restrict CRFs to working with candidates that conform to the grammar. ", "mid_sen": "Thus, unlike McDonald (2006) , Clarke and Lapata (2006) and Cohn and Lapata (2007) , we do not insist on finding a globally optimal solution in the space of 2 n possible compressions for an n word long sentence. ", "after_sen": "Rather we insist on finding a most plausible compression among those that are explicitly warranted by the grammar."}
{"citeStart": 135, "citeEnd": 147, "citeStartToken": 135, "citeEndToken": 147, "sectionName": "UNKNOWN SECTION NAME", "string": "This intuitive evidence can be backed up by considering garden path effects with quantifier scope tunbiguities (called jungle paths by Barwise 1987) . The original examples, such ~s the fbllowing, 9) Statistics show that every 11 seconds a man is mugged here in New York city. We are here today to interview hiln showed that preferences for a particular scope are established and are overturned. 'Po show that preferences are sometimes established before the end of' a sentence, and before a potential sentence end, we need to show ga.rden path effects in examples such as the following:", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "b Every gM in the class showed a rather strict new teacher the results of her attempt to get the grammar exercises correct.", "mid_sen": "This intuitive evidence can be backed up by considering garden path effects with quantifier scope tunbiguities (called jungle paths by Barwise 1987) . ", "after_sen": "The original examples, such ~s the fbllowing, 9) Statistics show that every 11 seconds a man is mugged here in New York city. "}
{"citeStart": 74, "citeEnd": 91, "citeStartToken": 74, "citeEndToken": 91, "sectionName": "UNKNOWN SECTION NAME", "string": "The Generative Programming approach to NLP infrastructure development will allow tools such as sentence boundary detectors, POS taggers, chunkers and named entity recognisers to be rapidly composed from many elemental components. For instance, implementing an efficient version of the MXPOST POS tagger (Ratnaparkhi, 1996) will simply involve composing and configuring the appropriate text file reading component, with the sequential tagging component, the collection of feature extraction components and the maximum entropy model component.", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The Generative Programming approach to NLP infrastructure development will allow tools such as sentence boundary detectors, POS taggers, chunkers and named entity recognisers to be rapidly composed from many elemental components. ", "mid_sen": "For instance, implementing an efficient version of the MXPOST POS tagger (Ratnaparkhi, 1996) will simply involve composing and configuring the appropriate text file reading component, with the sequential tagging component, the collection of feature extraction components and the maximum entropy model component.", "after_sen": "The individual components will provide state of the art accuracy and be highly optimised for both time and space efficiency. "}
{"citeStart": 91, "citeEnd": 111, "citeStartToken": 91, "citeEndToken": 111, "sectionName": "UNKNOWN SECTION NAME", "string": "As was pointed out above, one of the requirements in many techniques for automatic learning of part-ofspeech guessing rules is specially prepared training data --a pre-tagged training corpus, training examples, etc. In our approach we decided to reuse the data which come naturally with a tagger, viz. the lexicon. Another source of information which is used and which is not prepared specially for the task is a text corpus. Unlike other approaches we don't require the corpus to be pre-annotated but use it in its raw form. In our experiments we used the lexicon and word-frequencies derived from the Brown Corpus (Francis&Kucera, 1982) . There are a number of reasons for choosing the Brown Corpus data for training. The most important ones are that the Brown Corpus provides a model of general multi-domain language use, so general language regularities can be induced from it, and second, many taggers come with data trained on the Brown Corpus which is useful for comparison and evaluation. This, however, by no means restricts the described technique to that or any other tag-set, lexicon or corpus. Moreover, despite the fact that the training is performed on a particular lexicon and a particular corpus, the obtained guessing rules suppose to be domain and corpus independent and the only training-dependent feature is the tag-set in use.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Unlike other approaches we don't require the corpus to be pre-annotated but use it in its raw form. ", "mid_sen": "In our experiments we used the lexicon and word-frequencies derived from the Brown Corpus (Francis&Kucera, 1982) . ", "after_sen": "There are a number of reasons for choosing the Brown Corpus data for training. "}
{"citeStart": 297, "citeEnd": 322, "citeStartToken": 297, "citeEndToken": 322, "sectionName": "UNKNOWN SECTION NAME", "string": "In applying the grammar in generation we are faced with the problem of balancing over and undergeneration by tweaking grammatical constraints, there being no way to prefer fully grammatical target sentences over more marginal ones. Qualitative approaches to grammar tend to emphasize the ability to capl, uro generalizations as the main measure of success in linguistic modeling. This might explain why producing appropriate lexical collocations is rarely addressed seriously in these models, even though lexical collocations are important for fluent generation. '/'he study of collocations for generation fits in more naturally with sl.atistical techniques, as illustrated by Smajda and McKeown (1990) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Qualitative approaches to grammar tend to emphasize the ability to capl, uro generalizations as the main measure of success in linguistic modeling. ", "mid_sen": "This might explain why producing appropriate lexical collocations is rarely addressed seriously in these models, even though lexical collocations are important for fluent generation. '/'he study of collocations for generation fits in more naturally with sl.atistical techniques, as illustrated by Smajda and McKeown (1990) .", "after_sen": ""}
{"citeStart": 92, "citeEnd": 104, "citeStartToken": 92, "citeEndToken": 104, "sectionName": "UNKNOWN SECTION NAME", "string": "Our computational paradigm suggests using a SNoW based predictor as a building block that learns to perform each of the required predictions, and writing a simple program that activates these predictors with the appropriate input, aggregates their output and controls the interaction between the predictors. Two instantiations of this paradigm are studied and evaluated on two different shallow parsing tasksidentifying base NPs and SV phrases. The first instantiation of this para4igm uses predictors to decide whether each word belongs to the in-terior of a phrase or not, and then groups the words into phrases. The second instantiation finds the borders of phrases (beginning and end) and then pairs !them in an \"optimal\" way into different phrases. These problems formulations are similar to those studied in (Ramshaw and Marcus, 1995) and (Church, 1988; Argamon et al., 1998) , respectively.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The second instantiation finds the borders of phrases (beginning and end) and then pairs !them in an \"optimal\" way into different phrases. ", "mid_sen": "These problems formulations are similar to those studied in (Ramshaw and Marcus, 1995) and (Church, 1988; Argamon et al., 1998) , respectively.", "after_sen": "The experimental results presented using the SNoW based approach compare favorably with previously published results, both for NPs and SV phrases. "}
{"citeStart": 154, "citeEnd": 175, "citeStartToken": 154, "citeEndToken": 175, "sectionName": "UNKNOWN SECTION NAME", "string": "For languages that have articles, like English, we can use articles (\"the\", \"a\", and so on) to decide whether a noun phrase has an antecedent or not. Ill contrast, for languages that have no articles, like Japanese, it is difficult to decide whether a noun phrase has an antecedent. We previously estimated the referential properties of noun phrases that correspond to articles for the translation of Japanese noun phrases into English (Murata and Nagao 1993) . By using these referential properties, our system determines the referents of noun phrases in Japanese sentences. Noun phrases are classified by referential property into generic noun phrases, definite noun phrases, and indefinite noun phrases. When the referential property of a noun phrase is a definite noun phrase, the noun phrase can refer to the entity denoted by a noun phrase that has already appeared. When the referential property of a noun phrase is an indefinite noun phrase or a generic noun phrase, the noun phrase cannot refer to the entity denoted by a noun phrase that has already appeared.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Ill contrast, for languages that have no articles, like Japanese, it is difficult to decide whether a noun phrase has an antecedent. ", "mid_sen": "We previously estimated the referential properties of noun phrases that correspond to articles for the translation of Japanese noun phrases into English (Murata and Nagao 1993) . ", "after_sen": "By using these referential properties, our system determines the referents of noun phrases in Japanese sentences. "}
{"citeStart": 55, "citeEnd": 73, "citeStartToken": 55, "citeEndToken": 73, "sectionName": "UNKNOWN SECTION NAME", "string": "There have been a number of proposals to incorporate syntactic information into phrasal decoding. Early experiments with syntactically-informed phrases (Koehn et al., 2003) , and syntactic reranking of K-best lists (Och et al., 2004) produced mostly negative results. The most successful attempts at syntax-enhanced phrasal SMT have directly targeted movement modeling: Zens et al. (2004) modified a phrasal decoder with ITG constraints, while a number of researchers have employed syntax-driven source reordering before decoding begins (Xia and McCord, 2004; Collins et al., 2005; Wang et al., 2007) . 2 We attempt something between these two approaches: our constraint is derived from a linguistic parse tree, but it is used inside the decoder, not as a preprocessing step.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There have been a number of proposals to incorporate syntactic information into phrasal decoding. ", "mid_sen": "Early experiments with syntactically-informed phrases (Koehn et al., 2003) , and syntactic reranking of K-best lists (Och et al., 2004) produced mostly negative results. ", "after_sen": "The most successful attempts at syntax-enhanced phrasal SMT have directly targeted movement modeling: "}
{"citeStart": 185, "citeEnd": 201, "citeStartToken": 185, "citeEndToken": 201, "sectionName": "UNKNOWN SECTION NAME", "string": "Although there are several well-known spectral clustering algorithms in the literature (e.g., Weiss (1999) , Shi and Malik (2000) , Kannan et al. (2004) ), we adopt the one proposed by Ng et al. (2002) , as it is arguably the most widely-used. The algorithm takes as input a similarity matrix S created by applying a user-defined similarity function to each pair of data points. Below are the main steps of the algorithm:", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Although there are several well-known spectral clustering algorithms in the literature (e.g., Weiss (1999) , Shi and Malik (2000) , Kannan et al. (2004) ), we adopt the one proposed by Ng et al. (2002) , as it is arguably the most widely-used. ", "after_sen": "The algorithm takes as input a similarity matrix S created by applying a user-defined similarity function to each pair of data points. "}
{"citeStart": 94, "citeEnd": 108, "citeStartToken": 94, "citeEndToken": 108, "sectionName": "UNKNOWN SECTION NAME", "string": "This equivalence is doing essentially the same job as Pereira's pronoun abstraction schema in Pereira (1990) . It will identify a pronoun with any term of type e elsewhere in the QLF, relying on the binding conditions to prevent impossible associations.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Pron-he-intra Rest(~=~)=>~(Ay.Pred(y, he)) ~ Rest(~)=~(Ay.Pred(y,y)) if binding_conditions_hold ....", "mid_sen": "This equivalence is doing essentially the same job as Pereira's pronoun abstraction schema in Pereira (1990) . ", "after_sen": "It will identify a pronoun with any term of type e elsewhere in the QLF, relying on the binding conditions to prevent impossible associations."}
{"citeStart": 16, "citeEnd": 30, "citeStartToken": 16, "citeEndToken": 30, "sectionName": "UNKNOWN SECTION NAME", "string": "Collins et al. (Collins, 2001a; Collins, 2001b) proposed an efficient method to calculate Tree Kernel by using C(n 1 , n 2 ) as follows.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Collins et al. (Collins, 2001a; Collins, 2001b) proposed an efficient method to calculate Tree Kernel by using C(n 1 , n 2 ) as follows.", "after_sen": "• If the productions at n 1 and n 2 are different C(n 1 , n 2 ) = 0"}
{"citeStart": 102, "citeEnd": 128, "citeStartToken": 102, "citeEndToken": 128, "sectionName": "UNKNOWN SECTION NAME", "string": "is obtained efficiently by the Viterbi algorithm. The optimal set of parameters λ is determined efficiently by the Generalized Iterative Scaling (GIS) (Darroch and Ratcliff, 1972) or Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) (Nocedal and Wright, 1999) method.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "is obtained efficiently by the Viterbi algorithm. ", "mid_sen": "The optimal set of parameters λ is determined efficiently by the Generalized Iterative Scaling (GIS) (Darroch and Ratcliff, 1972) or Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) (Nocedal and Wright, 1999) method.", "after_sen": ""}
{"citeStart": 157, "citeEnd": 183, "citeStartToken": 157, "citeEndToken": 183, "sectionName": "UNKNOWN SECTION NAME", "string": "Looking first at the differences between these approaches to constructing distributional representations, it is reasonably clear that within each parser the worst performing models tend to be those based on bag-of-words contexts (BOW, SGnews and SG-bio). Of the neural embedding models, SENNA gets the best performance, which we attribute to its preservation of sequential order in handling context. Surprisingly, the Skip-gram model retrained on biomedical data (SG-bio) fared worse than the original (SG-news), due probably in large part to the fact that the original training data was almost 100 times larger than our 1.2B word corpus. The ngram contexts achieved the best F-Scores fairly consistently for all parsers, vindicating our appeal to the psycholinguistic research of Cartwright and Brent (1997), Mintz (2003) and Redington et al. (1998) .", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Surprisingly, the Skip-gram model retrained on biomedical data (SG-bio) fared worse than the original (SG-news), due probably in large part to the fact that the original training data was almost 100 times larger than our 1.2B word corpus. ", "mid_sen": "The ngram contexts achieved the best F-Scores fairly consistently for all parsers, vindicating our appeal to the psycholinguistic research of Cartwright and Brent (1997), Mintz (2003) and Redington et al. (1998) .", "after_sen": "Turning now to each parser individually, the baseline performance of the Berkeley Parser proved difficult to exceed, with only the 2gram distributional contexts giving any improvement. "}
{"citeStart": 86, "citeEnd": 95, "citeStartToken": 86, "citeEndToken": 95, "sectionName": "UNKNOWN SECTION NAME", "string": "Next, we can rank all the sentences by adopting the multi-manifold ranking algorithm (Wan, 2009) , in which the ranking function F is to be learned from k W (1≤k≤N tu ) and Y. In this study, the constraints from k S (1 ≤ k ≤N tu ) and Y are naturally fused in a regularized optimization framework defined by the following cost function.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We also define a prior vector Y = [y 0 ,…, y n ] T , in which y =1 for the k-th interest aspect p k and y i =0 (1≤i≤n) for all the remaining sentences.", "mid_sen": "Next, we can rank all the sentences by adopting the multi-manifold ranking algorithm (Wan, 2009) , in which the ranking function F is to be learned from k W (1≤k≤N tu ) and Y. ", "after_sen": "In this study, the constraints from k S (1 ≤ k ≤N tu ) and Y are naturally fused in a regularized optimization framework defined by the following cost function."}
{"citeStart": 327, "citeEnd": 343, "citeStartToken": 327, "citeEndToken": 343, "sectionName": "UNKNOWN SECTION NAME", "string": "We compare the results for the 1911 and 1987 Roget's Thesauri with a variety of WordNet-based semantic relatedness measures -see Table 5 . We consider 10 measures, noted in the table as J&C (Jiang and Conrath, 1997) , Resnik (Resnik, 1995) , Lin (Lin, 1998) , W&P (Wu and Palmer, 1994) , L&C (Leacock and Chodorow, 1998) , H&SO (Hirst and St-Onge, 1998) , Path (counts edges between synsets), Lesk (Banerjee and Pedersen, 2002) , and finally Vector and Vector Pair (Patwardhan, 2003) . The latter two work with large vectors of cooccurring terms from a corpus, so WordNet is only part of the system. We used Pedersen's Semantic Distance software package (Pedersen et al., 2004) .", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We compare the results for the 1911 and 1987 Roget's Thesauri with a variety of WordNet-based semantic relatedness measures -see Table 5 . ", "mid_sen": "We consider 10 measures, noted in the table as J&C (Jiang and Conrath, 1997) , Resnik (Resnik, 1995) , Lin (Lin, 1998) , W&P (Wu and Palmer, 1994) , L&C (Leacock and Chodorow, 1998) , H&SO (Hirst and St-Onge, 1998) , Path (counts edges between synsets), Lesk (Banerjee and Pedersen, 2002) , and finally Vector and Vector Pair (Patwardhan, 2003) . ", "after_sen": "The latter two work with large vectors of cooccurring terms from a corpus, so WordNet is only part of the system. "}
{"citeStart": 57, "citeEnd": 68, "citeStartToken": 57, "citeEndToken": 68, "sectionName": "UNKNOWN SECTION NAME", "string": "The basic task we consider in this paper is that of using spoken language to give commands to a semiautonomous robot or other similar system. As evidence of the importance of this task in the NLP community note that the early, influential system SHRDLU (Winograd, 1973) was intended to address just this type of problem. More recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot (Konolige et al., 1993) and NCARArs InterBOT project (Perzanowski et al., 1998; Perzanowski et al., 1999) . A number of other systems have addressed part of the task. Com-mandTalk (Moore et al., 1997) , Circuit Fix-It Shop (Smith, 1997) and (Traum and Allen, 1994; Tranm and Andersen, 1999) are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents. Jack's MOOse Lodge (Badler et al., 1999 ) takes text rather than speech as natural language input and the avatars being controlled are not semi-autonomous. Other researchers have considered particular aspects of the problem such as accounting for various aspects of actions (Webber, 1995; Pyre et al., 1995) . In most of this and other related work the treatment is some variant of the following. If there is a speech interface, the input speech signal is converted into text. Text either from the recognizer or directly input by the user is then converted into some kind of logical formula, which abstractly represents the user's intended command; this formula is then fed into a command interpreter, which executes the command.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A number of other systems have addressed part of the task. ", "mid_sen": "Com-mandTalk (Moore et al., 1997) , Circuit Fix-It Shop (Smith, 1997) and (Traum and Allen, 1994; Tranm and Andersen, 1999) are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents. ", "after_sen": "Jack's MOOse Lodge (Badler et al., 1999 ) takes text rather than speech as natural language input and the avatars being controlled are not semi-autonomous. "}
{"citeStart": 27, "citeEnd": 44, "citeStartToken": 27, "citeEndToken": 44, "sectionName": "UNKNOWN SECTION NAME", "string": "The approach described in (Auli et al., 2009) is very similar to ours: in this study, the authors propose to find and analyze the limits of machine translation systems by studying the reference reachability. A reference is reachable for a given system if it can be exactly generated by this system. Reference reachability is assessed using Moses in forced decoding mode: during search, all hypotheses that deviate from the reference are simply discarded. Even though the main goal of this study was to compare the search space of phrase-based and hierarchical systems, it also provides some insights on the impact of various search parameters in Moses, delivering conclusions that are consistent with our main results. As described in Section 1.2, these authors also propose a typology of the errors of a statistical translation systems, but do not attempt to provide methods for identifying them.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "To the best of our knowledge, there are only a few works that try to study the expressive power of phrase-based machine translation systems or to provide tools for analyzing potential causes of failure.", "mid_sen": "The approach described in (Auli et al., 2009) is very similar to ours: in this study, the authors propose to find and analyze the limits of machine translation systems by studying the reference reachability. ", "after_sen": "A reference is reachable for a given system if it can be exactly generated by this system. "}
{"citeStart": 64, "citeEnd": 84, "citeStartToken": 64, "citeEndToken": 84, "sectionName": "UNKNOWN SECTION NAME", "string": "More and more often, in real-word natural language processing (NLP) applications based upon grammars, these grammars are no more written by hand but are automatically generated, this has several consequences. This paper will consider one of these consequences: the generated grammars may be very large. Indeed, we aim to deal with grammars that have, say, over a million symbol occurrences and several hundred thousands rules. Traditional parsers are not usually prepared to handle them, either because these grammars are simply too big (the parser's internal structures blow up) or the time spent to analyze a sentence becomes prohibitive. This paper will concentrate on context-free grammars (CFG) and their associated parsers. However, virtually all Tree Adjoining Grammars (TAG, see e.g., (Schabes et al., 1988) ) used in NLP applications can (almost) be seen as lexicalized Tree Insertion Grammars (TIG), which can be converted into strongly equivalent CFGs (Schabes and Waters, 1995) . Hence, the parsing techniques and tools described here can be applied to most TAGs used for NLP, with, in the worst case, a light over-generation which can be easily and efficiently eliminated in a complementary pass. This is indeed what we have achieved with a TAG automatically extracted from (Villemonte de La Clergerie, 2005)'s large-coverage factorized French TAG, as we will see in Section 4. Even (some kinds of) non CFGs may benefit from the ideas described in this paper.", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This paper will concentrate on context-free grammars (CFG) and their associated parsers. ", "mid_sen": "However, virtually all Tree Adjoining Grammars (TAG, see e.g., (Schabes et al., 1988) ) used in NLP applications can (almost) be seen as lexicalized Tree Insertion Grammars (TIG), which can be converted into strongly equivalent CFGs (Schabes and Waters, 1995) . ", "after_sen": "Hence, the parsing techniques and tools described here can be applied to most TAGs used for NLP, with, in the worst case, a light over-generation which can be easily and efficiently eliminated in a complementary pass. "}
{"citeStart": 119, "citeEnd": 133, "citeStartToken": 119, "citeEndToken": 133, "sectionName": "UNKNOWN SECTION NAME", "string": "Besides, an increasing concern in current projects is that of linguistic relevance of the analysis t)erformed by the grammar correction system. In this sense, the adequate integration of error detection and correction techniques within mainstream grammm\" formalisms has l)een addressed by a nunl|)er of these projects ([Iolioli eta/., 1992) , (Vosse, 1992) , ((]enthia.l ctal., t992), (O(~uthial et al., 1994) . l~bllowing this concern, this paper presents resuits fl'om the project GramCheck (A Grammar and Style Checker, MLAP93-11), flmded by the CEC. GramCheck has developed a grammar checker demonstrator for Spanish and Greek native writers using ALEP (ET6/1, 1991), (Simpkins, 1994) as the NLP development platform, a client-server architeeUlre as implenmnted in the X Windows system, Motif as the 'look ~md fe, el' interface and Xminfo as the kllowh!dge t)ase, storage format. Generalized use of extensions to the highly typed and unifi(:ation based formalism imi)Iemented in ALEP has been 1)erformed. These extensions (called Constraint Solvers, CSs) are nothing but pieces of PR()I,OG code l)erforlning different l)oolean and relational operations over feature wdues. Besides, GramCheck has used ongoing results Dora LS-GRAM (LRE61029), a project alining at the implementation of middle coverage ALEP grammars for a number of European languages.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In this sense, the adequate integration of error detection and correction techniques within mainstream grammm\" formalisms has l)een addressed by a nunl|)er of these projects ([Iolioli eta/., 1992) , (Vosse, 1992) , ((]enthia.l ctal., t992), (O(~uthial et al., 1994) . l~bllowing this concern, this paper presents resuits fl'om the project GramCheck (A Grammar and Style Checker, MLAP93-11), flmded by the CEC. ", "mid_sen": "GramCheck has developed a grammar checker demonstrator for Spanish and Greek native writers using ALEP (ET6/1, 1991), (Simpkins, 1994) as the NLP development platform, a client-server architeeUlre as implenmnted in the X Windows system, Motif as the 'look ~md fe, el' interface and Xminfo as the kllowh!", "after_sen": "dge t)ase, storage format. "}
{"citeStart": 163, "citeEnd": 173, "citeStartToken": 163, "citeEndToken": 173, "sectionName": "UNKNOWN SECTION NAME", "string": "We focus on two theories: RST, which offers the model for the annotations of the RST treebank Carlson, Marcu, and Okurowski 2002 and the Potsdam commentary corpus Stede 2004 , and on SDRT, which counts several small corpora annotated with semantic scopes, Discor Baldridge, Asher, and Hunter 2007 and Annodis Afantenos et al. 2012 . We describe these theories in section 2. We will also compare these two theories to dependency tree representations of discourse Muller et al. 2012 . Section 3 introduces a language for describing semantics scopes of relations that is powerful enough to: i) compare the expressiveness (in terms of what different scopes can be expressed) of the different formalisms considered; ii) give a formal target language that will provide comparable interpretations of the different structures at stake. Section 4 discusses Marcu's nuclearity principle and proposes an alternative way to interpret an RST tree as a set of different possible scopes expressed in our language. Section 5 provides intertranslability results between the different formalisms. Section 6 defines a measure of similarity over discourse structures in different formalisms.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "According to Marcu 1996 , an RST tree is not by itself sufficient to generate desired predictions; he employs the nuclearity principle, NP, as an additional interpretation principle on scopes of relations.", "mid_sen": "We focus on two theories: RST, which offers the model for the annotations of the RST treebank Carlson, Marcu, and Okurowski 2002 and the Potsdam commentary corpus Stede 2004 , and on SDRT, which counts several small corpora annotated with semantic scopes, Discor Baldridge, Asher, and Hunter 2007 and Annodis Afantenos et al. 2012 . ", "after_sen": "We describe these theories in section 2. "}
{"citeStart": 126, "citeEnd": 130, "citeStartToken": 126, "citeEndToken": 130, "sectionName": "UNKNOWN SECTION NAME", "string": "Three of the examples are uses of it that seem to be lexicalized with certain verbs, e.g. They hit IT off real well. One can imagine these being treated as phrasal lexical items, and therefore not handled by an anaphoric processing component [AS89] .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "They hit IT off real well. ", "mid_sen": "One can imagine these being treated as phrasal lexical items, and therefore not handled by an anaphoric processing component [AS89] .", "after_sen": "Most of the interchanges in the task dialogues consist of the client responding to cotmnands with cues such as O.K. or Ready to let the expert know when they have completed a task. "}
{"citeStart": 230, "citeEnd": 258, "citeStartToken": 230, "citeEndToken": 258, "sectionName": "UNKNOWN SECTION NAME", "string": "Statistical word alignment models learn word associations between parallel sentences from statistics. Most models are trained from corpora in an unsupervised manner whose success is heavily dependent on the quality and quantity of the training data. It has been shown that human knowledge, in the form of a small amount of manually annotated parallel data to be used to seed or guide model training, can significantly improve word alignment F-measure and translation performance (Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Most models are trained from corpora in an unsupervised manner whose success is heavily dependent on the quality and quantity of the training data. ", "mid_sen": "It has been shown that human knowledge, in the form of a small amount of manually annotated parallel data to be used to seed or guide model training, can significantly improve word alignment F-measure and translation performance (Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006) .", "after_sen": "As formulated in the competitive linking algorithm (Melamed, 2000) , the problem of word alignment can be regarded as a process of word linkage disambiguation, that is, choosing correct associations among all competing hypothesis. "}
{"citeStart": 68, "citeEnd": 86, "citeStartToken": 68, "citeEndToken": 86, "sectionName": "UNKNOWN SECTION NAME", "string": "Experiments were conducted over the same set of documents on which we did analysis: the 511 documents which have completed annotation in all of the fp1, fp2 and adj from the ACE 2005 Multilingual Training Data V3.0. To reemphasize, we apply the hierarchical learning scheme and we focus on improving relation detection while keeping relation classification unchanged (results show that its performance is improved because of the improved detection). We use SVM as our learning algorithm with the full feature set from Zhou et al. (2005) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "To reemphasize, we apply the hierarchical learning scheme and we focus on improving relation detection while keeping relation classification unchanged (results show that its performance is improved because of the improved detection). ", "mid_sen": "We use SVM as our learning algorithm with the full feature set from Zhou et al. (2005) .", "after_sen": "Baseline algorithm: "}
{"citeStart": 222, "citeEnd": 248, "citeStartToken": 222, "citeEndToken": 248, "sectionName": "UNKNOWN SECTION NAME", "string": "The event structure (EVENTSTtL) indicates that mental adjectives have a complex event structure. They denote n, cntal state (el) (examlJes (1) to (3)), but they are also able to make reference to events, the cause of the state (c2) and/or its manifestation (ca) (as shown in examples 4to 7). The Restr(iction) relation indicates the temporal precedence between the state and the two events: the cause (e2) must precede the state and the manifestation (e3) must follow it. The two events are default events, as the adjective ~:emains a state, even when it; has a causative sense, contrary to real transitions (a.ecomplishnw.nt or achievement), like eouler 'sink', for example (as pointed out in Pustejovsky, 1995, chapter ] ", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The Restr(iction) relation indicates the temporal precedence between the state and the two events: the cause (e2) must precede the state and the manifestation (e3) must follow it. ", "mid_sen": "The two events are default events, as the adjective ~:emains a state, even when it; has a causative sense, contrary to real transitions (a.ecomplishnw.nt or achievement), like eouler 'sink', for example (as pointed out in Pustejovsky, 1995, chapter ] ", "after_sen": "0)"}
{"citeStart": 43, "citeEnd": 68, "citeStartToken": 43, "citeEndToken": 68, "sectionName": "UNKNOWN SECTION NAME", "string": "Many approaches have been proposed in the literature of relation extraction. Among them, feature-based and kernel-based approaches are most popular. Kernel-based approaches exploit the structure of the tree that connects two entities. Zelenko et al (2003) proposed a kernel over two parse trees, which recursively matched nodes from roots to leaves in a top-down manner. Culotta and Sorensen (2004) extended this work to estimate similarity between augmented dependency trees. The above two work was further advanced by Bunescu and Mooney (2005) who argued that the information to extract a relation between two entities can be typically captured by the shortest path between them in the dependency graph. Later, Zhang et al (2006) developed a composite kernel that combined parse tree kernel with entity kernel and Zhou et al (2007) experimented with a context-sensitive kernel by automatically determining context-sensitive tree spans.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Culotta and Sorensen (2004) extended this work to estimate similarity between augmented dependency trees. ", "mid_sen": "The above two work was further advanced by Bunescu and Mooney (2005) who argued that the information to extract a relation between two entities can be typically captured by the shortest path between them in the dependency graph. ", "after_sen": "Later, Zhang et al (2006) developed a composite kernel that combined parse tree kernel with entity kernel and Zhou et al (2007) experimented with a context-sensitive kernel by automatically determining context-sensitive tree spans."}
{"citeStart": 67, "citeEnd": 86, "citeStartToken": 67, "citeEndToken": 86, "sectionName": "UNKNOWN SECTION NAME", "string": "The description of the EAGLE workbench for linguistic engineering (Baldwin et al. 1997 ) mentions a case normalization module that uses a heuristic in which a capitalized word in an ambiguous position should be rewritten without capitalization if it is found lower-cased in the same document. This heuristic also employs a database of bigrams and unigrams of lower-cased and capitalized words found in unambiguous positions. It is quite similar to our method for capitalized-word disambiguation. The description of the EAGLE case normalization module provided by Baldwin et al. is, however, very brief and provides no performance evaluation or other details.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This is similar to \"one sense per collocation\" idea of Yarowsky (1993) .", "mid_sen": "The description of the EAGLE workbench for linguistic engineering (Baldwin et al. 1997 ) mentions a case normalization module that uses a heuristic in which a capitalized word in an ambiguous position should be rewritten without capitalization if it is found lower-cased in the same document. ", "after_sen": "This heuristic also employs a database of bigrams and unigrams of lower-cased and capitalized words found in unambiguous positions. "}
{"citeStart": 116, "citeEnd": 135, "citeStartToken": 116, "citeEndToken": 135, "sectionName": "UNKNOWN SECTION NAME", "string": "In the past, a significant number of techniques have been presented to reduce the hierarchical rule table. He et al. (2009) just used the key phrases of source side to filter the rule table without taking advantage of any linguistic information. Iglesias et al. (2009) put rules into syntactic classes based on the number of non-terminals and patterns, and applied various filtration strategies to improve the rule table quality. Shen et al. (2008) discarded most entries of the rule table by using the constraint that rules of the target-side are well-formed (WF) dependency structure, but this filtering led to degradation in translation performance. They obtained improvements by adding an additional dependency language model. The basic difference of our method from (Shen et al., 2008 ) is that we keep rules that both sides should be relaxed-wellformed dependency structure, not just the target side. Besides, our system complexity is not increased because no additional language model is introduced. The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach (Hasan and Ney, 2009) . Hasan and Ney (2009) introduced a second word to trigger the target word without considering any linguistic information. Furthermore, since the second word can come from any part of the sentence, there may be a prohibitively large number of parameters involved. Besides, He et al. (2008) built a maximum entropy model which combines rich context information for selecting translation rules during decoding. However, as the size of the corpus increases, the maximum entropy model will become larger. Similarly, In (Shen et al., 2009) , context language model is proposed for better rule selection. Taking the dependency edge as condition, our approach is very different from previous approaches of exploring context information.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Besides, our system complexity is not increased because no additional language model is introduced. ", "mid_sen": "The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach (Hasan and Ney, 2009) . ", "after_sen": "Hasan and Ney (2009) introduced a second word to trigger the target word without considering any linguistic information. "}
{"citeStart": 186, "citeEnd": 207, "citeStartToken": 186, "citeEndToken": 207, "sectionName": "UNKNOWN SECTION NAME", "string": "One technical difficulty is that D(p [1 p') is not defined when p'(x) = 0 but p(x) > 0. We could sidestep this problem (as we did initially) by smoothing zero frequencies appropriately (Church and Gale, 1991) . However, this is not very satisfactory because one of the goals of our work is precisely to avoid the problems of data sparseness by grouping words into classes. It turns out that the problem is avoided by our clustering technique, since it does not need to compute the KL distance between individual word distributions, but only between a word distribution and average distributions, the current cluster centroids, which are guaranteed to be nonzero whenever the word distributions are. This is a useful advantage of our method compared with agglomerative clustering techniques that need to compare individual objects being considered for grouping.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Finally, relative entropy is a natural measure of similarity between distributions for clustering because its minimization leads to cluster centroids that are a simple weighted average of member distributions.", "mid_sen": "One technical difficulty is that D(p [1 p') is not defined when p'(x) = 0 but p(x) > 0. We could sidestep this problem (as we did initially) by smoothing zero frequencies appropriately (Church and Gale, 1991) . ", "after_sen": "However, this is not very satisfactory because one of the goals of our work is precisely to avoid the problems of data sparseness by grouping words into classes. "}
{"citeStart": 175, "citeEnd": 196, "citeStartToken": 175, "citeEndToken": 196, "sectionName": "UNKNOWN SECTION NAME", "string": "For generating a personalized summary, traditional methods usually require that a user explicitly provides his interest aspects, such as specifying the categories he prefers (Díaz and Gervás, 2007) or clicking a subset of sentences in a document according to his interests (Yan et al., 2011) . However, most users are reluctant to provide such information, thus it is more meaningful to infer a user's interests implicitly.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "All these information can be considered as the potential data source for document understanding and personalization.", "mid_sen": "For generating a personalized summary, traditional methods usually require that a user explicitly provides his interest aspects, such as specifying the categories he prefers (Díaz and Gervás, 2007) or clicking a subset of sentences in a document according to his interests (Yan et al., 2011) . ", "after_sen": "However, most users are reluctant to provide such information, thus it is more meaningful to infer a user's interests implicitly."}
{"citeStart": 62, "citeEnd": 79, "citeStartToken": 62, "citeEndToken": 79, "sectionName": "UNKNOWN SECTION NAME", "string": "Some domains and tasks lend themselves more obviously to a clustering approach than others. An obvious and trivial case where clustering is likely to be useful is a speech understander for use by travelers in an international airport; here, an utterance will typically consist of words from one, and only one, natural language, and clusters for different lan-guages will be totally dissimilar. However, clustering may also give us significant leverage in monolingual cases. If the dialogue handling capabilities of a system are relatively rigid, the system may only ask the user a small number of different questions (modulo the filling of slots with different values). For example, the CLARE interface to the Autoroute PC package (Lewin et al, 1993) has a fairly simple dialogue model which allows it to ask only a dozen or so different types of question of the user. A Wizard of Oz exercise, carried out to collect data for this task, was conducted in a similarly rigid way; thus it is straightforward to divide the training corpus into clusters, one cluster for utterances immediately following each kind of system query. Other corpora, such as Wall Street Journal articles, might also be expected to fall naturally into clusters for different subject areas, and indeed Iyer el al (1994) report positive results from corpus clustering here.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "If the dialogue handling capabilities of a system are relatively rigid, the system may only ask the user a small number of different questions (modulo the filling of slots with different values). ", "mid_sen": "For example, the CLARE interface to the Autoroute PC package (Lewin et al, 1993) has a fairly simple dialogue model which allows it to ask only a dozen or so different types of question of the user. ", "after_sen": "A Wizard of Oz exercise, carried out to collect data for this task, was conducted in a similarly rigid way; thus it is straightforward to divide the training corpus into clusters, one cluster for utterances immediately following each kind of system query. "}
{"citeStart": 60, "citeEnd": 79, "citeStartToken": 60, "citeEndToken": 79, "sectionName": "UNKNOWN SECTION NAME", "string": "However, because the parameters are all of the form P(FplE ) where E is a sentence, the above framework is not amenable to the situation where a French sentence corresponds to no English sentences. Hence, we use a slightly different framework. We view a bilingual corpus as a sequence of sentence beads (Brown et al., 1991b) , where a sentence bead corresponds to an irreducible group of sentences that align with each other. For example, the correct alignment of the bilingual corpus in Figure 2 consists ", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Hence, we use a slightly different framework. ", "mid_sen": "We view a bilingual corpus as a sequence of sentence beads (Brown et al., 1991b) , where a sentence bead corresponds to an irreducible group of sentences that align with each other. ", "after_sen": "For example, the correct alignment of the bilingual corpus in Figure 2 consists "}
{"citeStart": 106, "citeEnd": 140, "citeStartToken": 106, "citeEndToken": 140, "sectionName": "UNKNOWN SECTION NAME", "string": "The paradigm of two-level morphology (Koskenniemi, 1983) has become popular for handling word formation phenomena in a variety of languages. The original formulation has been extended to allow morphotactic constraints to be expressed by feature specification (Trost, 1990; A1shawi et al, 1991) rather than Koskenniemi's less perspicuous device of continuation classes. Methods for the automatic compilation of rules from a notation convenient for the rule-writer into finitestate automata have also been developed, allowing the efficient analysis and synthesis of word forms. The automata may be derived from the rules alone (Trost, 1990) , or involve composition with the lexicon (Karttunen, Kaplan and Zaenen, 1992) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Methods for the automatic compilation of rules from a notation convenient for the rule-writer into finitestate automata have also been developed, allowing the efficient analysis and synthesis of word forms. ", "mid_sen": "The automata may be derived from the rules alone (Trost, 1990) , or involve composition with the lexicon (Karttunen, Kaplan and Zaenen, 1992) .", "after_sen": "However, there is often a trade-off between runtime efficiency and factors important for rapid and accurate system development, such as perspicuity of notation, ease of debugging, speed of compilation and the size of its output, and the independence of the morphological and lexical components. "}
{"citeStart": 282, "citeEnd": 293, "citeStartToken": 282, "citeEndToken": 293, "sectionName": "UNKNOWN SECTION NAME", "string": "Both classes of adjectives exhibit the property of syntactic polyvalency, being able to appear in several distinct contexts, with optional complement structures (as illustrated in (1), (2) and(3)). In the case of agent-oriented adjectives, the complement expresses the manifestation of the state and call be realized as an infinitive with d/pour or de (examples (2a,b)) or a prepositional phrase (2c): (2a,b,c)means that somebody is skilful in what he does or how he does it (see Croft, 1984 ).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Both classes of adjectives exhibit the property of syntactic polyvalency, being able to appear in several distinct contexts, with optional complement structures (as illustrated in (1), (2) and(3)). ", "mid_sen": "In the case of agent-oriented adjectives, the complement expresses the manifestation of the state and call be realized as an infinitive with d/pour or de (examples (2a,b)) or a prepositional phrase (2c): (2a,b,c)means that somebody is skilful in what he does or how he does it (see Croft, 1984 ).", "after_sen": "(1) Cet homme est triste/habile/furieux \"This man is sad/clever/angry TM (2) a. Cet homme est habile de partir \"This man is skilful to leave\" b. Cet homme est habile £/pour tricher \"This man is skilful at cheating\" c. Cet homme est habile au bridge \"This man is skilful at bridge\""}
{"citeStart": 7, "citeEnd": 42, "citeStartToken": 7, "citeEndToken": 42, "sectionName": "UNKNOWN SECTION NAME", "string": "Sentence alignment approaches can be categorized as based on sentence length, word correspondence, and composite (where more than one approaches are combined), though other techniques, such as cog-nate matching (Simard et al., 1992) were also tried. Word correspondence was used by Kay (Kay, 1991; Kay and Roscheisen, 1993) . It was based on the idea that words which are translations of each other will have similar distributions in the SL and TL texts. Sentence length methods were based on the intuition that the length of a translated sentence is likely to be similar to that of the source sentence. Brown, Lai and Mercer (Brown et al., 1991) used word count as the sentence length, whereas Gale and Church (Gale and Church, 1991) used character count. Brown, Lai and Mercer assumed prior alignment of paragraphs. Gale and Church relied on some previously aligned sentences as 'anchors '. Wu (Wu, 1994) also used lexical cues from corpus-specific bilingual lexicon for better alignment.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Sentence length methods were based on the intuition that the length of a translated sentence is likely to be similar to that of the source sentence. ", "mid_sen": "Brown, Lai and Mercer (Brown et al., 1991) used word count as the sentence length, whereas Gale and Church (Gale and Church, 1991) used character count. ", "after_sen": "Brown, Lai and Mercer assumed prior alignment of paragraphs. "}
{"citeStart": 320, "citeEnd": 332, "citeStartToken": 320, "citeEndToken": 332, "sectionName": "UNKNOWN SECTION NAME", "string": "Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expensive in the cost of human effort at development time and limited ability to scale to new domains, more recent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge. Similarly to them we do not use any sentence parsing or structural analysis, but just rely on morphosyntactic and semantic word information.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Resolving pronouns in English technical manuals to the most recent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the antecedent (cf. section 3).", "mid_sen": "Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expensive in the cost of human effort at development time and limited ability to scale to new domains, more recent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge. ", "after_sen": "Similarly to them we do not use any sentence parsing or structural analysis, but just rely on morphosyntactic and semantic word information."}
{"citeStart": 80, "citeEnd": 97, "citeStartToken": 80, "citeEndToken": 97, "sectionName": "UNKNOWN SECTION NAME", "string": "Our difficulty prediction approach is based on the model described in the previous section. We extract the features using tools for natural language processing provided by DKPro Core (de Castilho and Gurevych, 2014). We then perform experiments with different datasets and classifiers using Weka (Hall et al., 2009) through the DKPro TC framework (Daxenberger et al., 2014) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We extract the features using tools for natural language processing provided by DKPro Core (de Castilho and Gurevych, 2014). ", "mid_sen": "We then perform experiments with different datasets and classifiers using Weka (Hall et al., 2009) through the DKPro TC framework (Daxenberger et al., 2014) .", "after_sen": ""}
{"citeStart": 41, "citeEnd": 68, "citeStartToken": 41, "citeEndToken": 68, "sectionName": "UNKNOWN SECTION NAME", "string": "\"Comprehension-based summarization, e.g. Kintsch and Van Dijk (1978) and Brown et al. (1983) , is the most ambitious model of automatic summarization, requiring a complete understanding of the text. Due to the failure of rule-based NLP and knowledge representation, other less knowledge-intensive methods now dominate\".", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Consider the following paragraph containing a citation:", "mid_sen": "\"Comprehension-based summarization, e.g. Kintsch and Van Dijk (1978) and Brown et al. (1983) , is the most ambitious model of automatic summarization, requiring a complete understanding of the text. ", "after_sen": "Due to the failure of rule-based NLP and knowledge representation, other less knowledge-intensive methods now dominate\"."}
{"citeStart": 0, "citeEnd": 27, "citeStartToken": 0, "citeEndToken": 27, "sectionName": "UNKNOWN SECTION NAME", "string": "The input to reference resolution in the theoretical literature is assumed to be fully parsed sentences, often with syntactic attributes such as grammatical functions and thematic roles on the constituents (Webber, 1978; Sidner, 1979; Hobbs, 1978; Grosz, Joshi, and Weinstein, 1995) . In implemented reference resolution systems, for pronoun resolution in particular, there seems to be a trade-off between the completeness of syntactic input and the robustness with real-world sentences. In short, more robust and partial parsing gives us wider coverage, but less syntactic information also leads to less accuyate reference resolution. For instance, Lappin and Leass (1994) report an 86% accuracy for a resolution algorithm for third-person pronouns using fully parsed sentences as input. Kennedy and Boguraev (1996) then report a 75% accuracy for an algorithm that approximates Lappin and Leass's with more robust and coarse-grained syntactic input. After describing the algorithm in the next section, I will briefly compare the present approach with these pronoun resolution approaches.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For instance, Lappin and Leass (1994) report an 86% accuracy for a resolution algorithm for third-person pronouns using fully parsed sentences as input. ", "mid_sen": "Kennedy and Boguraev (1996) then report a 75% accuracy for an algorithm that approximates Lappin and Leass's with more robust and coarse-grained syntactic input. ", "after_sen": "After describing the algorithm in the next section, I will briefly compare the present approach with these pronoun resolution approaches."}
{"citeStart": 157, "citeEnd": 169, "citeStartToken": 157, "citeEndToken": 169, "sectionName": "UNKNOWN SECTION NAME", "string": "hl otrr model, each agerlt associates a numeric confidence value with each of tile attributes in the relSrring expression, and by composing these, computes a level of confidence in the adequacy of the complete referring expression plan that can be interpreted as ranging from low confidence to high confidence. The present composition function is simple addition, but one could envision more complex systems to compute confidence, such as an algebra of confidence or a non-numeric system. If the overall confidence value exceeds some set value, the agent's confidence threshold, then the agent believes the plan is adequate. That is, if the agent is the initiator, she believes that the other will be able to understand the reference; if the agent is the other, he believes that he has understood the reference. Now, the confidence value of each attribute is equivalent to its salience within the context of the referring expression. Salience, for our purposes in directiongiving, is primarily visual prominence, but can also involve identifiability, familiarity, and functional importance (Devlin, 1976; Lynch, 1960) . One approach is to encode the salient properties in a static hierarchy as Davis (1989) , and Reiter and Dale (1992) have done. I But, ideally, salience should depend on the context sun-ounding the referent. For example, the height of a tall building would normally be salient, but not if it were surrounded by other tall buildings. This computation Would be quite complex, so we have adopted a middle ground between the simple contextindependent approaches, and a full-blown contextual analysis. The middle ground involves taking the type of object into account when choosing attributes and landmarks that relate to it. For example, height and architectural style can be very salient features for describing a building, but not for describing an intersection, for which having a sign or traffic lights is important. This approach still allows us to encode salience in a hierarchy, but it is dependent on the referent. Table 1 shows an example of a simple salience hierarchy that an agent might have. The hierarchy is actually a set of partial orderings of attributes, represented by lambda expressions, indexed by object type. In the table, the confidence value of using architectural style to describe a building is 4. The confidence value of a tall building is 3, and so this attribute is less salient than architectural style. The other rows (for describing intersections) follow similarly. 2 Each agent has his own beliefs about salience. It is the difference in their beliefs that leads to the necessity for collaboration on reference. Ideally, the initiator should construct referring expressions with the recipients' (believed) beliefs about salience in mind, but we have chosen to avoid this complexity by making the simplifying assumption that the initiator is an expert IThese models assmne that all agents have identical beliefs, which is clearly insufficient for modeling collaborative dialogue.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Now, the confidence value of each attribute is equivalent to its salience within the context of the referring expression. ", "mid_sen": "Salience, for our purposes in directiongiving, is primarily visual prominence, but can also involve identifiability, familiarity, and functional importance (Devlin, 1976; Lynch, 1960) . ", "after_sen": "One approach is to encode the salient properties in a static hierarchy as Davis (1989) , and Reiter and Dale (1992) have done. "}
{"citeStart": 34, "citeEnd": 46, "citeStartToken": 34, "citeEndToken": 46, "sectionName": "UNKNOWN SECTION NAME", "string": "In this section we compare a number of variants of the general VSM framework, differing in the way vectors are defined and constructed (see Sections 3.2-3.4). Translation quality of all experiments is measured with case-insensitive BLEU (Papineni et al., 2002) using the closest-reference brevity penalty. We use approximate randomization (Noreen, 1989) for significance testing (Riezler and Maxwell, 2005) . Statistically significant differences are marked by and for the p ≤ 0.05 and the p ≤ 0.01 level, respectively. VSM using intrinsic text features. We first test various VSM variants that use automatic indicators of genre and do not depend on the availability of provenance information or manual subcorpus labels (Table 4 ). Of these, genre adaptation with LDA-based features (Section 3.4) achieves strongly significant improvements over the unadapted baseline for the NIST-NW and the complete NIST test sets, however improvements on the other test portions are very small. When manually inspecting the LDA-inferred latent dimensions, we observe that LDA is overly aggressive in considering all of the UG genre as a single thread, while latent dimensions inferred for NW are more finegrained. While this finding can be explained by the unbalanced amount of training data per genre, it also illustrates that LDA-based features seem less suitable to capture low-resource genres. Next, we evaluate the VSM variant that uses genre-revealing text features inspired by genre classification research (Section 3.3). This approach achieves statistically significant improvements over the baseline in all runs except one (i.e., target-side features on Gen&Topic NW). We also see that translation quality is fairly similar for features computed on either side of the bitext, indicating that the proposed genre features can generalize across languages.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Translation quality of all experiments is measured with case-insensitive BLEU (Papineni et al., 2002) using the closest-reference brevity penalty. ", "mid_sen": "We use approximate randomization (Noreen, 1989) for significance testing (Riezler and Maxwell, 2005) . ", "after_sen": "Statistically significant differences are marked by and for the p ≤ 0.05 and the p ≤ 0.01 level, respectively. "}
{"citeStart": 81, "citeEnd": 107, "citeStartToken": 81, "citeEndToken": 107, "sectionName": "UNKNOWN SECTION NAME", "string": "Turning to Figure 2 , we find (consistent with previous results) that low-probability words have dramatically higher error rates than high-probability Figure 2 shows that means of pitch and intensity have relatively little effect except at extreme values, where more errors occur. In contrast, pitch and intensity range show clear linear trends, with greater range of pitch or intensity leading to lower IWER. 3 As noted above, decreased duration is associated with increased IWER, and (as in previous work), we find that IWER increases dramatically for fast speech. We also see a tendency towards higher IWER for very slow speech, consistent with Shinozaki and Furui (2001) and Siegler and Stern (1995) . The effects of pitch minimum and maximum are not shown for reasons of space, but are similar to pitch mean. Also not shown are intensity minimum (with more errors at higher values) and intensity maximum (with more errors at lower values).", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "3 As noted above, decreased duration is associated with increased IWER, and (as in previous work), we find that IWER increases dramatically for fast speech. ", "mid_sen": "We also see a tendency towards higher IWER for very slow speech, consistent with Shinozaki and Furui (2001) and Siegler and Stern (1995) . ", "after_sen": "The effects of pitch minimum and maximum are not shown for reasons of space, but are similar to pitch mean. "}
{"citeStart": 244, "citeEnd": 256, "citeStartToken": 244, "citeEndToken": 256, "sectionName": "UNKNOWN SECTION NAME", "string": "Much work has been done on both detecting boundary tones (e.g. (Wang and Hirschberg, 1992; Wightman and Ostendorf, 1994; Stolcke and Shriberg, 1996a; Kompe et al., 1994; Mast et al., 1996) ) and on speech repair detection and correction (e.g. (Hindle, 1983; Bear, Dowding, and Shriberg, 1992; Nakatani and Hirschberg, 1994; Heeman and Allen, 1994; Stolcke and Shriberg, 1996b) ). This work has focused on one of the issues in isolation of the other. However, these two issues are intertwined. Cues such as the presence of silence, final syllable lengthening, and presence of filled pauses tend to mark both events. Even the presence of word correspondences, a tradition cue for detecting and correcting speech repairs, sometimes marks boundary tones as well, as illustrated by the following example where the intonational phrase boundary is marked with the ToBI symbol %.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Much work has been done on both detecting boundary tones (e.g. (Wang and Hirschberg, 1992; Wightman and Ostendorf, 1994; Stolcke and Shriberg, 1996a; Kompe et al., 1994; Mast et al., 1996) ) and on speech repair detection and correction (e.g. (Hindle, 1983; Bear, Dowding, and Shriberg, 1992; Nakatani and Hirschberg, 1994; Heeman and Allen, 1994; Stolcke and Shriberg, 1996b) ). ", "after_sen": "This work has focused on one of the issues in isolation of the other. "}
{"citeStart": 86, "citeEnd": 96, "citeStartToken": 86, "citeEndToken": 96, "sectionName": "UNKNOWN SECTION NAME", "string": "Finally, we observe that the skew metric seems quite promising. We conjecture that appropriate values for a may inversely correspond to the degree of sparseness in the data, and intend in the future to test this conjecture on larger-scale prediction tasks. We also plan to evaluate skewed versions of the Jensen-Shannon divergence proposed by Rao (1982) and J. Lin (1991) .", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We conjecture that appropriate values for a may inversely correspond to the degree of sparseness in the data, and intend in the future to test this conjecture on larger-scale prediction tasks. ", "mid_sen": "We also plan to evaluate skewed versions of the Jensen-Shannon divergence proposed by Rao (1982) and J. Lin (1991) .", "after_sen": "1The term \"similarity-based\", which we have used previously, has been applied to describe other models as well (L.Lee, 1997;Karov and Edelman, 1998)."}
{"citeStart": 49, "citeEnd": 77, "citeStartToken": 49, "citeEndToken": 77, "sectionName": "UNKNOWN SECTION NAME", "string": "On the other hand, in spite of several attempts (Lindblom and Maddieson, 1988; Boersma, 1998; Clements, 2004) the organization of the consonant inventories lacks a satisfactory explanation. However, one of the earliest observations about the consonant inventories has been that consonants tend to occur in pairs that exhibit strong correlation in terms of their features (Trubetzkoy, 1931) . In order to explain these trends, feature economy was proposed as the organizing principle of the consonant inventories (Martinet, 1955) . According to this principle, languages tend to maximize the combinatorial possibilities of a few distinctive features to generate a large number of consonants. Stated differently, a given consonant will have a higher than expected chance of occurrence in inventories in which all of its features have distinctively occurred in other consonants. The idea is illustrated, with an example, through Table 1. Various attempts have been made in the past to explain the aforementioned trends through linguistic insights (Boersma, 1998; Clements, 2004) mainly establishing their statistical significance. On the contrary, there has been very little work pertaining to the quantification of feature economy except in (Clements, 2004) , where the author defines economy index, which is the ratio of the size of an inventory to the number of features that characterizes the inventory. However, this definition does not take into account the complexity that is involved in communicating the information about the inventory in terms of its constituent features.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In fact, the organization of the vowel inventories (especially those with a smaller size) across languages has been satisfactorily explained in terms of the single principle of maximal perceptual contrast (Jakobson, 1941; Liljencrants and Lindblom, 1972; de Boer, 2000) .", "mid_sen": "On the other hand, in spite of several attempts (Lindblom and Maddieson, 1988; Boersma, 1998; Clements, 2004) the organization of the consonant inventories lacks a satisfactory explanation. ", "after_sen": "However, one of the earliest observations about the consonant inventories has been that consonants tend to occur in pairs that exhibit strong correlation in terms of their features (Trubetzkoy, 1931) . "}
{"citeStart": 73, "citeEnd": 90, "citeStartToken": 73, "citeEndToken": 90, "sectionName": "UNKNOWN SECTION NAME", "string": "The noisy-channel model (Brown et al., 1990) has been the foundation for statistical machine translation (SMT) for over ten years. Recently so-called reranking techniques, such as maximum entropy models (Och and Ney, 2002) and gradient methods (Och, 2003) , have been applied to machine translation (MT), and have provided significant improvements. In this paper, we introduce two novel machine learning algorithms specialized for the MT task.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The noisy-channel model (Brown et al., 1990) has been the foundation for statistical machine translation (SMT) for over ten years. ", "mid_sen": "Recently so-called reranking techniques, such as maximum entropy models (Och and Ney, 2002) and gradient methods (Och, 2003) , have been applied to machine translation (MT), and have provided significant improvements. ", "after_sen": "In this paper, we introduce two novel machine learning algorithms specialized for the MT task."}
{"citeStart": 134, "citeEnd": 146, "citeStartToken": 134, "citeEndToken": 146, "sectionName": "UNKNOWN SECTION NAME", "string": "To automatically learn extraction patterns that are associated with subjectivity, we use a learning algorithm similar to AutoSlog-TS (Riloff, 1996) . For training, AutoSlog-TS uses a text corpus consisting of two distinct sets of texts: \"relevant\" texts (in our case, subjective sentences) and \"irrelevant\" texts (in our case, objective sentences). A set of syntactic templates represents the space of possible extraction patterns.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "To automatically learn extraction patterns that are associated with subjectivity, we use a learning algorithm similar to AutoSlog-TS (Riloff, 1996) . ", "after_sen": "For training, AutoSlog-TS uses a text corpus consisting of two distinct sets of texts: \"relevant\" texts (in our case, subjective sentences) and \"irrelevant\" texts (in our case, objective sentences). "}
{"citeStart": 74, "citeEnd": 100, "citeStartToken": 74, "citeEndToken": 100, "sectionName": "UNKNOWN SECTION NAME", "string": "This section has given an overview of the approach to history-based expectation processing. The details of the method are dependent on how the functions P, Predicts, Mergeable, and Merge are implemented. The following sections describe our implementation, which was used to investigate the viability of this approach and the performance it can achieve. The usefulness of the methodology described above was tested in the implementation of a connected speech understanding system. An off-the-shelf speech recognition device, a Nippon Electric Corporation DP-200, was added to an existing natural language processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann and Ballard 1980 ). The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC. The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983) . [The current system should be distinguished from an earlier voice system (VNLC, Biermann et al. 1985) , which had no expectation and which handled discrete speech where a 300 millisecond pause must follow each word.]", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983) . ", "mid_sen": "[The current system should be distinguished from an earlier voice system (VNLC, Biermann et al. 1985) , which had no expectation and which handled discrete speech where a 300 millisecond pause must follow each word.]", "after_sen": "It should be emphasized, of course, that the central issue here is the study of expectation mechanisms and the details of the design decisions could have been made in rather different ways. "}
{"citeStart": 77, "citeEnd": 89, "citeStartToken": 77, "citeEndToken": 89, "sectionName": "UNKNOWN SECTION NAME", "string": "Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus. State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus. The best performance on the WSJ corpus was achieved by a combination of the SATZ system (Palmer and Hearst 1997 ) with the Alembic system (Aberdeen et al. 1995) : a 0.5% error rate. The best performance on the Brown corpus, a 0.2% error rate, was reported by Riley (1989) , who trained a decision tree classifier on a 25-million-word corpus. In the disambiguation of capitalized words, the most widespread method is POS tagging, which achieves about a 3% error rate on the Brown corpus and a 5% error rate on the WSJ corpus, as reported in Mikheev (2000) . We are not aware of any studies devoted to the identification of abbreviations with comprehensive evaluation on either the Brown corpus or the WSJ corpus.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The best performance on the WSJ corpus was achieved by a combination of the SATZ system (Palmer and Hearst 1997 ) with the Alembic system (Aberdeen et al. 1995) : a 0.5% error rate. ", "mid_sen": "The best performance on the Brown corpus, a 0.2% error rate, was reported by Riley (1989) , who trained a decision tree classifier on a 25-million-word corpus. ", "after_sen": "In the disambiguation of capitalized words, the most widespread method is POS tagging, which achieves about a 3% error rate on the Brown corpus and a 5% error rate on the WSJ corpus, as reported in Mikheev (2000) . "}
{"citeStart": 140, "citeEnd": 153, "citeStartToken": 140, "citeEndToken": 153, "sectionName": "UNKNOWN SECTION NAME", "string": "CRFs have been previously applied to other tasks such as name entity extraction (McCallum and Li, 2003) , table extraction (Pinto et al., 2003) and shallow parsing (Sha and Pereira, 2003) . The basic theory of CRFs is now well-understood, but the best-practices for applying them to new, real-world data is still in an early-exploration phase. Here we explore two key practical issues: (1) regularization, with an empirical study of Gaussian (Chen and Rosenfeld, 2000) , exponential (Goodman, 2003) , and hyperbolic-L 1 (Pinto et al., 2003) priors; (2) exploration of various families of features, including text, lexicons, and layout, as well as proposing a method for the beneficial use of zero-count features without incurring large memory penalties.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The basic theory of CRFs is now well-understood, but the best-practices for applying them to new, real-world data is still in an early-exploration phase. ", "mid_sen": "Here we explore two key practical issues: (1) regularization, with an empirical study of Gaussian (Chen and Rosenfeld, 2000) , exponential (Goodman, 2003) , and hyperbolic-L 1 (Pinto et al., 2003) priors; (2) exploration of various families of features, including text, lexicons, and layout, as well as proposing a method for the beneficial use of zero-count features without incurring large memory penalties.", "after_sen": "We describe a large collection of experimental results on two traditional benchmark data sets. "}
{"citeStart": 83, "citeEnd": 94, "citeStartToken": 83, "citeEndToken": 94, "sectionName": "UNKNOWN SECTION NAME", "string": "Discussion. The intuition behind this algorithm is essentially the same intuition exploited by Lesk (1986) , Sussna (1993) , and others: the most plausible assignment of senses to multiple co-occurring words is the one that maximizes relatedness of meaning among the senses chosen. Here I make an explicit comparison with Sussna's approach, since it is the most similar of previous work.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Discussion. ", "mid_sen": "The intuition behind this algorithm is essentially the same intuition exploited by Lesk (1986) , Sussna (1993) , and others: the most plausible assignment of senses to multiple co-occurring words is the one that maximizes relatedness of meaning among the senses chosen. ", "after_sen": "Here I make an explicit comparison with Sussna's approach, since it is the most similar of previous work."}
{"citeStart": 149, "citeEnd": 163, "citeStartToken": 149, "citeEndToken": 163, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper we have addressed two, previously neglected questions about the DOP model: how does DOP perform if tested on unedited Penn Treebank data, and (2), how can DOP be used for directly parsing word strings that contain unknown words. We have shown that although parse results are considerably lower on unedited data than on cleaned-up data, they are very competitive, if not better than other models. With respect to the parsing of word strings, we have shown that the hardness of the problem does not lie so much in unknown words, but in previously unseen lexical categories of known words. We have given a novel method for parsing these words by estimating the probabilities of unknown subtrees. The method was tested on ATIS trees obtaining results that to the best of our knowledge are not exceeded by other stochastic parsers. Moreover, the results of a less-than-optimal version of DOP on the Wall Street Journal corpus suggest that the approach can be succesfully extended to larger domains. As future research, we will apply the full DOP model on WSJ word strings in order to compare our results with the best known parsers on this domain (Magerman, 1995; Collins, 1996) .", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Moreover, the results of a less-than-optimal version of DOP on the Wall Street Journal corpus suggest that the approach can be succesfully extended to larger domains. ", "mid_sen": "As future research, we will apply the full DOP model on WSJ word strings in order to compare our results with the best known parsers on this domain (Magerman, 1995; Collins, 1996) .", "after_sen": ""}
{"citeStart": 40, "citeEnd": 63, "citeStartToken": 40, "citeEndToken": 63, "sectionName": "UNKNOWN SECTION NAME", "string": "Example. The following table shows the semantic similarity computed for several word pairs, in each case shown with the most informative subsumer. 6 Probabifities were estimated using the Penn Treebank version of the Brown corpus. The pairs come from an example given by Church and Hanks (1989) , illustrating the words that human subjects most frequently judged as being associated with the word doctor. (The word sick also appeared on the list, but is excluded here because it is not a noun.)", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "6 Probabifities were estimated using the Penn Treebank version of the Brown corpus. ", "mid_sen": "The pairs come from an example given by Church and Hanks (1989) , illustrating the words that human subjects most frequently judged as being associated with the word doctor. ", "after_sen": "(The word sick also appeared on the list, but is excluded here because it is not a noun.)"}
{"citeStart": 160, "citeEnd": 174, "citeStartToken": 160, "citeEndToken": 174, "sectionName": "UNKNOWN SECTION NAME", "string": "Tile algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner. Although we believe that this algorithm could be seen as an instance of a uniform architecture for parsing and generation--just as tile extended Earley parser (Shieber, 1985b) and the bottom-up generator were instances of the generalized Earley deduction architecture--our efforts to date have been aimed foremost toward the development of the algorithm for generation alone. We will mention efforts toward this end in Section 5.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Tile algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner. ", "mid_sen": "Although we believe that this algorithm could be seen as an instance of a uniform architecture for parsing and generation--just as tile extended Earley parser (Shieber, 1985b) and the bottom-up generator were instances of the generalized Earley deduction architecture--our efforts to date have been aimed foremost toward the development of the algorithm for generation alone. ", "after_sen": "We will mention efforts toward this end in Section 5."}
{"citeStart": 167, "citeEnd": 183, "citeStartToken": 167, "citeEndToken": 183, "sectionName": "UNKNOWN SECTION NAME", "string": "(III) The way in which spans are annotated as ar-guments to connectives also raises a challenge. First, because the PDTB annotates both structural and anaphoric connectives (Webber et al., 2003) , a span can serve as argument to >1 connective. Secondly, unlike in the RST corpus (Carlson et al., 2003) or the Discourse GraphBank (Wolf and Gibson, 2005) , discourse segments are not separately annotated, with annotators then identifying what discourse relations hold between them. Instead, in annotating arguments, PDTB annotators have selected the minimal clausal text span needed to interpret the relation. This could comprise an embedded, subordinate or coordinate clause, an entire sentence, or a (possibly disjoint) sequence of sentences. As a result, there are fairly complex patterns of spans within and across sentences that serve as arguments to different connectives, and there are parts of sentences that don't appear within the span of any connective, explicit or implicit. The result is that the PDTB provides only a partial but complexly-patterned cover of the corpus. Understanding what's going on and what it implies for discourse structure (and possibly syntactic structure as well) is a challenge we're currently trying to address (Lee et al., 2006) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The result is that the PDTB provides only a partial but complexly-patterned cover of the corpus. ", "mid_sen": "Understanding what's going on and what it implies for discourse structure (and possibly syntactic structure as well) is a challenge we're currently trying to address (Lee et al., 2006) .", "after_sen": ""}
{"citeStart": 130, "citeEnd": 148, "citeStartToken": 130, "citeEndToken": 148, "sectionName": "UNKNOWN SECTION NAME", "string": "Functions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state. They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of Chu-Carroll (2000) .", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Functions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state. ", "mid_sen": "They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of Chu-Carroll (2000) .", "after_sen": "phase and change the holder of the initiative as well as change the dialogue state. "}
{"citeStart": 71, "citeEnd": 87, "citeStartToken": 71, "citeEndToken": 87, "sectionName": "UNKNOWN SECTION NAME", "string": "As discussed earlier, the word alignment models are asymmetric, whereas most applications require a single alignment for each sentence pair. Typically this is achieved by a symmetrization heuristic that takes two directional alignments and produces a single alignment. For MT the most commonly used heuristic is called grow diagonal final (Och and Ney 2003) . This starts with the intersection of the sets of aligned points and adds points around the diagonal that are in the union of the two sets of aligned points. The alignment produced has high recall relative to the intersection and only slightly lower recall than the union. In syntax transfer the intersection heuristic is normally used, because one wants to have high precision links to transfer knowledge between languages. One pitfall of these symmetrization heuristics is that they can obfuscate the link between the original alignment and the ones used for a specific task, making errors more difficult to analyze. Because they are heuristics tuned for a particular phrasebased translation system, it is not clear when they will help and when they will hinder system performance. In this work we followed a more principled approach that uses the knowledge about the posterior distributions of each directional model. We include a point in the final alignment if the average of the posteriors under the two models for that point is above a threshold. This heuristic is called soft union (DeNero and Klein 2007) . Figure 8 shows the Precision/Recall curves after symmetrization for the En-Fr corpus. The posterior regularization-trained models still performed better, but the differences get smaller after doing the symmetrization. This should not be very surprising, because the soft union symmetrization can be viewed as an approximation of our symmetry constraint applied only at decode time. Applying the symmetrization to the model with symmetry constraints does not affect performance.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Typically this is achieved by a symmetrization heuristic that takes two directional alignments and produces a single alignment. ", "mid_sen": "For MT the most commonly used heuristic is called grow diagonal final (Och and Ney 2003) . ", "after_sen": "This starts with the intersection of the sets of aligned points and adds points around the diagonal that are in the union of the two sets of aligned points. "}
{"citeStart": 140, "citeEnd": 152, "citeStartToken": 140, "citeEndToken": 152, "sectionName": "UNKNOWN SECTION NAME", "string": "Since the SemEval dataset is of a very specific nature, we have also applied our classification framework to the (Nastase and Szpakowicz, 2003) dataset, which contains 600 pairs labeled with 5 main relationship types. We have used the exact evaluation procedure described in (Turney, 2006) , achieving a class f-score average of 60.1, as opposed to 54.6 in (Turney, 2005) and 51.2 in (Nastase et al., 2006) . This shows that our method produces superior results for rather differing datasets.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Since the SemEval dataset is of a very specific nature, we have also applied our classification framework to the (Nastase and Szpakowicz, 2003) dataset, which contains 600 pairs labeled with 5 main relationship types. ", "mid_sen": "We have used the exact evaluation procedure described in (Turney, 2006) , achieving a class f-score average of 60.1, as opposed to 54.6 in (Turney, 2005) and 51.2 in (Nastase et al., 2006) . ", "after_sen": "This shows that our method produces superior results for rather differing datasets."}
{"citeStart": 85, "citeEnd": 103, "citeStartToken": 85, "citeEndToken": 103, "sectionName": "UNKNOWN SECTION NAME", "string": "3 A second baseline that accounts for text segments is also calculated and reported in section 6. centroid-based method implemented in the MEAD system , for three main reasons. First, MEAD was shown to lead to good performance in several DUC evaluations, e.g., (Radev et al., 2003; Li et al., 2005) . Second, it is an unsupervised method which, unlike supervised approaches, does not require training data (not available in our case). Finally, the centroid-based techniques implemented in MEAD can be optimized and made very efficient, which is an important aspect in the summarization of very long documents such as books.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "3 A second baseline that accounts for text segments is also calculated and reported in section 6. centroid-based method implemented in the MEAD system , for three main reasons. ", "mid_sen": "First, MEAD was shown to lead to good performance in several DUC evaluations, e.g., (Radev et al., 2003; Li et al., 2005) . ", "after_sen": "Second, it is an unsupervised method which, unlike supervised approaches, does not require training data (not available in our case). "}
{"citeStart": 55, "citeEnd": 68, "citeStartToken": 55, "citeEndToken": 68, "sectionName": "UNKNOWN SECTION NAME", "string": "Background Existing work falls into one of two categories, lexical cohesion methods and multi-source methods (Yaari, 1997) . The former stem from the work of Halliday and Hasan (Halliday and Hasan, 1976) . They proposed that text segments with similar vocabulary are likely to be part of a coherent topic segment. hnplementations of this idea use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997) , context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999) , entity repetition (Kan et al., 1998) , semantic similarity (Morris and Hirst, 1991; Kozima, 1993) , word distance model (Beeferman et al., 1997a ) and word frequency model (Reynar, 1999) to detect cohesion. Methods for finding the topic boundaries include sliding window (Hearst, 1994) , lexical chains (Morris, 1988; Kan et al., 1998) , dynamic programming (Ponte and Croft, 1997; Heinonen, 1998) , agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994) . Lexical cohesion methods are typically used for segmenting written text in a collection to improve information retrieval (Hearst, 1994; Reynat, 1998) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "They proposed that text segments with similar vocabulary are likely to be part of a coherent topic segment. ", "mid_sen": "hnplementations of this idea use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997) , context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999) , entity repetition (Kan et al., 1998) , semantic similarity (Morris and Hirst, 1991; Kozima, 1993) , word distance model (Beeferman et al., 1997a ) and word frequency model (Reynar, 1999) to detect cohesion. ", "after_sen": "Methods for finding the topic boundaries include sliding window (Hearst, 1994) , lexical chains (Morris, 1988; Kan et al., 1998) , dynamic programming (Ponte and Croft, 1997; Heinonen, 1998) , agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994) . "}
{"citeStart": 89, "citeEnd": 102, "citeStartToken": 89, "citeEndToken": 102, "sectionName": "UNKNOWN SECTION NAME", "string": "We illustrate this approach with the program in Figure 4 , following the presentation of Ullman (1989a; 1989b) . We assume the query to take the form \"?− S(0, x).\", so that the input database can be processed incrementally. The program is first made safe by eliminating the possibility of deriving nonground atoms:", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "By applying the same rewriting method to Datalog programs representing almost linear CFLGs, we can obtain efficient parsing and generation algorithms for various grammar formalisms with context-free derivations.", "mid_sen": "We illustrate this approach with the program in Figure 4 , following the presentation of Ullman (1989a; 1989b) . ", "after_sen": "We assume the query to take the form \"?− S(0, x).\", so that the input database can be processed incrementally. "}
{"citeStart": 100, "citeEnd": 125, "citeStartToken": 100, "citeEndToken": 125, "sectionName": "UNKNOWN SECTION NAME", "string": "The idea that nouns co-occurring in conjunctions tend to be semantically related has been noted in (Riloff and Shepherd, 1997) and used effectively to automatically cluster semantically similar words (Roark and Charniak, 1998; Caraballo, 1999; Widdows and Dorow, 2002) . The tendency for conjoined nouns to be semantically similar has also been exploited for coordinate noun phrase disambiguation by Resnik (1999) who employed a measure of similarity based on WordNet to measure which were the head nouns being conjoined in certain types of coordinate noun phrase.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "If nouns co-occurring in coordination patterns are often semantically similar, and if a simi-larity measure could be defined so that, for example: sim(executives, spouses) > sim(busloads, spouses) then it is potentially useful for coordination disambiguation.", "mid_sen": "The idea that nouns co-occurring in conjunctions tend to be semantically related has been noted in (Riloff and Shepherd, 1997) and used effectively to automatically cluster semantically similar words (Roark and Charniak, 1998; Caraballo, 1999; Widdows and Dorow, 2002) . ", "after_sen": "The tendency for conjoined nouns to be semantically similar has also been exploited for coordinate noun phrase disambiguation by Resnik (1999) who employed a measure of similarity based on WordNet to measure which were the head nouns being conjoined in certain types of coordinate noun phrase."}
{"citeStart": 22, "citeEnd": 34, "citeStartToken": 22, "citeEndToken": 34, "sectionName": "UNKNOWN SECTION NAME", "string": "In this paper, we describes a lexicon organized around systematic polysemy. The lexicon is derived by a fully automatic extraction method which utilizes a clustering technique called tree-cut (Li and Abe, 1998) . In our previous work (Tomuro, 2000) , we applied this method to a small subset of Word-Net nouns and showed potential applicability. In the current work, we applied the method to all nouns and verbs in WordNet, and built a lexicon in which word senses are partitioned by systematic polysemy. We report results of comparing our lexicon with the WordNet cousins as well as the inter-annotator disagreement observed between two semantically annotated corpora: WordNet Semcor (Landes et al., 1998) and DSO (Ng and Lee, 1996) . The results are quite promising: our extraction method discovered 89% of the WordNet cousins, and the sense partitions in our lexicon yielded better values (Carletta, 1996) than arbitrary sense groupings on the agreement data.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The lexicon is derived by a fully automatic extraction method which utilizes a clustering technique called tree-cut (Li and Abe, 1998) . ", "mid_sen": "In our previous work (Tomuro, 2000) , we applied this method to a small subset of Word-Net nouns and showed potential applicability. ", "after_sen": "In the current work, we applied the method to all nouns and verbs in WordNet, and built a lexicon in which word senses are partitioned by systematic polysemy. "}
{"citeStart": 4, "citeEnd": 14, "citeStartToken": 4, "citeEndToken": 14, "sectionName": "UNKNOWN SECTION NAME", "string": "There have been other attempts to link floor participation with topics in political science. In (Hall, 1996) , the author found that serving on a committee can positively predict participation in Congress, but that seniority was not a good predictor. His measure only looked at six bills in three committees, so his method is by far not as comprehensive as the one that we present here. Our approach with MavenRank differs from previous work by providing a large scale analysis of speaker centrality and bringing natural language processing techniques to the realm of political science.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There have been other attempts to link floor participation with topics in political science. ", "mid_sen": "In (Hall, 1996) , the author found that serving on a committee can positively predict participation in Congress, but that seniority was not a good predictor. ", "after_sen": "His measure only looked at six bills in three committees, so his method is by far not as comprehensive as the one that we present here. "}
{"citeStart": 65, "citeEnd": 75, "citeStartToken": 65, "citeEndToken": 75, "sectionName": "UNKNOWN SECTION NAME", "string": "The notion of ~head' employed here is connected more closely with processing control than linguistics. In particular, nothing requires that a head of a rule should share any information with the LItS item, although in practice it often will. Heads serve as anchor-points in the input string around which islands may be formed, and are accordingly treated before non-head items (RHS items are re-ordered during compilation-see below). In the central role of heads, LtIIP resembles parsers devised by Kay (1989) and van Noord (1991) ; in other respects, including the use which is made of heads, the approaches are rather different, however.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Heads serve as anchor-points in the input string around which islands may be formed, and are accordingly treated before non-head items (RHS items are re-ordered during compilation-see below). ", "mid_sen": "In the central role of heads, LtIIP resembles parsers devised by Kay (1989) and van Noord (1991) ; in other respects, including the use which is made of heads, the approaches are rather different, however.", "after_sen": ""}
{"citeStart": 66, "citeEnd": 86, "citeStartToken": 66, "citeEndToken": 86, "sectionName": "UNKNOWN SECTION NAME", "string": "In global linear models (GLMs) for structured prediction, (e.g., (Johnson et al., 1999; Lafferty et al., 2001; Collins, 2002; Altun et al., 2003; Taskar et al., 2004) ), the optimal label y * for an input x is", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "In global linear models (GLMs) for structured prediction, (e.g., (Johnson et al., 1999; Lafferty et al., 2001; Collins, 2002; Altun et al., 2003; Taskar et al., 2004) ), the optimal label y * for an input x is", "after_sen": "EQUATION"}
{"citeStart": 205, "citeEnd": 225, "citeStartToken": 205, "citeEndToken": 225, "sectionName": "UNKNOWN SECTION NAME", "string": "The implementation described in this paper is based on the most recent model, that of (Gorrell (in press) ). This model is interesting in that it does not allow the parser to employ delay tactics, such as using a lookahead buffer (Marcus (1980) , Marcus et al (1983) ), or waiting for the head of a phrase to appear in the input before constructing that phrase (Abney (1987 (Abney ( , 1989 , Pritehett (1992)). Instead, processing is guided by the principle of Incremental Licensing, which states that \"the parser attempts incrementally to satisfy the principles of grammar\". For the purposes of this implementation, I have interpreted this to mean that each word must be attached into a fullyconnected phrase marker as it is found in the input. 1 The psychological desirability of such a 1In fact, GorreU conjectures that, where there is insufficient grammatical information to postulate a structural relation between two constituents, such as in a sequence of two non-case marked NPs in an English centre-embedded construction, the parser may hold these constituents unstructured in its memory (in press, p.212). However, for the purposes of this implementation, we have taken the most constrained position. Note that, since we do not deal with such Full Attachment model has been argued for, especially with regard to the processing of headfinal languages, where evidence has been found of pre-head structuring (Inoue & Fodor (1991) , Frazier (1987) ). Such models have also been explored computationally (Milward (1995) , Crocker (1991) ).", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, for the purposes of this implementation, we have taken the most constrained position. ", "mid_sen": "Note that, since we do not deal with such Full Attachment model has been argued for, especially with regard to the processing of headfinal languages, where evidence has been found of pre-head structuring (Inoue & Fodor (1991) , Frazier (1987) ). ", "after_sen": "Such models have also been explored computationally (Milward (1995) , Crocker (1991) )."}
{"citeStart": 312, "citeEnd": 337, "citeStartToken": 312, "citeEndToken": 337, "sectionName": "UNKNOWN SECTION NAME", "string": "The interest in the 80's begun to turn considering grammar checking as an enterprise of its own right (Carbonell & Hayes, 1983) , (Ilayes & Mouradian, 1981) , (Heidorn et al., 1982) , (.lensen at al., 1983) , though many of the approaches were still in I;t1(: NLU tradition ((]harniak, 198a), (Granger, 1983) , (Kwasny & Sondheimer, 1981) , (Weischedel & Black, ] 980), (Weisehedel & Sondheimer, 1983) . A 1985 Ovum report on nal;llral language applications (.lohnson, 1985) already identifies grammar and style checking as one of the seven major apt)lications of NLP. Currently, every project in grammar checking has as its goal the creation of a writing aid rather than a robust man-machine interface (Adriaens, 1994) , (llolioli ctal., 1992) , (Vosse, 1992) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Many of the NLU systems developed in the 70's indu(le(l a kind of error recovery Inechanisln ranging flom the treatment only of spelling e.rrors, PARRY (1)arkinson c 't al., 1977) , to tile inclusion also of incomplete int)ut containing some kind of ellipsis, LAD-DEll,/LIFEll (Hendrix et al., 1977) .", "mid_sen": "The interest in the 80's begun to turn considering grammar checking as an enterprise of its own right (Carbonell & Hayes, 1983) , (Ilayes & Mouradian, 1981) , (Heidorn et al., 1982) , (.lensen at al., 1983) , though many of the approaches were still in I;t1(: NLU tradition ((]harniak, 198a), (Granger, 1983) , (Kwasny & Sondheimer, 1981) , (Weischedel & Black, ] 980), (Weisehedel & Sondheimer, 1983) . ", "after_sen": "A 1985 Ovum report on nal;llral language applications (.lohnson, 1985) already identifies grammar and style checking as one of the seven major apt)lications of NLP. "}
{"citeStart": 20, "citeEnd": 34, "citeStartToken": 20, "citeEndToken": 34, "sectionName": "UNKNOWN SECTION NAME", "string": "This type of learners constructs a representation for document vectors belonging to a certain class during the learning phase, e.g. decision trees, decision rules or probability weightings. During the categorization phase, the representation is used to assign the appropriate class to a new document vector. Several pruning or specialization heuristics can be used to control the amount of generalization. We used ID3 (Quinlan, 1986) , C4.5 (Quinlan, 1992) and C5.0, RIPPER (Cohen, 1995) , and the Naive Bayes inducer (Good, 1965) contained in the MLCq-q-library. ID3, C4.5 and C5.0 produce decision trees, RIPPER isa rulebased learner and the Naive Bayes algorithm computes conditional probabilities of the classes from the instances. Support Vector Machines (SVMs): SVMs are described in (Vapnik, 1995) . SVMs are binary learners in that they distinguish positive and negative examples for each class. Like eager learners, they construct a representation during the learning phase, namely a hyper plane supported by vectors of positive and negative examples. For each class, a categorizer is built by computing such a hyper plane. During the categorization phase, each categorizer is applied to the new document vector, yielding the probabilities of the document belonging to a class. The probability increases with the distance of thevector from the hyper plane. A document is said to belong to the class with the highest probability. We chose SVM_Light (Joachims, 1998) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A document is said to belong to the class with the highest probability. ", "mid_sen": "We chose SVM_Light (Joachims, 1998) .", "after_sen": "Neural Networks: Neural Networks are a special kind of \"non-symbolic\" eager learning algo-rithm. "}
{"citeStart": 181, "citeEnd": 196, "citeStartToken": 181, "citeEndToken": 196, "sectionName": "UNKNOWN SECTION NAME", "string": "We compute the LMI over a corpus of positive, respectively negative tweets, in order to obtain positive (LMI pos ) and negative (LMI neg ) bigram scores. We combine the following freely available data, leading to a large corpus of positive and negative tweets: -1.6 million automatically labeled tweets from the Sentiment140 data set (Go et al., 2009) , collected by searching for positive and negative emoticons;", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We compute the LMI over a corpus of positive, respectively negative tweets, in order to obtain positive (LMI pos ) and negative (LMI neg ) bigram scores. ", "mid_sen": "We combine the following freely available data, leading to a large corpus of positive and negative tweets: -1.6 million automatically labeled tweets from the Sentiment140 data set (Go et al., 2009) , collected by searching for positive and negative emoticons;", "after_sen": "An online demo illustrating the score values and distributional term similarities in this Twitter space can be found at the LT website http://maggie.lt.informatik. tu-darmstadt.de/jobimviz/ -7,000 manually labeled tweets from University of Michigan; 2 -5,500 manually labeled tweets from Niek J. Sanders; 3 -2,000 manually labeled tweets from the STS-Gold data set (Saif et al., 2013) . "}
{"citeStart": 198, "citeEnd": 203, "citeStartToken": 198, "citeEndToken": 203, "sectionName": "UNKNOWN SECTION NAME", "string": "In any process of learning from examples the accuracy of the training set is the base for the system to make correct predictions. In our case, where the semantic classes are hypothesized not univoquely from the ex~ staples, accuracy becomes fundamental. Different approaches to obtain lexical co-occurrences have been proposed in the literature [BPV92, CGHH91, CH90]. These approaches seem inappropriate for tackling our needs, either because they detect only local co-occurrences[CGHtI9i, CtI90], or because they extract many spurious co-occurrence triples [BPV92, Clt90] . On the one hand, our system intends to learn SRs on any kind of verb's complements. On the other hand, the fact that these approaches extract co-occurrences without reliability on being verbcomplements violates accuracy requirements.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Different approaches to obtain lexical co-occurrences have been proposed in the literature [BPV92, CGHH91, CH90]. ", "mid_sen": "These approaches seem inappropriate for tackling our needs, either because they detect only local co-occurrences[CGHtI9i, CtI90], or because they extract many spurious co-occurrence triples [BPV92, Clt90] . ", "after_sen": "On the one hand, our system intends to learn SRs on any kind of verb's complements. "}
{"citeStart": 64, "citeEnd": 77, "citeStartToken": 64, "citeEndToken": 77, "sectionName": "UNKNOWN SECTION NAME", "string": "We use notation from the PATR-II formalism (Shieber, 1986) and (Shieber, 1992) . The extraction function D/pl extracts the subdag under path pl for a given D, and the embedding function D \\ pl injects D into the enclosing dag D' such that D'/pl = D. The filtering function p is similar to (Shieber, 1992) : p(D) returns a copy of D in which some features may be removed. Note that in this paper .restrictor. specifies the features to be removed by p, whereas in (Shieber, 1985 (Shieber, , 1992 restrictor specifies the features to be retained by restriction which is equivalent to p.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We use notation from the PATR-II formalism (Shieber, 1986) and (Shieber, 1992) . ", "after_sen": "The extraction function D/pl extracts the subdag under path pl for a given D, and the embedding function D \\ pl injects D into the enclosing dag D' such that D'/pl = D. "}
{"citeStart": 123, "citeEnd": 127, "citeStartToken": 123, "citeEndToken": 127, "sectionName": "UNKNOWN SECTION NAME", "string": "(5) Our highest scores of 90.8% LP and 90.5% LR outperform the scores of the best previously published parser by Charniak (2000) who obtains 90.1% for both LP and LR.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "(4) Brill's results demonstrate that this approach can outperform the Hidden Markov Model approaches that are frequently used for part-of-speech tagging (Jelinek, 1985; Church, 1988; DeRose, 1988; Cutting et al., 1992; Weischedel et al., 1993) , as well as showing promise for other applications.", "mid_sen": "(5) Our highest scores of 90.8% LP and 90.5% LR outperform the scores of the best previously published parser by Charniak (2000) who obtains 90.1% for both LP and LR.", "after_sen": "Extracting such comparisons from citations can be of great benefit to researchers. "}
{"citeStart": 25, "citeEnd": 48, "citeStartToken": 25, "citeEndToken": 48, "sectionName": "UNKNOWN SECTION NAME", "string": "Our pruning differs from Zhang and Gildea (2005) in two major ways. First, we perform pruning using both directions of the IBM Model 1 scores; instead of a single figure of merit V , we have two: V F and V B . Only those spans that pass the pruning threshold in both directions are kept. Second, we allow whole spans to be pruned. The figure of merit for a span is", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The total score is the product of the Model probabilities for each column; \"inside\" columns in the range [l, m] are scored according to the sum (or maximum) of Model 1 probabilities for [i, j], and \"outside\" columns use the sum (or maximum) of all probabilities not in the range [i, j] .", "mid_sen": "Our pruning differs from Zhang and Gildea (2005) in two major ways. ", "after_sen": "First, we perform pruning using both directions of the IBM Model 1 scores; instead of a single figure of merit V , we have two: V F and V B . "}
{"citeStart": 37, "citeEnd": 57, "citeStartToken": 37, "citeEndToken": 57, "sectionName": "UNKNOWN SECTION NAME", "string": "Using vector space model and similarity measures for ranking is a common approach in IR for query/text and text/text comparisons (Salton and Buckley, 1988; Salton and Yang, 1973; Croft, 1984; Turtle and Croft, 1992; Bookstein, 1983; Korflmge, 1995; Jones, 1979) . This approach has also been used by (Dagan and Itai, 1994; Gale et al., 1992; Shiitze, 1992; Yarowsky, 1995; 1Lunar is not an unknown word in English, Yeltsin finds its translation in the 4-th candidate. 1994) for sense disambiguation between multiple usages of the same word. Some of the early statistical terminology translation methods are (Brown et al., 1993; Wu and Xia, 1994; Dagan and Church, 1994; Gale and Church, 1991; Kupiec, 1993; Smadja et al., 1996; Kay and RSscheisen, 1993; Fung and Church, 1994; Fhmg, 1995b) . These algorithms all require parallel, translated texts as input. Attempts at exploring nonparallel corpora for terminology translation are very few (Rapp, 1995; Fung, 19953; Fung and McKeown, 1997) . Among these, (Rapp, 1995) proposes that the association between a word and its close collocate is preserved in any language, and (Fung and McKeown, 1997) suggests that the associations between a word and many seed words are also preserved in another language. In this paper,", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Using vector space model and similarity measures for ranking is a common approach in IR for query/text and text/text comparisons (Salton and Buckley, 1988; Salton and Yang, 1973; Croft, 1984; Turtle and Croft, 1992; Bookstein, 1983; Korflmge, 1995; Jones, 1979) . ", "mid_sen": "This approach has also been used by (Dagan and Itai, 1994; Gale et al., 1992; Shiitze, 1992; Yarowsky, 1995; 1Lunar is not an unknown word in English, Yeltsin finds its translation in the 4-th candidate. 1994) for sense disambiguation between multiple usages of the same word. ", "after_sen": "Some of the early statistical terminology translation methods are (Brown et al., 1993; Wu and Xia, 1994; Dagan and Church, 1994; Gale and Church, 1991; Kupiec, 1993; Smadja et al., 1996; Kay and RSscheisen, 1993; Fung and Church, 1994; Fhmg, 1995b) . "}
{"citeStart": 62, "citeEnd": 81, "citeStartToken": 62, "citeEndToken": 81, "sectionName": "UNKNOWN SECTION NAME", "string": "We performed an analysis of our classification features using Guyon et al. (2002) method. The analysis revealed that both structural and syntactic features are important. Among the syntactic features, the dependency path is the most important. Among the structural features, the segment feature (as described in Table 1 ) is the most important.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We performed an analysis of our classification features using Guyon et al. (2002) method. ", "after_sen": "The analysis revealed that both structural and syntactic features are important. "}
{"citeStart": 48, "citeEnd": 73, "citeStartToken": 48, "citeEndToken": 73, "sectionName": "UNKNOWN SECTION NAME", "string": "whereas LFG accounts make use of the following (Bresnan and Kanerva, 1989) : Agent > Beneficiary > Goal / Experiencer > Inst > Patient/Theme > Locative.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This research is supported by TUBITAK (EEEAG-90) and NATO Science Division (TU-LANGUAGE).", "mid_sen": "whereas LFG accounts make use of the following (Bresnan and Kanerva, 1989) : ", "after_sen": "Agent > Beneficiary > Goal / Experiencer > Inst > Patient/Theme > Locative."}
{"citeStart": 115, "citeEnd": 124, "citeStartToken": 115, "citeEndToken": 124, "sectionName": "UNKNOWN SECTION NAME", "string": "In our experiments, the SV, VO and AN relations are extracted from each document by the MINIPAR dependency parser (Lin, 1998) . As with n-grams, instead of using all the SV, VO and AN relations as features, we select among them the best 5000 according to their WLLR and retrain the polarity classifier with our n-gram-based feature set augmented by these 5000 dependencybased features. Results in row 3 of Table 1 are somewhat surprising: the addition of dependencybased features does not offer any improvements over the simple n-gram-based classifier.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, incorporating the VO relation (like, actors) as a feature may allow the learner to learn that the author likes the actors and not necessarily the movie.", "mid_sen": "In our experiments, the SV, VO and AN relations are extracted from each document by the MINIPAR dependency parser (Lin, 1998) . ", "after_sen": "As with n-grams, instead of using all the SV, VO and AN relations as features, we select among them the best 5000 according to their WLLR and retrain the polarity classifier with our n-gram-based feature set augmented by these 5000 dependencybased features. "}
{"citeStart": 100, "citeEnd": 121, "citeStartToken": 100, "citeEndToken": 121, "sectionName": "UNKNOWN SECTION NAME", "string": "The basic task we consider in this paper is that of using spoken language to give commands to a semiautonomous robot or other similar system. As evidence of the importance of this task in the NLP community note that the early, influential system SHRDLU (Winograd, 1973) was intended to address just this type of problem. More recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot (Konolige et al., 1993) and NCARArs InterBOT project (Perzanowski et al., 1998; Perzanowski et al., 1999) . A number of other systems have addressed part of the task. Com-mandTalk (Moore et al., 1997) , Circuit Fix-It Shop (Smith, 1997) and (Traum and Allen, 1994; Tranm and Andersen, 1999) are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents. Jack's MOOse Lodge (Badler et al., 1999 ) takes text rather than speech as natural language input and the avatars being controlled are not semi-autonomous. Other researchers have considered particular aspects of the problem such as accounting for various aspects of actions (Webber, 1995; Pyre et al., 1995) . In most of this and other related work the treatment is some variant of the following. If there is a speech interface, the input speech signal is converted into text. Text either from the recognizer or directly input by the user is then converted into some kind of logical formula, which abstractly represents the user's intended command; this formula is then fed into a command interpreter, which executes the command.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "As evidence of the importance of this task in the NLP community note that the early, influential system SHRDLU (Winograd, 1973) was intended to address just this type of problem. ", "mid_sen": "More recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot (Konolige et al., 1993) and NCARArs InterBOT project (Perzanowski et al., 1998; Perzanowski et al., 1999) . ", "after_sen": "A number of other systems have addressed part of the task. "}
{"citeStart": 220, "citeEnd": 236, "citeStartToken": 220, "citeEndToken": 236, "sectionName": "UNKNOWN SECTION NAME", "string": "Adaptor grammars achieve this by associating each adapted nonterminal A ∈ M with a Dirichlet Process (DP). A DP is a function of a base distribution H and a concentration parameter α, and it returns a distribution over distributions DP(α, H). There are several different ways to define DPs; one of the most useful is the characterization of the conditional or sampling distribution of a draw from DP(α, H) in terms of the Polya urn or Chinese Restaurant Process (Teh et al., 2006) . The Polya urn initially contains αH(x) balls of color x. We sample a distribution from DP(α, H) by repeatedly drawing a ball at random from the urn and then returning it plus an additional ball of the same color to the urn.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A DP is a function of a base distribution H and a concentration parameter α, and it returns a distribution over distributions DP(α, H). ", "mid_sen": "There are several different ways to define DPs; one of the most useful is the characterization of the conditional or sampling distribution of a draw from DP(α, H) in terms of the Polya urn or Chinese Restaurant Process (Teh et al., 2006) . ", "after_sen": "The Polya urn initially contains αH(x) balls of color x. "}
{"citeStart": 60, "citeEnd": 93, "citeStartToken": 60, "citeEndToken": 93, "sectionName": "UNKNOWN SECTION NAME", "string": "where t i is a disambiguated POS tag of the ith word, a i is the abbreviation flag of the ith word, and O i is the observation at the ith position, which in our case is the ambiguity class the word belongs to, its capitalization, and its abbreviation flag (AmbClass i , a i , Cap i ) . Since the abbreviation flag of the previous word strongly influences period disambiguation, it was included in the standard trigram model. We decided to train the tagger with the minimum of preannotated resources. First, we used 20,000 tagged words to \"bootstrap\" the training process, because purely unsupervised techniques, at least for the HMM class of taggers, yield lower precision. We also used our DCA system to assign capitalized words, abbreviations, and sentence breaks, retaining only cases assigned by the strategies with an accuracy not less than 99.8%. This was done because purely unsupervised techniques (e.g., Baum-Welch [Baum and Petrie 1966] or Brill's [Brill 1995b ]) enable regularities to be induced for word classes which contain many entries, exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns. Counting all possible POS combinations in these ambiguity patterns over multiple patterns usually produces the right combinations as the most frequent. Periods as many other closed-class words cannot be successfully covered by such technique.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We also used our DCA system to assign capitalized words, abbreviations, and sentence breaks, retaining only cases assigned by the strategies with an accuracy not less than 99.8%. ", "mid_sen": "This was done because purely unsupervised techniques (e.g., Baum-Welch [Baum and Petrie 1966] or Brill's [Brill 1995b ]) enable regularities to be induced for word classes which contain many entries, exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns. ", "after_sen": "Counting all possible POS combinations in these ambiguity patterns over multiple patterns usually produces the right combinations as the most frequent. "}
{"citeStart": 90, "citeEnd": 115, "citeStartToken": 90, "citeEndToken": 115, "sectionName": "UNKNOWN SECTION NAME", "string": "In order to build our computational model, we combine a linguistic scheme opinion frames (Somasundaran et al., 2008 ) with a collective classification framework (Bilgic et al., 2007) . According to this scheme, two opinions are related in the discourse when their targets (what they are about) are related. Further, these pair-wise discourse-level relations between opinions are either reinforcing or non-reinforcing frames. Reinforcing frames capture reinforcing discourse scenarios where the individual opinions reinforce one another, contributing to the same opinion polarity or stance. Non-reinforcing frames, on the other hand, capture discourse scenarios where the individual opinions do not support the same stance. The individual opinion polarities and the type of relation between their targets determine whether the discourse frame is reinforcing or non-reinforcing.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "To capture this information, we propose discourse-level opinion graphs for classifying opinion polarity.", "mid_sen": "In order to build our computational model, we combine a linguistic scheme opinion frames (Somasundaran et al., 2008 ) with a collective classification framework (Bilgic et al., 2007) . ", "after_sen": "According to this scheme, two opinions are related in the discourse when their targets (what they are about) are related. "}
{"citeStart": 62, "citeEnd": 73, "citeStartToken": 62, "citeEndToken": 73, "sectionName": "UNKNOWN SECTION NAME", "string": "Selection of learning algorithm and its algorithmspecific parameters were done as follows. For each of the 7 classification tasks (one per relationship type), for each of the 128 pattern clustering schemes, we prepared a list of most of the compatible algorithms available in Weka, and we automatically selected the model (a parameter set and an algorithm) which gave the best 10-fold cross-validation results. The winning algorithms were LWL (Atkeson et al., 1997) , SMO (Platt, 1999) , and K* (Cleary and Trigg, 1995 ) (there were 7 tasks, and different algorithms could be selected for each task). We then used the obtained model to classify the testing set. This allowed us to avoid fixing parameters that are best for a specific dataset but not for others. Since each dataset has only 140 examples, the computation time of each learning algorithm is negligible.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For each of the 7 classification tasks (one per relationship type), for each of the 128 pattern clustering schemes, we prepared a list of most of the compatible algorithms available in Weka, and we automatically selected the model (a parameter set and an algorithm) which gave the best 10-fold cross-validation results. ", "mid_sen": "The winning algorithms were LWL (Atkeson et al., 1997) , SMO (Platt, 1999) , and K* (Cleary and Trigg, 1995 ) (there were 7 tasks, and different algorithms could be selected for each task). ", "after_sen": "We then used the obtained model to classify the testing set. "}
{"citeStart": 15, "citeEnd": 47, "citeStartToken": 15, "citeEndToken": 47, "sectionName": "UNKNOWN SECTION NAME", "string": "When ρ 12 is positive, x 1 and x 2 are positively correlated: a rise in x 1 or x 2 tends to be accompanied by a rise in the other result. When ρ 12 is negative, x 1 and x 2 are negatively correlated: a rise in x 1 or x 2 tends to be accompanied by a decline in the other result. −1 ≤ ρ 12 ≤ 1 (Larsen and Marx, 1986, Sec. 10.2) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "When ρ 12 is negative, x 1 and x 2 are negatively correlated: a rise in x 1 or x 2 tends to be accompanied by a decline in the other result. ", "mid_sen": "−1 ≤ ρ 12 ≤ 1 (Larsen and Marx, 1986, Sec. 10.2) .", "after_sen": "The assumption of independence is often used in formulas to determine the statistical significance of the difference d = x 1 − x 2 . "}
{"citeStart": 4, "citeEnd": 20, "citeStartToken": 4, "citeEndToken": 20, "sectionName": "UNKNOWN SECTION NAME", "string": "It should be noted that specificity by it-self is not enough information from which to construct a noun hierarchy. This project is meant to provide a tool to support other methods. See Caraballo (1999) for a detailed description of a method to construct such a hierarchy.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This project is meant to provide a tool to support other methods. ", "mid_sen": "See Caraballo (1999) for a detailed description of a method to construct such a hierarchy.", "after_sen": ""}
{"citeStart": 121, "citeEnd": 143, "citeStartToken": 121, "citeEndToken": 143, "sectionName": "UNKNOWN SECTION NAME", "string": "The seminal work of Brown et al. (1993b) introduced a series of probabilistic models (IBM Models 1-5) for statistical machine translation and the concept of \"word-byword\" alignment, the correspondence between words in source and target languages. Although no longer competitive as end-to-end translation models, the IBM Models, as well as the hidden Markov model (HMM) of Vogel, Ney, and Tillmann (1996) , are still widely used for word alignment. Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003 ] and rules [Galley et al. 2004; Chiang et al. 2005] ) as well as for MT system combination (Matusov, Ueffing, and Ney 2006) . But their importance has grown far beyond machine translation: for instance, transferring annotations between languages (Yarowsky and Ngai 2001; Hwa et al. 2005; Ganchev, Gillenwater, and Taskar 2009) ; discovery of paraphrases (Bannard and Callison-Burch 2005) ; and joint unsupervised POS and parser induction across languages (Snyder and Barzilay 2008) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003 ] and rules [Galley et al. 2004; Chiang et al. 2005] ) as well as for MT system combination (Matusov, Ueffing, and Ney 2006) . ", "mid_sen": "But their importance has grown far beyond machine translation: for instance, transferring annotations between languages (Yarowsky and Ngai 2001; Hwa et al. 2005; Ganchev, Gillenwater, and Taskar 2009) ; discovery of paraphrases (Bannard and Callison-Burch 2005) ; and joint unsupervised POS and parser induction across languages (Snyder and Barzilay 2008) .", "after_sen": "IBM Models 1 and 2 and the HMM are simple and tractable probabilistic models, which produce the target sentence one target word at a time by choosing a source word and generating its translation. "}
{"citeStart": 82, "citeEnd": 105, "citeStartToken": 82, "citeEndToken": 105, "sectionName": "UNKNOWN SECTION NAME", "string": "It is known that the distribution of words in a document is related to its topic (Salton and McGill, 1983) . We have developed related techniques for approximating pragmatic constraints using words that appear in the immediate context of the entity.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A writer is likely to select a description that puts the entity in the context of the rest of the article.", "mid_sen": "It is known that the distribution of words in a document is related to its topic (Salton and McGill, 1983) . ", "after_sen": "We have developed related techniques for approximating pragmatic constraints using words that appear in the immediate context of the entity."}
{"citeStart": 78, "citeEnd": 89, "citeStartToken": 78, "citeEndToken": 89, "sectionName": "UNKNOWN SECTION NAME", "string": "In this section we describe the stages of the cascade. The very first stage consists of a Memory-Based Part-of-Speech Tagger (MBT) for which we refer to (Daelemans et al., 1996) . The next three stages involve determining boundaries and labels of chunks. Chunks are nonrecursive, non-overlapping constituent parts of sentences (see (Abney, 1991) ). First, we simultaneously chunk sentences into: NP-, VP-, Prep-, ADJP-and APVP-chunks. As these chunks are non-overlapping, no words can belong to more than one chunk, and thus no conflicts can arise. Prep-chunks are the prepositional part of PPs, thus excluding the nominal part. Then we join a Prep-chunk and one -or more coordinated --NP-chunks into a PPchunk. Finally, we assign adverbial function (ADVFUNC) labels (e.g. locative or temporal) to all chunks.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The next three stages involve determining boundaries and labels of chunks. ", "mid_sen": "Chunks are nonrecursive, non-overlapping constituent parts of sentences (see (Abney, 1991) ). ", "after_sen": "First, we simultaneously chunk sentences into: NP-, VP-, Prep-, ADJP-and APVP-chunks. "}
{"citeStart": 433, "citeEnd": 457, "citeStartToken": 433, "citeEndToken": 457, "sectionName": "UNKNOWN SECTION NAME", "string": "There is a large body of psycholinguistic evidence which suggests that meaning can be extracted before the end of a sentence, and before the end of phrasal constituents (e.g. Marslen-Wilson 1973 , Tanenhaus et al. 1990 ). There is also recent evidence suggesting that, during speech processing, partial interpretations can be built extremely rapidly, even before words are completed (Spivey-Knowlton et al. 1994) 1. There are also potential computational applications for incremental interpretation, including early parse filtering using statistics based on logical form plausibility, and interpretation of fragments of dialogues (a survey is provided by Milward and Cooper, 1994 , henceforth referred to as M&:C).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There is a large body of psycholinguistic evidence which suggests that meaning can be extracted before the end of a sentence, and before the end of phrasal constituents (e.g. Marslen-Wilson 1973 , Tanenhaus et al. 1990 ). ", "mid_sen": "There is also recent evidence suggesting that, during speech processing, partial interpretations can be built extremely rapidly, even before words are completed (Spivey-Knowlton et al. 1994) 1. There are also potential computational applications for incremental interpretation, including early parse filtering using statistics based on logical form plausibility, and interpretation of fragments of dialogues (a survey is provided by Milward and Cooper, 1994 , henceforth referred to as M&:C).", "after_sen": "In the current computational and psycholinguistic literature there are two main approaches to the incremental construction of logical forms. "}
{"citeStart": 0, "citeEnd": 14, "citeStartToken": 0, "citeEndToken": 14, "sectionName": "UNKNOWN SECTION NAME", "string": "Recognition of punctuational phenomena does not imply tha.t they can be successfully encoded into a NL grammar, or whether the use of such a punctuated grammar will result in arty analytical advantages. Nunberg [1990] adw~cates two separate grammars, operatiug at different levels.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Recognition of punctuational phenomena does not imply tha.t they can be successfully encoded into a NL grammar, or whether the use of such a punctuated grammar will result in arty analytical advantages. ", "mid_sen": "Nunberg [1990] adw~cates two separate grammars, operatiug at different levels.", "after_sen": "A lexical grammar is proposed ['or the lexical expressions occurring between l~unctuation marl;s, and a text grammar is proposed for the structure of the punctuation, and the relation of those marks to the lexical expre."}
{"citeStart": 112, "citeEnd": 123, "citeStartToken": 112, "citeEndToken": 123, "sectionName": "UNKNOWN SECTION NAME", "string": "Using this information we manually constructed transitions of the CoreSC categories that best fit the observed frequencies and our own intuitions. This gave us the following sequence: MOT > (HYP) > OBJ > GOA > BAC > MOD > MET > EXP > OBS > (HYP) > RES > CON. HYP appears twice in the sequence as annotators had distinguished two types of hypotheses, global hypotheses (stated together with other objectives) and hypotheses about particular observations. The model provides an amalgamated representation of CoreSC concepts in abstracts. Interestingly, our semi-empirically derived model closely follows the content model for abstracts described in (Liddy, 1991) . It would be interesting to see how this compares to a Markov model of CoreSC categories learnt from the annotated abstracts.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The model provides an amalgamated representation of CoreSC concepts in abstracts. ", "mid_sen": "Interestingly, our semi-empirically derived model closely follows the content model for abstracts described in (Liddy, 1991) . ", "after_sen": "It would be interesting to see how this compares to a Markov model of CoreSC categories learnt from the annotated abstracts."}
{"citeStart": 0, "citeEnd": 21, "citeStartToken": 0, "citeEndToken": 21, "sectionName": "UNKNOWN SECTION NAME", "string": "Several researchers have worked on learning grammatical properties of words. Elman (1990) trains a connectionist net to predict words, a process that generates internal representations that reflect grammatical category. Brill et al. (1990) try to infer grammatical category from bigram statistics. Finch and Chater (1992) and Finch (1993) use vector models in which words are clustered according to the similarity of their close neighbors in a corpus. Kneser and Ney (1993) present a probabilistic model for entropy maximization that also relies on the immediate neighbors of words in a corpus. Biber (1993) applies factor analysis to collocations of two target words (\"certain\" and \"right\") with their immediate neighbors.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Finch and Chater (1992) and Finch (1993) use vector models in which words are clustered according to the similarity of their close neighbors in a corpus. ", "mid_sen": "Kneser and Ney (1993) present a probabilistic model for entropy maximization that also relies on the immediate neighbors of words in a corpus. ", "after_sen": "Biber (1993) applies factor analysis to collocations of two target words (\"certain\" and \"right\") with their immediate neighbors."}
{"citeStart": 79, "citeEnd": 95, "citeStartToken": 79, "citeEndToken": 95, "sectionName": "UNKNOWN SECTION NAME", "string": "Three papers already annotated according to the GENIA event annotation scheme (Kim et al., 2008) , were further annotated according to the three annotation schemes described above. We obtained all corresponding CoreSCs, events and segments per sentence. Each sentence has a single CoreSC annotation and one or more segment annotations (depending on the number of clauses). Event annotations in a sentence may range from zero to multiple, according to whether any relevant biomedical events are described in the sentence.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Three papers already annotated according to the GENIA event annotation scheme (Kim et al., 2008) , were further annotated according to the three annotation schemes described above. ", "after_sen": "We obtained all corresponding CoreSCs, events and segments per sentence. "}
{"citeStart": 62, "citeEnd": 85, "citeStartToken": 62, "citeEndToken": 85, "sectionName": "UNKNOWN SECTION NAME", "string": "We use the standard generative Dependency Model with Valence (Klein and Manning, 2004) . The generative story is the following: First, the head of the sentence is generated. Then, for each head, all its left children are generated, then the left STOP, then all its right children, and then the right STOP. When a child is generated, the algorithm immediately recurses to generate its subtree. When deciding whether to generate another child in the direction dir or the STOP symbol, we use the", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We use the standard generative Dependency Model with Valence (Klein and Manning, 2004) . ", "after_sen": "The generative story is the following: "}
{"citeStart": 117, "citeEnd": 148, "citeStartToken": 117, "citeEndToken": 148, "sectionName": "UNKNOWN SECTION NAME", "string": "There are several advantages to this approach. Firstly, the system can take advantage of existing research. For example, the name recognition module can make use of the considerable research that exists on name recognition, e.g. (McDonald, 1996) , (Mani et al., 1996) . Secondly, individual components can be replaced when improved models are available, without affecting other parts of the system. Thirdly, this approach is compatible with incorporating multiple components of the same type to improve performance (cf. (van Halteren et al., 1998) who found that combining the results of several part of speech taggers increased performance).", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Secondly, individual components can be replaced when improved models are available, without affecting other parts of the system. ", "mid_sen": "Thirdly, this approach is compatible with incorporating multiple components of the same type to improve performance (cf. (van Halteren et al., 1998) who found that combining the results of several part of speech taggers increased performance).", "after_sen": ""}
{"citeStart": 165, "citeEnd": 177, "citeStartToken": 165, "citeEndToken": 177, "sectionName": "UNKNOWN SECTION NAME", "string": "(XTAG, 1998) describes a baseNP chunker built from training data by a technique called supertagging. The performance of the chunker was an improvement of the Ramshaw and Marcus results (Fz=I =92.4). (Mufioz et al., 1999) use SNOW, a network of linear units, for recognizing baseNP phrases 6We have applied majority voting of five data representations to the Ramshaw and Marcus data set without using lexical information and the results were: accuracy O: 97.60%, accuracy C: 98.10%, precision: 92.19%, recall: 91.53% and F~=I: 91.86. and SV phrases. They compare two data representations and report that a representation with bracket structures outperforms the IOB tagging representation introduced by (Ramshaw and Marcus, 1995) . SNoW reaches the best performance on this task (Fz=I =92.8).", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "(Mufioz et al., 1999) use SNOW, a network of linear units, for recognizing baseNP phrases 6We have applied majority voting of five data representations to the Ramshaw and Marcus data set without using lexical information and the results were: accuracy O: 97.60%, accuracy C: 98.10%, precision: 92.19%, recall: 91.53% and F~=I: 91.86. and SV phrases. ", "mid_sen": "They compare two data representations and report that a representation with bracket structures outperforms the IOB tagging representation introduced by (Ramshaw and Marcus, 1995) . SNoW reaches the best performance on this task (Fz=I =92.8).", "after_sen": "There has been less work on identifying general noun phrases than on recognizing baseNPs. "}
{"citeStart": 265, "citeEnd": 277, "citeStartToken": 265, "citeEndToken": 277, "sectionName": "UNKNOWN SECTION NAME", "string": "The agent architecture R/r deliberalion and means-end reasoning is based on the IRMA architeclure, also used in the 'l-'ile, World simulation environment IPollack and R.inguclte, 19901, with Ihe addition of a model o1' lira-ile(l Allenlkm/Working IllellIOfy, AWM, [Walker, 1993] inchldes a fullef disctlssion of tile l)esig,>WorM deliberation and melms-end reasoning mechanism and Ihe underlying mechanisms assumed in collaborative planning.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This seclion discusses how Design-World SUl)ports Ihc plu'iunetfization of these [~ICIOfS.", "mid_sen": "The agent architecture R/r deliberalion and means-end reasoning is based on the IRMA architeclure, also used in the 'l-'ile, World simulation environment IPollack and R.inguclte, 19901, with Ihe addition of a model o1' lira-ile(l Allenlkm/Working IllellIOfy, AWM, [Walker, 1993] inchldes a fullef disctlssion of tile l)esig,>WorM deliberation and melms-end reasoning mechanism and Ihe underlying mechanisms assumed in collaborative planning.", "after_sen": "We hypolhcsizcd lhal a warrant Inllsi be ,'qAIJENT for hoth agents (as shown by example 2). "}
{"citeStart": 32, "citeEnd": 44, "citeStartToken": 32, "citeEndToken": 44, "sectionName": "UNKNOWN SECTION NAME", "string": "Ino earlyi tradingr ino Hongl Kongz MondayB ,o goldz waso quotedo ato $r 366.50z anB ounce/ -o This set of three tags is sufficient for encoding baseNP structures since these structures are nonrecursive and nonoverlapping. (Tjong Kim Sang and Veenstra, 1999) have presented three variants of this tagging representation. First, the B tag can be used for the first word of every noun phrase (IOB2 representation). Second, instead of the B tag an E tag can be used to mark the last word of a baseNP immediately before another baseNP (IOE1). And third, the E tag can be used for every noun phrase final word (IOE2). They have used the (Ramshaw and Marcus, 1995) representation as well (IOB1). We will use these four tagging representations as well as the O+C representation.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "And third, the E tag can be used for every noun phrase final word (IOE2). ", "mid_sen": "They have used the (Ramshaw and Marcus, 1995) representation as well (IOB1). ", "after_sen": "We will use these four tagging representations as well as the O+C representation."}
{"citeStart": 67, "citeEnd": 81, "citeStartToken": 67, "citeEndToken": 81, "sectionName": "UNKNOWN SECTION NAME", "string": "Two coders each coded 482 utterances with the adapted DRI features (44% of our corpus). Table 1 reports values for the Kappa (K) coefficient of agreement (Carletta, 1996) for Forward and Backward Functions .6 The columns in the tables read as follows: if utterance Ui has tag X, do coders agree on the subtag? For example, the possible set of values for I-on-H are: NIL (Ui is not tagged with this dimension), Action-Directive, Open-Option, and Info-Request. The last two columns probe the subtypes of Backward Functions: was Ui tagged as an answer to the same antecedent? was Ui tagged as accepting, re. jecting, or holding the same antecedent? T K factors out chance agreement between coders; K=0 means agreement is not different from chance, and K=I means perfect agreement. To assess the import of the values 0 <: K < 1 beyond K's statistical significance (all of our K values are significant at p=0.000005), the discourse processing community uses Krippendorf's scale (1980) 8, which dis-eFor problem solving features, K for two doubly coded dialogues was > .8. Since reliability was good and time was short, we used one coder for the remaining dialogues.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Two coders each coded 482 utterances with the adapted DRI features (44% of our corpus). ", "mid_sen": "Table 1 reports values for the Kappa (K) coefficient of agreement (Carletta, 1996) for Forward and Backward Functions .6 The columns in the tables read as follows: if utterance Ui has tag X, do coders agree on the subtag? ", "after_sen": "For example, the possible set of values for I-on-H are: NIL (Ui is not tagged with this dimension), Action-Directive, Open-Option, and Info-Request. "}
{"citeStart": 1, "citeEnd": 9, "citeStartToken": 1, "citeEndToken": 9, "sectionName": "UNKNOWN SECTION NAME", "string": "There are three key issues which pertain to example-based translation : ® establishment of correspondence between units in a bi/multi-lingual text at sentence, phrase or word level • a mechanism for retrieving from the database the unit that best matches the input • exploiting the retrieved translation example to produce the actual translation of the input sentence [Brown 91 ] and [Gale 91 ] have prolx~Sed methods for establishing correspondence between sentences in bilingual corpora. [Brown 93 ], [Sadler 901 and [Kaji 92 ] have tackled the problem of establishing correspondences between words and phrases in bilingual texts.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "There are three key issues which pertain to example-based translation : ® establishment of correspondence between units in a bi/multi-lingual text at sentence, phrase or word level • a mechanism for retrieving from the database the unit that best matches the input • exploiting the retrieved translation example to produce the actual translation of the input sentence [Brown 91 ] and [Gale 91 ] have prolx~Sed methods for establishing correspondence between sentences in bilingual corpora. ", "mid_sen": "[Brown 93 ], [Sadler 901 and [Kaji 92 ] have tackled the problem of establishing correspondences between words and phrases in bilingual texts.", "after_sen": "The third key issue of EBMT, that is exploiting the retrieved translation example, is usually dealt with by integrating into the system conventional MT techniques [Kaji 92 ], [Sumita 91] . "}
{"citeStart": 1, "citeEnd": 12, "citeStartToken": 1, "citeEndToken": 12, "sectionName": "UNKNOWN SECTION NAME", "string": "TAGs are important in the modelling of natural language since they can be easily lexicalized; moreover the trees associated with words can be used to encode argument and adjunct relations in various syntactic environments. This paper assumes some familiarity with the TAG formalism. (Joshi, 1988) and (Joshi and Schabes, 1992) are good introductions to the formalism and its linguistic relevance. TAGs have been shown to have relations with both phrasestructure grammars and dependency grammars (Rambow and Joshi, 1995) and can handle (non-projective) long distance dependencies.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This paper assumes some familiarity with the TAG formalism. ", "mid_sen": "(Joshi, 1988) and (Joshi and Schabes, 1992) are good introductions to the formalism and its linguistic relevance. ", "after_sen": "TAGs have been shown to have relations with both phrasestructure grammars and dependency grammars (Rambow and Joshi, 1995) and can handle (non-projective) long distance dependencies."}
{"citeStart": 276, "citeEnd": 289, "citeStartToken": 276, "citeEndToken": 289, "sectionName": "UNKNOWN SECTION NAME", "string": "(5) Table 2 shows an example of feature weighting for the text \"I like football\" using 1-skip-2-grams 3 . Each row represents a skipgram with a value for each polarity, calculated as score(s,p)⋅skips (s i ) . The final row is the sum of all the previous values, which will be employed as feature weights for the machine learning process. Table 2 : Example of features weights for the sentence \"I like football\" with 1-skip-2-grams To build our model we employed Support Vector Machines (SVM), as it has been proved to be effective on text categorisation tasks and robust on large feature spaces [Sebastiani 2002 , Mohammad 2013 . More specifically, we used the LibSVM [Chang 2011 ] default implementation (linear kernel, C=1, ε=0.1).", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The final row is the sum of all the previous values, which will be employed as feature weights for the machine learning process. ", "mid_sen": "Table 2 : Example of features weights for the sentence \"I like football\" with 1-skip-2-grams To build our model we employed Support Vector Machines (SVM), as it has been proved to be effective on text categorisation tasks and robust on large feature spaces [Sebastiani 2002 , Mohammad 2013 . ", "after_sen": "More specifically, we used the LibSVM [Chang 2011 ] default implementation (linear kernel, C=1, ε=0.1)."}
{"citeStart": 112, "citeEnd": 137, "citeStartToken": 112, "citeEndToken": 137, "sectionName": "UNKNOWN SECTION NAME", "string": "Our experiments will result in different classifications of the data and we need to find out how to combine these. For this purpose we have evaluated different voting mechanisms, effectively the voting methods as described in (Van Halteren et al., 1998) . All combination methods assign some weight to the results of the individual classifier. For each input token, they pick the classification score with the highest total score. For example, if five classifiers have weights 0.9, 0.4, 0.8, 0.6 and 0.6 respectively and they classify some token as npstart, null, npstart, null and null, then the combination method will pick npstart since it has a higher total score (1.7) than null (1.6). The values of the weights are usually estimated by processing a part of the training data, the tuning data, which has been kept separate as training data for the combination process.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Our experiments will result in different classifications of the data and we need to find out how to combine these. ", "mid_sen": "For this purpose we have evaluated different voting mechanisms, effectively the voting methods as described in (Van Halteren et al., 1998) . ", "after_sen": "All combination methods assign some weight to the results of the individual classifier. "}
{"citeStart": 144, "citeEnd": 169, "citeStartToken": 144, "citeEndToken": 169, "sectionName": "UNKNOWN SECTION NAME", "string": "Your datasets had many labeled reviews and only one author each. Is your work relevant to settings with many authors but very little data for each? A: As discussed in Section 2, it can be quite difficult to properly calibrate different authors' scales, since the same number of \"stars\" even within what is ostensibly the same rating system can mean different things for different authors. But since you ask: we temporarily turned a blind eye to this serious issue, creating a collection of 5394 reviews by 496 authors with at most 80 reviews per author, where we pretended that our rating conversions mapped correctly into a universal rating scheme. Preliminary results on this dataset were actually comparable to the results reported above, although since we are not confident in the class labels themselves, more work is needed to derive a clear analysis of this setting. (Abusing notation, since we're already playing fast and loose: [3c]: baseline 52.4%, reg 61.4%, reg In future work, it would be interesting to determine author-independent characteristics that can be used on (or suitably adapted to) data for specific authors. Q: How about trying -A: -Yes, there are many alternatives. A few that we tested are described in the Appendix, and we propose some others in the next section. We should mention that we have not yet experimented with all-vs.-all (AVA), another standard binary-tomulti-category classifier conversion method, because we wished to focus on the effect of omitting pairwise information. In independent work on 3-category rating inference for a different corpus, Koppel and Schler (2005) found that regression outperformed AVA, and Rifkin and Klautau (2004) argue that in principle OVA should do just as well as AVA. But we plan to try it out.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We should mention that we have not yet experimented with all-vs.-all (AVA), another standard binary-tomulti-category classifier conversion method, because we wished to focus on the effect of omitting pairwise information. ", "mid_sen": "In independent work on 3-category rating inference for a different corpus, Koppel and Schler (2005) found that regression outperformed AVA, and Rifkin and Klautau (2004) argue that in principle OVA should do just as well as AVA. ", "after_sen": "But we plan to try it out."}
{"citeStart": 21, "citeEnd": 25, "citeStartToken": 21, "citeEndToken": 25, "sectionName": "UNKNOWN SECTION NAME", "string": "Thus whilst we do lmblishers ' style guides, of the punctuation systenr, is not really want to rely on since the accounts of i)unctuation they contain are rather too proscriptive and concentrate on tile nse of punctuation rather than its ine~.tnillg, tim academic accounts of l)nnetnation are far from numerous. In the work of Dale [1991] , the potential o1' punctuation in the tiehl of discourse and natnral hmguage generation is explored. However, little mention is made anywhere of tile role of lmnctuation within a syntactic framework. '£herefore the current investigation tries to determine whether taldng consideration of lmnetuation can further the goals of syntactic analysis of natural language.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "tnillg, tim academic accounts of l)nnetnation are far from numerous. ", "mid_sen": "In the work of Dale [1991] , the potential o1' punctuation in the tiehl of discourse and natnral hmguage generation is explored. ", "after_sen": "However, little mention is made anywhere of tile role of lmnctuation within a syntactic framework. "}
{"citeStart": 0, "citeEnd": 13, "citeStartToken": 0, "citeEndToken": 13, "sectionName": "UNKNOWN SECTION NAME", "string": "Researchers have studied the analysis and generation of arguments (Birnbaum et al., 1980; Reichman, 1981; Cohen, 1987; Sycara, 1989; Quilici, 1992; Maybury, 1993) ; however, agents engaging in argumentative dialogues are solely interested in winning an argument and thus exhibit different behavior from collaborative agents. Sidner (1992; formulated an artificial language for modeling collaborative discourse using propo~acceptance and proposal/rejection sequences; however, her work is descriptive and does not specify response generation strategies for agents involved in collaborative interactions. Webber and Joshi (1982) have noted the importance of a cooperative system providing support for its responses. They identified strategies that a system can adopt in justifying its beliefs; however, they did not specify the criteria under which each of these strategies should be selected. Walker (1994) described a method of determining when to include optional warrants to justify a claim based on factors such as communication cost, inference cost, and cost of memory retrieval. However, her model focuses on determining when to include informationally redundant utterances, whereas our model determines whether or not justification is needed for a claim to be convincing and, ff so, selects appropriate evidence from the system's private beliefs to support the claim.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "They identified strategies that a system can adopt in justifying its beliefs; however, they did not specify the criteria under which each of these strategies should be selected. ", "mid_sen": "Walker (1994) described a method of determining when to include optional warrants to justify a claim based on factors such as communication cost, inference cost, and cost of memory retrieval. ", "after_sen": "However, her model focuses on determining when to include informationally redundant utterances, whereas our model determines whether or not justification is needed for a claim to be convincing and, ff so, selects appropriate evidence from the system's private beliefs to support the claim."}
{"citeStart": 15, "citeEnd": 40, "citeStartToken": 15, "citeEndToken": 40, "sectionName": "UNKNOWN SECTION NAME", "string": "As proposed by Pereira and Wright (1997) , our implementation applies the approximation separately for each nonterminal occurring in a set Ni that reveals selfembedding.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This theoretical analysis seems to be in keeping with the high costs of applying this method in practice, as will be shown later in this article.", "mid_sen": "As proposed by Pereira and Wright (1997) , our implementation applies the approximation separately for each nonterminal occurring in a set Ni that reveals selfembedding.", "after_sen": "A different superset approximation based on LR automata was proposed by Baker (1981) and rediscovered by Heckert (1994) . "}
{"citeStart": 31, "citeEnd": 48, "citeStartToken": 31, "citeEndToken": 48, "sectionName": "UNKNOWN SECTION NAME", "string": "13 For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ∈ Σ; their weights are normalized to sum to 1. Besides computing c, the E step must count the expected number dj,a of traversals of arcs in each Dj,a. Then the predicted vector given θ is j,a dj,a • (expected feature counts on a randomly chosen arc in Dj,a). Per-state joint normalization (Eisner, 2001b, §8. 2) is similar but drops the dependence on a. The difficult case is global conditional normalization. It arises, for example, when training a joint model of the form", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Then the predicted vector given θ is j,a dj,a • (expected feature counts on a randomly chosen arc in Dj,a). ", "mid_sen": "Per-state joint normalization (Eisner, 2001b, §8. 2) is similar but drops the dependence on a. ", "after_sen": "The difficult case is global conditional normalization. "}
{"citeStart": 132, "citeEnd": 144, "citeStartToken": 132, "citeEndToken": 144, "sectionName": "UNKNOWN SECTION NAME", "string": "The Model Instead of employing the source-channel paradigm for tagging (more or less explicitly present e.g. in (Merialdo, 1992) , (Church, 1988) , (HajiS, HladkA, 1997) ) used in the past (notwithstanding some exceptions, such as Maximum Entropy and rule-based taggers), we are using here a \"direct\" approach to modeling, for which we have chosen an exponential probabilistic model. Such model (when predicting an event ~ y E Y in a context x) has the general form", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The Model Instead of employing the source-channel paradigm for tagging (more or less explicitly present e.g. in (Merialdo, 1992) , (Church, 1988) , (HajiS, HladkA, 1997) ) used in the past (notwithstanding some exceptions, such as Maximum Entropy and rule-based taggers), we are using here a \"direct\" approach to modeling, for which we have chosen an exponential probabilistic model. ", "after_sen": "Such model (when predicting an event ~ y E Y in a context x) has the general form"}
{"citeStart": 68, "citeEnd": 90, "citeStartToken": 68, "citeEndToken": 90, "sectionName": "UNKNOWN SECTION NAME", "string": "The research reported is in a similar vein to that of, for example, Moore & Dowding (1991) , Samuelsson & Rayner (1991) , and Maxwell & Kaplan (1993) , in that it relies on empirical results for the study and optimisation of parsing algorithms rather than on traditional techniques of complexity analysis. The paper demonstrates that research in this area will have to rely on empirical data until complexity theory is developed to a point where it is sufficiently fine-grained and ac-curate to predict how the properties of individual unification-based grammars will interact with particular parsing algorithms to determine practical performance.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The research reported is in a similar vein to that of, for example, Moore & Dowding (1991) , Samuelsson & Rayner (1991) , and Maxwell & Kaplan (1993) , in that it relies on empirical results for the study and optimisation of parsing algorithms rather than on traditional techniques of complexity analysis. ", "after_sen": "The paper demonstrates that research in this area will have to rely on empirical data until complexity theory is developed to a point where it is sufficiently fine-grained and ac-curate to predict how the properties of individual unification-based grammars will interact with particular parsing algorithms to determine practical performance."}
{"citeStart": 76, "citeEnd": 96, "citeStartToken": 76, "citeEndToken": 96, "sectionName": "UNKNOWN SECTION NAME", "string": "Next, we consider narrative progression in quantified contexts, as in sentence 3. The basic construction is just the same as in the paradigm structure, but now we have narrative progression in the consequent box. This narrative progression is handled as ordinary narrative progression in (Kamp and Reyle, 1993) , i.e. by resetting the Rpt. The DRS in Figure 5 describes the complex state sl, that after each event of John's coming home, there is a sequence of subsequent events according to his activities.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The basic construction is just the same as in the paradigm structure, but now we have narrative progression in the consequent box. ", "mid_sen": "This narrative progression is handled as ordinary narrative progression in (Kamp and Reyle, 1993) , i.e. by resetting the Rpt. The DRS in Figure 5 describes the complex state sl, that after each event of John's coming home, there is a sequence of subsequent events according to his activities.", "after_sen": "Finally, we deal with sentences such as (4), which contain an iteration of an implicit generic quantifier and always. "}
{"citeStart": 65, "citeEnd": 77, "citeStartToken": 65, "citeEndToken": 77, "sectionName": "UNKNOWN SECTION NAME", "string": "Tense interpretation has received much attention in linguistics (Partee, 1984; Hinrichs, 1986; Nerbonne, 1986, inter alia) and natural language processing (Webber, 1988; Kameyama et al., 1993; Lascarides and Asher, 1993, inter alia) . Several researchers (Partee, 1984; Hinrichs, 1986; Nerbonne, 1986; Webber, 1988) have sought to explain the temporal relations induced by tense by treating it as anaphoric, drawing on Reichenbach's separation between event, speech, and reference times (Reichenbach, 1947) . Specifically, to account for the forward progression of time induced by successive simple past tenses in a narrative, they treat the simple past as referring to a time evoked by a previous past tense. For instance, in Hinrichs's (1986) proposal, accomplishments and achievements x introduce a new reference point that is temporally ordered after the time of the event itself, \"ensuring that two consecutive accomplishments or achievements in a discourse are always ordered in a temporal sequence.\" On the other hand, Lascarides and Asher (1993) take the view that temporal relations are resolved purely as a by-product of reasoning about coherence relations holding between utterances, and in doing so, argue that treating simple and complex tenses as anaphoric is unnecessary. This approach parallels the treatment of pronoun resolution espoused by Hobbs (1979) , in which pronouns are modeled as free variables that are bound as a byproduct of coherence resolution. The Temporal Centering framework (Kameyama et al., 1993) integrates lWe will limit the scope of this paper by restricting the discussion to accomplishments and achievements. aspects of both approaches, but patterns with the first in treating tense as anaphoric.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Tense interpretation has received much attention in linguistics (Partee, 1984; Hinrichs, 1986; Nerbonne, 1986, inter alia) and natural language processing (Webber, 1988; Kameyama et al., 1993; Lascarides and Asher, 1993, inter alia) . ", "after_sen": "Several researchers (Partee, 1984; Hinrichs, 1986; Nerbonne, 1986; Webber, 1988) have sought to explain the temporal relations induced by tense by treating it as anaphoric, drawing on Reichenbach's separation between event, speech, and reference times (Reichenbach, 1947) . "}
{"citeStart": 4, "citeEnd": 15, "citeStartToken": 4, "citeEndToken": 15, "sectionName": "UNKNOWN SECTION NAME", "string": "In (Riley, 1989 ), Riley describes a decision-tree based approach to the problem. His performance on /he Brown corpus is 99.8%, using a model learned t'rom a corpus of 25 million words. Liberman and Church suggest in (Liberlnan and Church, 1992) that. a system could be quickly built to divide newswire text into sentences with a nearly negligible error rate. but, do not actually build such a system.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "corpus.", "mid_sen": "In (Riley, 1989 ), Riley describes a decision-tree based approach to the problem. ", "after_sen": "His performance on /he Brown corpus is 99.8%, using a model learned t'rom a corpus of 25 million words. "}
{"citeStart": 82, "citeEnd": 102, "citeStartToken": 82, "citeEndToken": 102, "sectionName": "UNKNOWN SECTION NAME", "string": "The first major use of HMMs for part of speech tagging was in CLAWS (Garside et al., 1987) in the 1970s. With the availability of large corpora and fast computers, there has been a recent resurgence of interest, and a number of variations on and alter-natives to the FB, Viterbi and BW algorithms have been tried; see the work of, for example, Church (Church, 1988) , Brill (Brill and Marcus, 1992; Brill, 1992) , DeRose (DeRose, 1988) and gupiec (Kupiec, 1992) . One of the most effective taggers based on a pure HMM is that developed at Xerox (Cutting et al., 1992) . An important aspect of this tagger is that it will give good accuracy with a minimal amount of manually tagged training data. 96% accuracy correct assignment of tags to word token, compared with a human annotator, is quoted, over a 500000 word corpus.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "With the availability of large corpora and fast computers, there has been a recent resurgence of interest, and a number of variations on and alter-natives to the FB, Viterbi and BW algorithms have been tried; see the work of, for example, Church (Church, 1988) , Brill (Brill and Marcus, 1992; Brill, 1992) , DeRose (DeRose, 1988) and gupiec (Kupiec, 1992) . ", "mid_sen": "One of the most effective taggers based on a pure HMM is that developed at Xerox (Cutting et al., 1992) . ", "after_sen": "An important aspect of this tagger is that it will give good accuracy with a minimal amount of manually tagged training data. "}
{"citeStart": 296, "citeEnd": 327, "citeStartToken": 296, "citeEndToken": 327, "sectionName": "UNKNOWN SECTION NAME", "string": "We gave our human annotators the same task that a coreference resolution system shall solve. This task is similar to the core annotation task of the ACE program: in the so-called \"entity detection and tracking (EDT) task, all mentions of an entity, whether a name, a description, or a pronoun, are to be found and collected into equivalence classes based on reference to the same entity\" (Doddington et al., 2004, p. 837) . However, unlike in ACE, we did not restrict the type of entities to be annotated. Because of this we do not even distinguish entity types in our annotation scheme.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We gave our human annotators the same task that a coreference resolution system shall solve. ", "mid_sen": "This task is similar to the core annotation task of the ACE program: in the so-called \"entity detection and tracking (EDT) task, all mentions of an entity, whether a name, a description, or a pronoun, are to be found and collected into equivalence classes based on reference to the same entity\" (Doddington et al., 2004, p. 837) . ", "after_sen": "However, unlike in ACE, we did not restrict the type of entities to be annotated. "}
{"citeStart": 10, "citeEnd": 25, "citeStartToken": 10, "citeEndToken": 25, "sectionName": "UNKNOWN SECTION NAME", "string": "Following Jacobson (1990) , a more empiricallymotivated assignment is (20):", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We conclude, therefore, that the assignment of the vp/vp type to English auxiliaries and modal verbs is unsupported on both formal and linguistic grounds.", "mid_sen": "Following Jacobson (1990) , a more empiricallymotivated assignment is (20):", "after_sen": "(20) can s/s : λp t .♦p"}
{"citeStart": 277, "citeEnd": 288, "citeStartToken": 277, "citeEndToken": 288, "sectionName": "UNKNOWN SECTION NAME", "string": "Relation transitivity. Some relations, like part-of, in, from can be transitive. For example, we can map a graph that contains a concept A in a certain relation to concept B onto another graph where concept A is in the same relation with a part or a piece of B as exemplified in Figure 2 . Transitivity in relations is in itself a challenging area of study (Cruse, 1986) and we have only begun to explore it.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Some relations, like part-of, in, from can be transitive. ", "mid_sen": "For example, we can map a graph that contains a concept A in a certain relation to concept B onto another graph where concept A is in the same relation with a part or a piece of B as exemplified in Figure 2 . Transitivity in relations is in itself a challenging area of study (Cruse, 1986) and we have only begun to explore it.", "after_sen": ""}
{"citeStart": 9, "citeEnd": 22, "citeStartToken": 9, "citeEndToken": 22, "sectionName": "UNKNOWN SECTION NAME", "string": "Mellish (Mellish, 1989) introduced some chartbased techniques using only syntactic information for extragrammatical sentences. This technique has an advantage that there is no repeating work for the chart to prevent the parser from generating the same edge as the previously existed edge. Also, because the recovery process runs when a normal parser terminates unsuccessfully, the performance of the normal parser does not decrease in case of handling grammatical sentences. However, his experiment was not based on the errors in running texts but on artificial ones which were randomly generated by human. Moreover, only one word error was considered though several word errors can occur simultaneously in the running text.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Therefore, it is important to recover extragrammatical sentences using syntactic factors only, which are independent of any particular system and any particular domain.", "mid_sen": "Mellish (Mellish, 1989) introduced some chartbased techniques using only syntactic information for extragrammatical sentences. ", "after_sen": "This technique has an advantage that there is no repeating work for the chart to prevent the parser from generating the same edge as the previously existed edge. "}
{"citeStart": 130, "citeEnd": 147, "citeStartToken": 130, "citeEndToken": 147, "sectionName": "UNKNOWN SECTION NAME", "string": "The representation scheme described below ix I);~scd on information theory (for more examples of coding systems, see, e.g., Li L: VitKnyi, 1993 and Quinlan & Rivest, 1989) . From this representation, we can derive a formula describing its length in bits. However, the discrete form of the formula would not work well in practice for our simulations. Instead, we use a continuous approximation of the discrete formula; this approximation typically involves dropping the ceiling function from length computations. For example, we sometimes use a self-delimiting representation for integers ( Ill the hhm, ry relu'esentation , the two rohmms a, re", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "and Length Formulae", "mid_sen": "The representation scheme described below ix I);~scd on information theory (for more examples of coding systems, see, e.g., Li L: VitKnyi, 1993 and Quinlan & Rivest, 1989) . ", "after_sen": "From this representation, we can derive a formula describing its length in bits. "}
{"citeStart": 111, "citeEnd": 132, "citeStartToken": 111, "citeEndToken": 132, "sectionName": "UNKNOWN SECTION NAME", "string": "Stochastic parsing models capturing contextual constraints beyond the dependencies of probabilistic context-free grammars (PCFGs) are currently the subject of intensive research. An interesting feature common to most such models is the incorporation of contextual dependencies on individual head words into rulebased probability models. Such word-based lexicalizations of probability models are used successfully in the statistical parsing models of, e.g., Collins (1997) , Charniak (1997) , or Ratnaparkhi (1997) . However, it is still an open question which kind of lexicalization, e.g., statistics on individual words or statistics based upon word classes, is the best choice. Secondly, these approaches have in common the fact that the probability models are trained on treebanks, i.e., corpora of manually disambiguated sentences, and not from corpora of unannotated sentences. In all of the cited approaches, the Penn Wall Street Journal Treebank (Marcus et al., 1993) is used, the availability of which o b viates the standard e ort required for treebank training handannotating large corpora of speci c domains of speci c languages with speci c parse types. Moreover, common wisdom is that training from unannotated data via the expectationmaximization (EM) algorithm (Dempster et al., 1977) yields poor results unless at least partial annotation is applied. Experimental results con rming this wisdom have beenpresented, e.g., by Elworthy (1994) and Pereira and Schabes (1992) for EM training of Hidden Markov Models and PCFGs.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In all of the cited approaches, the Penn Wall Street Journal Treebank (Marcus et al., 1993) is used, the availability of which o b viates the standard e ort required for treebank training handannotating large corpora of speci c domains of speci c languages with speci c parse types. ", "mid_sen": "Moreover, common wisdom is that training from unannotated data via the expectationmaximization (EM) algorithm (Dempster et al., 1977) yields poor results unless at least partial annotation is applied. ", "after_sen": "Experimental results con rming this wisdom have beenpresented, e.g., by Elworthy (1994) and Pereira and Schabes (1992) for EM training of Hidden Markov Models and PCFGs."}
{"citeStart": 47, "citeEnd": 68, "citeStartToken": 47, "citeEndToken": 68, "sectionName": "UNKNOWN SECTION NAME", "string": "The dependency model has also been proposed by Kobayasi et al (1994) for analysing Japanese noun compounds, apparently independently. Using a corpus to acquire associations, they bracket sequences of Kanji with lengths four to six (roughly equivalent to two or three words). A simple calculation shows that using their own preprocessing hueristics to guess a bracketing provides a higher accuracy on their test set than their statistical model does. This renders their experiment inconclusive.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In contrast, the adjacency model appears to predict a proportion of 50%.", "mid_sen": "The dependency model has also been proposed by Kobayasi et al (1994) for analysing Japanese noun compounds, apparently independently. ", "after_sen": "Using a corpus to acquire associations, they bracket sequences of Kanji with lengths four to six (roughly equivalent to two or three words). "}
{"citeStart": 25, "citeEnd": 44, "citeStartToken": 25, "citeEndToken": 44, "sectionName": "UNKNOWN SECTION NAME", "string": "The lack of sufficient data for training appears to be the main reason for the virtual absence of experiments with statistical classifiers in sentiment tagging at the sentence level. To our knowledge, the only work that describes the application of statistical classifiers (SVM) to sentence-level sentiment classification is 1 . The average performance of the system on ternary classification (positive, negative, and neutral) was between 0.50 and 0.52 for both average precision and recall. The results reported by (Riloff et al., 2006) for binary classification of sentences in a related domain of subjectivity tagging (i.e., the separation of sentiment-laden from neutral sentences) suggest that statistical classifiers can perform well on this task: the authors have reached 74.9% accuracy on the MPQA corpus (Riloff et al., 2006) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The average performance of the system on ternary classification (positive, negative, and neutral) was between 0.50 and 0.52 for both average precision and recall. ", "mid_sen": "The results reported by (Riloff et al., 2006) for binary classification of sentences in a related domain of subjectivity tagging (i.e., the separation of sentiment-laden from neutral sentences) suggest that statistical classifiers can perform well on this task: the authors have reached 74.9% accuracy on the MPQA corpus (Riloff et al., 2006) .", "after_sen": "In order to explore the performance of different approaches in sentiment annotation at the text and sentence levels, we used a basic Naïve Bayes classifier. "}
{"citeStart": 73, "citeEnd": 87, "citeStartToken": 73, "citeEndToken": 87, "sectionName": "UNKNOWN SECTION NAME", "string": "We first mangally define the similarity between the EngliSh letter e and the first romanized letter for each katakana character j, as shown in Table 1 . In this table, \"phonetically similar\" letters refer to a certain pair of letters, such as \"L\" and \"R ''4. We then consider the similarity for afiy possible combination of letters in English and romanized katakana words, which can be represented as a matrix, as shown in Figure 3 . This figure shows the similarity between letters in \"<text, te-ki-su-to>\". We put a dummy letter \"$\", which has a positive similarity only t.o itself, at the end of both English and katakana words. One may notice that matching plausible symbols can be seen as finding the path which maximizes the total similarity from the first to last letters. The best path can easily be found by, for example, Dijkstra's algorithm (Dijkstra, 1959) . From Figure 3 , we can derive the following correspondences: \"<re, te>\", \"<X, ki-su>\" and \"<t, to>\". The resultant correspondences contain 944 Japanese and 790 English symbol types, from which we also estimated P(si [ti) and P(ti+l]ti).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "One may notice that matching plausible symbols can be seen as finding the path which maximizes the total similarity from the first to last letters. ", "mid_sen": "The best path can easily be found by, for example, Dijkstra's algorithm (Dijkstra, 1959) . From Figure 3 , we can derive the following correspondences: \"<re, te>\", \"<X, ki-su>\" and \"<t, to>\". ", "after_sen": "The resultant correspondences contain 944 Japanese and 790 English symbol types, from which we also estimated P(si [ti) and P(ti+l]ti)."}
{"citeStart": 70, "citeEnd": 79, "citeStartToken": 70, "citeEndToken": 79, "sectionName": "UNKNOWN SECTION NAME", "string": "To demonstrate our model, we use a 6-fold cross validation procedure, in which we use each sixth of the corpus for testing data, and the rest for training data. We start with the word transcriptions of the Trains corpus, thus allowing us to get a clearer indication of the performance of our model without having to take into account the poor performance of speech recognizers on spontaneous speech. All silence durations are automatically obtained from a word aligner (Ent, 1994) . Table 2 shows how POS tagging, discourse marker identification and perplexity benefit by modeling the speaker's utterance. The POS tagging results are reported as the percentage of words that were assigned the wrong tag. The detection of discourse markers is reported using recall and precision. The recall rate of X is the number of X events that were correctly determined by the algorithm over the number of occurrences of X. The precision rate is the number of X events that were correctly determined over the number of times that the algorithm guessed X. The error rate is the number of X events that the algorithm missed plus the number of X events that it incorrectly guessed as occurring over the number of X events. The last measure is perplexity, which is ", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We start with the word transcriptions of the Trains corpus, thus allowing us to get a clearer indication of the performance of our model without having to take into account the poor performance of speech recognizers on spontaneous speech. ", "mid_sen": "All silence durations are automatically obtained from a word aligner (Ent, 1994) . ", "after_sen": "Table 2 shows how POS tagging, discourse marker identification and perplexity benefit by modeling the speaker's utterance. "}
{"citeStart": 99, "citeEnd": 117, "citeStartToken": 99, "citeEndToken": 117, "sectionName": "UNKNOWN SECTION NAME", "string": "For the evaluation, we use the ROUGE evaluation toolkit. ROUGE is a method based on Ngram statistics, found to be highly correlated with human evaluations (Lin and Hovy, 2003) . 1 Throughout the paper, the evaluations are reported using the ROUGE-1 setting, which seeks unigram matches between the generated and the reference summaries, and which was found to have high correlation with human judgments at a 95% confidence level. Additionally, the final system is also evaluated using the ROUGE-2 (bigram matches) and ROUGE-SU4 (noncontiguous bigrams) settings, which have been frequently used in the DUC evaluations.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For the evaluation, we use the ROUGE evaluation toolkit. ", "mid_sen": "ROUGE is a method based on Ngram statistics, found to be highly correlated with human evaluations (Lin and Hovy, 2003) . ", "after_sen": "1 Throughout the paper, the evaluations are reported using the ROUGE-1 setting, which seeks unigram matches between the generated and the reference summaries, and which was found to have high correlation with human judgments at a 95% confidence level. "}
{"citeStart": 55, "citeEnd": 68, "citeStartToken": 55, "citeEndToken": 68, "sectionName": "UNKNOWN SECTION NAME", "string": "We use notation from the PATR-II formalism (Shieber, 1986) and (Shieber, 1992) . The extraction function D/pl extracts the subdag under path pl for a given D, and the embedding function D \\ pl injects D into the enclosing dag D' such that D'/pl = D. The filtering function p is similar to (Shieber, 1992) : p(D) returns a copy of D in which some features may be removed. Note that in this paper .restrictor. specifies the features to be removed by p, whereas in (Shieber, 1985 (Shieber, , 1992 restrictor specifies the features to be retained by restriction which is equivalent to p.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Note that in this paper .restrictor. ", "mid_sen": "specifies the features to be removed by p, whereas in (Shieber, 1985 (Shieber, , 1992 restrictor specifies the features to be retained by restriction which is equivalent to p.", "after_sen": ""}
{"citeStart": 147, "citeEnd": 170, "citeStartToken": 147, "citeEndToken": 170, "sectionName": "UNKNOWN SECTION NAME", "string": "A second response is to admit that there is a dynamic residue, but to deal with it in overtly computational terms. In particular, it may be possible to augment our approach with an explicit operational semantics, perhaps the evolving algebra approach adopted by Moss and Johnson (1994) . Their approach is attractive, because it permits a computational treatment of dynamism that abstracts from low level algorithmic details. In short, the second strategy is a 'divide and conquer' strategy: treat structural issues using model theoretic tools, and procedural issues with (revealing) computational tools. It's worth remarking that this second response is not incompatible with the first; it is common to provide programming languages with both a denotational and an operational semantics.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A second response is to admit that there is a dynamic residue, but to deal with it in overtly computational terms. ", "mid_sen": "In particular, it may be possible to augment our approach with an explicit operational semantics, perhaps the evolving algebra approach adopted by Moss and Johnson (1994) . ", "after_sen": "Their approach is attractive, because it permits a computational treatment of dynamism that abstracts from low level algorithmic details. "}
{"citeStart": 135, "citeEnd": 154, "citeStartToken": 135, "citeEndToken": 154, "sectionName": "UNKNOWN SECTION NAME", "string": "Paradigmatic associations are words with high semantic similarity. According to Ruge (1992) , the semantic similarity of two words can be computed by determining the agreement of their lexical neighborhoods. For example, the semantic similarity of the words red and blue can be derived from the fact that they both frequently co-occur with words like color, flower, dress, car, dark, bright, beautiful, and so forth. If for each word in a corpus a cooccurrence vector is determined whose entries are the co-occurrences with all other words in the corpus, then the semantic similarities between words can be computed by conducting simple vector comparisons. To determine the words most similar to a given word, its co-occurrence vector is compared to the co-occurrence vectors of all other words using one of the standard similarity measures, for example, the cosine coefficient. Those words that obtain the best values are considered to be most similar. Practical implementations of algorithms based on this principle have led to excellent results as documented in papers by Ruge (1992) , Grefenstette (1994) , Agarwal (1995) , Landauer & Dumais (1997) , Schütze (1997) , and Lin (1998) .", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Those words that obtain the best values are considered to be most similar. ", "mid_sen": "Practical implementations of algorithms based on this principle have led to excellent results as documented in papers by Ruge (1992) , Grefenstette (1994) , Agarwal (1995) , Landauer & Dumais (1997) , Schütze (1997) , and Lin (1998) .", "after_sen": ""}
{"citeStart": 32, "citeEnd": 50, "citeStartToken": 32, "citeEndToken": 50, "sectionName": "UNKNOWN SECTION NAME", "string": "A third relevant line of research is on reusing bitexts between related languages without or with very little adaptation, which works well for very closely related languages. For example, our previous work (Nakov and Ng, 2009; Nakov and Ng, 2012) experimented with various techniques for combining a small bi-text for a resource-poor language (Indonesian or Spanish, pretending that Spanish is resource-poor) with a much larger bi-text for a related resource-rich language (Malay or Portuguese); the target language of all bi-texts was English. However, our previous work did not attempt language adaptation, except for very simple transliteration for Portuguese-Spanish that ignored context entirely; since it could not substitute one word for a completely different word, it did not help much for Malay-Indonesian, which use unified spelling. Still, once we have language-adapted the large bi-text, it makes sense to try to combine it further with the small bi-text; thus, below we will directly compare and combine these two approaches.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A third relevant line of research is on reusing bitexts between related languages without or with very little adaptation, which works well for very closely related languages. ", "mid_sen": "For example, our previous work (Nakov and Ng, 2009; Nakov and Ng, 2012) experimented with various techniques for combining a small bi-text for a resource-poor language (Indonesian or Spanish, pretending that Spanish is resource-poor) with a much larger bi-text for a related resource-rich language (Malay or Portuguese); the target language of all bi-texts was English. ", "after_sen": "However, our previous work did not attempt language adaptation, except for very simple transliteration for Portuguese-Spanish that ignored context entirely; since it could not substitute one word for a completely different word, it did not help much for Malay-Indonesian, which use unified spelling. "}
{"citeStart": 151, "citeEnd": 170, "citeStartToken": 151, "citeEndToken": 170, "sectionName": "UNKNOWN SECTION NAME", "string": "Several problems remain with WIT. One of the most significant is that the system developer must write language generation functions. If the generation functions employ sophisticated dialogue strategies, the system can perform complicated dialogues that are not just question answering. WIT, however, does not provide task-independent facilities that make it easier to employ such dialogue strategies. There have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests (Bobrow et al., 1977; Chu-CarroU, 1999) . Incorporating such techniques would deo crease the system developer workload. However, there has been no work on domain-independent response generation for robust spoken dialogue systems that can deal with utterances that might include pauses in the middle of a sentence, which WIT handles well. Therefore incorporating those techniques remains as a future work.", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "WIT, however, does not provide task-independent facilities that make it easier to employ such dialogue strategies. ", "mid_sen": "There have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests (Bobrow et al., 1977; Chu-CarroU, 1999) . ", "after_sen": "Incorporating such techniques would deo crease the system developer workload. "}
{"citeStart": 67, "citeEnd": 92, "citeStartToken": 67, "citeEndToken": 92, "sectionName": "UNKNOWN SECTION NAME", "string": "We have directly addressed the question as to whether inflection should be predicted using surface forms as the target of the prediction, or whether linguistic features should be predicted, along with the use of a subsequent generation step. The direct prediction of surface forms is limited to those forms observed in the training data, which is a significant limitation. However, it is reasonable to expect that the use of features (and morphological generation) could also be problematic as this requires the use of morphologically-aware syntactic parsers to annotate the training data with such features, and additionally depends on the coverage of morphological analysis and generation. Despite this, our research clearly shows that the feature-based approach is superior for English-to-German SMT. This is a striking result considering state-of-theart performance of German parsing is poor compared with the best performance on English parsing. As parsing performance improves, the performance of linguistic-feature-based approaches will increase. Virpioja et al. (2007) , Badr et al. (2008) , Luong et al. (2010), Clifton and Sarkar (2011) , and others are primarily concerned with using morpheme segmentation in SMT, which is a useful approach for dealing with issues of word-formation. However, this does not deal directly with linguistic features marked by inflection. In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "As parsing performance improves, the performance of linguistic-feature-based approaches will increase. ", "mid_sen": "Virpioja et al. (2007) , Badr et al. (2008) , Luong et al. (2010), Clifton and Sarkar (2011) , and others are primarily concerned with using morpheme segmentation in SMT, which is a useful approach for dealing with issues of word-formation. ", "after_sen": "However, this does not deal directly with linguistic features marked by inflection. "}
{"citeStart": 62, "citeEnd": 83, "citeStartToken": 62, "citeEndToken": 83, "sectionName": "UNKNOWN SECTION NAME", "string": "Context sensitive rewrite rules have been widely used in several areas of natural language processing. Johnson (1972) has shown that such rewrite rules are equivalent to finite state transducers in the special case that they are not allowed to rewrite their own output. An algorithm for compilation into transducers was provided by Kaplan and Kay (1994) . Improvements and extensions to this algorithm have been provided by Karttunen (1995) , Karttunen (1997) , Karttunen (1996) and Mohri and Sproat (1996) . In this paper, the algorithm will be extended to provide a limited form of backreferencing.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Johnson (1972) has shown that such rewrite rules are equivalent to finite state transducers in the special case that they are not allowed to rewrite their own output. ", "mid_sen": "An algorithm for compilation into transducers was provided by Kaplan and Kay (1994) . ", "after_sen": "Improvements and extensions to this algorithm have been provided by Karttunen (1995) , Karttunen (1997) , Karttunen (1996) and Mohri and Sproat (1996) . "}
{"citeStart": 48, "citeEnd": 60, "citeStartToken": 48, "citeEndToken": 60, "sectionName": "UNKNOWN SECTION NAME", "string": "The Generalized LR Parser, developed by Tomita [Tomita, 1986] , extended the original Lit parsing algorithm to the case of non-LR languages, where the parsing tables contain entries with multiple parsing actions. Tomita's algorithm uses a Graph Structured Stack (GSS) in order to efficiently pursue in parallel the different parsing options that arise as a result of the multiple entries in the parsing tables. A second data structure uses pointers to keep track of all possible parse trees throughout the parsing of the input, while sharing common subtrees of these different parses. A process of local ambiguity packing allows the parser to pack subparses that are rooted in the same non-terminal into a single structure that represents them all.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The GLR Parsing Algorithm", "mid_sen": "The Generalized LR Parser, developed by Tomita [Tomita, 1986] , extended the original Lit parsing algorithm to the case of non-LR languages, where the parsing tables contain entries with multiple parsing actions. ", "after_sen": "Tomita's algorithm uses a Graph Structured Stack (GSS) in order to efficiently pursue in parallel the different parsing options that arise as a result of the multiple entries in the parsing tables. "}
{"citeStart": 136, "citeEnd": 156, "citeStartToken": 136, "citeEndToken": 156, "sectionName": "UNKNOWN SECTION NAME", "string": "(4) cat_2(property_l,property_2 .... ). a derived fact or seed magic_cat_l(property_l) bottom-up evaluation of the abstract grammar in figure 7 leads to spurious ambiguity. There are two possible solutions for cat_2 as a result of the fact that the filtering resulting from the magic literal in rule 1 is too unspecific. This is not problematic as long as this nondeterminism will eventually disappear, e.g., by combining these solutions with the solutions to cat_3. The problem arises as a result of the fact that these solutions lead to identical filters for the evaluation of the cat_~ literal, i.e., the solutions to cat_2 do not uniquely determine cat_3. Also with respect to the dependency constraint an optimization of the rules in the grammar is important. Through reordering the right-hand sides of the rules in the grammar the amount of nondeterminism can be drastically reduced as shown in Minnen et al. (1996) . This way of following the intended semantic dependencies the dependency constraint is satisfied automatically for a large class of grammars.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Also with respect to the dependency constraint an optimization of the rules in the grammar is important. ", "mid_sen": "Through reordering the right-hand sides of the rules in the grammar the amount of nondeterminism can be drastically reduced as shown in Minnen et al. (1996) . ", "after_sen": "This way of following the intended semantic dependencies the dependency constraint is satisfied automatically for a large class of grammars."}
{"citeStart": 213, "citeEnd": 228, "citeStartToken": 213, "citeEndToken": 228, "sectionName": "UNKNOWN SECTION NAME", "string": "There have been successful attempts at using machine learning in search of a solution for linguistic tasks, e.g. discriminating between discourse and sentential senses of cues ([Litman 1996]) or resolution of coreferences in texts ([McCarthy & Lehnert 1995] ). Like our work, these problems are cast as classification problems, and then machine learning (mainly C4.5) techniques are used to induce classifiers for each class. What makes \"these applications different from ours is that they have worked on surface linguistic or mixed surface linguistic and intonational representation, and that the classes are relatively balanced, while in our case the class of compound sentences is much less numerous than the class of non-composite sentences. Such unbalanced classes create problems for the majority of inductive learning systems. A distinctive feature of our work is the fact that we used machine learning techniques to improve an existing rule-based natural language processor from the inside. This contrasts with approaches where there are essentially no explicit rules, such as neural networks (e.g. [Buo 1996]) , or approaches where the machine learning algorithms attempt to infer--via deduction (e.g. [Samuelsson 1994] ), induction (e.g. [Theeramunkong et al. 1997] ; [Zelle & Mooney 1994] ) under user cooperation (e.g. [Simmons & Yu 1992] ; [Hermjakob & Mooney 1997] ), transformation-based error-driven learning (e.g. [Brill 1993]) , or even decision trees (e.g. [Magerman 1995])--a grammar from raw or preprocessed data. In our work, we do not wish to acquire a grammar: we have one and want to devise a mechanism to make some of its parts adaptable to the corpus at hand or, to improve some aspect of its performance. Other researchers, such as [Lawrence et al. 1996] , have compared neural networks and machine learning methods at the task of sentence classification. In this task, the system must classify a string as either grammatical or not. We do not content ourselves with results based on a grammatical/ungrammatical dichotomy. We are looking for heuristics, using relevant features, that will do better than the current ones and improve the overall performance of a natural language processor: this is a very difficult problem (see, e.g., [Huyck & Lytinen 1993] ). One could also look at this problem as one of optimisation of a rule-based system.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A distinctive feature of our work is the fact that we used machine learning techniques to improve an existing rule-based natural language processor from the inside. ", "mid_sen": "This contrasts with approaches where there are essentially no explicit rules, such as neural networks (e.g. [Buo 1996]) , or approaches where the machine learning algorithms attempt to infer--via deduction (e.g. [Samuelsson 1994] ), induction (e.g. [Theeramunkong et al. 1997] ; [Zelle & Mooney 1994] ) under user cooperation (e.g. [Simmons & Yu 1992] ; [Hermjakob & Mooney 1997] ), transformation-based error-driven learning (e.g. [Brill 1993]) , or even decision trees (e.g. [Magerman 1995])--a grammar from raw or preprocessed data. ", "after_sen": "In our work, we do not wish to acquire a grammar: we have one and want to devise a mechanism to make some of its parts adaptable to the corpus at hand or, to improve some aspect of its performance. "}
{"citeStart": 159, "citeEnd": 184, "citeStartToken": 159, "citeEndToken": 184, "sectionName": "UNKNOWN SECTION NAME", "string": "Value \"the price was right\", \"My soup was cold and expensive\", \"well worth the cost\" provide ratings for each aspect making automated means unnecessary. Aspect identification has also been thoroughly studied (Hu and Liu, 2004b; Gamon et al., 2005; Titov and McDonald, 2008) , but again, ontologies and users often provide this information negating the need for automation. Though it may be reasonable to expect a user to provide a rating for each aspect, it is unlikely that a user will annotate every sentence and phrase in a review as being relevant to some aspect. Thus, it can be argued that the most pressing challenge in an aspect-based summarization system is to extract all relevant mentions for each aspect, as illustrated in figure 2. When labeled data exists, this problem can be solved effectively using a wide variety of methods available for text classification and information extraction (Manning and Schutze, 1999) . However, labeled data is often hard to come by, especially when one considers all possible domains of products and services. Instead, we propose an unsupervised model that leverages aspect ratings that frequently accompany an online review.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Thus, it can be argued that the most pressing challenge in an aspect-based summarization system is to extract all relevant mentions for each aspect, as illustrated in figure 2. ", "mid_sen": "When labeled data exists, this problem can be solved effectively using a wide variety of methods available for text classification and information extraction (Manning and Schutze, 1999) . ", "after_sen": "However, labeled data is often hard to come by, especially when one considers all possible domains of products and services. "}
{"citeStart": 152, "citeEnd": 178, "citeStartToken": 152, "citeEndToken": 178, "sectionName": "UNKNOWN SECTION NAME", "string": "Our second measure is derived from purity, a global measure which evaluates the mean precision of the clusters, weighted according to the cluster size (Stevenson and Joanis, 2003) . We associate with each cluster its most prevalent semantic class, and denote the number of verbs in a cluster K that take its prevalent class by n prevalent (K). Verbs that do not take this class are considered as errors. Given our task, we are only interested in classes which contain two or more verbs. We therefore disregard those clusters where n prevalent (K) = 1. This leads us to define modified purity:", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This factor compensates for a bias towards small clusters.", "mid_sen": "Our second measure is derived from purity, a global measure which evaluates the mean precision of the clusters, weighted according to the cluster size (Stevenson and Joanis, 2003) . ", "after_sen": "We associate with each cluster its most prevalent semantic class, and denote the number of verbs in a cluster K that take its prevalent class by n prevalent (K). "}
{"citeStart": 227, "citeEnd": 247, "citeStartToken": 227, "citeEndToken": 247, "sectionName": "UNKNOWN SECTION NAME", "string": "In addition, a χ 2 dependency analysis showed that the NM presence interacts significantly with both AsrMis (p<0.02) and SemMis (p<0.001), with fewer than expected AsrMis and SemMis in the 3 Due to random assignment to conditions, before the first problem the F and S populations are similar (e.g. no difference in pretest); thus any differences in metrics can be attributed to the NM presence/absence. However, in the second problem, the two populations are not similar anymore as they have received different forms of instruction; thus any difference has to be attributed to the NM presence/absence in this problem as well as to the NM absence/presence in the previous problem. 4 Due to logging issues, 2 S users are excluded from this analysis (13 F and 13 S users remaining). We run the subjective metric analysis from Section 5.1 on this subset and the results are similar. NM condition. The fact that in the second problem the differences are much smaller (e.g. 2% for AsrMis) and that the NM-AsrMis and NM-SemMis interactions are not significant anymore, suggests that our observations can not be attributed to a difference in population with respect to system's ability to recognize their speech. We hypothesize that these differences are due to the NM text influencing users' lexical choice. Discourse structure has been successfully used in non-interactive settings (e.g. understanding specific lexical and prosodic phenomena (Hirschberg and Nakatani, 1996) , natural language generation (Hovy, 1993) , essay scoring (Higgins et al., 2004) as well as in interactive settings (e.g. predictive/generative models of postural shifts (Cassell et al., 2001) , generation/interpretation of anaphoric expressions (Allen et al., 2001) , performance modeling (Rotaru and Litman, 2006) ).", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We hypothesize that these differences are due to the NM text influencing users' lexical choice. ", "mid_sen": "Discourse structure has been successfully used in non-interactive settings (e.g. understanding specific lexical and prosodic phenomena (Hirschberg and Nakatani, 1996) , natural language generation (Hovy, 1993) , essay scoring (Higgins et al., 2004) as well as in interactive settings (e.g. predictive/generative models of postural shifts (Cassell et al., 2001) , generation/interpretation of anaphoric expressions (Allen et al., 2001) , performance modeling (Rotaru and Litman, 2006) ).", "after_sen": "In this paper, we study the utility of the discourse structure on the user side of a dialogue system. "}
{"citeStart": 33, "citeEnd": 51, "citeStartToken": 33, "citeEndToken": 51, "sectionName": "UNKNOWN SECTION NAME", "string": "OPINE uses explicit features to identify potential opinion phrases. Our intuition is that an opinion phrase associated with a product feature will occur in its vicinity. This idea is similar to that of (Kim and Hovy, 2004) and (Hu and Liu, 2004) , but instead of using a window of size k or the output of a noun phrase chunker, OPINE takes advantage of the syntactic dependencies computed by the MINIPAR parser. Our intuition is embodied by 10 extraction rules, some of which are shown in Table 4 . If an explicit feature is found in a sentence, OPINE applies the extraction rules in order to find the heads of potential opinion phrases. Each head word together with its modi-fiers is returned as a potential opinion phrase 1 . OPINE examines the potential opinion phrases in order to identify the actual opinions. First, the system finds the semantic orientation for the lexical head of each potential opinion phrase. Every phrase whose head word has a positive or negative semantic orientation is then retained as an opinion phrase. In the following, we describe how OPINE finds the semantic orientation of words.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Our intuition is that an opinion phrase associated with a product feature will occur in its vicinity. ", "mid_sen": "This idea is similar to that of (Kim and Hovy, 2004) and (Hu and Liu, 2004) , but instead of using a window of size k or the output of a noun phrase chunker, OPINE takes advantage of the syntactic dependencies computed by the MINIPAR parser. ", "after_sen": "Our intuition is embodied by 10 extraction rules, some of which are shown in Table 4 . "}
{"citeStart": 92, "citeEnd": 109, "citeStartToken": 92, "citeEndToken": 109, "sectionName": "UNKNOWN SECTION NAME", "string": "This paper proposes an approach to improve domain-specific word alignment through alignment model adaptation. Our approach first trains two alignment models with a large-scale out-of-domain corpus and a small-scale domain-specific corpus. Second, we build a new adaptation model by linearly interpolating these two models. Third, we apply the new model to the domain-specific corpus and improve the word alignment results. In addition, with the training data, an interpolated translation dictionary is built to select the word alignment links from different alignment results. Experimental results indicate that our approach achieves a precision of 84.90% and a recall of 75.99% for word alignment in a specific domain. Our method achieves a relative error rate reduction of 17.43% as compared with the method directly combining the out-of-domain corpus and the in-domain corpus as training data. It also achieves a relative error rate reduction of 6.56% as compared with the previous work in ( Wu and Wang, 2004) . In addition, when we train the model with a smaller-scale in-domain corpus as described in (Wu and Wang, 2004) , our method achieves an error rate reduction of 10.15% as compared with the method in (Wu and Wang, 2004) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It also achieves a relative error rate reduction of 6.56% as compared with the previous work in ( Wu and Wang, 2004) . ", "mid_sen": "In addition, when we train the model with a smaller-scale in-domain corpus as described in (Wu and Wang, 2004) , our method achieves an error rate reduction of 10.15% as compared with the method in (Wu and Wang, 2004) .", "after_sen": "We also use in-domain corpora and out-of-domain corpora of different sizes to perform adaptation experiments. "}
{"citeStart": 199, "citeEnd": 207, "citeStartToken": 199, "citeEndToken": 207, "sectionName": "UNKNOWN SECTION NAME", "string": "While our work is in part motivated by the above research, other developmental research supports certain ;assumptions we make. The input to our system is represented as a sequence of i)houenms, so we implicitly assume that infants are aisle I.o ,'ouv('rl, from acoustic inl)ut to phoneme sequem:es; research i)y Kuhl (e.g., Gricser & Kuhl, 1989) suggests tha.t this assmnl)tion is remsonal)h,. Since sentence I)oundaries provide informal.ion ahout word I)oumlaries (the end of a sentence is also the end of a word), our input contains sentence I~oumhu'ik~s; several studies (13ernstein-II.atm 'r, 1985; Ilirsh-lh~sek et al., 1987; Kemler Nels~m, I lirsh-I'asek, ,lusczyk & Wright C; msidy, 1989; ,I usczyk et al., 1992) have shown that infimts can perceive senl,cncc I)oundarics using prosodic cues. Ih)wever, FiSher and 'lbkura (in press) found m) evidence that prosody can accurately predict word boundaries, .so the task of finding words remains. Finally, one might question whether in-Ikmts have the ability we are trying to model--that is, whether they can identify words embedded in sentences; Jusczyk and Aslin (submitted) found that 7 I/2-month-olds can do so.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The input to our system is represented as a sequence of i)houenms, so we implicitly assume that infants are aisle I.o ,'ouv('rl, from acoustic inl)ut to phoneme sequem:es; research i)y Kuhl (e.g., Gricser & Kuhl, 1989) suggests tha.t this assmnl)tion is remsonal)h,. ", "mid_sen": "Since sentence I)oundaries provide informal.ion ahout word I)oumlaries (the end of a sentence is also the end of a word), our input contains sentence I~oumhu'ik~s; several studies (13ernstein-II.atm 'r, 1985; Ilirsh-lh~sek et al., 1987; Kemler Nels~m, I lirsh-I'asek, ,lusczyk & Wright C; msidy, 1989; ,I usczyk et al., 1992) have shown that infimts can perceive senl,cncc I)oundarics using prosodic cues. ", "after_sen": "Ih)wever, FiSher and 'lbkura (in press) found m) evidence that prosody can accurately predict word boundaries, .so the task of finding words remains. "}
{"citeStart": 136, "citeEnd": 148, "citeStartToken": 136, "citeEndToken": 148, "sectionName": "UNKNOWN SECTION NAME", "string": "Background Existing work falls into one of two categories, lexical cohesion methods and multi-source methods (Yaari, 1997) . The former stem from the work of Halliday and Hasan (Halliday and Hasan, 1976) . They proposed that text segments with similar vocabulary are likely to be part of a coherent topic segment. hnplementations of this idea use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997) , context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999) , entity repetition (Kan et al., 1998) , semantic similarity (Morris and Hirst, 1991; Kozima, 1993) , word distance model (Beeferman et al., 1997a ) and word frequency model (Reynar, 1999) to detect cohesion. Methods for finding the topic boundaries include sliding window (Hearst, 1994) , lexical chains (Morris, 1988; Kan et al., 1998) , dynamic programming (Ponte and Croft, 1997; Heinonen, 1998) , agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994) . Lexical cohesion methods are typically used for segmenting written text in a collection to improve information retrieval (Hearst, 1994; Reynat, 1998) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Methods for finding the topic boundaries include sliding window (Hearst, 1994) , lexical chains (Morris, 1988; Kan et al., 1998) , dynamic programming (Ponte and Croft, 1997; Heinonen, 1998) , agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994) . ", "mid_sen": "Lexical cohesion methods are typically used for segmenting written text in a collection to improve information retrieval (Hearst, 1994; Reynat, 1998) .", "after_sen": "Multi-source methods combine lexical cohesion with other indicators of topic shift such as cue phrases, prosodic features, reference, syntax and lexical attraction (Beeferman et al., 1997a) using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995) and probabilistic models (Beeferman et al., 1997b; Hajime et al., 1998; Reynar, 1998) . "}
{"citeStart": 52, "citeEnd": 72, "citeStartToken": 52, "citeEndToken": 72, "sectionName": "UNKNOWN SECTION NAME", "string": "We use the pair-wise similarities of words in each cluster, and build a network of words and their similarities. Intuitively, words that appear in similar contexts are more similar to each other and will have a stronger edge between them in the network. Therefore, similar words, or words that appear in similar contexts, will form communities in this graph. Ideally, each community in the word similarity network would represent a factoid. To find the communities in the word network we use (Clauset et al., 2004) , a hierarchical agglomeration algorithm which works by greedily optimizing the modularity in a linear running time for sparse graphs.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Ideally, each community in the word similarity network would represent a factoid. ", "mid_sen": "To find the communities in the word network we use (Clauset et al., 2004) , a hierarchical agglomeration algorithm which works by greedily optimizing the modularity in a linear running time for sparse graphs.", "after_sen": "The community detection algorithm will assign to each word w i , a community label C i . "}
{"citeStart": 142, "citeEnd": 156, "citeStartToken": 142, "citeEndToken": 156, "sectionName": "UNKNOWN SECTION NAME", "string": "Within our definition o[' punctuation then, we lind bro~*dly three types of mark: delimiting, separating and disambigu~tting, as described by Nunberg [1990] . Some marks, the COlnlna especially, fall into multiple categories since they can have different roles, and the categories each per[brm distinct lingnistic functions. l)elimiters (e.g. comma, (hush, l)arenthesis) occur to either side of a l)articular lexical expression to remove that exl)ression from the immediate syntactic context of the surrounding sentence (1). Tile delimited phr~e acts as a modifier to the adjacent phrase instead.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Indeed, it is difficult t,o imagine the representation of structural punctuation, other than through the use of some special structural description language such ~m SGM I,.", "mid_sen": "Within our definition o[' punctuation then, we lind bro~*dly three types of mark: delimiting, separating and disambigu~tting, as described by Nunberg [1990] . ", "after_sen": "Some marks, the COlnlna especially, fall into multiple categories since they can have different roles, and the categories each per[brm distinct lingnistic functions. "}
{"citeStart": 84, "citeEnd": 100, "citeStartToken": 84, "citeEndToken": 100, "sectionName": "UNKNOWN SECTION NAME", "string": "Recent work using so-called meta-level priors to transfer information across tasks (Lee et al., 2007) , while related, does not take into explicit account the hierarchical structure of these meta-level features often found in NLP tasks. Daumé allows an extra degree of freedom among the features of his domains, implicitly creating a two-level feature hierarchy with one branch for general features, and another for domain specific ones, but does not extend his hierarchy further (Daumé III, 2007) ). Similarly, work on hierarchical penalization (Szafranski et al., 2007) in two-level trees tries to produce models that rely only on a relatively small number of groups of variable, as structured by the tree, as opposed to transferring knowledge between branches themselves.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Most of this prior work deals with supervised transfer learning, and thus requires labeled source domain data, though there are examples of unsupervised (Arnold et al., 2007) , semi-supervised (Grandvalet and Bengio, 2005; Blitzer et al., 2006) , and transductive approaches (Taskar et al., 2003) .", "mid_sen": "Recent work using so-called meta-level priors to transfer information across tasks (Lee et al., 2007) , while related, does not take into explicit account the hierarchical structure of these meta-level features often found in NLP tasks. ", "after_sen": "Daumé allows an extra degree of freedom among the features of his domains, implicitly creating a two-level feature hierarchy with one branch for general features, and another for domain specific ones, but does not extend his hierarchy further (Daumé III, 2007) ). "}
{"citeStart": 107, "citeEnd": 119, "citeStartToken": 107, "citeEndToken": 119, "sectionName": "UNKNOWN SECTION NAME", "string": "Collaborative negoti~ion occurs when conflicts arise among agents developing a shared plan 1 during collaborative planning. A collaborative agent is driven by the goal of developing a plan that best satisfies the interests of all the agents as a group, instead of one that maximizes his own interest. This results in several distinctive features of collaborative negotiation: 1) A collaborative agent does not insist on winning an argument, and may change his beliefs ff another agent presents convincing justification for an opposing belief. This differentiates collaborative negotiation from argumentation (Birnbaum et al., 1980; Reichman, 1981; Cohen, 1987; Quilici, 1992) . 2) Agents involved in collaborative negotiation are open and honest with one another; they will not deliberately present false information to other agents, present information in such a way as to mislead the other agents, or strategically hold back information from other agents for later use. This distinguishes collaborative negotiation from non-collaborative negotiation such as labor negotiation (Sycara, 1989) . 3) Collaborative agents are interested in 1The notion of shared plan has been used in (Grosz and Sidner, 1990; Allen, 1991) . others' beliefs in order to decide whether to revise their own beliefs so as to come to agreement (Chu-Carroll and Carberry, 1995) . Although agents involvedin argumentation and non-collaborative negotiation take other agents' beliefs into consideration, they do so mainly to find weak points in their opponents' beliefs and attack them to win the argument.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "2) Agents involved in collaborative negotiation are open and honest with one another; they will not deliberately present false information to other agents, present information in such a way as to mislead the other agents, or strategically hold back information from other agents for later use. ", "mid_sen": "This distinguishes collaborative negotiation from non-collaborative negotiation such as labor negotiation (Sycara, 1989) . ", "after_sen": "3) Collaborative agents are interested in 1The notion of shared plan has been used in (Grosz and Sidner, 1990; Allen, 1991) . others' beliefs in order to decide whether to revise their own beliefs so as to come to agreement (Chu-Carroll and Carberry, 1995) . "}
{"citeStart": 233, "citeEnd": 251, "citeStartToken": 233, "citeEndToken": 251, "sectionName": "UNKNOWN SECTION NAME", "string": "Our baseline word alignment model is the word-toword Hidden Markov Model (Vogel et al., 1996) . Basic models in two translation directions are trained simultaneously where statistics of two directions are shared to learn symmetric translation lexicon and word alignments with high precision motivated by (Zens et al., 2004) and (Liang et al., 2006) . The baseline translation results (BLEU and TER) on the dev and test set are presented in the line \"HMM\" of Table 1 . We also compare with results of IBM Model-4 word alignments implemented in GIZA++ toolkit (Och and Ney, 2003) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Our baseline word alignment model is the word-toword Hidden Markov Model (Vogel et al., 1996) . ", "mid_sen": "Basic models in two translation directions are trained simultaneously where statistics of two directions are shared to learn symmetric translation lexicon and word alignments with high precision motivated by (Zens et al., 2004) and (Liang et al., 2006) . ", "after_sen": "The baseline translation results (BLEU and TER) on the dev and test set are presented in the line \"HMM\" of Table 1 . "}
{"citeStart": 0, "citeEnd": 25, "citeStartToken": 0, "citeEndToken": 25, "sectionName": "UNKNOWN SECTION NAME", "string": "More recently, the field of dialectometry, as introduced by S~guy (1971, 1973) , has addressed these issues by developing several techniques for summarizing and presenting variation along multiple dimensions. They replace isoglosses with a distance matrix, which compares each site directly with all other sites, ultimately yielding a single figure that measures the linguistic distances between each pair of sites. There is however no firm agreement on just how to compute the distance matrices. Sfiguy's earliest work (1971) was based on lexical correspondences: sites differed in the extent to which they used different words for the same concept. S~guy (1973), Philps (1987) , and Durand (1989) use some combination of lexical, phonological, and morphological data. Babitch (1988) described the dialectal distances in Acadian villages by the degree to which their fishing terminology varied. Babitch and Lebrun (1989) did a similar analysis based on the varying pronunciation of/r/. Elsie (1986) grouped the Gaelic dialects on the basis of whether the vocabulary matched. Ebobisse (1989) grouped the Sawabantu languages of Cameroon by whether phonological correspondences in matching vocabulary items were complete, partial, or lacking. There seems to be a certain bias in favour of working with lexical correspondences, which is understandable, since deciding whether two sites use the same word for the same concept is perhaps one of the easiest linguistic judgements to make. The need to figure out such systems as the comparative phonology of various linguistic sites can be very time-consuming and fraught with arbitrary choices.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Babitch (1988) described the dialectal distances in Acadian villages by the degree to which their fishing terminology varied. ", "mid_sen": "Babitch and Lebrun (1989) did a similar analysis based on the varying pronunciation of/r/. Elsie (1986) grouped the Gaelic dialects on the basis of whether the vocabulary matched. ", "after_sen": "Ebobisse (1989) grouped the Sawabantu languages of Cameroon by whether phonological correspondences in matching vocabulary items were complete, partial, or lacking. "}
{"citeStart": 78, "citeEnd": 98, "citeStartToken": 78, "citeEndToken": 98, "sectionName": "UNKNOWN SECTION NAME", "string": "It is essentially ill addressing the issue of ovelgenerality that Mel'~:uk introduces sub-and superscripts to lexical functions, enhancing their precision and making them sensitive to meaning aspects of tile lcxical items over which they operate. Superscripts are illtended to make the nleaning of tile I,F nlore precise and he|me |nero likely to imply unary inappings between argu|nents and vahlcs, subscripts a|e used to reference a particular semautic COlllpOUellt of a keyword. The introduclion of such devices into tile account of l,Fs demtmstrates hoth the need tk)r precision and the fact lbat it does seeul necessary to address semantic aspects of lexemes stand| ng it| co-occurrence relatio|ls. Ill fact it has been asserted by sonm (e.g., (Anick and Pustciovsky, 1990) , (lteid and Raab, 1989) ) that collocational systems are systematically predictable from the lexical Selllantics Of nt)tUlS, it) till atteln]Jt to explore this notion furthel; we have investigated the appr(lach to nolninal semantics known as Qualia structure (Pustejovsky, 1991) and conside|ed how this lnay ct)tnple-u|ent the LF notion to inlprove its descriptive powe| r.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The introduclion of such devices into tile account of l,Fs demtmstrates hoth the need tk)r precision and the fact lbat it does seeul necessary to address semantic aspects of lexemes stand| ng it| co-occurrence relatio|ls. ", "mid_sen": "Ill fact it has been asserted by sonm (e.g., (Anick and Pustciovsky, 1990) , (lteid and Raab, 1989) ) that collocational systems are systematically predictable from the lexical Selllantics Of nt)tUlS, it) till atteln]Jt to explore this notion furthel; we have investigated the appr(lach to nolninal semantics known as Qualia structure (Pustejovsky, 1991) and conside|ed how this lnay ct)tnple-u|ent the LF notion to inlprove its descriptive powe| r.", "after_sen": "alnoDg tile prolnising avenues that occur to tlS are, firstly, tile postulation of I,F subscripts based on the four Qualia roles (assuming thal these are tim lexically hies) relevant aspects of noun selnantics) and, secondly, the application of l,Fs to senlaulic (Qualia) structures rather titan monolithic lexenles; cg: tile I ,l; Ibm is used in delivering evahlative qualitiers which are standard expressions of praise or approval. "}
{"citeStart": 57, "citeEnd": 67, "citeStartToken": 57, "citeEndToken": 67, "sectionName": "UNKNOWN SECTION NAME", "string": "These probabilities can be directly trained from a manually annotated corpus, where all repairs are labeled with begin, end, IP and editing term and for each reparandum the words are linked to the corresponding words in the respective reparans. All distributions are smoothed by a simple back-o method Katz, 1987 to avoid zero probabilities with the exception that the word replacement probability PRD j jRS a j i s smoothed in a more sophisticated way.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "These probabilities can be directly trained from a manually annotated corpus, where all repairs are labeled with begin, end, IP and editing term and for each reparandum the words are linked to the corresponding words in the respective reparans. ", "mid_sen": "All distributions are smoothed by a simple back-o method Katz, 1987 to avoid zero probabilities with the exception that the word replacement probability PRD j jRS a j i s smoothed in a more sophisticated way.", "after_sen": ""}
{"citeStart": 156, "citeEnd": 179, "citeStartToken": 156, "citeEndToken": 179, "sectionName": "UNKNOWN SECTION NAME", "string": "The improvement using longer Markov windows (up to 2.13%) is also shown -and longer windows are better, although there is diminishing returns. We chose a Markov history of the four previous decisions for the rest of our experiments. Table 4 also shows that knowing the previous label perfectly (with the Oracle experiment) can make a large difference to classification accuracy. Table 5 presents the subtractive analysis to determine the impact of different feature types. From this we can see that the n-grams (unigrams and bigrams) have by far the largest impact -and neither of these feature types was directly implemented by Teufel and Moens (2002) . The next most important features are the first few words (again a unigram type feature), length and the section number. The Markov history features also have an impact of just over 1%. Table 6 shows a different story for Teufel's features using the maximum entropy model. It seems that none of the feature types alone are making an enormous contribution and that the impact of them varies enormously between folds (the confidence intervals are far bigger than the differences).", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Table 5 presents the subtractive analysis to determine the impact of different feature types. ", "mid_sen": "From this we can see that the n-grams (unigrams and bigrams) have by far the largest impact -and neither of these feature types was directly implemented by Teufel and Moens (2002) . ", "after_sen": "The next most important features are the first few words (again a unigram type feature), length and the section number. "}
{"citeStart": 178, "citeEnd": 197, "citeStartToken": 178, "citeEndToken": 197, "sectionName": "UNKNOWN SECTION NAME", "string": "This binary distinction has often been used to motivate a two-level architecture in the human syntactic processing system, where what we will call the \"core parser\" performs standard attachment, as well as being able to reanalyse in the easy cases (such as on reaching hurts in (2)), but where the assistance of a higher level resolver(to use Abney's terminology (1987 Abney's terminology ( , 1989 ), is required to solve the difficult cases, (such as on reaching melted in (1)). This \"core parser\" has been the subject of a number of computational implementations, including Marcus's deterministic parser (1980) , Description theory (henceforth, D-theory) (Marcus et al (1983) ), and Abney's licensing based model (1987, 1989) . It has also been the subject of a number of psycholinguistic studies on a more theoretical level (Pritchett (1992) , Gorrell (in press) ).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This binary distinction has often been used to motivate a two-level architecture in the human syntactic processing system, where what we will call the \"core parser\" performs standard attachment, as well as being able to reanalyse in the easy cases (such as on reaching hurts in (2)), but where the assistance of a higher level resolver(to use Abney's terminology (1987 Abney's terminology ( , 1989 ), is required to solve the difficult cases, (such as on reaching melted in (1)). ", "mid_sen": "This \"core parser\" has been the subject of a number of computational implementations, including Marcus's deterministic parser (1980) , Description theory (henceforth, D-theory) (Marcus et al (1983) ), and Abney's licensing based model (1987, 1989) . ", "after_sen": "It has also been the subject of a number of psycholinguistic studies on a more theoretical level (Pritchett (1992) , Gorrell (in press) )."}
{"citeStart": 117, "citeEnd": 130, "citeStartToken": 117, "citeEndToken": 130, "sectionName": "UNKNOWN SECTION NAME", "string": "Latent Semantic Analysis has been applied to the problem of spelling correction previously (Kukich, 1992b) . However, this work focused on detecting misspelled words, not contextual spelling errors. The approach taken used letter n-grams to build the semantic space. In this work, we use the words directly. Yarowsky (1994) notes that conceptual spelling correction is part of a closely related class of problems which include word sense disambiguation, word choice selection in machine translation, and accent and capitalization restoration. This class of problems has been attacked by many others. A number of feature-based methods have been tried, including Bayesian classifiers (Gale, Church, and Yarowsky, 1992; Golding, 1995) , decision lists (Yarowsky, 1994) , and knowledge-based approaches (McRoy, 1992) . Recently, Golding and Schabes (1996) described a system, Tribayes, that combines a trigram model of the words' parts of speech with a Bayesian classifier. The trigram component of the system is used to make decisions for those confusion sets that contain words with different parts of speech. The Bayesian component is used to predict the correct word from among same part-of-speech words. Golding and Schabes selected 18 confusion sets from a list of commonly confused words plus a few that represent typographical errors. They trained their system using a random 80% of the Brow [/corpus (Ku~era and Francis, 1967) . The remaining 20% of the corpus was used to test how well the system performed. We have chosen to use the same 18 confusion sets and the Brown corpus in order to compare LSA to Tribayes.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This class of problems has been attacked by many others. ", "mid_sen": "A number of feature-based methods have been tried, including Bayesian classifiers (Gale, Church, and Yarowsky, 1992; Golding, 1995) , decision lists (Yarowsky, 1994) , and knowledge-based approaches (McRoy, 1992) . ", "after_sen": "Recently, Golding and Schabes (1996) described a system, Tribayes, that combines a trigram model of the words' parts of speech with a Bayesian classifier. "}
{"citeStart": 227, "citeEnd": 241, "citeStartToken": 227, "citeEndToken": 241, "sectionName": "UNKNOWN SECTION NAME", "string": "We first compare the retrieval performance of query expansion with different similarity functions using short keyword (i.e., title-only) queries, because query expansion techniques are often more effective for shorter queries (Voorhees, 1994; Fang and Zhai, 2006) . The results are presented in Table 2 . It is clear that query expansion with these functions can improve the retrieval performance, although the performance gains achieved by different functions vary a lot. In particular, we make the following observations. First, the similarity function based on synset definitions is the most effective one. QE def significantly improves the retrieval performance for all the data sets. For example, in trec7, it improves the performance from 0.186 to 0.216. As far as we know, none of the previous studies showed such significant performance improvement by using only WordNet as query expansion resource.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We first compare the retrieval performance of query expansion with different similarity functions using short keyword (i.e., title-only) queries, because query expansion techniques are often more effective for shorter queries (Voorhees, 1994; Fang and Zhai, 2006) . ", "after_sen": "The results are presented in Table 2 . "}
{"citeStart": 250, "citeEnd": 270, "citeStartToken": 250, "citeEndToken": 270, "sectionName": "UNKNOWN SECTION NAME", "string": "Design-World is an experimentld enviro|unent for testiug the relationship hetween discourse strategies, task p~u'ameters ,and agents' cognitive capabilities, similar to the single ,agent TileWorld simnlalion environment [Pollack and Ringuette, 1990; Hanks et al., 199311. Design-World agents can be parametrized as to discourse strategy, and tilt elfecls of this strategy can he me~Lsured against a |'imge of cognitive and task p~u'ameters. This paper compares [l~e Explicit-Winrant strategy to the All-lmplicil strategy as strategies lot supporting deliberation. Other strategies tested in Design-World me presented elsewhere [W~dker, 1993; Walker, 1994a; Riunbow ~md Walker, 19941. 3.1 Design World l)omain and task Both agents know whal tile I)ESI(;N-IIOUSE pl~ requires and stm'l out with a set of fnmiture pieces that can he used to design each room.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Design-World is an experimentld enviro|unent for testiug the relationship hetween discourse strategies, task p~u'ameters ,and agents' cognitive capabilities, similar to the single ,agent TileWorld simnlalion environment [Pollack and Ringuette, 1990; Hanks et al., 199311. ", "after_sen": "Design-World agents can be parametrized as to discourse strategy, and tilt elfecls of this strategy can he me~Lsured against a |'imge of cognitive and task p~u'ameters. "}
{"citeStart": 43, "citeEnd": 67, "citeStartToken": 43, "citeEndToken": 67, "sectionName": "UNKNOWN SECTION NAME", "string": "We have used the baseNP data presented in (Ramshaw and Marcus, 1995) 2. This data was divided in two parts. The first part was training data and consisted of 211727 words taken from sections 15, 16, 17 and 18 from the Wall Street Journal corpus (WSJ). The second part was test data and consisted of 47377 words taken from section 20 of the same corpus. The words were part-of-speech (POS) tagged with the Brill tagger and each word was classified as being inside or outside a baseNP with the IOB1 representation scheme. The chunking classification was made by (Ramshaw and Marcus, 1995) based on the parsing information in the WSJ corpus. The performance of the baseNP recognizer can be measured in different ways: by computing the percentage of correct classification tags (accuracy), the percentage of recognized baseNPs that are correct (precision) and the percentage of baseNPs inthe corpus that are found (recall). We will follow (Argamon et al., 1998) and use a combination of the precision and recall rates: F~=I = (2\" precision*recall) / (precision+recall).", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We have used the baseNP data presented in (Ramshaw and Marcus, 1995) 2. This data was divided in two parts. ", "after_sen": "The first part was training data and consisted of 211727 words taken from sections 15, 16, 17 and 18 from the Wall Street Journal corpus (WSJ). "}
{"citeStart": 29, "citeEnd": 43, "citeStartToken": 29, "citeEndToken": 43, "sectionName": "UNKNOWN SECTION NAME", "string": "The studies presented by and Johnson (2007) differed in the number of states that they used. evaluated against the reduced tag set of 17 tags developed by Smith and Eisner (2005) , while Johnson (2007) evaluated against the full Penn Treebank tag set. We ran all our estimators in both conditions here (thanks to Noah Smith for supplying us with his tag set).", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "The studies presented by and Johnson (2007) differed in the number of states that they used. ", "after_sen": "evaluated against the reduced tag set of 17 tags developed by Smith and Eisner (2005) , while Johnson (2007) evaluated against the full Penn Treebank tag set. "}
{"citeStart": 121, "citeEnd": 134, "citeStartToken": 121, "citeEndToken": 134, "sectionName": "UNKNOWN SECTION NAME", "string": "LFG posits several different representation levels, called projections. Within a projection, a certain type of linguistic knowledge is represented, which explains differences in the formal setup (data types and operations) of the projections. The two standard projections, and those used here, are the constituent (c-) structure and the functional (f-) structure (Kaplan (1995) and Halvorsen & Kaplan (1995) discuss the projection idea in more detail). C-structure is defined in terms of context-free phrase structure rules, and thus forms a projective tree of categories over the input. It is assumed to encode language particularities with respect to the set of categories and the possible orderings. The fstructure is constructed fi'om additional annotations attached to the phrase structure rules, and has the form of an attribute-value matrix or feature structure. It is assumed to represent more or less langnage-independent information about grammatical functions and predicate-argument structure. In addition to the usual unification operation, LFG employs existential and negative constraints on features, which allow the fornmlation of constraints about the existence of features without specifying the associated value.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Within a projection, a certain type of linguistic knowledge is represented, which explains differences in the formal setup (data types and operations) of the projections. ", "mid_sen": "The two standard projections, and those used here, are the constituent (c-) structure and the functional (f-) structure (Kaplan (1995) and Halvorsen & Kaplan (1995) discuss the projection idea in more detail). ", "after_sen": "C-structure is defined in terms of context-free phrase structure rules, and thus forms a projective tree of categories over the input. "}
{"citeStart": 56, "citeEnd": 68, "citeStartToken": 56, "citeEndToken": 68, "sectionName": "UNKNOWN SECTION NAME", "string": "The final process determines the location of the topic boundaries. The method is based on Reynar's maximisation algorithm (Reynar, 1998; Helfman, 1996; Church, 1993; Church and Helfman, 1993) . ", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The final process determines the location of the topic boundaries. ", "mid_sen": "The method is based on Reynar's maximisation algorithm (Reynar, 1998; Helfman, 1996; Church, 1993; Church and Helfman, 1993) . ", "after_sen": ""}
{"citeStart": 119, "citeEnd": 142, "citeStartToken": 119, "citeEndToken": 142, "sectionName": "UNKNOWN SECTION NAME", "string": "The corpus has been automatically annotated using part-of-speech tagging, named entity recognition and parsing (Padró et al., 2010) . Furthermore, a text aligning algorithm based on Hidden Markov Models (Bott and Saggion, 2011) has been applied to obtain sentence-level alignments. The automatic alignments have then been manually corrected through a graphical editing tool within the GATE framework (Cunningham et al., 2002) . A total of 570 sentences have been aligned (246 in original and 324 in simple texts), with the following correlations between them: one to one, one to many or many to one, as well as cases where there is no correlation (cases of content reduction through summarisation or information expansion through the introduction of definitions). The alignments facilitate the observation of the corpus, particularly cases where entire sentences have been eliminated or inserted.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Furthermore, a text aligning algorithm based on Hidden Markov Models (Bott and Saggion, 2011) has been applied to obtain sentence-level alignments. ", "mid_sen": "The automatic alignments have then been manually corrected through a graphical editing tool within the GATE framework (Cunningham et al., 2002) . ", "after_sen": "A total of 570 sentences have been aligned (246 in original and 324 in simple texts), with the following correlations between them: one to one, one to many or many to one, as well as cases where there is no correlation (cases of content reduction through summarisation or information expansion through the introduction of definitions). "}
{"citeStart": 181, "citeEnd": 202, "citeStartToken": 181, "citeEndToken": 202, "sectionName": "UNKNOWN SECTION NAME", "string": "In Section 2 we describe our general framework of the generic beam-search algorithm and the generalized perceptron. Then in the subsequent sections we describe each task in turn, based on conference papers including Zhang and Clark (2007 , 2008a , 2008b , presented in our single coherent framework. We give an updated set of results, plus a number of additional experiments which probe further into the advantages and disadvantages of our framework. For the segmentation task, we also compare our beam-search framework with alternative decoding algorithms including an exact dynamic-programming method, showing that the beam-search method is significantly faster with comparable accuracy. For the joint segmentation and POS-tagging task, we present a novel solution using the framework in this article, and show that it gives comparable accuracies to our previous work (Zhang and Clark 2008a) , while being more than an order of magnitude faster.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "For the segmentation task, we also compare our beam-search framework with alternative decoding algorithms including an exact dynamic-programming method, showing that the beam-search method is significantly faster with comparable accuracy. ", "mid_sen": "For the joint segmentation and POS-tagging task, we present a novel solution using the framework in this article, and show that it gives comparable accuracies to our previous work (Zhang and Clark 2008a) , while being more than an order of magnitude faster.", "after_sen": "In Section 7 we provide further discussion of the framework based on the studies of the individual tasks. "}
{"citeStart": 19, "citeEnd": 40, "citeStartToken": 19, "citeEndToken": 40, "sectionName": "UNKNOWN SECTION NAME", "string": "is the difference found between x 1 and x 2 , the results for the new and current techniques, respectively. E[d] is the expected difference (which is 0 under the null hypothesis) and s d is an estimate of the standard deviation of d. Standard deviation is the square root of the variance, a measure of how much a random variable is expected to vary. The results of equation 1 are compared to tables (c.f. in Box et al. (1978, Appendix)) to find out what the chances are of equaling or exceeding the equation 1 results if the null hypothesis were true. The larger the equation 1 results, the more unusual it would be under the null hypothesis. A complication of using equation 1 is that one usually does not have s d , but only s 1 and s 2 , where s 1 is the estimate for x 1 's standard deviation and similarly for s 2 . How does one get the former from the latter? It turns out that (Box et al., 1978, Ch. 3)", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "How does one get the former from the latter? ", "mid_sen": "It turns out that (Box et al., 1978, Ch. 3)", "after_sen": "σ 2 d = σ 2 1 + σ 2 2 − 2ρ 12 σ 1 σ 2"}
{"citeStart": 30, "citeEnd": 45, "citeStartToken": 30, "citeEndToken": 45, "sectionName": "UNKNOWN SECTION NAME", "string": "In empirical approaches to parsing, lexical/semantic collocation extracted from corpus has been proved to be quite useful for ranking parses in syntactic analysis. For example, Magerman (1995) , Collins (1996) , and Charniak (1997) proposed statistical parsing models which incorporated lexical/semantic information. In their models, syntactic and lexical/semantic features are dependent on each other and are combined together. This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis. However, unlike the models of Magerman (1995) , Collins (1996) , and Charniak (1997), we assume that syntactic and lexical/semantic features are independent. Then, we focus on extracting lcxical/semantic collocational knowledge of verbs which is useful in syntactic analysis.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis. ", "mid_sen": "However, unlike the models of Magerman (1995) , Collins (1996) , and Charniak (1997), we assume that syntactic and lexical/semantic features are independent. ", "after_sen": "Then, we focus on extracting lcxical/semantic collocational knowledge of verbs which is useful in syntactic analysis."}
{"citeStart": 53, "citeEnd": 77, "citeStartToken": 53, "citeEndToken": 77, "sectionName": "UNKNOWN SECTION NAME", "string": "This section describes the process of converting the Vadas and Curran (2007a) data to CCG derivations. The tokens dominated by NML and JJP brackets in the source data are formed into constituents in the corresponding CCGbank sentence. We generate the two forms of output that CCGbank contains: AUTO files, which represent the tree structure of each sentence; and PARG files, which list the word-word dependencies (Hockenmaier and Steedman, 2005) . We apply one preprocessing step on the Penn Treebank data, where if multiple tokens are enclosed by brackets, then a NML node is placed around those tokens. For example, we would insert the NML bracket shown below:", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "This section describes the process of converting the Vadas and Curran (2007a) data to CCG derivations. ", "after_sen": "The tokens dominated by NML and JJP brackets in the source data are formed into constituents in the corresponding CCGbank sentence. "}
{"citeStart": 245, "citeEnd": 268, "citeStartToken": 245, "citeEndToken": 268, "sectionName": "UNKNOWN SECTION NAME", "string": "It is likely that further improvements in generation performance will be achieved when both the grammatical structures and the extracted choosers are pruned. The current results have focused primarily on the improvements brought by reconfiguring the type lattice that defines the grammar. The structures generated are still the 'full' grammatical structures that are produced by the corresponding full grammar: if, however, certain constituent descriptions are always unified (conflated in systemic terminology) then, analogously to (Rayner and Carter, 1996) , they are candidates for replacement by a single constituent description in the extracted subgrammar. Moreover, the extracted choosers can also be pruned directly with respect to the sublanguage. Currently the pruning carried improvement sentence worst case 80 best case average case run time (in ms) full grammar subgrammar 380 300 3250 1830 ca. 900 ca. 590 310 \"There is Patti Delaroche.\" \"John Foster was born in Liverpool on 1 January c 1787, and he died at Birkenhead on 21 August 1846.\" e.g., \"Mary Moser was an English painter.\" \"George Richmond studied at Royal Academy in 1824.\" (Under Allegro Common Lisp running on a Sparcl0.) Table 1 : Example run times for \"short artist biographies\" out is only that entailed by the type lattice, It is also possible however to maintain a record of the classificatory inquiry responses that are used in a subgrammar: responses that do not occur can then motivate further reductions in the choosers that are kept in the extracted grammar. Evaluation of the improvements in performance that these strategies bring are in progress.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The current results have focused primarily on the improvements brought by reconfiguring the type lattice that defines the grammar. ", "mid_sen": "The structures generated are still the 'full' grammatical structures that are produced by the corresponding full grammar: if, however, certain constituent descriptions are always unified (conflated in systemic terminology) then, analogously to (Rayner and Carter, 1996) , they are candidates for replacement by a single constituent description in the extracted subgrammar. ", "after_sen": "Moreover, the extracted choosers can also be pruned directly with respect to the sublanguage. "}
{"citeStart": 77, "citeEnd": 102, "citeStartToken": 77, "citeEndToken": 102, "sectionName": "UNKNOWN SECTION NAME", "string": "We decompose each event E into a tripartite structure in a manner similar to Moens and Steedman (1988) , introducing a time function for each predicate to specify whether the predicate is true in the preparatory (duringE), culmination (endE), or consequent (resultE) stage of an event.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "By using TAGs we get the additional benefit of an existing parser that yields derivations and derived trees from which we can construct the compositional semantics of a given sentence.", "mid_sen": "We decompose each event E into a tripartite structure in a manner similar to Moens and Steedman (1988) , introducing a time function for each predicate to specify whether the predicate is true in the preparatory (duringE), culmination (endE), or consequent (resultE) stage of an event.", "after_sen": "Initial trees capture the semantics of the basic senses of verbs in each class. "}
{"citeStart": 62, "citeEnd": 66, "citeStartToken": 62, "citeEndToken": 66, "sectionName": "UNKNOWN SECTION NAME", "string": "In the West, research on situation has a long history. The earliest can be traced to the times of Aristotle. In resent years, Western researchers have published a large volume of papers, which present many points of view. The most important are Vendler(1967), Bache(1982), and Smith (1985) They approximately classify the situation as four types: state, activity, accomplishment, and achievement.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In resent years, Western researchers have published a large volume of papers, which present many points of view. ", "mid_sen": "The most important are Vendler(1967), Bache(1982), and Smith (1985) They approximately classify the situation as four types: state, activity, accomplishment, and achievement.", "after_sen": "Chinese researchers have also done considerable work, among which the most typical research were done by Chen [3] and Ma [5] ."}
{"citeStart": 175, "citeEnd": 195, "citeStartToken": 175, "citeEndToken": 195, "sectionName": "UNKNOWN SECTION NAME", "string": "Local collocation knowledge yields the highest accuracy, followed by POS and morphological form. Surrounding words give lower accuracy, perhaps because in our work, only the current sentence forms the surrounding context, which averages about 20 words. Previous work on using the unordered set of surrounding words have used a much larger window, such as the 100-word window of (Yarowsky, 1992) , and the 2-sentence context of (Leacock et al., 1993) . Verb-object syntactic relation is the weakest knowledge source.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Surrounding words give lower accuracy, perhaps because in our work, only the current sentence forms the surrounding context, which averages about 20 words. ", "mid_sen": "Previous work on using the unordered set of surrounding words have used a much larger window, such as the 100-word window of (Yarowsky, 1992) , and the 2-sentence context of (Leacock et al., 1993) . ", "after_sen": "Verb-object syntactic relation is the weakest knowledge source."}
{"citeStart": 227, "citeEnd": 257, "citeStartToken": 227, "citeEndToken": 257, "sectionName": "UNKNOWN SECTION NAME", "string": "In our earlier work, we built on Sidner's proposal/acceptance and proposal/rejection sequences (Sitnet, 1994 ) and developed a model tha¢ captures collaborative planning processes in a Propose-Evaluate-Modify cycle of actions (Chu-Carroll and Carberry, 1994) . This model views coll~tive planning as agent A proposing a set of actions and beliefs to be i~ted into the plan being developed, agent B evaluating the proposal to determine whether or not he accepts the proposal and, ff not, agent B proposing a set of modifications to A's original proposal. The proposed modifications will again be evaluated by A, and if conflicts arise, she may propose modifications to B's previously proposed modifications, resulting in a recursive process. However, our research did not specify, in cases where multiple conflicts arise, how an agent should identify which pm of an unaccept~ proposal to address or how to select evidence to support the proposed modification. This paper extends that work by i~ting into the modification process a slrategy to determine the aspect of the proposal that the agent will address in her pursuit of conflict resolution, as well as a means of selecting appropriate evidence to justify the need for such modification.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Although agents involvedin argumentation and non-collaborative negotiation take other agents' beliefs into consideration, they do so mainly to find weak points in their opponents' beliefs and attack them to win the argument.", "mid_sen": "In our earlier work, we built on Sidner's proposal/acceptance and proposal/rejection sequences (Sitnet, 1994 ) and developed a model tha¢ captures collaborative planning processes in a Propose-Evaluate-Modify cycle of actions (Chu-Carroll and Carberry, 1994) . ", "after_sen": "This model views coll~tive planning as agent A proposing a set of actions and beliefs to be i~ted into the plan being developed, agent B evaluating the proposal to determine whether or not he accepts the proposal and, ff not, agent B proposing a set of modifications to A's original proposal. "}
{"citeStart": 7, "citeEnd": 18, "citeStartToken": 7, "citeEndToken": 18, "sectionName": "UNKNOWN SECTION NAME", "string": "The major topic in the development of word-Pos guessers is the strategy which is to be used for the acquisition of the guessing rules. A rule-based tagger described in (Voutilainen, 1995) is equipped with a set of guessing rules which has been hand-crafted using knowledge of English morphology and intuition. A more appealing approach is an empirical automatic acquisition of such rules using available lexical resources. In (Zhang&Kim, 1990) a system for the automated learning of morphological word-formation rules is described. This system divides a string into three regions and from training examples infers their correspondence to underlying morphological features. Brill (Brill, 1995) outlines a transformation-based learner which learns guessing rules from a pre-tagged training corpus. A statistical-based suffix learner is presented in (Schmid, 1994) . From a pre-tagged training corpus it constructs the suffix tree where every suffix is associated with its information measure. Although the learning process in these and some other systems is fully unsupervised and the accuracy of obtained rules reaches current state-of-the-art, they require specially prepared training data --a pretagged training corpus, training examples, etc.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This system divides a string into three regions and from training examples infers their correspondence to underlying morphological features. ", "mid_sen": "Brill (Brill, 1995) outlines a transformation-based learner which learns guessing rules from a pre-tagged training corpus. ", "after_sen": "A statistical-based suffix learner is presented in (Schmid, 1994) . "}
{"citeStart": 136, "citeEnd": 151, "citeStartToken": 136, "citeEndToken": 151, "sectionName": "UNKNOWN SECTION NAME", "string": "Rogers' regular form restriction (Rogers, 1994) , we can cite verb-raised complement auxiliary trees in Dutch as in Figure 5 (Kroch and Santorini, 1991) . Trees with this structure may adjoin into each others' internal spine nodes an unbounded number of times, in violation of Rogers' definition of regular form adjunction, but within our criteria of wrapping adjunction at only one node on the spine. ", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "~Except in tile case of raising, discussed below.", "mid_sen": "Rogers' regular form restriction (Rogers, 1994) , we can cite verb-raised complement auxiliary trees in Dutch as in Figure 5 (Kroch and Santorini, 1991) . ", "after_sen": "Trees with this structure may adjoin into each others' internal spine nodes an unbounded number of times, in violation of Rogers' definition of regular form adjunction, but within our criteria of wrapping adjunction at only one node on the spine. "}
{"citeStart": 20, "citeEnd": 41, "citeStartToken": 20, "citeEndToken": 41, "sectionName": "UNKNOWN SECTION NAME", "string": "The agreement/disagreement labels can be thought of as a sort of speech act categorization. Automatic classification of speech acts has been the subject of several studies. Our work builds on (Shriberg et al., 1998) , which showed that prosodic features are useful for classifying speech acts and lead to increased accuracy when combined with word based cues. Other studies look at prediction of speech acts primarily from word-based cues, using language models or syntactic structure and discourse history (Chu-Carroll, 1998; Reithinger and Klesen, 1997) . Our work is informed by these studies, but departs significantly by exploring unsupervised training techniques.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Automatic classification of speech acts has been the subject of several studies. ", "mid_sen": "Our work builds on (Shriberg et al., 1998) , which showed that prosodic features are useful for classifying speech acts and lead to increased accuracy when combined with word based cues. ", "after_sen": "Other studies look at prediction of speech acts primarily from word-based cues, using language models or syntactic structure and discourse history (Chu-Carroll, 1998; Reithinger and Klesen, 1997) . "}
{"citeStart": 89, "citeEnd": 95, "citeStartToken": 89, "citeEndToken": 95, "sectionName": "UNKNOWN SECTION NAME", "string": "BFP can add the VP and the S onto the end of the forward centers list, as Sidner does in her algorithm for local focusing [Sid79] . This lets BFP get the two examples of event anaphora. Hobbs discusses the fact that his algorithm cannot be modified to get event anaphora in [Hob76b] .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This lets BFP get the two examples of event anaphora. ", "mid_sen": "Hobbs discusses the fact that his algorithm cannot be modified to get event anaphora in [Hob76b] .", "after_sen": "Another interesting fact is that in every case in which Hobbs' algorithm gets the correct co-specifier and BFP didn't, the relevant factor is Hobbs' preference for intrasentential co-specifiers. "}
{"citeStart": 130, "citeEnd": 145, "citeStartToken": 130, "citeEndToken": 145, "sectionName": "UNKNOWN SECTION NAME", "string": "The possibility of inserting a word into a domain of some transitive head raises the questions of how to require continuity (as needed in nmst cases), and how to limit the distance between the governor and the modifier. Both questions will be soh,ed with reference to the dependency relation. From a descriptive viewpoint, the syntactic construction is often cited to determine the possibility and scope of discontinuities (Bhatt, 1990; Matthews, 1981) . In PSbased accounts, the construction is represented by phrasal categories, and extraction is limited 1)3-\" bounding nodes (e.g., Haegeman (1994) , Becker et al. (1991) ). In dependency-based accounts, the construction is represented by the dependency relation, which is typed or labelled to indicate constructional distinctions which are configurationally defined in PSG. Given this correspondence, it is natural to employ dependencies in the description of discontinuities as follows: For each modifier, a set of dependency types is defined which may link the direct head and the positional head of the modifier (\"gesehen\" and \"hat\", respectively). If this set is empty, both heads are identical and a continuous attachment results. The impossibility of extraction from, e.g., a finite verb phrase follows from the fact that the dependency embedding finite verbs, propo, may not appear on any path 2Note that each phrasal level in PS-based trees defines a scope for linear precedence rules, which only apply to sister nodes. 32 between a direct and a positional head.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "From a descriptive viewpoint, the syntactic construction is often cited to determine the possibility and scope of discontinuities (Bhatt, 1990; Matthews, 1981) . ", "mid_sen": "In PSbased accounts, the construction is represented by phrasal categories, and extraction is limited 1)3-\" bounding nodes (e.g., Haegeman (1994) , Becker et al. (1991) ). ", "after_sen": "In dependency-based accounts, the construction is represented by the dependency relation, which is typed or labelled to indicate constructional distinctions which are configurationally defined in PSG. "}
{"citeStart": 190, "citeEnd": 205, "citeStartToken": 190, "citeEndToken": 205, "sectionName": "UNKNOWN SECTION NAME", "string": "Many natural language applications are beginning to exploit some underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990) , Grishman (1995) , and Hobbs et al. (1997) ) and Statistical Parsing (such as Charniak (1996) , Magerman (1995) , and Collins (1996) ). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. The idea underlying the approach is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (Supertags) that impose complex constraints in a local context. Supertag disambiguation is resolved \"Supported by NSF grants ~SBR-9710411 and ~GER-9354869 by using statistical distributions of supertag cooccurrences collected from a corpus of parses. It results in a representation that is effectively a parse (almost parse).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The need to impose structure leads to the need to have robust parsers. ", "mid_sen": "There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990) , Grishman (1995) , and Hobbs et al. (1997) ) and Statistical Parsing (such as Charniak (1996) , Magerman (1995) , and Collins (1996) ). ", "after_sen": "Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. "}
{"citeStart": 106, "citeEnd": 131, "citeStartToken": 106, "citeEndToken": 131, "sectionName": "UNKNOWN SECTION NAME", "string": "nique for efficient bottom-up evaluation of logic programs developed in the deductive database community (Ramakrishnan et al., 1992) . Given a logic program, Magic produces a new program in which the filtering as normally resulting from top-down evaluation is explicitly characterized through, so-called, *url: http://www.sfs.nphil.uni-tuebingen/'minnen magic predicates, which produce variable bindings for filtering when evaluated bottom-up. The original rules of the program are extended such that these bindings can be made effective.", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "nique for efficient bottom-up evaluation of logic programs developed in the deductive database community (Ramakrishnan et al., 1992) . ", "after_sen": "Given a logic program, Magic produces a new program in which the filtering as normally resulting from top-down evaluation is explicitly characterized through, so-called, *url: http://www.sfs.nphil.uni-tuebingen/'minnen magic predicates, which produce variable bindings for filtering when evaluated bottom-up. "}
{"citeStart": 124, "citeEnd": 145, "citeStartToken": 124, "citeEndToken": 145, "sectionName": "UNKNOWN SECTION NAME", "string": "Though pilot studies have been performed to make use of English corpora for subjectivity classification in other languages (Mihalcea et al., 2007; Banea et al., 2008) , the methods are very straightforward by directly employing an inductive classifier (e.g. SVM, NB), and the classification performance is far from satisfactory because of the language gap between the original language and the translated language.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Note that the above problem is not only defined for Chinese sentiment classification, but also for various sentiment analysis tasks in other different languages.", "mid_sen": "Though pilot studies have been performed to make use of English corpora for subjectivity classification in other languages (Mihalcea et al., 2007; Banea et al., 2008) , the methods are very straightforward by directly employing an inductive classifier (e.g. SVM, NB), and the classification performance is far from satisfactory because of the language gap between the original language and the translated language.", "after_sen": "In this study, we propose a co-training approach to improving the classification accuracy of polarity identification of Chinese product reviews. "}
{"citeStart": 119, "citeEnd": 139, "citeStartToken": 119, "citeEndToken": 139, "sectionName": "UNKNOWN SECTION NAME", "string": "This system has been deployed and tested using a subset of the resources provided by the UK Grid for Particle Physics (Britton et al., 2009) , part of the worldwide Grid of around 200000 CPU cores assembled to allow analysis of the petabyte-scale data volumes to be recorded each year by experiments at the Large Hadron Collider in Geneva. Processing of the FlyBase archive of around 15000 papers required about 8000 hours of CPU time, and has been successfully completed in about 3 days, with up to a few hundred jobs run in parallel. A distributed spider for collecting open-source PDF documents has also been developed. This has been run concurrently on over 2000 cores cores, and has been used to retrieve over 350000 subject-specific papers, but these are not considered in the present demo.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "To provide a scalable solution capable of analysing the entire STEM bibliome of over 20m electronic journal and conference papers, we have developed a robust system that can be used with a grid of computers running distributed job management software.", "mid_sen": "This system has been deployed and tested using a subset of the resources provided by the UK Grid for Particle Physics (Britton et al., 2009) , part of the worldwide Grid of around 200000 CPU cores assembled to allow analysis of the petabyte-scale data volumes to be recorded each year by experiments at the Large Hadron Collider in Geneva. ", "after_sen": "Processing of the FlyBase archive of around 15000 papers required about 8000 hours of CPU time, and has been successfully completed in about 3 days, with up to a few hundred jobs run in parallel. "}
{"citeStart": 263, "citeEnd": 275, "citeStartToken": 263, "citeEndToken": 275, "sectionName": "UNKNOWN SECTION NAME", "string": "While different schemes have been proposed for annotating citations according to their function (Spiegel-Rosing, 1977; Nanba and Okumura, 1999; Garzone and Mercer, 2000) , the only recent work on citation sentiment detection using a relatively large corpus is by Athar (2011) . However, this work does not handle citation context. Piao et al. (2007) proposed a system to attach sentiment information to the citation links between biomedical papers by using existing semantic lexical resources. A common approach for sentiment detection is to use a labelled lexicon to score sentences (Hatzivassiloglou and McKeown, 1997; Turney, 2002; Yu and Hatzivassiloglou, 2003) . However, such approaches have been found to be highly topic dependent (Engström, 2004; Gamon and Aue, 2005; Blitzer et al., 2007) . Teufel et al. (2006) worked on a 2,829 sentence citation corpus using a 12-class classification scheme. Although they used context in their annotation, their focus was on determining the author's reason for citing a given paper. This task differs from citation sentiment, which is in a sense a \"lower level\" of analysis.", "label": "Weakness", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "While different schemes have been proposed for annotating citations according to their function (Spiegel-Rosing, 1977; Nanba and Okumura, 1999; Garzone and Mercer, 2000) , the only recent work on citation sentiment detection using a relatively large corpus is by Athar (2011) . ", "after_sen": "However, this work does not handle citation context. "}
{"citeStart": 33, "citeEnd": 52, "citeStartToken": 33, "citeEndToken": 52, "sectionName": "UNKNOWN SECTION NAME", "string": "To overcome this limitation, in (Fang and Zhai, 2006) , we proposed a set of semantic term matching constraints and modified the previously derived axiomatic functions to make them satisfy these additional constraints. In particular, the primitive weighting function is generalized as", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "A limitation of the primitive weighting function described in Equation 1 is that it can not bridge vocabulary gaps between documents and queries.", "mid_sen": "To overcome this limitation, in (Fang and Zhai, 2006) , we proposed a set of semantic term matching constraints and modified the previously derived axiomatic functions to make them satisfy these additional constraints. ", "after_sen": "In particular, the primitive weighting function is generalized as"}
{"citeStart": 147, "citeEnd": 170, "citeStartToken": 147, "citeEndToken": 170, "sectionName": "UNKNOWN SECTION NAME", "string": "Kernel-based methods such as support vector machines (SVMs) consider feature combinations space-efficiently by using a polynomial kernel function (Cortes and Vapnik, 1995) . The kernelbased classification is, however, known to be very slow in NLP tasks, so efficient classifiers should sum up the weights of the explicit conjunctive features (Isozaki and Kazawa, 2002; Kudo and Matsumoto, 2003; Goldberg and Elhadad, 2008) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, 'explicit' feature combinations significantly increase the feature space, which slows down not only training but also testing of the classifier.", "mid_sen": "Kernel-based methods such as support vector machines (SVMs) consider feature combinations space-efficiently by using a polynomial kernel function (Cortes and Vapnik, 1995) . ", "after_sen": "The kernelbased classification is, however, known to be very slow in NLP tasks, so efficient classifiers should sum up the weights of the explicit conjunctive features (Isozaki and Kazawa, 2002; Kudo and Matsumoto, 2003; Goldberg and Elhadad, 2008) ."}
{"citeStart": 48, "citeEnd": 66, "citeStartToken": 48, "citeEndToken": 66, "sectionName": "UNKNOWN SECTION NAME", "string": "1 Introduction (Van Halteren et al., 1998) and (Brill and Wu, 1998) describe a series of successful experiments for improving the performance of part-of-speech taggers. Their results have been obtained by combining the output of different taggers with system combination techniques such as majority voting. This approach cancels errors that are made by the minority of the taggers. With the best voting technique, the combined results decrease the lowest error rate of the component taggers by as much as 19% (Van Halteren et al., 1998) . The fact that combination of classifiers leads to improved performance has been reported in a large body of machine learning work.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "1 Introduction (Van Halteren et al., 1998) and (Brill and Wu, 1998) describe a series of successful experiments for improving the performance of part-of-speech taggers. ", "after_sen": "Their results have been obtained by combining the output of different taggers with system combination techniques such as majority voting. "}
{"citeStart": 180, "citeEnd": 203, "citeStartToken": 180, "citeEndToken": 203, "sectionName": "UNKNOWN SECTION NAME", "string": "In the version of the algorithm that we have used, IBI-IG, the distances between feature representations are computed as the weighted sum of distances between individual features (Daeleroans et al., 1998) . Equal features are defined to have distance 0, while the distance between other pairs is some feature-dependent value. This value is equal to the information gain of the feature, an information theoretic measure which contains the Table 2 : Results first experiment series: the best F~=I scores for different left (L) and right (R) word/POS tag pair context sizes for the seven representation formats using 5-fold cross-validation on section 15 of the WSJ corpus.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In the testing phase the algorithm compares a feature representation of a test word with every training data item and chooses the classification of the training item which is closest to the test item.", "mid_sen": "In the version of the algorithm that we have used, IBI-IG, the distances between feature representations are computed as the weighted sum of distances between individual features (Daeleroans et al., 1998) . ", "after_sen": "Equal features are defined to have distance 0, while the distance between other pairs is some feature-dependent value. "}
{"citeStart": 40, "citeEnd": 62, "citeStartToken": 40, "citeEndToken": 62, "sectionName": "UNKNOWN SECTION NAME", "string": "We use the CLASSIFIEDS data provided by Grenager et al. (2005) and compare with results reported by HK06 (Haghighi and Klein, 2006) and CRR07 (Chang et al., 2007) . HK06 introduced a set of 33 features along with their majority labels, these are the primary set of additional constraints (Table 1) . As HK06 notes, these features are selected using statistics of the labeled data, and here we used similar features here in order to compare with previous results. Though in practice we have found that feature selection is often intuitive, recent work has experimented with automatic feature selection using LDA (Druck et al., 2008) . For some of the experiments we also use two sets of 33 additional features that we chose by the same method as HK06, the first 33 of which are also shown in Table 1 . We use the same tokenization of the dataset as HK06, and training/test/unsupervised sets of 100 instances each. This data differs slightly from the tokenization used by CRR07. In particular it lacks the newline breaks which might be a useful piece of information.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We use the CLASSIFIEDS data provided by Grenager et al. (2005) and compare with results reported by HK06 (Haghighi and Klein, 2006) and CRR07 (Chang et al., 2007) . ", "after_sen": "HK06 introduced a set of 33 features along with their majority labels, these are the primary set of additional constraints (Table 1) . "}
{"citeStart": 24, "citeEnd": 41, "citeStartToken": 24, "citeEndToken": 41, "sectionName": "UNKNOWN SECTION NAME", "string": "It is not a simple matter to compare results with previous work, due to differing evaluation techniques, data sets, and POS tag sets. With different data sets and training sizes, Habash and Rambow (2005) report 99.3% word accuracy on tokenization, and Diab et al. (2007) reports a score of 99.1%. Habash and Rambow (2005) reported 97.6% on the LDC-supplied reduced tag set, and Diab et al. (2007) reported 96.6%. The LDCsupplied tag set used is smaller than the one in this paper (24 tags), but does distinguish between NOUN and ADJ. However, both (Habash and Rambow, 2005; Diab et al., 2007) assume gold tokenization for evaluation of POS results, which we do not. The \"MorphPOS\" task in (Roth et al., 2008) , 96.4%, is somewhat similar to ours in that it scores on a \"core tag\", but unlike for us there is only one such tag for a source token (easier) but it distinguishes between NOUN and ADJ (harder).", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, both (Habash and Rambow, 2005; Diab et al., 2007) assume gold tokenization for evaluation of POS results, which we do not. ", "mid_sen": "The \"MorphPOS\" task in (Roth et al., 2008) , 96.4%, is somewhat similar to ours in that it scores on a \"core tag\", but unlike for us there is only one such tag for a source token (easier) but it distinguishes between NOUN and ADJ (harder).", "after_sen": "We would like to do a direct comparison by simply runing the above systems on the exact same data and evaluating them the same way. "}
{"citeStart": 84, "citeEnd": 104, "citeStartToken": 84, "citeEndToken": 104, "sectionName": "UNKNOWN SECTION NAME", "string": "Neither Kamp nor Kehler extend their copying/substitution mechanism to anything besides pronouns, as we have done. In Kehler's case, it is hard to see how his role assignment functions can be extended to deal with non-referential terms in the desired manner. DRT's use of discourse referents to indicate scope suggests that Kamp's treatment may be more readily extended in this manner; lists of discourse referents at the top of DRS boxes are highly reminiscent of the index lists in scope nodes. Figure 1 defines a valuation relation for the QLF fragment used above, derived from Cooper et al., 1994a) . If a QLF expression contains uninstantiated recta-variables, the valuation relation can associate more than one value with the expression. In the case of formulas, they may be given both the values true and false, corresponding to the formula being true under one possible resolution and false under another. A subsumption ordering over QLFS, ~, is employed in the evaluation rules, in effect to propose possible instantiations for meta-variables (the rule fragment only allows for scope meta-variables, but (Cooper et al., 1994a) describes the more general case where other kinds of meSa-variable are permitted). A partially instantiated QLF therefore effectively specifies a set of possible evaluations (or semantic compositions).", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "DRT's use of discourse referents to indicate scope suggests that Kamp's treatment may be more readily extended in this manner; lists of discourse referents at the top of DRS boxes are highly reminiscent of the index lists in scope nodes. ", "mid_sen": "Figure 1 defines a valuation relation for the QLF fragment used above, derived from Cooper et al., 1994a) . ", "after_sen": "If a QLF expression contains uninstantiated recta-variables, the valuation relation can associate more than one value with the expression. "}
{"citeStart": 4, "citeEnd": 35, "citeStartToken": 4, "citeEndToken": 35, "sectionName": "UNKNOWN SECTION NAME", "string": "Not all dialectometrists agree on the wisdom of delineating dialect areas. Sdguy (1973:18) insisted that the concept of dialect boundaries was meaningless, and his emphasis on the gradience of language similarity has been widely maintained. Bu't those who do look for firna dialect affiliations (such as Babitch and Ebobisse) use bottom-up agglomerative techniques. The two linguistically closest sites are grouped into one dialect, and thenceforth treated as a unit. The process continues recursively until all sites are grouped into one superdialect embracing the entire language area under consideration. This yields a binary tree. But Kaufman and Rousseeuw (1990:44) suggest that when the emphasis in a clustering problem is on the top-level clusters--here, finding the two main dialects--then such bottom-up methods, which can potentially introduce error at each of several steps, are less reliable than top-down partitioning methods. Perhaps past researchers have used inferior bottom-up techniques simply because the necessary algorithms are computationally more tractable. Comparing all possible pairs of sites is a O(N 2) problem, 1 whereas considering all possible two-way partitions of tile dialect area is 0(2 N).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "This yields a binary tree. ", "mid_sen": "But Kaufman and Rousseeuw (1990:44) suggest that when the emphasis in a clustering problem is on the top-level clusters--here, finding the two main dialects--then such bottom-up methods, which can potentially introduce error at each of several steps, are less reliable than top-down partitioning methods. ", "after_sen": "Perhaps past researchers have used inferior bottom-up techniques simply because the necessary algorithms are computationally more tractable. "}
{"citeStart": 57, "citeEnd": 79, "citeStartToken": 57, "citeEndToken": 79, "sectionName": "UNKNOWN SECTION NAME", "string": "In the SUM project we are investigating methods for generating flexible summaries of documents in the legal domain. Our methodology builds and extends the Teufel and Moens (Teufel and Moens, 2002) approach to automatic summarisation. The work we report on in this paper deals with judgments from the judicial branch of the House of Lords. We have completed a preliminary study using a small sample of judgment documents. We have hand-annotated the sentences in these documents and performed automatic linguistic processing in order to study the link between the argumentative role and linguistic features of a sentence. Our primary focus is on correlations between sentence type and verb group properties (e.g. tense, aspect). To this end, we have used state-ofthe-art NLP techniques to distinguish main and subordinate clauses and to find the tense and aspect features of the main verb in each sentence. In this paper we report on our NLP techniques and on the findings of our study. We discuss the implications for the summarisation system that we are in the process of developing.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "In the SUM project we are investigating methods for generating flexible summaries of documents in the legal domain. ", "mid_sen": "Our methodology builds and extends the Teufel and Moens (Teufel and Moens, 2002) approach to automatic summarisation. ", "after_sen": "The work we report on in this paper deals with judgments from the judicial branch of the House of Lords. "}
{"citeStart": 296, "citeEnd": 301, "citeStartToken": 296, "citeEndToken": 301, "sectionName": "UNKNOWN SECTION NAME", "string": "The BFP algorithm assumes that some other mech~ anism can structure both written texts and taskoriented dialogues into hierarchical segments. The present concern is not with whether there might be a grammar of discourse that determines this structure, or whether it is derived from the cues that cooperative speakers give hearers to aid in processing. Since centering is a local phenomenon and is intended to operate within a segment, we needed to deduce a segmental structure in order to analyse the data. Speaker's intentions, task structure, cue words like O.K. now.., intonational properties of utterances, coherence relations, the scoping of modal, operators, and mechanisms for shift'ing control between discourse participants have all been proposed as ways of determining discourse segmentation [Gro77, GS86, Rei85, PH87, HL87, Hob78, Hob85, Rob88, WS88] . Here, we use a combination of orthography, anaphora distribution, cue words and task structure. The rules are\"", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Since centering is a local phenomenon and is intended to operate within a segment, we needed to deduce a segmental structure in order to analyse the data. ", "mid_sen": "Speaker's intentions, task structure, cue words like O.K. now.., intonational properties of utterances, coherence relations, the scoping of modal, operators, and mechanisms for shift'ing control between discourse participants have all been proposed as ways of determining discourse segmentation [Gro77, GS86, Rei85, PH87, HL87, Hob78, Hob85, Rob88, WS88] . ", "after_sen": "Here, we use a combination of orthography, anaphora distribution, cue words and task structure. "}
{"citeStart": 124, "citeEnd": 125, "citeStartToken": 124, "citeEndToken": 125, "sectionName": "UNKNOWN SECTION NAME", "string": "The implementation of best-first search does not combine new itelns with the chart immediately, but makes use of an agenda [8] , on which new items are ordered in order of descending priority. The following is the algorithm for bottom-up bestfirst F, arley deduction. procedure prove( Goal): ", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "of an interpretation as probabilities: 1), so that the priority is equal to the maximal possible preference valne for the clause, s", "mid_sen": "The implementation of best-first search does not combine new itelns with the chart immediately, but makes use of an agenda [8] , on which new items are ordered in order of descending priority. ", "after_sen": "The following is the algorithm for bottom-up bestfirst F, arley deduction. "}
{"citeStart": 43, "citeEnd": 63, "citeStartToken": 43, "citeEndToken": 63, "sectionName": "UNKNOWN SECTION NAME", "string": "Previous work has examined applying models often used in MT to the paired corpus described above (Fleischman and Roy, 2006) . Recent work in automatic image annotation (Barnard et al., 2003; and natural language processing (Steyvers et al., 2004) , however, have demonstrated the advantages of using hierarchical Bayesian models for related tasks. In this work we follow closely the Author-Topic (AT) model (Steyvers et al., 2004) which is a generalization of Latent Dirichlet Allocation (LDA) (Blei et al., 2005) . 3 LDA is a technique that was developed to model the distribution of topics discussed in a large corpus of documents. The model assumes that every document is made up of a mixture of topics, and that each word in a document is generated from a probability distribution associated with one of those topics. The AT model generalizes LDA, saying that the mixture of topics is not dependent on the document itself, but rather on the authors who wrote it. According to this model, for each word (or phrase) in a document, an author is chosen uniformly from the set of the authors of the document. Then, a topic is chosen from a distribution of topics associated with that particular author. Finally, the word is generated from the distribution associated with that chosen topic. We can express the probability of the words in a document (W) given its authors (A) as:", "label": "Motivation", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Previous work has examined applying models often used in MT to the paired corpus described above (Fleischman and Roy, 2006) . ", "mid_sen": "Recent work in automatic image annotation (Barnard et al., 2003; and natural language processing (Steyvers et al., 2004) , however, have demonstrated the advantages of using hierarchical Bayesian models for related tasks. ", "after_sen": "In this work we follow closely the Author-Topic (AT) model (Steyvers et al., 2004) which is a generalization of Latent Dirichlet Allocation (LDA) (Blei et al., 2005) . "}
{"citeStart": 54, "citeEnd": 77, "citeStartToken": 54, "citeEndToken": 77, "sectionName": "UNKNOWN SECTION NAME", "string": "in this case with the iterated reading of the clause (Moens and Steedman 1988) .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "He was hiccupping (process).", "mid_sen": "in this case with the iterated reading of the clause (Moens and Steedman 1988) .", "after_sen": ""}
{"citeStart": 96, "citeEnd": 116, "citeStartToken": 96, "citeEndToken": 116, "sectionName": "UNKNOWN SECTION NAME", "string": "The line data was created by (Leacock et al., 1993) by tagging every occurrence of line in the ACL/DCI Wall Street Journal corpus and the American Printing House for the Blind corpus with one of six possible WordNet senses. These senses and their frequency distribution are shown in Table 1 . This data has since been used in studies by (Mooney, 1996) , (Towell and Voorhees, 1998) , and (Leacock et al., 1998) . In that work, as well as in this paper, a subset of the corpus is utilized such that each sense is uniformly distributed; this reduces the accuracy of the majority classifier to 17%. The uniform distribution is created by randomly sampling 349 sense-tagged examples from each sense, resulting in a training corpus of 2094 sense-tagged sentences.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "These senses and their frequency distribution are shown in Table 1 . ", "mid_sen": "This data has since been used in studies by (Mooney, 1996) , (Towell and Voorhees, 1998) , and (Leacock et al., 1998) . ", "after_sen": "In that work, as well as in this paper, a subset of the corpus is utilized such that each sense is uniformly distributed; this reduces the accuracy of the majority classifier to 17%. "}
{"citeStart": 273, "citeEnd": 287, "citeStartToken": 273, "citeEndToken": 287, "sectionName": "UNKNOWN SECTION NAME", "string": "This algorithm was first implemented for the MUC-6 FASTUS system (Appelt et al., 1995) , and produced one of the top scores (a recall of 59% and precision of 72%) in the MUC-6 Coreference Task, which evaluated systems' ability to recog-nize coreference among noun phrases (Sundheim, 1995) . Note that only identity of reference was evaluated there. 2", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "This algorithm was first implemented for the MUC-6 FASTUS system (Appelt et al., 1995) , and produced one of the top scores (a recall of 59% and precision of 72%) in the MUC-6 Coreference Task, which evaluated systems' ability to recog-nize coreference among noun phrases (Sundheim, 1995) . ", "after_sen": "Note that only identity of reference was evaluated there. "}
{"citeStart": 62, "citeEnd": 74, "citeStartToken": 62, "citeEndToken": 74, "sectionName": "UNKNOWN SECTION NAME", "string": "Our work is related to a large body of research on citations (Hodges, 1972; Garfield et al., 1984) . The interest in studying citations stems from the fact that bibliometric measures are commonly used to estimate the impact of a researcher's work (Borgman and Furner, 2002; Luukkonen, 1992) . White (2004) provides a good recent survey of the different research lines that use citations. In this section we review the research lines that are relevant to our work and show how our work is different.", "label": "Similar", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "Our work is related to a large body of research on citations (Hodges, 1972; Garfield et al., 1984) . ", "after_sen": "The interest in studying citations stems from the fact that bibliometric measures are commonly used to estimate the impact of a researcher's work (Borgman and Furner, 2002; Luukkonen, 1992) . "}
{"citeStart": 76, "citeEnd": 96, "citeStartToken": 76, "citeEndToken": 96, "sectionName": "UNKNOWN SECTION NAME", "string": "We had 8135 spurts available for training and testing, and performed two sets of experiments to evaluate the performance of our system. The tools used to perform the training are the same as those described in section 3.4. In the first set of experiments, we reproduced the experimental setting of (Hillard et al., 2003) , a three-way classification (BACKCHANNEL and OTHER are merged) using hand-labeled data of a single meeting as a test set and the remaining data as training material; for this experiment, we used the same training set as (Hillard et al., 2003) . Performance is reported in Table 6 . In the second set of experiments, we aimed at reducing the expected variance of our experimental results and performed N-fold cross-validation in a four-way classification task, at each step retaining the hand-labeled data of a meeting for testing and the rest of the data for training. Table 7 summarizes the performance of our classifier with the different feature sets in this classification task, distinguishing the case where the four label-dependency pragmatic features are available during decoding from the case where they are not. First, the analysis of our results shows that with our three local feature sets only, we obtain substantially better results than (Hillard et al., 2003) . This", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The tools used to perform the training are the same as those described in section 3.4. ", "mid_sen": "In the first set of experiments, we reproduced the experimental setting of (Hillard et al., 2003) , a three-way classification (BACKCHANNEL and OTHER are merged) using hand-labeled data of a single meeting as a test set and the remaining data as training material; for this experiment, we used the same training set as (Hillard et al., 2003) . ", "after_sen": "Performance is reported in Table 6 . "}
{"citeStart": 157, "citeEnd": 170, "citeStartToken": 157, "citeEndToken": 170, "sectionName": "UNKNOWN SECTION NAME", "string": "Magic compilation is illustrated on the basis of the simple logic grammar extract in figure 1. This grammar has been optimized automatically for generation (Minnen et al., 1996) : The right-hand sides of the rules are reordered such that a simple left-to-right evaluation order constitutes the optimal evaluation order. With this grammar a simple top-down generation strategy does not terminate as a result of the head recursion in rule 3. It is necessary to use memoization extended with an abstraction function and a subsumption check. Strict bottom-up generation is not attractive either as it is extremely inefficient: One is forced to generate all possible natural language expressions licensed by the grammar and subsequently check them against the start category. It is possible to make the process more efficient through excluding specific lexical entries with a semantic filter. The use of such a semantic filter in bottom-up evaluation requires the grammar to obey the semantic monotonicity constraint in order to ensure completeness (Shieber, 1988 ) (see below).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "It is possible to make the process more efficient through excluding specific lexical entries with a semantic filter. ", "mid_sen": "The use of such a semantic filter in bottom-up evaluation requires the grammar to obey the semantic monotonicity constraint in order to ensure completeness (Shieber, 1988 ) (see below).", "after_sen": "The 'magic-compiled grammar' in figure 2 is the result of applying the algorithm in the previous section to the head-recursive example grammar and subsequently performing two optimizations (Beeri and Ramakrishnan, 1991) : "}
{"citeStart": 85, "citeEnd": 102, "citeStartToken": 85, "citeEndToken": 102, "sectionName": "UNKNOWN SECTION NAME", "string": "Interestingly, there are conflicting conclusions about the usefulness of the statistical features in sentiment analysis tasks (Pang and Lee, 2008) . Pang et al. (2002) presents empirical results indicating that using term presence over term frequency is more effective in a data-driven sentiment classification task. Such a finding suggests that sentiment analysis may exploit different types of characteristics from the topical tasks, that, unlike fact-based text analysis tasks, repetition of terms does not imply a significance on the overall sentiment. On the other hand, Wiebe et al. (2004) have noted that hapax legomena (terms that only appear once in a collection of texts) are good signs for detecting subjectivity. Other works have also exploited rarely occurring terms for sentiment analysis tasks (Dave et al., 2003; Yang et al., 2006 ).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "On the other hand, Wiebe et al. (2004) have noted that hapax legomena (terms that only appear once in a collection of texts) are good signs for detecting subjectivity. ", "mid_sen": "Other works have also exploited rarely occurring terms for sentiment analysis tasks (Dave et al., 2003; Yang et al., 2006 ).", "after_sen": "The opinion retrieval task is a relatively recent issue that draws both the attention of IR and NLP communities. "}
{"citeStart": 89, "citeEnd": 117, "citeStartToken": 89, "citeEndToken": 117, "sectionName": "UNKNOWN SECTION NAME", "string": "Although exploration of the tradeoffs between generative and discriminative machine learning techniques is one of the aims of this work, our ultimate goal, however, is to build clinical systems that provide timely access to information essential to the patient treatment process. In truth, our crossvalidation experiments do not correspond to any meaningful naturally-occurring task-structured abstracts are, after all, already appropriately labeled. The true utility of content models is to structure abstracts that have no structure to begin with. Thus, our exploratory experiments in applying content models trained with structured RCTs on unstructured RCTs is a closer approximation of an extrinsically-valid measure of performance. Such a component would serve as the first stage of a clinical question answering system (Demner-Fushman and Lin, 2005) or summarization system (McKeown et al., 2003) . We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured. Table 3 (b) shows the effectiveness of our trained content models on abstracts that had no explicit structure to begin with. We can see that although classification accuracy is lower than that from our cross-validation experiments, performance is quite respectable. Thus, our hypothesis that unstructured abstracts are not qualitatively different from structured abstracts appears to be mostly valid.", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Thus, our exploratory experiments in applying content models trained with structured RCTs on unstructured RCTs is a closer approximation of an extrinsically-valid measure of performance. ", "mid_sen": "Such a component would serve as the first stage of a clinical question answering system (Demner-Fushman and Lin, 2005) or summarization system (McKeown et al., 2003) . ", "after_sen": "We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured. "}
{"citeStart": 1, "citeEnd": 20, "citeStartToken": 1, "citeEndToken": 20, "sectionName": "UNKNOWN SECTION NAME", "string": "(XTAG, 1998) describes a baseNP chunker built from training data by a technique called supertagging. The performance of the chunker was an improvement of the Ramshaw and Marcus results (Fz=I =92.4). (Mufioz et al., 1999) use SNOW, a network of linear units, for recognizing baseNP phrases 6We have applied majority voting of five data representations to the Ramshaw and Marcus data set without using lexical information and the results were: accuracy O: 97.60%, accuracy C: 98.10%, precision: 92.19%, recall: 91.53% and F~=I: 91.86. and SV phrases. They compare two data representations and report that a representation with bracket structures outperforms the IOB tagging representation introduced by (Ramshaw and Marcus, 1995) . SNoW reaches the best performance on this task (Fz=I =92.8).", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The performance of the chunker was an improvement of the Ramshaw and Marcus results (Fz=I =92.4). ", "mid_sen": "(Mufioz et al., 1999) use SNOW, a network of linear units, for recognizing baseNP phrases", "after_sen": "They compare two data representations and report that a representation with bracket structures outperforms the IOB tagging representation introduced by (Ramshaw and Marcus, 1995) . SNoW reaches the best performance on this task (Fz=I =92.8)."}
{"citeStart": 240, "citeEnd": 262, "citeStartToken": 240, "citeEndToken": 262, "sectionName": "UNKNOWN SECTION NAME", "string": "The reasoning behind this scheme is that a paper is the human-readable representation of a scientific investigation. Therefore, the goal of the annotation is to retrieve the content model of scientific investigations as reflected within scientific discourse. The hypothesis is that there is a set of core scientific concepts (CoreSC), which constitute the key components of a scientific investigation. CoreSCs consist of 11 concepts originating from the CISP (Core Information about Scientific Papers) meta-data (Soldatova & Liakata, 2007) , which are a subset of classes from the EXPO ontology for the description of scientific experiments (Soldatova & King, 2006 The CoreSC scheme (Liakata et al., 2010; Liakata et al., 2012) implements the abovementioned concepts as a 3-layered sentence-based annotation scheme. This means that each sentence in a document is assigned one of the 11 CoreSC concepts. The scheme also considers a layer designated to properties of the concepts (e.g. New Method vs Old Method) as well as identifiers which link instances of the same concept across sentences. A short definition of CoreSC categories and their properties can be found in Table 1 .", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The hypothesis is that there is a set of core scientific concepts (CoreSC), which constitute the key components of a scientific investigation. ", "mid_sen": "CoreSCs consist of 11 concepts originating from the CISP (Core Information about Scientific Papers) meta-data (Soldatova & Liakata, 2007) , which are a subset of classes from the EXPO ontology for the description of scientific experiments (Soldatova & King, 2006 The CoreSC scheme (Liakata et al., 2010; Liakata et al., 2012) implements the abovementioned concepts as a 3-layered sentence-based annotation scheme. ", "after_sen": "This means that each sentence in a document is assigned one of the 11 CoreSC concepts. "}
{"citeStart": 206, "citeEnd": 224, "citeStartToken": 206, "citeEndToken": 224, "sectionName": "UNKNOWN SECTION NAME", "string": "To train models using this information we use generalized expectation (GE) criteria. GE criteria are terms in a training objective function that assign scores to values of a model expectation. In particular we use a version of GE that prefers parameter settings in which certain model expectations are close to target distributions. Previous work has shown how to apply GE criteria to maximum entropy classifiers. In section 4, we extend GE criteria to semi-supervised learning of linear-chain conditional random fields, using conditional probability distributions of labels given features. To empirically evaluate this method we compare it with several competing methods for CRF training, including entropy regularization and expected gradient, showing that GE provides significant improvements. We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM (Haghighi and Klein, 2006) and HMMs trained with soft constraints (Chang et al., 2007) . Finally, in Section 5.3 we show that feature-labeling can lead to dramatic reductions in the annotation time that is required in order to achieve the same level of accuracy as traditional instance-labeling.", "label": "CoCoRes", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "To empirically evaluate this method we compare it with several competing methods for CRF training, including entropy regularization and expected gradient, showing that GE provides significant improvements. ", "mid_sen": "We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM (Haghighi and Klein, 2006) and HMMs trained with soft constraints (Chang et al., 2007) . ", "after_sen": "Finally, in Section 5.3 we show that feature-labeling can lead to dramatic reductions in the annotation time that is required in order to achieve the same level of accuracy as traditional instance-labeling."}
{"citeStart": 60, "citeEnd": 78, "citeStartToken": 60, "citeEndToken": 78, "sectionName": "UNKNOWN SECTION NAME", "string": "We adopt the definition of countability in English given in Allan (1980:541-3) .", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "", "mid_sen": "We adopt the definition of countability in English given in Allan (1980:541-3) .", "after_sen": "A countable noun phrase is defined as follows:"}
{"citeStart": 53, "citeEnd": 63, "citeStartToken": 53, "citeEndToken": 63, "sectionName": "UNKNOWN SECTION NAME", "string": "Lexical selection is the task of choosing target language words that accurately reflect the meaning of the corresponding source language words. It plays an important role in machine translation ( (Dorr, 1989) or interlingua (Nirenberg, 1987) . This engineering approach requires great effort in designing the representation and the mapping rules.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Lexical selection is the task of choosing target language words that accurately reflect the meaning of the corresponding source language words. ", "mid_sen": "It plays an important role in machine translation ( (Dorr, 1989) or interlingua (Nirenberg, 1987) . ", "after_sen": "This engineering approach requires great effort in designing the representation and the mapping rules."}
{"citeStart": 98, "citeEnd": 109, "citeStartToken": 98, "citeEndToken": 109, "sectionName": "UNKNOWN SECTION NAME", "string": "In the literature of norl-incremental generation, the need for defaults is hardly ever taken into account. The conunon point of view restricts the iulmt to be sulIicient for generation (see, e.g., the Te:ct Slructure by (Meteer, 1990 ) for a syntactic generator). In incremental gm,eration, most authors agree on the necessity of using defaults (see, e.g., (l)e Smedt, 1990; Kitano, 1990; Ward, 1991) ). Nevertheless, they do not in sufficient depth answer the question of how to guide the processes of default handling an(l repair wil;hin a generator. This I~roblem is the starting--point tbr the following considerations. We assume tlm.t generation is a decision-making process witll the aim o[' producing it phmsiMe ul:t(wance 1)ased on given information. As mentioned in section 1, there are cases where this I)rocess stops (caused by underspccifical.ioll of the input) before finishing its output.", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The conunon point of view restricts the iulmt to be sulIicient for generation (see, e.g., the Te:ct Slructure by (Meteer, 1990 ) for a syntactic generator). ", "mid_sen": "In incremental gm,eration, most authors agree on the necessity of using defaults (see, e.g., (l)e Smedt, 1990; Kitano, 1990; Ward, 1991) ). ", "after_sen": "Nevertheless, they do not in sufficient depth answer the question of how to guide the processes of default handling an(l repair wil;hin a generator. "}
{"citeStart": 170, "citeEnd": 190, "citeStartToken": 170, "citeEndToken": 190, "sectionName": "UNKNOWN SECTION NAME", "string": "We evaluate the extractive CoreSC summaries in terms of how well they enable 12 chemistry experts/evaluators (with at least a Masters degree in chemistry) to answer complex questions about the papers. Our test corpus consists of 28 papers held out from the ART/CoreSC corpus, roughly 1/9, which were annotated automatically with the SVM and CRF classifiers described in (Liakata et al., 2012) trained on the remaining 8/9 of the corpus. For each of the 28 papers in the test corpus, we generated CoreSC summaries automatically using the method described in section 3. We compare the performance of the experts on a question answering (Q-A) task when given the CoreSC summaries and two other types of summary, amounting to a total of three experimental conditions (A,B,C) . The other two types of summary are the original paper abstracts (summaries A), in the absence of human summaries, and summaries generated by Microsoft Office Word 2007 AutoSummarize (summaries B). Microsoft Office Word 2007 AutoSummarize (MA) is a widely available commercial system with reportedly good results (Garcia-Hernandez et al., 2009) and performance equivalent to TextRank (Mihalcea and Tarau, 2004) . MA works by assigning a score to each word in a sentence depending on its frequency in the document and sentences are ranked and extracted according to the combination of scores of the words they contain. MA therefore follows classic lexicalised text extraction techniques, is domain independent and is completely agnostic of the discourse. For the latter reason, we considered MA to be a suitable baseline the comparison with which would illustrate the effect of using CoreSC categories on the summary and the merits of having a discourse based model for summarisation.", "label": "Usage", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "We evaluate the extractive CoreSC summaries in terms of how well they enable 12 chemistry experts/evaluators (with at least a Masters degree in chemistry) to answer complex questions about the papers. ", "mid_sen": "Our test corpus consists of 28 papers held out from the ART/CoreSC corpus, roughly 1/9, which were annotated automatically with the SVM and CRF classifiers described in (Liakata et al., 2012) trained on the remaining 8/9 of the corpus. ", "after_sen": "For each of the 28 papers in the test corpus, we generated CoreSC summaries automatically using the method described in section 3. "}
{"citeStart": 175, "citeEnd": 186, "citeStartToken": 175, "citeEndToken": 186, "sectionName": "UNKNOWN SECTION NAME", "string": "Future work will involve testing our approach with higher-discrimination datasets, developing methods to pre-process review texts (e.g., improved negation tagging, and incorporating partof-speech tagging), and further addressing the problem of overfitting. To this effect we will investigate different feature selection algorithms, e.g., (Weston et al., 2003) , and their utilisation within the classifier trees. We also propose to consider aspects of reviews (Snyder and Barzilay, 2007) , and investigate other methods that measure class similarity, such as selecting typical instances (Zhang, 1992) .", "label": "Future", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "To this effect we will investigate different feature selection algorithms, e.g., (Weston et al., 2003) , and their utilisation within the classifier trees. ", "mid_sen": "We also propose to consider aspects of reviews (Snyder and Barzilay, 2007) , and investigate other methods that measure class similarity, such as selecting typical instances (Zhang, 1992) .", "after_sen": "The root node always considers all classes and therefore considers all features across the whole training dataset."}
{"citeStart": 107, "citeEnd": 126, "citeStartToken": 107, "citeEndToken": 126, "sectionName": "UNKNOWN SECTION NAME", "string": "The pseudo-likelihood estimator described in the last section finds parameter values which maximize the conditional probabilities of the observed parses (syntactic analyses) given the observed sentences (yields) in the training corpus. One of the empirical evaluation measures we use in the next section measures the number of correct parses selected from the set of all possible parses. This suggests another possible objective function: choose ~ to maximize the number Co (~) of times the maximum likelihood parse (under 0) is in fact the correct parse, in the training corpus. Co(~) is a highly discontinuous function of 0, and most conventional optimization algorithms perform poorly on it. We had the most success with a slightly modified version of the simulated annealing optimizer described in Press et al. (1992) . This procedure is much more computationally intensive than the gradient-based pseudo-likelihood procedure. Its computational difficulty grows (and the quality of solutions degrade) rapidly with the number of features.", "label": "Basis", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Co(~) is a highly discontinuous function of 0, and most conventional optimization algorithms perform poorly on it. ", "mid_sen": "We had the most success with a slightly modified version of the simulated annealing optimizer described in Press et al. (1992) . ", "after_sen": "This procedure is much more computationally intensive than the gradient-based pseudo-likelihood procedure. "}
{"citeStart": 36, "citeEnd": 55, "citeStartToken": 36, "citeEndToken": 55, "sectionName": "UNKNOWN SECTION NAME", "string": "We further optimized string recognition and plurality detection for handling citation-strings. See Table 3 for the full list of our features. While both (Soon et al., 2001) and (Ng and Cardie, 2002) induced decision trees (C5 and C4.5, respectively) we opted for using an SVM-based approach instead (Vapnik, 1998; Joachims, 1999) . SVMs are known for being reliable and having good performance.", "label": "CoCoGM", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "See Table 3 for the full list of our features. ", "mid_sen": "While both (Soon et al., 2001) and (Ng and Cardie, 2002) induced decision trees (C5 and C4.5, respectively) we opted for using an SVM-based approach instead (Vapnik, 1998; Joachims, 1999) . SVMs are known for being reliable and having good performance.", "after_sen": ""}
{"citeStart": 198, "citeEnd": 216, "citeStartToken": 198, "citeEndToken": 216, "sectionName": "UNKNOWN SECTION NAME", "string": "6.1.1 Experiment 1. Until now, translation models have been evaluated either subjectively (e.g. White and O'Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b) . Objective and more accurate tests can be carried out using a \"gold standard.\" I hired bilingual annotators to link roughly 16,000 corresponding words between on-line versions of the Bible in French and English. This bitext was selected to facilitate widespread use and standardization (see Melamed [1998c] for details). The entire Bible bitext comprised 29,614 verse pairs, of which 250 verse pairs were hand-linked using a specially developed annotation tool. The annotation style guide (Melamed 1998b ) was based on the intuitions of the annotators, so it was not biased towards any particular translation model. The annotation was replicated five times by seven different annotators.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "Certainly, more sophisticated word classification methods could produce better models, but even the simple classification in Table 4 should suffice to demonstrate the method's potential.", "mid_sen": "6.1.1 Experiment 1. Until now, translation models have been evaluated either subjectively (e.g. White and O'Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b) . ", "after_sen": "Objective and more accurate tests can be carried out using a \"gold standard.\" I hired bilingual annotators to link roughly 16,000 corresponding words between on-line versions of the Bible in French and English. "}
{"citeStart": 253, "citeEnd": 264, "citeStartToken": 253, "citeEndToken": 264, "sectionName": "UNKNOWN SECTION NAME", "string": "The implementation described in this paper is based on the most recent model, that of (Gorrell (in press) ). This model is interesting in that it does not allow the parser to employ delay tactics, such as using a lookahead buffer (Marcus (1980) , Marcus et al (1983) ), or waiting for the head of a phrase to appear in the input before constructing that phrase (Abney (1987 (Abney ( , 1989 , Pritehett (1992)). Instead, processing is guided by the principle of Incremental Licensing, which states that \"the parser attempts incrementally to satisfy the principles of grammar\". For the purposes of this implementation, I have interpreted this to mean that each word must be attached into a fullyconnected phrase marker as it is found in the input. 1 The psychological desirability of such a 1In fact, GorreU conjectures that, where there is insufficient grammatical information to postulate a structural relation between two constituents, such as in a sequence of two non-case marked NPs in an English centre-embedded construction, the parser may hold these constituents unstructured in its memory (in press, p.212). However, for the purposes of this implementation, we have taken the most constrained position. Note that, since we do not deal with such Full Attachment model has been argued for, especially with regard to the processing of headfinal languages, where evidence has been found of pre-head structuring (Inoue & Fodor (1991) , Frazier (1987) ). Such models have also been explored computationally (Milward (1995) , Crocker (1991) ).", "label": "Neutral", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "The implementation described in this paper is based on the most recent model, that of (Gorrell (in press) ). ", "mid_sen": "This model is interesting in that it does not allow the parser to employ delay tactics, such as using a lookahead buffer (Marcus (1980) , Marcus et al (1983) ), or waiting for the head of a phrase to appear in the input before constructing that phrase (Abney (1987 (Abney ( , 1989 , Pritehett (1992)). ", "after_sen": "Instead, processing is guided by the principle of Incremental Licensing, which states that \"the parser attempts incrementally to satisfy the principles of grammar\". "}
{"citeStart": 128, "citeEnd": 151, "citeStartToken": 128, "citeEndToken": 151, "sectionName": "UNKNOWN SECTION NAME", "string": "these subscript indices are redundant given the string positions of the constituents, which means we do not need to track the index u in L u and u R but can parse with just the two categories L and R, and determine the index from the constituent's span when required. It is straight-forward to extend the split-head CFG to encode the additional state information required by the head automata of Eisner and Satta (1999) ; this corresponds to splitting the non-terminals L u and u R. For simplicity we work with PBDGs in this paper, but all of the Unfold-Fold transformations described below extend to split-head grammars with the additional state structure required by head automata. Implementation note: it is possible to directly parse the \"undoubled\" input string w by modifying both the CKY algorithm and the CFGs described in this paper. Modify L u and u R so they both ultimately expand to the same terminal u, and specialcase the implementation of production X u → L u u R and all productions derived from it to permit L u and u R to overlap by the terminal u.", "label": "Support", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "these subscript indices are redundant given the string positions of the constituents, which means we do not need to track the index u in L u and u R but can parse with just the two categories L and R, and determine the index from the constituent's span when required. ", "mid_sen": "It is straight-forward to extend the split-head CFG to encode the additional state information required by the head automata of Eisner and Satta (1999) ; this corresponds to splitting the non-terminals L u and u R. ", "after_sen": "For simplicity we work with PBDGs in this paper, but all of the Unfold-Fold transformations described below extend to split-head grammars with the additional state structure required by head automata. "}
{"citeStart": 173, "citeEnd": 182, "citeStartToken": 173, "citeEndToken": 182, "sectionName": "UNKNOWN SECTION NAME", "string": "However, due to the lack of a tight definition for the concept of distributional similarity and the broad range of potential applications, a large number of measures of distributional similarity have been proposed or adopted (see Section 2). Previous work on the evaluation of distributional similarity methods tends to either compare sets of distributionally similar words to a manually created semantic resource (Lin, 1998; Curran and Moens, 2002) or be oriented towards a particular task such as language modelling (Dagan et al., 1999; Lee, 1999) . The first approach is not ideal since it assumes that the goal of distributional similarity methods is to predict semantic similarity and that the semantic resource used is a valid gold standard. Further, the second approach is clearly advantageous when one wishes to apply distributional similarity methods in a particular application area. However, it is not at all obvious that one universally best measure exists for all applications (Weeds and Weir, 2003) . Thus, applying a distributional similarity technique to a new application necessitates evaluating a large number of distributional similarity measures in addition to evaluating the new model or algorithm.", "label": "CoCoXY", "title": "UNKNOWN TITLE", "cited_title": "UNK CITED TITLE", "prev_sen": "However, due to the lack of a tight definition for the concept of distributional similarity and the broad range of potential applications, a large number of measures of distributional similarity have been proposed or adopted (see Section 2). ", "mid_sen": "Previous work on the evaluation of distributional similarity methods tends to either compare sets of distributionally similar words to a manually created semantic resource (Lin, 1998; Curran and Moens, 2002) or be oriented towards a particular task such as language modelling (Dagan et al., 1999; Lee, 1999) . ", "after_sen": "The first approach is not ideal since it assumes that the goal of distributional similarity methods is to predict semantic similarity and that the semantic resource used is a valid gold standard. "}
